[["index.html", "Statistics for Ecology Chapter 1 Introduction 1.1 Learning Objectives", " Statistics for Ecology Dr. Sara Souther Chapter 1 Introduction Welcome to our statistical exploration of the natural world! My goal is for you to develop an intuitive understanding of statistical analysis—how to choose the right test, understand its assumptions, visualize and interpret results, and communicate findings clearly in a report. By the end of this course, I hope you’ll feel confident tackling any analytical situation you encounter. Let’s get one thing out of the way early: we are not statisticians—whew! We are ecologists and social scientists. Our goal is not to master the theoretical mathematics behind statistics, but rather to apply statistical tools appropriately and thoughtfully. For this reason, we won’t spend much time on the underlying equations or proofs, but instead focus on practical application, critical interpretation, and making our data tell a clear story. For this reason, I will not spend much space describing the mathematical understanding of statistics! 1.1 Learning Objectives By the end of this course, you will be able to: • Select appropriate statistical tests based on the type of data (categorical, continuous, ordinal), the structure of your study design, and the research question being asked (e.g., comparing groups, testing relationships, evaluating change over time). • Properly run statistical analyses using R, including data cleaning, assumption checking, and the implementation of common tests such as t-tests, ANOVA, chi-squared tests, correlation, linear regression, and basic non-parametric alternatives. • Report and interpret statistical results in clear, publication-ready language. This includes summarizing findings with appropriate measures of central tendency and variation (mean, median, standard error), reporting test statistics and p-values, and interpreting both statistical and biological/social significance. • Visualize data effectively using plots and figures that aid interpretation and communicate key findings to scientific and non-scientific audiences. • Understand the assumptions behind common statistical methods and recognize when those assumptions are violated, along with strategies for addressing or adjusting for these issues. • Develop confidence and critical thinking in applying statistical tools to real-world ecological and social science data, with a focus on transparency, reproducibility, and responsible data use. "],["why-statistics.html", "Chapter 2 Why Statistics?", " Chapter 2 Why Statistics? "],["back-to-the-basics.html", "Chapter 3 Back to the basics 3.1 What can statistics tell us? 3.2 The Frequentist Framework 3.3 Bayesian statistics 3.4 Data Types and Why They Matter 3.5 Linking Data Types to Distributions 3.6 Overview of Common Statistical Distributions 3.7 What is a model? 3.8 Key takeaways 3.9 Test your knowledge! 3.10 Assignment", " Chapter 3 Back to the basics 3.1 What can statistics tell us? Almost all statistical analysis boils down to answering one of two questions: 1. Do these groups differ? 2. Is there a relationship between these variables? These seem like simple questions — in theory you might just “look at the data” to answer the questions — so why do we need statistics? The short answer is: error and sampling. Whenever we collect data, we introduce error: – our instruments have limits – humans make mistakes – environmental conditions vary – biological systems are inherently noisy And we are always measuring a subset of the true population. Even when we try to measure every individual (e.g., rare plant censuses), some individuals may be dormant, hidden, or unreachable. If we were omniscient, we would simply compute the true population parameters (mean, variance, etc.), compare them directly, and skip statistics entirely. But in the real world, we estimate these values from samples and quantify the uncertainty around them. Statistics is practical: it asks, what can we say given imperfect measurements, small samples, and noisy biological systems? 3.2 The Frequentist Framework The statistics we use most commonly in ecology — t-tests, ANOVA, linear models, GLMs, mixed models — are all built within the frequentist or parametric framework. Frequentist statistics assumes: 1. There is a true but unknown parameter The population mean, variance, slope, etc. are fixed constants — but we don’t know their values. 2. Your sample is one of many possible samples you could have taken If you collected data again under the same conditions, you’d get a different sample and different estimates. 3. Variation in your estimates comes from sampling error The parameter does not vary — you vary because you sampled imperfectly. Uncertainty is therefore in the estimator, not the parameter. 4. Probability statements describe long-run frequencies of repeated sampling For example: A 95% confidence interval contains the true parameter in 95% of hypothetical repeated samples. It does not mean “there is a 95% chance the true mean is in this interval.” What does “parametric” mean? Parametric tests assume the data follow a particular probability distribution (e.g., normal, Poisson, binomial). These assumptions influence: which model we choose how we estimate uncertainty what kinds of inferences we can make If you understand distributions, you understand why models behave the way they do. 3.3 Bayesian statistics The main alternative statistical framework to frequentist or parameteric statistics is Bayesian statistics. Bayesian statistics is based on Bayes’ Theorem, which provides a mathematical way to update our beliefs in light of new data. In this framework, we start with a prior distribution representing what we believe about a parameter before collecting data. We then combine this prior with the likelihood (the information contained in the data) to obtain a posterior distribution, which reflects our updated beliefs after seeing the evidence. This allows us to make intuitive probability statements about parameters—such as the probability that a parameter lies within a certain range—and provides a flexible foundation for modeling uncertainty, especially in hierarchical and ecological systems. We (and most other ecologist) will learn frequentist methods first, because: Most classical ecological statistics (t-tests, ANOVA, GLMs) use the frequentist framework. Frequentist thinking aligns with standard experimental design. Historically, Bayesian methods were computationally difficult. Most journals still expect p-values and confidence intervals. 3.3.1 When might you choose Bayesian statistics? Although we begin with frequentist methods for their simplicity and historical use in ecology, there are many situations where Bayesian approaches offer clear advantages. Ecologists often choose Bayesian statistics when: Data are sparse, noisy, or imbalanced. Bayesian priors help stabilize estimates when sample sizes are small or data contain many zeros (common in rare species monitoring or demographic studies). Hierarchical or multilevel structure is important. Many ecological datasets have natural grouping—plots within sites, individuals within populations, years within climate regimes. Bayesian methods handle hierarchical models gracefully and provide full uncertainty estimates for every level.You want to incorporate prior information. In wildlife ecology, population modeling, or long-term monitoring, previous studies often contain valuable information that can inform current estimates. Priors allow you to formally combine past research with new data. You care more about parameter uncertainty than about p-values. Bayesian posterior distributions provide intuitive quantities such as: “There is a 94% probability that survival increased after treatment.” This is often more interpretable than a traditional p-value. Models are too complex for frequentist methods.Nonlinear state–space models, integrated population models, hierarchical occupancy models, and many SDM frameworks are more stable and easier to fit using Bayesian tools like Stan, JAGS, or NIMBLE. You need robust propagation of uncertainty. Bayesian methods naturally propagate uncertainty across multiple model components, which is critical for forecasting, resilience modeling, and structured decision making. In short, Bayesian statistics shines when ecological questions involve complex models, low sample sizes, hierarchical structure, prior knowledge, or full uncertainty estimation. 3.4 Data Types and Why They Matter Before we analyze or visualize anything, we need to understand data types, because the type of data determines the probability distribution, which determines the statistical test. Data type → Distribution → Model choice Categorical variables are non-numeric variables. Examples: Pet type (dog, cat, fish, bird), Size (small, medium, large), Car type (sedan, SUV), Present/Absent Numerical variables are variables that are numbers, and occur in two forms: *Discrete = Counts of things (no decimal points/fractions) Data are discrete when it does not make sense to have a partial number of the variable. For instance, if counting the number of insects in a pond, it does not make sense to count a half a species. Examples: Number of people in a building, number of trees in a plot, number of bugs in a pond *Continuous = Numerical data that can occur at any value. These are variables that can occur in any quantity. If you can have a fraction of this variable, it is continuous. Examples = Height, Weight, Length Ordinal variables (sometimes referred to as ranked) can be categorical or numerical, but the order matters. Examples = Grades (A, B, C, D, E), Likert scale variables (Strongly disagree, Agree, Strongly Agree), Class rank (1, 2, 3, 4, 5) 3.5 Linking Data Types to Distributions In statistics, a distribution describes how likely different values are to occur. We choose a distribution, because different types of ecological data arise from different underlying processes. Here, is a reference table of common statistical distribution and the associated statistical test: Data Type Distribution (GLM Family) Common Link Function Example Ecological Question Typical Tests / Models Continuous Normal (Gaussian) Identity Do burned plots have taller seedlings than unburned plots? t-test, ANOVA, Linear Regression, Gaussian GLM, LMM Continuous (positive-only, skewed) Gamma Log Does fertilizer increase biomass (always &gt; 0)? Gamma GLM, Gamma GLMM Continuous (bounded 0–1) Beta (for proportions not from counts) Logit / log–log What proportion of cover is bare soil? Beta regression, Beta GLMM Counts (integers ≥ 0) Poisson Log Does precipitation influence the number of pitfall-trapped insects? Poisson GLM, Poisson GLMM Counts with overdispersion Negative Binomial Log Does nutrient addition affect flower counts when variance &gt; mean? Negative Binomial GLM, NB GLMM Counts with many zeros Zero-inflated Poisson / Zero-inflated NB Log Do invasive grasses produce many zero seedling counts? ZIP / ZINB models, hurdle models Binary outcomes (0/1) Binomial (Bernoulli) Logit / probit Does shade increase the probability that a seedling survives? Logistic regression, Binomial GLM, Binomial GLMM Proportions from counts (successes/n) Binomial Logit What proportion of seeds germinate in each treatment? Binomial GLM, Logistic regression Categorical (unordered) Multinomial Logit Do grazing treatments differ in vegetation type frequencies? Multinomial logistic regression, Chi-square Ordinal (ordered categories) Ordinal logistic (cumulative link) Logit / probit / complementary log–log Does grazing intensity affect seedling vigor ranks? Proportional odds models (CLM/CLMM) Time-to-event data Exponential / Weibull / Survival models Log (depends on model) How long do seedlings survive under drought vs irrigation? Survival analysis, Cox regression Nonlinear continuous response Non-normal, unknown Identity or specialized Is the relationship between age and growth curved? GAM, GAMM | We will apply statistics later in later chapters, but let’s check out some common statistical distributions! 3.6 Overview of Common Statistical Distributions 3.6.1 The Normal Distribution This is the classic bell-shaped distribution! The Normal distribution arises from the Central Limit Theorem, which states that when many small, independent factors add together (growth, genetics, microclimate, measurement error), their sum tends to be normally distributed. Ecological examples: Height of Asclepias seedlings Tree diameter (DBH) Leaf nitrogen content Continuous traits affected by many genes Check out the distribution: set.seed(1) heights &lt;- rnorm(1000, mean = 10, sd = 2) hist(heights, breaks = 20, col = &quot;lightblue&quot;, main = &quot;Simulated Normal Distribution&quot;, xlab = &quot;Height (cm)&quot;) 3.6.2 The Binomial Distribution: Outcomes are “success” or “failure” The binomial distribution arises when: 1. There are two possible outcomes (success/failure). 2. Each trial has the same probability of success. 3. You repeat the trial n times. Example: flipping a biased coin 10 times. Ecological examples: Seed germination (germinated / not) Survival (alive / dead) Flowering (reproductive / not) Presence/absence at survey points Check out the distribution: set.seed(1) germination &lt;- rbinom(1000, size = 10, prob = 0.6) hist(germination, breaks = 10, col = &quot;lightgreen&quot;, main = &quot;Simulated Binomial Distribution&quot;, xlab = &quot;Number of seeds germinated (out of 10)&quot;) 3.6.3 The Poisson Distribution: Counts from random events The Poisson distribution arises when: 1. Events happen independently 2. With a constant average rate 3. Over a fixed time or space 4. And events can occur 0, 1, 2, 3… times It often appears in ecology because many biological events behave like “random arrivals.” Ecological examples: Number of flowers on a plant Number of birds detected per point survey Number of insects in a pitfall trap Seedling recruitment counts In a true Poisson process: mean = variance If variance &gt;&gt; mean → overdispersion → use Negative Binomial, not Poisson. Check out the distribution: set.seed(1) flower_counts &lt;- rpois(1000, lambda = 4) hist(flower_counts, breaks = 15, col = &quot;salmon&quot;, main = &quot;Simulated Poisson Distribution&quot;, xlab = &quot;Number of flowers&quot;) 3.6.4 The Negative Binomial Distribution: Overdispersed counts Where it comes from When data are “count-like” but more variable than a Poisson model allows, they are overdispersed. This often happens when: Individuals vary in productivity (e.g., some plants are “super reproducers”) There is clustering (patchy distributions) Rates vary in space/time Ecological examples: Insect counts in patchy habitat Flower counts with many zeros Seed production with strong individual differences Check out the distribution: set.seed(1) nb_counts &lt;- rnbinom(1000, size = 2, mu = 4) hist(nb_counts, breaks = 15, col = &quot;tan&quot;, main = &quot;Simulated Negative Binomial Distribution&quot;, xlab = &quot;Count&quot;) 3.6.5 The Uniform Distribution: All values equally likely This distribution arises when every value in a range has equal probability. Relatively rare but useful for: Simulating randomness Creating null models Generating starting conditions for stochastic models Check out the distribution: set.seed(1) uniform_vals &lt;- runif(1000, min = 0, max = 1) hist(uniform_vals, breaks = 20, col = &quot;gray&quot;, main = &quot;Simulated Uniform Distribution&quot;, xlab = &quot;Value&quot;) 3.7 What is a model? A statistical model is a mathematical expression that describes how a response variable changes as a function of one or more predictors. All the models we will use in this course follow the same structure: Response = Deterministic component + Random variation The deterministic component represents the systematic pattern we want to explain (e.g., how plant height changes with grazing treatment or soil moisture). The random variation represents the noise or uncertainty that remains after accounting for the predictors, and it follows one of the probability distributions we learned earlier. In later chapters, we will learn how to build these models and interpret what they tell us about ecological patterns and processes. 3.8 Key takeaways Different kinds of data follow different probability distributions. Those distributions determine which statistical models we use. You don’t need to memorize distributions — you just need to recognize the data type. Everything in this course builds on this foundation. 3.9 Test your knowledge! Answer the following questions: Part 1 — Why We Use Statistics In your own words, why do we need statistics in ecology? Name at least two sources of variation or uncertainty that make statistics necessary. Explain the difference between a population and a sample. Why do we rarely observe entire populations in ecological studies? What are the two main questions most statistical analyses attempt to answer? Part 2 — Frequentist Thinking Fill in the blank: In the frequentist framework, parameters (such as the true mean height of a plant population) are considered _______ but _______. What does a 95% confidence interval mean in frequentist statistics? Choose the correct statement: There is a 95% probability that the true mean lies in this specific interval. If we repeated our sampling many times, 95% of the intervals we calculate would contain the true mean. The data contain 95% of the true values. In frequentist statistics, uncertainty comes from: The parameter being uncertain Variation in the estimator due to sampling The prior distribution (circle all that apply) Part 3 — Data Types and Distributions Identify the data type (categorical, continuous, discrete, ordinal) for each of the following variables: Number of acorns produced by a tree Grazing treatment (ungrazed, low, high) Plant height in centimeters Likert scale: “Strongly disagree” → “Strongly agree” Match each variable to its likely statistical distribution (Normal, Poisson, Binomial, Negative Binomial, Beta, Ordinal logistic): Presence/absence of a species at a site Number of insects caught in a pitfall trap Proportion of ground covered by bare soil Flower count with many zeros Seedling height Seedling health score (poor, fair, good, excellent) Which distribution assumes mean = variance? What does it mean if the variance is much larger than the mean? Part 4 — Understanding Distributions Briefly describe why the Normal distribution is common in biological systems. (Hint: many small factors…) What ecological process might produce Poisson-distributed data? Give a real example. What is the key characteristic of the Binomial distribution? Why is it appropriate for germination data? Under what ecological conditions might you expect a Negative Binomial distribution instead of a Poisson? Part 5 — Short Model Concept Fill in the blanks: A statistical model can be written as: Response = ______ + ______ In this expression, what does the “deterministic component” represent? What does the “random variation” represent? Part 6 — Reflection Question Write 2–3 sentences about one concept from this chapter that felt intuitive and one that felt confusing. What would help clarify the confusing part? 3.10 Assignment Make a list of the response variables that you plan to measure for your project, the associated data type, and the most appropriate error distribution. "],["randomness-and-probability.html", "Chapter 4 Randomness and probability 4.1 The sample point method 4.2 Combinatorials 4.3 Union and intersection of events 4.4 Conditional probability 4.5 Multiplicative Law of Probability of Independent Events 4.6 Additive Law of Probability of Mutually Exclusive Events 4.7 General Additive Law of Probability 4.8 Key concepts 4.9 Practice problems", " Chapter 4 Randomness and probability Randomness is statistically a simple concept with incredible repercussions for understanding natural systems, human decisions, and, well, life! One of the most interesting panels that I attended as a graduate student was a debate between scientific and religious philosophers over the meaning of randomness. There were a range of viewpoints; the theologian believed that randomness was where the divine could work; at the other extreme, the science philosopher believed that there is no such thing as random, only that we haven’t developed the capacity to measure what we perceive as random, and that everything we experience is a deterministic outcome of physics manifest in the world around us. As I write this lesson, I’m sitting on the couch with my younger child watching Jurassic Park. Ian Malcolm has just introduced himself as a ‘chaotician’ (he he). Chaos theory is one way to explain what appears to us as ‘randomness’, because small initial differences in conditions of complex systems leads to extremely different end states, even when the same deterministic rules apply to that system. The ‘butterfly effect’ (a butterfly flaps its wings in Asia causes a tornado in Texas) is often used to describe this core concept of chaos (the example originally created by Edward Norton Lorenz used a seagull instead of a butterfly). Chaos theory is incorporated into modeling simulations (particularly in population biology). In statistics, we have specific definition of randomness: The case when each item in a set has an equal probably of being selected. Statistics also acknowledges unexplained variation in nature, but doesn’t distinguish between true randomness or the inability to perfectly measure all variables explaining an observed phenomenon. Instead, all unpredictability is lumped together. The difference between the true value of an estimate (e.g., mean hieght of giraffes, slope describing the relationship between snail shell length and speed) and the observed estimate is called ‘error’. We use statistical models to parse ‘error’ (unexplained variation in the response variable) from treatment effects (variation in the response variable explained by the explanatory variables). [Add info on random effects here or introduce later?] Statistical error can arise for several reasons: random variation inherent to natural systems, mistakes during measurement or data collection, inaccuracy of measuring devices, omitted variables. As long as this error isn’t ‘systematic’, we accept that it is there, complete statistical analysis and move-on. However, systematic error, whenever you are directionally biasing your sample, or biasing your sampling in the same way, is something to be avoided when designing your experiment and collecting data. An example of a systematic measure would be if you are trying to estimate the mean weight of blue morpho butterflies in southern Brazil, and you never zero your balance. The true mean weight is lower than the mean weight that you calculate. Since randomness is inherent, we need to calculate the probability that we Our ability to say that an observed effect is statistically significant is based on probability: the proportion of times an event occurs in repeated trials or more generally , the quantitative measure of one’s belief in the occurrence of a future event. In other words, when conducting a statistical analysis, we need to be able to determine the likelihood that two or more groups differ by chance, or that an observed a relationship occurred by chance. Remember that probabilities vary between 0 and 1, with 0 indicating no chance of an event occurring and 1 indicating a 100% chance of an event occurring. Because statistics relies so heavily on probability, let’s review some basic concepts. Prepare yourself for lots of focus on ‘true coins’ (coins that have the equal likelihood have being heads or tails) and dice! Rolling dice and flipping coins are random events, and we will use them to look at predictability! [When to introduce Bayesian vs Frequentist concepts?] 4.1 The sample point method The sample point method is one method of determining the likelihood of an event, and entails the following steps: Define the sample space, S, by listing all possible outcomes of the ‘experiment’ or ‘trial’ you are conducting. Assign probabilities to all sample points, Pi, such that the probability of all events within the experiment tally to 1. Sum all sample points that constitute the outcome you are interested in to find the probability of that outcome. Let’s practice this concept with an example. Let’s calculate the probability of getting two heads in three tosses of a fair coin. library(readr) url &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1KDvCzj9-YzN1zDHdLutcpruYx5mpcEWH&quot; example1 &lt;- read_csv(url) ## Rows: 8 Columns: 6 ## ── Column specification ───────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): Toss1, Toss2, Toss3, Abbreviated ## dbl (2): Outcome, Probability ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. knitr::kable(example1, caption=&quot;Sample Space&quot;, full_width = F, html_font = &quot;Arial&quot;) Table 4.1: Sample Space Outcome Toss1 Toss2 Toss3 Abbreviated Probability 1 Heads Heads Heads HHH 0.125 2 Heads Heads Tails HHT 0.125 3 Heads Tails Heads HTH 0.125 4 Tails Heads Heads THH 0.125 5 Tails Tails Heads TTH 0.125 6 Tails Heads Tails THT 0.125 7 Heads Tails Tails HTT 0.125 8 Tails Tails Tails TTT 0.125 The first step is to define the sample space for this experiment, by showing all possible outcomes of tossing a coin 3 times, as we have done in the table, called ‘Sample Space’. Since this is a fair or balanced coin, all of the outcomes are equally likely, so we assign them a probability of 1/8. Then, we can simply sum the runs that meet our criterion of 2 heads (HHT, HTH, THH): 1/8 + 1/8 + 1/8 = 0.375. The equation of an event occurring (A) is: \\(P(A) =\\frac{n_a}{N}\\) where P(A) is the probability of event A equals the number of points constituting event A (\\(n_a\\)) divided by the total number of sample points (N). Applying this equation to the above example, P(A) = \\(\\frac{3}{8} = 0.375\\) 4.2 Combinatorials Because defining the sample space can be cumbersome for larger sample spaces, we can use combinatorial math, specifically the mn rule, to calculate sample space! The mn rule simply states that if one group contains m elements and another group contains n elements, you can for m x n pairs containing an element from each group. For instance, if we were determining the sample space for outcomes of rolling 2, 6-sided dice, we could multiply 6 x 6 (or \\(6^2\\)). Using the equation for calculating the probability of an event, what is the probability of rolling double 6s? answer = 1/36; answer ## [1] 0.02777778 Let’s try another example with even larger sample space: Calculate the probability of each person in a class of 14 students has a different birthday. In this case, a sample point consists of 14 dates, since there are 14 different students. Assuming that each student has the same probability of being born on any one of 365 days (over course in the real world the likelihood of being born on particular dates differs). The total number of sample points is \\(N = 365^{14}\\) (i.e., there are 365 possible birthdays for Student 1, 365 possible birthdays for student 2, yielding 716835279219613000000000000000000000 possible combinations of b-days). To calculate the probability that each student has a different birthday, you would apply the same equation as above, but calculate the number of points to satisfy our event, keeping in mind that there are 365 birthdays possible for Student 1, 264 possible birthdays for Student 2, 263 possible birthdays for Student 3, and so on, as: P(A) = \\(\\frac{n_a}{N} = \\frac{365 \\times 364 \\times 363 \\dots \\times 352}{365^{14}}=0.7769\\) Sample points can be represented as sequences of numbers or symbols. An ordered arrangement of of distinct objects is called a permutation. We can calculate the sample space as total number of distinct ways of arranging these symbols or numbers in a sequence, using the following equation: \\(P_r^n = n(n-1)(n-2)\\dots(n-r+1) = \\frac{n!}{(n-r)!}\\) where \\(n! = n \\times (n-1) \\times (n-2) \\times\\dots\\times2\\times1\\), where the total number of ordering \\(n\\) objects taken \\(r\\) at a time. #factorial of 5 or 5! factorial &lt;- 5*4*3*2*1; factorial ## [1] 120 factorialR &lt;- factorial(5); factorialR ## [1] 120 #remember that factorial(0) ## [1] 1 Let’s apply this equation: How many trinucleotide sequences can be formed without repeating a nucleotide? To put this another way, we ar interested in the number of ways of ordering \\(n = 4\\) elements (A, T, C, and G) taken 3 at a time (trinucleotide = 3; \\(r = 3\\)). permutations = (factorial(4))/factorial(4-3); permutations ## [1] 24 When the sequence is not important, we use a different formula. For unordered sets of r elements chosen without replacement from n available elements are called combinations, with total number of combinations calculated as: \\(C^n_r = \\frac{n!}{r!(n-r)!}\\) What are the number of combinations of 2 colors of m&amp;ms that we can select out of the 5 total colors? combinations = (factorial(5))/(factorial(2)*factorial(5-2)); combinations ## [1] 10 If it’s helpful, you can test the answer by hand, using these colors: tan, brown, orange, red, and green. Again, the basic concepts of the sample-point method, are to define sample space, and either assign probabilities to all sample points, then sum the probabilities OR calculate \\(P(A) =\\frac{n_a}{N}\\) where P(A) is the probability of event A equals the number of points constituting event A (\\(n_a\\)) divided by the total number of sample points (N). Note: these are the same equation, they only differ in terms of when you calculate the probability (of the points individually, or at the end after you define the sample space / and event number). When sample space is large, it is easier to use combinatorial math to calculate the points and the sample space. Let’s apply this understanding of probability to calculate the likelihood of two events occurring. 4.3 Union and intersection of events You might be gleaning that defining the appropriate sample space is critically important to correctly calculate probabilities of particular events occurring. Also important is the understanding relationship between events of interest for which we calculate probabilities. These concepts are also important for understanding Boolean operators, computer coding concepts, and modeling. Note: Boolean operators form the basis of mathematical sets and database logic. They connect your search words together to either narrow or broaden your set of results. The three basic boolean operators are: AND, OR, and NOT. (I copied and pasted this from the internet, should rewrite a bit - this is just taking a while) Union of events Union of events: What is the likelihood of both events A and B (this can be written as \\(A \\cup B\\))? contains all sampling points for A or B. Example calculating probability of union event: What is the likelihood of rolling an odd number (Event A) on a 6-side fair die OR that is less than 4 (Event B)? Event A = 1, 3, 5 Event B = 1, 2, 3 #The sample space is all possible rolls samplespace &lt;- c(1, 2, 3, 4, 5, 6); samplespace ## [1] 1 2 3 4 5 6 #We will use Boolean operators in R. They will return TRUE / FALSE statements. #Below we tell R to look for odd numbers OR (indicated by line) #numbers less than 4. unionevent &lt;- (samplespace%%2==1) | (samplespace &lt; 4); unionevent ## [1] TRUE TRUE TRUE FALSE TRUE FALSE #If the conditions are satisfied, TRUE will be returned. #If conditions are not met, FALSE will be returned. #Now, let&#39;s calculate the probability using techniques that you #have already seen above. probunion &lt;- 4/6; probunion ## [1] 0.6666667 Intersection of events Intersection of events: What is the likelihood of both events A and B (this can be written as \\(A \\cap B\\))? contains all sampling points for A and B. Example calculating probability of an intersection event: What is the likelihood of rolling an odd number (Event A) on a 6-side fair die AND that is less than 4 (Event B)? Event A = 1, 3, 5 Event B = 1, 2, 3 #The sample space is all possible rolls samplespace &lt;- c(1, 2, 3, 4, 5, 6); samplespace ## [1] 1 2 3 4 5 6 #We will use Boolean operators in R. They will return TRUE / FALSE statements. #Below we tell R to look for odd numbers OR (indicated by line) #numbers less than 4. intersectionevent &lt;- (samplespace%%2==1) &amp; (samplespace &lt; 4); intersectionevent ## [1] TRUE FALSE TRUE FALSE FALSE FALSE #If the conditions are satisfied, TRUE will be returned. #If conditions are not met, FALSE will be returned. #Now, let&#39;s calculate the probability using techniques that you #have already seen above. probintersection &lt;- 2/6; probintersection ## [1] 0.3333333 #Just for fun #The other common Boolean operator used in computer code is &#39;not&#39; #We want to roll any number except 2 nottwo &lt;- samplespace != 2; nottwo ## [1] TRUE FALSE TRUE TRUE TRUE TRUE probNOTtwo &lt;- 5/6; probNOTtwo ## [1] 0.8333333 4.4 Conditional probability Conditional probability indicates a situation when the probability of one event depends on the occurrence of another event. Conditional probability (written as P(A|B), and read as the probability of event A given B) is calculated with the following equation: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\) where \\(A \\cap B\\) indicates the probability of both event A and event B occurring. Example: I roll a die and ask you to guess the number. I want to increase your odds of guessing the correct number, so I tell you that the number is odd. You are going to guess the number 3 - What are your odd of guessing the correct number (odds that the answer is 3; event A) given that the result is an odd number (the answer is an odd number; event B)? To break this down, the probability of both A and B being true (\\(A \\cap B\\)) is 1/6. The likelihood of the roll being a 3 is the limiting factor in essence, so an ‘and’ probability is constrained by the least likely event. Then, we divide 1/6 by the probability of the roll being odd, which is 1/2 since there are 3 odd and 3 even numbers. conditional &lt;- (1/6)/(1/2); conditional ## [1] 0.3333333 #the likelihood of guessing the correct number, if the number is odd is 1/3. 4.5 Multiplicative Law of Probability of Independent Events For independent events, in other words, two events in which the occurrence of one event doesn’t depend on the occurrence of the other event, the probability of BOTH events occurring is the found by multiplying the probability of each event A and B happening: \\(P(A \\cap B)= P(A) \\times P(B)\\) where \\(A \\cap B\\) indicates the probability of both event A and event B occurring. Example: What is the probability of getting heads in two consecutive coin tosses? heads &lt;- (1/2)*(1/2); heads ## [1] 0.25 4.6 Additive Law of Probability of Mutually Exclusive Events For two events that are mutually exclusive (if event A occurs, then event B cannot occur), the probability of one of two mutually exclusive events happening is found by adding their individuals probabilities. \\(P(A \\cup B)= P(A) + P(B)\\) where \\(A \\cap B\\) indicates the probability of both event A and event B occurring. Example: What is the probability of rolling a 5 and a 6 on a fair die? That’s right! It’s zero, because the definition of mutual exclusivity indicates that if one event occurs the other can’t. Real example: What is the probability of rolling a 5 or a 6 on a fair die? fivesix &lt;- (1/6)+(1/6); fivesix ## [1] 0.3333333 4.7 General Additive Law of Probability When events are not mutually exclusive, we apply the general additive law of probability, which is written as: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) where \\(P(A \\cap B)\\) is the intersection of event A and event B. Why do we remove the intersection event? We essentially don’t want to double count the intersecting area of Event A and Event B. You’ve already completed one of these problems, we just hadn’t gone over intersection events. Let’s apply the general additive law of probability to the previous problem: What is the likelihood of rolling an odd number (Event A) on a 6-side fair die OR that is less than 4 (Event B)? Event A = 1, 3, 5 Event B = 1, 2, 3 Original calculation: #The sample space is all possible rolls samplespace &lt;- c(1, 2, 3, 4, 5, 6); samplespace ## [1] 1 2 3 4 5 6 #We will use Boolean operators in R. They will return TRUE / FALSE statements. #Below we tell R to look for odd numbers OR (indicated by line) #numbers less than 4. unionevent &lt;- (samplespace%%2==1) | (samplespace &lt; 4); unionevent ## [1] TRUE TRUE TRUE FALSE TRUE FALSE #If the conditions are satisfied, TRUE will be returned. #If conditions are not met, FALSE will be returned. #Now, let&#39;s calculate the probability using techniques that you #have already seen above. probunion &lt;- 4/6; probunion ## [1] 0.6666667 Calculation using the equation: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) probA &lt;- 3/6 probB &lt;- 3/6 intersection &lt;- 1/3 finalprob &lt;- probA + probB - intersection; finalprob ## [1] 0.6666667 4.8 Key concepts Summary: Randomness is inherent in natural systems. Whether this randomness is truly random or simply appears random due to the complexity of natural systems, we treat it the same in statistics. We want to avoid any form of systematic bias in experimental design. Randomness and other factors are lumped together in what we call statistical error; the difference between a true estimate of a parameter and what we estimate in our sample. Probability is the proportion of times an event occurs in repeated trials, and varies between 0 and 1. We practiced a bunch of different ways of calculating probability, for the long-term, what you really need to know is that to calculate probabilities, you need to understand your sample space and the likelihood and relationship of events of interest. -Two great rules of probability are: Additive Law of Probability &amp; the Multiplicative Law of Probability Union events and Intersection events 4.9 Practice problems Suggested Expanded Outline Randomness and Probability Introduction: Randomness in Nature and Statistics Philosophical perspectives on randomness (keep your nice intro!) Chaos theory and the butterfly effect Statistical definition of randomness Why probability matters for inference Statistical Error Random error vs systematic error (bias) Sources of error in ecological studies Why we can tolerate random error but must avoid systematic error Foundations of Probability Definition: proportion of times an event occurs in repeated trials Probability ranges from 0 to 1 Frequentist interpretation (preview — connects to later chapter) Calculating Probabilities: The Sample Point Method Define sample space Assign probabilities to sample points Sum relevant probabilities Coin flip example (keep existing) Combinatorials: When Sample Spaces Get Large The mn rule Permutations (order matters) Combinations (order doesn’t matter) Birthday problem example (keep existing) Trinucleotide example (keep existing) Relationships Between Events Union of events (OR) — with Venn diagrams Intersection of events (AND) Complement of events (NOT) Boolean operators in R Probability Laws Conditional probability P(A|B) definition and formula Die roll example (keep existing) Ecological example: P(species present | habitat type) Independence and the multiplicative law Definition of independent events P(A ∩ B) = P(A) × P(B) for independent events Coin toss example Ecological example: independent survival of seeds Additive law for mutually exclusive events Definition of mutually exclusive P(A ∪ B) = P(A) + P(B) Die roll example General additive law When events are not mutually exclusive P(A ∪ B) = P(A) + P(B) - P(A ∩ B) Why we subtract the intersection [NEW] Random Variables What is a random variable? Discrete random variables (counts, categories) Continuous random variables (measurements) Connecting back to data types from previous chapter [NEW] Expected Value and Variance Expected value (mean of a random variable) Definition: long-run average outcome Calculation for discrete variables: E(X) = Σ xᵢP(xᵢ) Intuition: weighted average by probability "],["expected-value-of-a-fair-die-roll.html", "Chapter 5 Expected value of a fair die roll", " Chapter 5 Expected value of a fair die roll outcomes &lt;- 1:6 probabilities &lt;- rep(1/6, 6) expected_value &lt;- sum(outcomes * probabilities) expected_value # 3.5 Variance of a random variable Definition: expected squared deviation from mean Var(X) = E[(X - μ)²] Standard deviation = √Variance "],["variance-of-a-fair-die-roll.html", "Chapter 6 Variance of a fair die roll", " Chapter 6 Variance of a fair die roll variance &lt;- sum((outcomes - expected_value)^2 * probabilities) variance sqrt(variance) # standard deviation Ecological example: Expected number of seeds germinating from a sample [NEW] The Law of Large Numbers As sample size increases, sample mean approaches population mean Why larger samples give more reliable estimates Simulation demonstration set.seed(123) # Simulate rolling a die many times n_rolls &lt;- c(10, 100, 1000, 10000) results &lt;- sapply(n_rolls, function(n) mean(sample(1:6, n, replace = TRUE))) data.frame(n = n_rolls, sample_mean = results, true_mean = 3.5) Ecological implication: Why sample size matters for estimating population parameters [NEW] Sampling Distributions From sample to inference We observe one sample, but want to know about the population If we repeated our study many times, we’d get different estimates The distribution of those estimates = sampling distribution Sampling distribution of the mean Take many samples, calculate mean of each Plot the distribution of sample means This distribution has its own mean and standard deviation set.seed(123) population &lt;- rgamma(10000, shape = 2, rate = 0.5) # Right-skewed population hist(population, main = “Population Distribution (Skewed)”, breaks = 30) "],["take-many-samples-and-calculate-means.html", "Chapter 7 Take many samples and calculate means", " Chapter 7 Take many samples and calculate means sample_means &lt;- replicate(1000, mean(sample(population, size = 30))) hist(sample_means, main = “Sampling Distribution of Means (n=30)”, breaks = 30) Standard error Standard deviation of the sampling distribution SE = σ / √n Measures precision of our estimate Decreases with larger sample size Standard deviation vs standard error MeasureWhat it describesFormulaStandard deviation (SD)Spread of individual observations√[Σ(xᵢ - x̄)² / (n-1)]Standard error (SE)Precision of the sample meanSD / √n [NEW] The Central Limit Theorem The most important theorem in statistics Regardless of population shape, the sampling distribution of means approaches normal as n increases This is why normal-based tests work even for non-normal data Rule of thumb: n ≥ 30 usually sufficient (but depends on skewness) Visual demonstration set.seed(123) par(mfrow = c(2, 3)) "],["uniform-population.html", "Chapter 8 Uniform population", " Chapter 8 Uniform population pop_uniform &lt;- runif(10000, 0, 1) hist(pop_uniform, main = “Uniform Population”, breaks = 20) means_n5 &lt;- replicate(1000, mean(sample(pop_uniform, 5))) means_n30 &lt;- replicate(1000, mean(sample(pop_uniform, 30))) hist(means_n5, main = “Sample Means (n=5)”, breaks = 20) hist(means_n30, main = “Sample Means (n=30)”, breaks = 20) "],["exponential-population-highly-skewed.html", "Chapter 9 Exponential population (highly skewed)", " Chapter 9 Exponential population (highly skewed) pop_exp &lt;- rexp(10000, rate = 1) hist(pop_exp, main = “Exponential Population”, breaks = 30) means_n5_exp &lt;- replicate(1000, mean(sample(pop_exp, 5))) means_n30_exp &lt;- replicate(1000, mean(sample(pop_exp, 30))) hist(means_n5_exp, main = “Sample Means (n=5)”, breaks = 20) hist(means_n30_exp, main = “Sample Means (n=30)”, breaks = 20) Why CLT matters for ecology Many ecological variables are not normally distributed (counts, skewed measurements) CLT tells us we can still use normal-based inference for means Justifies t-tests, ANOVA, and linear regression [NEW] Bayes’ Theorem Updating beliefs with evidence Reverses conditional probability P(A|B) = [P(B|A) × P(A)] / P(B) Components P(A) = prior probability (belief before seeing data) P(B|A) = likelihood (probability of data given hypothesis) P(A|B) = posterior probability (updated belief after seeing data) Classic example: Disease testing Disease prevalence: 1% (prior) Test sensitivity: 95% (true positive rate) Test specificity: 90% (true negative rate) If you test positive, what’s the probability you have the disease? prevalence &lt;- 0.01 sensitivity &lt;- 0.95 specificity &lt;- 0.90 "],["ppositive-pposdiseasepdisease-pposno-diseasepno-disease.html", "Chapter 10 P(positive) = P(pos|disease)P(disease) + P(pos|no disease)P(no disease)", " Chapter 10 P(positive) = P(pos|disease)P(disease) + P(pos|no disease)P(no disease) p_positive &lt;- sensitivity * prevalence + (1 - specificity) * (1 - prevalence) "],["pdisease-positive-pposdisease-pdisease-ppositive.html", "Chapter 11 P(disease | positive) = P(pos|disease) * P(disease) / P(positive)", " Chapter 11 P(disease | positive) = P(pos|disease) * P(disease) / P(positive) p_disease_given_positive &lt;- (sensitivity * prevalence) / p_positive p_disease_given_positive # Only about 8.8%! Ecological example: Species detection Prior: historical occupancy rate Likelihood: detection probability given presence Posterior: probability species is present given detection/non-detection Connection to Bayesian statistics Brief preview: Bayesian methods formalize this updating process Full treatment in Chapter 23 [NEW] From Probability to Inference (Bridge Section) The logic of hypothesis testing (preview) If the null hypothesis is true, what’s the probability of our observed result? If that probability is very low, we question the null hypothesis This probability = p-value Simple example I claim a coin is fair You flip it 10 times, get 9 heads If the coin is fair, P(9 or 10 heads) = ? "],["probability-of-9-or-10-heads-in-10-flips-of-fair-coin.html", "Chapter 12 Probability of 9 or 10 heads in 10 flips of fair coin", " Chapter 12 Probability of 9 or 10 heads in 10 flips of fair coin p_extreme &lt;- pbinom(8, size = 10, prob = 0.5, lower.tail = FALSE) p_extreme # About 1.1% This low probability makes us doubt the “fair coin” hypothesis This is the foundation of frequentist inference Type I and Type II errors (preview) Null is TRUENull is FALSEReject nullType I error (α)Correct decision (Power)Fail to rejectCorrect decisionType II error (β) Type I error (false positive): reject a true null Type II error (false negative): fail to reject a false null We’ll explore these more in the hypothesis testing chapter Key Takeaways Probability quantifies uncertainty and likelihood Random error is acceptable; systematic error must be avoided Understanding sample space is essential for calculating probabilities The Central Limit Theorem justifies normal-based inference Standard error measures precision of estimates Bayes’ theorem shows how to update beliefs with evidence Probability provides the foundation for all statistical inference Test Your Knowledge Conceptual questions What is the difference between standard deviation and standard error? Why does the Central Limit Theorem matter for ecological statistics? Explain why P(disease | positive test) is often much lower than the test’s sensitivity Calculation exercises Calculate expected value and variance for a given probability distribution Use Bayes’ theorem to calculate posterior probability in an ecological scenario Demonstrate CLT with a simulation Assignment (Keep existing, perhaps add: simulate the sampling distribution of a statistic from your project data) "],["data-exploration-and-assumption-checking.html", "Chapter 13 Data Exploration and Assumption Checking", " Chapter 13 Data Exploration and Assumption Checking Introduction: Why Explore Before You Analyze? The “look at your data first” principle EDA catches errors, reveals patterns, and guides model choice Assumptions aren’t just technicalities — violating them affects inference The goal: no surprises when you run your model Getting to Know Your Data Initial data checks str(), summary(), head(), dim() Checking for missing values (is.na(), naniar package) Identifying data entry errors (impossible values, typos in factor levels) Ecological example: Import a messy vegetation dataset and clean it Quick reference table: Common data problems and how to spot them Visualizing Distributions Univariate exploration Histograms — shape, skew, modes Density plots — smoother view of distribution Boxplots — median, spread, potential outliers QQ plots — comparing data to theoretical distribution R code examples with ecological data Seedling height (continuous) Species counts (discrete) Cover estimates (proportion) Multivariate exploration Scatterplots and scatterplot matrices (pairs(), GGally::ggpairs()) Correlation matrices Visualizing relationships between predictors and response Key questions to ask: Is the distribution roughly symmetric or skewed? Are there gaps or multiple modes? Do relationships look linear? Assumptions of Parametric Tests Why assumptions matter Models make predictions based on assumed data structure Violations can inflate Type I error or reduce power Some violations matter more than others The Big Four for linear models Normality of residuals What it means (residuals, not raw data!) How to check: histogram of residuals, QQ plot, Shapiro-Wilk test When it matters most (small samples) Homoscedasticity (equal variance) What it means: spread of residuals constant across fitted values How to check: residuals vs. fitted plot, Levene’s test, Breusch-Pagan test Common patterns: fan shape, trumpet shape Independence What it means: observations don’t influence each other How to check: study design review, residuals vs. time/space plots, Durbin-Watson test Common violations: repeated measures, spatial clustering, temporal autocorrelation Linearity What it means: relationship between predictors and response is linear How to check: residuals vs. fitted plot, component-residual plots What non-linearity looks like Visual guide: Example diagnostic plots showing “good” vs. “problematic” patterns Checking Assumptions in R Base R approach plot(model) — the four default diagnostic plots Interpreting each plot Using the performance package check_model() — visual dashboard check_normality(), check_heteroscedasticity() Using the DHARMa package (for GLMs) Simulated residuals for non-normal models simulateResiduals(), plot() Worked example: Fit a linear model to plant biomass data, walk through full diagnostic workflow Identifying and Handling Outliers What is an outlier? Statistical definition vs. ecological reality Outliers in predictor space vs. response space Influential points vs. just unusual values Detection methods Visual: boxplots, scatterplots, residual plots Statistical: Cook’s distance, leverage values, studentized residuals Rule of thumb thresholds (Cook’s D &gt; 4/n, etc.) What to do with outliers Investigate first — data entry error? Measurement issue? Real biology? Document decisions transparently Options: correct, remove (with justification), use robust methods, transform Never delete just to “improve” results Ecological example: An unusually large tree in a seedling dataset — error or legacy tree? When Assumptions Are Violated Transformation approaches Log, square root, arcsine-square root When transformations help vs. when to use a different model Back-transformation for interpretation Switch to appropriate GLM Skewed positive data → Gamma Counts → Poisson or Negative Binomial Proportions → Beta or Binomial Non-parametric alternatives Brief mention (covered in later chapter on permutation methods) Robust regression When useful, brief overview Decision flowchart: Assumption violated → what are your options? Putting It All Together: An EDA Workflow Step-by-step checklist Import and inspect data structure Check for missing values and errors Visualize each variable individually Explore relationships between variables Fit preliminary model Run diagnostic checks Address any issues Proceed with analysis Complete worked example: Forest plot data from import to model-ready Key Takeaways Always explore before modeling Check residuals, not raw data, for most assumptions Visualization is your most powerful tool Document your decisions about outliers and transformations When in doubt, try a different model rather than forcing transformations Test Your Knowledge Conceptual questions Why do we check normality of residuals rather than raw data? What does a “fan shape” in a residuals vs. fitted plot indicate? Name two ways to detect influential outliers. Applied exercises Given diagnostic plots, identify the assumption violation Import a dataset, conduct full EDA, report findings Identify and justify handling of outliers in a provided dataset Assignment Conduct a complete EDA on your project dataset: Report summary statistics and missing data Visualize distributions of key variables Create scatterplots of response vs. predictors Fit a preliminary model and check assumptions Document any issues found and your plan to address them "],["ecological-sampling.html", "Chapter 14 Ecological sampling 14.1 Background 14.2 Sampling approaches 14.3 Systematic Sampling 14.4 Adaptive Sampling (Sampling Rare or Patchy Species) 14.5 Imperfect Detection in Ecological Sampling 14.6 Temporal Sampling and Study Designs Through Time 14.7 Plot shapes, sizes, and transects 14.8 Distance Sampling and Point Counts 14.9 Reducing sampling error 14.10 Sample Size Determination in Ecology: Effect Sizes and Precision 14.11 Variables of interest 14.12 Test your knowledge 14.13 Assignment", " Chapter 14 Ecological sampling 14.1 Background Ecology is the study of organisms and their relationship to the environment. With infinite time and capacity, we could measure every organism, every characteristic of the environment, every physiological function that affects the way an organism responds to the environment, and every gene that underlies those physiological functions in order to understand ecological systems. In practice, such detailed measurements are time-consuming and impractical. For that reason, we use statistics to account for the fact we are always missing information when we conduct ecological studies. In statistics, a population refers to all units of the thing that you are interested in (i.e., all Suriname frogs, all species in a marshland, all grains of sand, all aspen leaves from a genotype found in southern Arizona). Note that the term ‘population’ in statistics differs from the term population in population ecology, where a population refers to a group of individuals in a particular area that interbreed. Statistics accounts for the fact that we never perfectly measure the ‘true population’ or the all units of interest. Luckily, by properly applying statistics, we can learn practically anything about almost any population using samples! A sample is a subset of the population that we measure to infer something about the true population. In order to avoid erroneous conclusions about the population, our sample must be representative of the population of interest and unbiased. As an example, imagine that you were interested in whether coat color in cats differed between house cats and feral cats. To select the house cat sample, you randomly select house numbers, visit the house and record coat color, thus collecting a random sample. However, to survey feral cats, you go to several cat colonies at night and record the first cat that you see, which are always white or tan. The sampling strategy for feral cats introduces bias, because darker cats are harder to see at night. This causes you to overestimate the number of light-coated feral cats, and underestimate dark-coated feral cats, resulting in the erroneous conclusion that a greater proportion of feral cats are light-colored compared to house cats. Experiments must be carefully planned to reduce bias. We can conduct statistical analysis until the cats come home (ha!), but if your sample is biased, our results will always be meaningless. In the cat example, it was pretty obvious that the researcher was introducing bias, BUT it is REALLY easy to introduce bias in ecological and social research on accident! Imagine that you looking at fire effects on vegetative communities in the Sonoran. In high severity burn areas, there are thickets of cat’s claw (a pokey plant). Without proper field sampling protocols, it is very tempting to avoid establishing plots in the cat claw thickets, thus not capturing true differences in vegetation along burn severity gradients. Let’s talk about several types of appropriate sampling strategies. 14.2 Sampling approaches Sampling approaches in how they balance randomness, spatial coverage, logistical constraints, and inference goals. Here is a brief overview, before we take a look at the most common sampling methods used in ecology. Sampling design What it does When you’d use it Simple random Completely random points Small, homogeneous areas Systematic Regular grid or transects Mapping gradients, efficiency Stratified random Random within strata Heterogeneous landscapes Cluster Groups of nearby points Reduce travel cost GRTS Spatially balanced random Large-scale monitoring Adaptive Adds points where signal is high Rare or patchy species Model-based Guided by covariates Targeting ecological processes 14.2.1 Random sampling In order to reduce bias, researchers randomize sampling. Random sampling is when every item within the focal population has an equal chance of being selected. In research, random sampling can be applied to selecting experimental subjects, assigning individuals to treatments, or identifying plot locations. It is REALLY easy to introduce bias in ecological and social research on accident if you do not use a random sampling technique! Imagine that you are looking at fire effects on vegetative communities in the Sonoran. In high severity burn areas, there are thickets of cat’s claw (a pokey plant). Without proper field sampling protocols, it is very tempting to avoid establishing plots in the cat claw thickets, thus not capturing true differences in vegetation along burn severity gradients. In practice, researchers use number generators, like those on your phone, or within computer programs, like ArcGIS, to randomly place sampling points. Here, we’ve included a random number sheet to use to randomly array plots. A random number sheet contains random numbers that someone generated in advance to assist in the field. Important note: “Random” is not the same as “wandering around and picking what looks good.” Random sampling = using a rule or tool (random number generator, coordinates, random bearings and distances) so every location has a known chance of being selected. Haphazard sampling = picking what feels convenient or “typical” – this almost always introduces bias. We can quickly and easily generate such a sample in R, using the sample function. sample(1:100, 10, replace=FALSE) ## [1] 100 84 31 77 3 40 24 93 10 97 #1:10000 = numbers to chose among #number of random numbers you wish to generate #to replace or not (in other words do you wish for the same number to be selected multiple times) 14.2.2 Stratified random sampling To make a sample representative of the population, you will want to capture the typical state of the population of interest. This is challenging, since prior to collecting data, you do not know the typical state of the population. With an understanding of ecology, however, and precisely describing your research question, you can improve the representation of your sample without a lot of specific a priori (beforehand) knowledge of the target population. One typical approach is referred to as stratified random sampling, in which you ensure that you are proportionately sampling from major habitat types or features. In the example in Fig. 1, a random sample of the study area overrepresents the forested habitat relative to the grassland habitat. To account for this, the researchers adjust the sampling technique, such that plot locations occur in both of the major habitats proportionally. Since grasslands make up 55% of the study area, 55% of the points would be randomly located in the grassland area. Since there are twenty plots, 11 are placed within grasslands (0.55*20). The remaining 9 plots are then randomly allotted to the forested habitat. Figure 1. Random versus stratified sampling. 14.2.3 Gridded random sampling In complex, multi-species systems, another approach to improve coverage of random sampling is to randomly place plots within a grid (Fig. 2). This is to ensure that you capture species, which may have an array of distributions. Distribution in plant ecology refers to the spatial arrangement of a species or organisms across the landscape. Depending on system dynamics, species may be dispersed, randomly arrayed, or clumped, thus a gridded approach can help capture species, no matter their spatial orientation (Fig. 2). Figure 2. Randomly placing plots within a gridded region helps maximize the likelihood to capture species dynamics in complex, multi-species systems, composed of species with a variety of spatial distributions. 14.2.4 Random cluster sampling Random cluster sampling randomly select groups (aka clusters) within a population. This sampling design is used commonly in ecology, when we select random locations for plots, then measure all individuals within those plots. If for instance, we are interested in Ponderosa Pine growth rates on the Coconino National Forest, we would randomly assign points across Pondo habitat on the Coconino. At each point, we would set up a plot in which we measure Ponderosa Pines within an 11.71m radius plot. Why wouldn’t we just go out to a point and measure 1 tree to create a totally random sample? The plots are randomly assigned (yay!), but the trees within the plots are not independent. In other words, we might expect measures of trees within plot A to be more similar to each other than they are to trees within plot B, due to differences in microsite characteristics, genetic similarity among co-occurring trees, or site history (logging, fire). Luckily, we can account for this non-independence, as long as the plots are random! 14.2.4.1 Pseudoreplication When we treat non-independent measurements as if they were independent replicates, we call this pseudoreplication. For example, if we measure 20 trees inside 1 plot and then pretend we have 20 independent “samples,” we are ignoring the fact that those trees share the same microsite, history, and environment. In most ecological studies, the plot is the true replicate, and the trees within the plot are subsamples that help us better estimate conditions at that plot. 14.2.5 GRTS Sampling (Generalized Random-Tessellation Stratified Sampling) As ecological questions increasingly span large, heterogeneous landscapes, researchers need sampling approaches that are both statistically rigorous and spatially balanced. One method that has become foundational in long-term ecological monitoring—used by the U.S. EPA, USGS, USFS (e.g., FIA intensification), and many watershed and biodiversity programs—is GRTS, which stands for Generalized Random-Tessellation Stratified sampling. 14.2.5.1 What problem does GRTS solve? Imagine trying to monitor a species or habitat across a large region using simple random sampling. Although “random,” this approach can still place many points close together and leave other parts of the landscape unrepresented (spatial clumping). Stratified random sampling improves representation across broad habitat types, but still may not ensure even spatial coverage within each stratum. GRTS was developed to solve two key issues: Ensuring spatial balance: Sample points are spread evenly across the landscape (or within strata), minimizing large gaps and clusters. Maintaining true probability-based sampling: Every location has a known probability of being selected, preserving the ability to make unbiased, design-based statistical inferences. This makes GRTS ideal for monitoring programs where the goal is to detect long-term changes in ecological condition, species distributions, or habitat quality. 14.2.5.2 How GRTS Works GRTS uses a special type of spatial ordering, similar to a space-filling curve, to assign every location on the landscape a unique hierarchical address. This lets us draw a sample that: spreads points out as evenly as possible, remains fully random and unbiased, allows consistent sampling over time (e.g., rotating panels), and accommodates stratification, unequal selection probabilities, or oversampling in rare habitats. While the algorithm is mathematically complex, researchers rarely need to understand the internals—the spsurvey package in R implements GRTS with a single function. 14.2.5.3 When to Use GRTS in Ecological Sampling Researchers choose GRTS when: The study area is large and spatially complex Habitat types are patchy or unevenly distributed Long-term monitoring requires consistency through time Detecting spatial trends or hotspots is important A mixture of old (“legacy”) and new plots must be integrated without bias GRTS is used in applications such as: Riparian and stream monitoring (EPA EMAP, NRSA) Forest health surveys (USFS FIA intensification) Sage-grouse habitat monitoring Wetland condition assessment Vegetation change detection after disturbance Species occupancy surveys over large regions Restoration monitoring (e.g., fuel treatments, floodplain restoration) In other words, GRTS is the tool of choice when spatial representativeness matters. 14.2.5.4 Example: Sampling Emory oak habitat in across drought and non-drought areas. Overview In this tutorial, you will learn how to implement a GRTS (Generalized Random-Tessellation Stratified) sampling design in R. GRTS produces spatially balanced sample points, meaning sites are evenly spread across the landscape while still being selected randomly. This makes GRTS widely used in ecological monitoring programs (EPA EMAP, NRSA, USFS FIA intensification, watershed monitoring, etc.). Other types of sampling can be implemented in R using similar mapping and spatial workflows. Common designs include simple random sampling, systematic sampling (e.g., regularly spaced grids or transects), stratified random sampling (where samples are allocated within predefined habitat types, management units, or elevation bands), and cluster sampling (where groups of nearby points are sampled together). R also supports adaptive sampling, where additional samples are placed based on initial observations (e.g., high-density patches), unequal probability sampling (e.g., probability proportional to area or habitat suitability), and model-based sampling designs that use covariates such as NDVI, elevation, or climate to guide site selection. GRTS is particularly valuable when spatial balance is critical, but other designs may be more appropriate depending on study objectives, scale, and field constraints. Since GRTS is widely used ecology-based projects, we will start there! We will: 1. Import a study area boundary from Google Drive 2. Generate a spatially balanced GRTS sample 3. Visualize the sample 4. Export the output for field use 14.2.5.4.1 Load Required Packages 14.2.5.4.2 Step 1: Load Spatial Data Our study area includes oak woodlands in southern Arizona. We’ll download three spatial datasets from Google Drive: the sampling frame (study area boundary), strata (drought vs. non-drought areas), and existing monitoring plots. # Temporary directory for downloads temp_dir &lt;- tempdir() # Google Drive file IDs file_ids &lt;- list( sampling_area = &quot;1TOr1BKJpqKYWsGOAPaGrhkql5ovNglqa&quot;, strata = &quot;1ms4ErDYOFkkB4UFFeGGXmWITa3WE97KS&quot;, existing_plots = &quot;1EfI6AorSrgOS1xmr4LioJeSCp6F1yFfZ&quot; ) # Download function (handles Google Drive&#39;s virus scan page) download_from_gdrive &lt;- function(file_id, dest, name) { zip_path &lt;- file.path(dest, paste0(name, &quot;.zip&quot;)) url &lt;- paste0( &quot;https://drive.usercontent.google.com/download?id=&quot;, file_id, &quot;&amp;export=download&amp;confirm=t&quot; ) GET(url, write_disk(zip_path, overwrite = TRUE), progress()) out_dir &lt;- file.path(dest, name) unzip(zip_path, exdir = out_dir) # Removed quiet = TRUE out_dir } # Download all datasets sampling_dir &lt;- download_from_gdrive(file_ids$sampling_area, temp_dir, &quot;SamplingArea&quot;) strata_dir &lt;- download_from_gdrive(file_ids$strata, temp_dir, &quot;Strata&quot;) existing_dir &lt;- download_from_gdrive(file_ids$existing_plots, temp_dir, &quot;ExistingPlots&quot;) # Helper function to read shapefiles read_shp &lt;- function(dir) { shp &lt;- list.files(dir, pattern = &quot;\\\\.shp$&quot;, recursive = TRUE, full.names = TRUE) st_read(shp[1], quiet = TRUE) } # Read the spatial data sampling_frame &lt;- read_shp(sampling_dir) strata &lt;- read_shp(strata_dir) legacy_points &lt;- read_shp(existing_dir) Let’s examine what we loaded: # Check the sampling frame cat(&quot;Sampling Frame contains&quot;, nrow(sampling_frame), &quot;features\\n&quot;) ## Sampling Frame contains 3 features cat(&quot;Available habitat types:&quot;, unique(sampling_frame$R3ERU), &quot;\\n\\n&quot;) ## Available habitat types: Madrean Encinal Woodland Madrean Pinyon-Oak Woodland Ponderosa Pine - Evergreen Oak # Check existing plots cat(&quot;Number of existing monitoring plots:&quot;, nrow(legacy_points), &quot;\\n&quot;) ## Number of existing monitoring plots: 82 14.2.5.4.3 Step 2: Define Study Area We’ll focus on the Madrean Encinal Woodland ecological unit and transform to Albers Equal Area projection for accurate area calculations. encinal &lt;- sampling_frame %&gt;% filter(R3ERU == &quot;Madrean Encinal Woodland&quot;) %&gt;% st_transform(5070) # NAD83 / Conus Albers # Calculate study area study_area_km2 &lt;- round(as.numeric(st_area(encinal)) / 1e6, 2) cat(&quot;Study area:&quot;, study_area_km2, &quot;km²\\n&quot;) ## Study area: 1195.44 km² 14.2.5.4.4 Step 3: Generate GRTS Sample GRTS (Generalized Random-Tessellation Stratified) sampling creates spatially balanced samples. We’ll select 40 base sites plus 10 oversample sites (used if base sites become inaccessible). set.seed(123) # For reproducibility grts_sites &lt;- grts( sframe = encinal, n_base = 40, n_over = 10 ) # Extract base and oversample sites base_sites &lt;- grts_sites$sites_base over_sites &lt;- grts_sites$sites_over cat(&quot;Generated&quot;, nrow(base_sites), &quot;base sites\\n&quot;) ## Generated 40 base sites cat(&quot;Generated&quot;, nrow(over_sites), &quot;oversample sites\\n&quot;) ## Generated 10 oversample sites 14.2.5.4.5 Step 4: Visualize the Sampling Design This step often takes a while, since ggplot is loading spatial data! ggplot() + geom_sf(data = encinal, fill = &quot;forestgreen&quot;, alpha = 0.3, color = &quot;darkgreen&quot;, linewidth = 0.5) + geom_sf(data = base_sites, aes(color = &quot;Base Sites&quot;), size = 3, shape = 19) + geom_sf(data = over_sites, aes(color = &quot;Oversample&quot;), size = 2.5, shape = 1, stroke = 1) + geom_sf(data = legacy_points, aes(color = &quot;Legacy Plots&quot;), size = 2.5, shape = 4, stroke = 1.5) + scale_color_manual( values = c(&quot;Base Sites&quot; = &quot;gold&quot;, &quot;Oversample&quot; = &quot;orange&quot;, &quot;Legacy Plots&quot; = &quot;dodgerblue&quot;), name = &quot;Site Type&quot; ) + theme_minimal(base_size = 14) + theme(legend.position = &quot;bottom&quot;) + labs( title = &quot;GRTS Sampling Design: Madrean Encinal Woodland&quot;, subtitle = paste0(&quot;Study area: &quot;, study_area_km2, &quot; km²&quot;) ) Figure 14.1: GRTS probability-based sampling design showing 40 base sites (gold circles), 10 oversample sites (orange circles), and existing monitoring plots (blue crosses) in the Madrean Encinal Woodland. Notice how GRTS sites are spatially balanced across the study area. Key observations: - Base sites (gold) are spread evenly across the landscape - Oversample sites (orange) fill spatial gaps and serve as replacements - Legacy plots (blue) show existing monitoring locations - This spatial balance ensures representative coverage 14.2.5.4.6 Step 5: Export Data for Field Work #------------------------------------------------------------ # Step 5: Export Data for Field Work #------------------------------------------------------------ # Create output directory dir.create(&quot;grts_outputs&quot;, showWarnings = FALSE) # Combine all new sample sites all_sites &lt;- rbind( base_sites %&gt;% mutate(site_type = &quot;Base&quot;), over_sites %&gt;% mutate(site_type = &quot;Oversample&quot;) ) #------------------------------------------------------------ # 1. FOR GPS DEVICES - Simplified GPX (just coordinates &amp; names) #------------------------------------------------------------ # GPX format is VERY strict - only name and geometry allowed gpx_sites &lt;- all_sites %&gt;% mutate(name = paste0(siteID, &quot; (&quot;, site_type, &quot;)&quot;)) %&gt;% dplyr::select(name, geometry) st_write(gpx_sites, &quot;grts_outputs/grts_sampling_points.gpx&quot;, driver = &quot;GPX&quot;, delete_dsn = TRUE) #------------------------------------------------------------ # 2. FOR GIS - Full data in Shapefile &amp; GeoJSON #------------------------------------------------------------ # Shapefile (most universal for GIS) st_write(all_sites, &quot;grts_outputs/grts_sampling_points.shp&quot;, delete_dsn = TRUE) # GeoJSON (modern, includes all fields) st_write(all_sites, &quot;grts_outputs/grts_sampling_points.geojson&quot;, delete_dsn = TRUE) # KML (alternative to GPX - works in Google Earth &amp; many GPS apps) kml_sites &lt;- all_sites %&gt;% mutate(Name = paste0(siteID, &quot; (&quot;, site_type, &quot;)&quot;)) st_write(kml_sites %&gt;% dplyr::select(Name, geometry), &quot;grts_outputs/grts_sampling_points.kml&quot;, driver = &quot;KML&quot;, delete_dsn = TRUE) #------------------------------------------------------------ # 3. FOR ANALYSIS - Full data in CSV #------------------------------------------------------------ # Get coordinates coords_albers &lt;- st_coordinates(all_sites) # Create comprehensive CSV with all information sites_csv &lt;- all_sites %&gt;% st_drop_geometry() %&gt;% mutate( X_albers = coords_albers[,1], Y_albers = coords_albers[,2] ) %&gt;% dplyr::select(siteID, site_type, lon_WGS84, lat_WGS84, X_albers, Y_albers, wgt, ip, R3ERU) write.csv(sites_csv, &quot;grts_outputs/grts_sampling_points.csv&quot;, row.names = FALSE) #------------------------------------------------------------ # 4. FIELD DATA SHEET - Blank template for data collection #------------------------------------------------------------ field_sheet &lt;- sites_csv %&gt;% dplyr::select(siteID, site_type, lon_WGS84, lat_WGS84) %&gt;% mutate( date_visited = &quot;&quot;, observers = &quot;&quot;, canopy_cover_pct = &quot;&quot;, tree_density = &quot;&quot;, notes = &quot;&quot; ) write.csv(field_sheet, &quot;grts_outputs/field_data_sheet.csv&quot;, row.names = FALSE) #------------------------------------------------------------ # 5. SAMPLING SUMMARY #------------------------------------------------------------ summary_table &lt;- data.frame( Category = c(&quot;Total Sites&quot;, &quot;Base Sites&quot;, &quot;Oversample Sites&quot;, &quot;Study Area (km²)&quot;, &quot;Average Site Weight (km²)&quot;), Value = c( nrow(all_sites), nrow(base_sites), nrow(over_sites), round(as.numeric(st_area(encinal)) / 1e6, 2), round(mean(as.numeric(all_sites$wgt)) / 1e6, 2) ) ) write.csv(summary_table, &quot;grts_outputs/sampling_summary.csv&quot;, row.names = FALSE) 14.2.6 Understanding Design Weights Important: Each GRTS site has a design weight (wgt) representing the area it represents. When analyzing data collected at these sites, you must use these weights to get unbiased population estimates. # Example: First 5 sites and their weights sites_csv %&gt;% dplyr::select(siteID, site_type, wgt) %&gt;% head(5) %&gt;% knitr::kable(caption = &quot;Sample sites with design weights&quot;) Table 14.1: Sample sites with design weights siteID site_type wgt Site-01 Base 29886054 [m^2] Site-02 Base 29886054 [m^2] Site-03 Base 29886054 [m^2] Site-04 Base 29886054 [m^2] Site-05 Base 29886054 [m^2] Example calculation: If you measure canopy cover at each site, calculate the population mean as: # Example field data (for demonstration) field_data &lt;- data.frame( canopy_cover = c(45, 62, 38, 71, 55), wgt = sites_csv$wgt[1:5] ) # Weighted mean (correct for GRTS) weighted.mean(field_data$canopy_cover, w = field_data$wgt) # Simple mean (WRONG - ignores spatial design) mean(field_data$canopy_cover) 14.3 Systematic Sampling Another approach commonly used in ecological studies is systematic sampling, in which sample points or transects are placed at regular intervals across the landscape (e.g., every 50 m along a grid or trail). Unlike random sampling, where points can be clustered, systematic sampling ensures even spatial coverage of a study area. Systematic sampling is useful when: The landscape is large and relatively uniform The goal is to detect broad-scale patterns Field logistics require simple, repeatable placement of plots However, systematic sampling carries one risk: If the sampling interval accidentally aligns with a natural pattern (e.g., spacing of vegetation bands, fence-line effects, or management history), the sample may over- or under-represent certain features. Despite this, systematic sampling performs extremely well in many ecological systems and often provides more spatially uniform coverage than simple random sampling. 14.4 Adaptive Sampling (Sampling Rare or Patchy Species) Some species of interest—threatened plants, cryptic mammals, rare insects—occur in patchy, clustered distributions. When organisms are rare, simple random sampling may completely miss them. Adaptive sampling increases sampling intensity only where the organism is found. For example: Select initial sample locations randomly. When a target species is detected at a site, sample additional plots in neighboring locations. Continue expanding sampling outward until no new detections occur. This approach is efficient for: Rare plants Disease outbreaks (e.g., white-nose syndrome, oak wilt) Invasive species early detection Patchy coral or seagrass distributions Adaptive sampling improves our ability to detect and map rare organisms, but it also introduces statistical challenges, since sampling intensity is no longer uniform. These can be addressed using specialized estimators or model-based inference. 14.5 Imperfect Detection in Ecological Sampling Ecologists rarely observe organisms perfectly. Whether estimating abundance, occupancy, or survival, detection probability can influence sampling accuracy. Common sources of imperfect detection include: Vegetation density (harder to see animals) Observer skill Weather, time of day, or season Species behavior (cryptic, nocturnal, burrowing) Habitat structure Even when sampling is random and unbiased, ignoring detection probability can lead to biased estimates. For example, frogs in dense vegetation may appear “absent” when they are simply undetected. This is especially important when comparing habitats, because detection typically differs among environments. Common study designs that account for detection include: Repeated surveys (occupancy modeling) Point counts with distance sampling Removal sampling Mark–recapture N-mixture models A simple conceptual model: Observed count = True abundance × Detection probability Accounting for detection sets the foundation for later modeling approaches in wildlife ecology and plant demography. 14.6 Temporal Sampling and Study Designs Through Time Sampling is not only about where you measure, but also when. Many ecological processes—recovery after disturbance, climate-driven changes, successional dynamics—require data collected over time. 14.6.1 Sampling Panels Long-term monitoring programs often use panels, which describe when sites are revisited: Permanent panel: Same sites revisited every year (high power to detect change). Rotating panels: Different subsets of sites visited in different years (greater spatial coverage). Split panels: Mixture of permanent and rotating sites (e.g., GRTS with a fixed core). GRTS integrates panel design naturally, making temporal inference more robust. 14.6.1.1 Sampling Frequency Sampling too infrequently risks missing important dynamics; too frequently wastes effort. Key considerations: Generation time of focal species Expected speed of recovery Variability of climate or disturbance regime Practical logistics Temporal sampling decisions strongly influence the ability to detect ecological change. 14.6.2 BACI Designs (Before–After–Control–Impact) When evaluating the effect of a treatment—like a fire, restoration project, or invasive removal—ecologists often use a BACI design: Before: Measure the system prior to disturbance or treatment After: Measure again post-treatment Control: A comparable, untreated reference area Impact: The treated area BACI isolates treatment effects from natural variation through time and space. 14.7 Plot shapes, sizes, and transects Deciding on the shape and size of your sampling unit depends on the species or feature that you are trying to measure. Plots can be ANY shape, but usually the shape of the plot is either a square or circle for simplicity – why would you sample using a hexagon? Often in forestry, plots are circular, marked with a central post, which foresters attach logging tape and rapidly measure trees that fall within a certain radius from the central post (Fig. 3). Since trees are large, this helps foresters quickly collect data on the species composition and structure of forests. For smaller organisms, like understory species, quadrats (small plots, often square and 1 m2 in size) are often used, since many smaller organisms occur in this area – if plots were too large, then data collection would be too time-consuming. In some cases, researchers are interested in how certain ecological variables differ as a function of distance from a feature. In these cases, researchers will often use a transect – a linear feature – and collect variables of interest along it. Any of these sampling shapes and sizes can be combined or adapted to measure ecological features to answer the question of interest. Figure 3. A) The standard plot configuration for the Forest Inventory and Analysis dataset, which includes data on all of our forested lands in the US. Forestry plots are often circular (A), allowing foresters to attach loggers tape to a central plot marker (B) and quickly measure trees within these fairly large plots (C). Plots must be large in order to include enough trees to describe stand characteristics. 14.8 Distance Sampling and Point Counts Distance sampling is widely used in wildlife ecology, especially for birds, mammals, and sometimes plants or shrubs. The key idea: the probability of detecting an organism decreases with distance from the observer. Two common designs: Line-Transect Distance Sampling Observers walk a transect and record the perpendicular distance to each detected organism. Detection probability is modeled as a function of distance. Point Count Distance Sampling Observers stand at a fixed point and record distances to detected individuals during a timed count. Distance sampling allows estimation of true density without needing to census every individual, making it fundamental for large-area monitoring. 14.9 Reducing sampling error What is sampling error? Sampling error is the difference between the true estimate of a population and the measurements that researchers collect on a sample. Error happens by chance and is unavoidable – it can be thought of as noise within the data. Error is different from bias, because it is non-systematic. For instance, imagine two people are measuring cactus heights for a demographic study. Error in height measurement is introduced by many things – the shakiness of each person’s hands, the amount of degradation and stretch in various measuring tapes. Bias, on the other hand, would be introduced if person 1 only measures the small cacti, or always mis-reading the measuring tape and measuring heights 5 cm less than their actual height. Bias should always be avoided, and error reduced as much as possible. Larger samples are less affected by chance and so will have lower sampling error. In ecology, we refer to the number of independent units being measured as replicates. The more replicates, the less sampling error! Figure 4. As the number of replicate plots increases so does the accuracy at which we can estimate parameters for this forest stand. 14.10 Sample Size Determination in Ecology: Effect Sizes and Precision Ecological studies often face constraints in time, funding, or accessibility. Although there is no universal sample size, several principles guide decisions: Effect Size Matters Small effects (e.g., a 2% change in cover) require more replication than large effects (e.g., a 50% mortality event). Variability Determines Needed Sampling Systems with high natural variability (e.g., deserts, wetlands) require more replicates to estimate population parameters precisely. Plot Size vs. Plot Number Trade-off • Larger plots reduce variance but are more time-consuming • More small plots increase representation and reduce sampling error Pilot Studies Often, researchers conduct a small pilot sampling effort to estimate variance and inform final sample size. Although formal power analyses in ecology can be complex, the principles above provide practical guidance for designing effective sampling. 14.11 Variables of interest Finally, depending on the research question, there are a number of different variables that you might want to measure. In ecology, you may want to measure the number of different species in an area to look at diversity patterns, or collect data on size or growth to look at performance, or monitor individuals after a disturbance to look at mortality. We will collect different forms of data throughout the semester, but the following principles will always apply: Samples should be random and representative Sampling methodology – plot shape and size – should reflect the organism or ecological feature that you are measuring More replication is better, since it reduces sampling error In the rest of this course, we’ll use these samples (collected with careful designs like the ones above) to estimate population parameters such as mean height, survival probability, or species richness. Good sampling design is what makes our later statistical inferences valid and trustworthy. 14.12 Test your knowledge Below are several examples of study designs. Select the best sampling method and indicate why you selected it! 14.13 Assignment Write out your sampling design. Be sure to clearly describe your sampling area, sampling unit, number of replicates, and sampling method (e.g., simple random, stratified random, systematic, GRTS, cluster). Specify whether your design includes stratification, spatial balance, or unequal sampling effort, and explain how sample locations will be selected. In addition, justify each component of your design in light of your study objectives, the ecological system, and any practical constraints (e.g., access, time, cost, safety, detectability). Your justification should explain why this design is appropriate for addressing your research question and what tradeoffs you are making (for example, between spatial coverage and replication, or statistical rigor and field feasibility). 14.13.1 Example Methods: Sampling Design Study Area This study was conducted across oak woodland habitat across Arizona and New Mexico, encompassing the current distribution of Quercus emoryi woodlands. The study area defined using oak habitat derived from vegetation classification maps and land cover data. Areas that were inaccessible due to land ownership restrictions, unsafe terrain, or logistical constraints were excluded prior to sample selection to ensure that all selected sites were feasible to sample and that the resulting dataset would be representative of accessible oak habitat. Sampling Design Monitoring locations were selected using a Generalized Random-Tessellation Stratified (GRTS) sampling design. GRTS generates a spatially balanced random sample, ensuring that sites are well distributed across the landscape while retaining the probabilistic properties required for unbiased inference. This approach is particularly appropriate for large, heterogeneous landscapes such as oak woodlands, where environmental conditions vary across elevation, aspect, and disturbance history, and where simple random sampling may result in clustered or uneven spatial coverage. Each sampling unit consisting of a circular, 16 m radius vegetation plot. A total of 100 plots were selected across the study area. To ensure adequate representation of ecologically meaningful gradients, the sampling frame was stratified by elevation zone and management status (e.g., burned vs. unburned areas). Stratification allowed us to explicitly capture variation associated with these factors while maintaining random, spatially balanced site selection within each stratum through the GRTS algorithm. "],["power-analysis.html", "Chapter 15 Power analysis 15.1 Prework 15.2 Statistical power 15.3 Describing data", " Chapter 15 Power analysis 15.1 Prework Install packages ‘pwr’, ‘faraway’, ‘simr’, ‘simglm’, and ‘Superpower’. 15.2 Statistical power As we learned in lesson 3, Basic Statistical Test, statistical power is a measure of making a Type II error - saying that there is no treatment effect when, in fact, there is one. A power analysis is a way of estimating statistical power to either speak to the ability of your experiment to detect treatment effects or estimate sample size needed to answer the question that you are interested in with your experimental design. library(pwr) library(tidyverse) library(simr) library(simglm) library(Superpower) #load data data(&#39;oatvar&#39;, package=&#39;faraway&#39;) #Using power analysis to estimate needed sample size. To conduct a power analysis, you will need to know: The number of groups in your study Significance level. It is standard to use a significance level of 0.05. The power required for your experiment, which is typically set at 0.8. Effect size, which can be calculated from data from a pilot study or estimated. Effect size is a relativized estimate of difference between groups being compared. Generally, effect size is calculated by taking the difference between the two groups (e.g., the mean of treatment group minus the mean of the control group) and dividing it by the standard deviation of one of the groups. Because effect size is converted to standard deviations units, it tells you how many standard deviations lie between the two means, and can be compared across datasets regardless of the original units of the study (which is why effect sizes are calculated for meta-analyses). A classic effect size calculation is Cohen’s D calculated as \\(\\frac{\\overline{x}_1 - \\overline{x}_2}{s_{pooled}}\\), where \\({\\overline{x}_1}\\) is the mean of one group, \\({\\overline{x}_2}\\) is the mean of the second group, and \\(s_{pooled}\\) is standard deviation (typically pooled; sometimes of the control or pretest data) calculated as \\(s_{pooled} = \\sqrt{\\frac{sd_{a}^{2}+ sd_{b}^{2}}{2}}\\). Note that Cohen’s D is one of many ways of calculating effect size. Two other metrics are used by the ‘pwr package’: \\(f\\), calculated as expected standard deviation of the group means divided by the pooled within-group standard deviation, is used in our example below. Another option is eta-squared (η2). The eta-squared is the proportion of the total variance explained by the means variance. It is harder to detect a smaller effect of the treatment, and easier to detect larger effects. Cohen in his 1988 book (citation below) classified effect sizes into 3 general categories for Cohen’s D (CONFIRM): a small effect is typically set at 0.1 - 0.3, a medium effect at 0.3 - 0.5, and a large effect at &gt; 0.5. Note that the range for small, medium, and large effects differ by effect size calculation Using these classifications, you can estimate the sample size for a proposed study even if you have no data. Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum. Below, we will run a power analysis with actual data, but let’s start by running a power analysis to guide experimental planning for a study when no opportunity to conduct a pilot. Imagine you are planning an experiment in which you are trialing the effect of a new fertilizer on oat growth. You plan to include three levels, a control (no fertilizer added), a moderate fertilization treatment, and a high fertilization treatment and measure height as a dependent variable. In the code below, k indicates the number of groups (here: control, moderate, high), f indicates an effect size (we selected a medium effect size), sig.level indicates the significance level (0.05), and power (standard to use 0.8). To calculate the number of groups, if you have two factors, simply multiply the number of groups in each factor to get the value k. For instance, say you are looking at the effect of 2 levels of pesticide and 3 temperature levels on bee longevity, you would multiply 2 * 3, yielding 6 groups. Why do we use 0.8? It is by convention, much like we set a significance level (\\(\\alpha\\)) of 0.05. At some point scientists agreed that a power level of 0.8, which means that the probability of rejecting a false null hypothesis is 0.8 (or 80%), is an acceptable risk of committing a Type II error. pwr.anova.test(k=3, f=0.3, sig.level=0.05, power=0.8) ## ## Balanced one-way analysis of variance power calculation ## ## k = 3 ## n = 36.70126 ## f = 0.3 ## sig.level = 0.05 ## power = 0.8 ## ## NOTE: n is number in each group In this case, we’d should include at least 37 individuals (plus a few extra) to accommodate loss of individuals during the experiment. When possible, it is preferable to run a pilot experiment in order to improve experimental design. The ‘pwr’ package in R allows you to run a power analysis on various forms of data. Let’s run through several quick analyses using the ‘pwr’ package. The effect size calculations will depend on your statistical test (for a full description of tests, go to the package). Since Cohen’s description of effect sizes as small, medium and large depend on each statistical test, there is an easy way to generate this information in the ‘pwr’ dataset. For example, if you are interested in determining the value associated with a small effect size for a regression, you would run the following code: cohen.ES(test = &#39;r&#39;, size = &#39;small&#39;) ## ## Conventional effect size from Cohen (1982) ## ## test = r ## size = small ## effect.size = 0.1 Note that you have several test options here: r = regression r; alternative = ‘two.sided’ = correlation (can specify direction ‘greater’) - not 100 percent sure I’m right here… p = t = for t-test (type = ‘paired’; you can select between two population to a repeated measure test) anov = anova chisq = chi sq tests *f2 = glms The ‘pwr’ package is nice for quick looks at power for simple analyses with no previous data. Note: that you can calculate effect sizes from data by hand and plug them into ‘pwr’ to generate sample sizes or power assessments. Let’s check this out with the ‘oatvar dataset’. ggplot(oatvar, aes(y=yield, x=block, color=variety)) + geom_point() + geom_line(aes(x=as.integer(block))) The cbpp is a dataset on contagious bovine pleuropneumonia. Data description is here: https://rdrr.io/cran/lme4/man/cbpp.html library(simr) head(cbpp) ## herd incidence size period obs ## 1 1 2 14 1 1 ## 2 1 3 12 2 2 ## 3 1 4 9 3 3 ## 4 1 0 5 4 4 ## 5 2 3 22 1 5 ## 6 2 1 18 2 6 cbpp$obs &lt;- 1:nrow(cbpp) 15.3 Describing data First, let’s take a spin with data description. We are starting here to introduce a few concepts that will be important to understand, as we launch into statistical analysis. We will start by describing continuous data. Let’s use a simplified version of a dataset that I’m working with right now to look at the performance of several species of pollinator-friendly native species in agricultural gardens. Eventually, we’d like to develop seed to provide to restorationists for restoration of arid and semiarid grasslands. To do this, we need to understand how reliable these species are at establishing, producing seed, and attracting pollinators. Initially, we are conducting experiments with multiple populations of each species to determine how consistently plants grow, reproduce, and perform. Here, We will take a look at the initial heights of 1 population of one species, Asclepias subverticulata. When doing an actual research write-up, I ask myself ‘What is the most important information for my audience to know about this dataset?’ to guide what descriptions of the data to include. Here, we are just going to play around with numbers and R code! #create vector of heights (cm) of one population of A. subverticulata sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) #take the mean mean(sedonapopulation) ## [1] 5.142857 #calculate variance var(sedonapopulation) ## [1] 7.47619 #calculate standard deviation sd(sedonapopulation) ## [1] 2.734262 #calculate standard error #base r doesn&#39;t have this function #so we have to write our own std_error &lt;- function(x) sd(x)/sqrt(length(x)) std_error(sedonapopulation) ## [1] 1.033454 Most of the time when writing up results, you present a mean (sum of numbers divided by the number of observations), and an estimate of variation (a measure of how different the observations are). Here, we calculated three estimates variation, variance, standard deviation, and standard error. Since you will occasionally need to include equations in your write-ups, let’s get use to mathematical syntax, with these simple examples. The formula for the sample mean is: \\(\\mu = \\frac{\\Sigma x_i}{n}\\); where \\(\\mu\\) indicates the sample mean (sample = group of numbers we are looking at); \\(\\Sigma\\) means to add what ever follows; \\(x_{i}\\) is the value of one observation; (subscript i is often used to indicate that the action should be repeated for all values); \\(n\\) is the number of observations Why didn’t we just use \\(\\bar{x}\\) to indicate the mean? Because statisticians typically use \\(\\bar{x}\\) to indicate the true mean of the population, and \\(\\mu\\) to indicate the sample mean! Just to show you, what the mean() function is doing, let’s run: sum = 3+3+3+3+7+8+9 #add all the numbers in the sample n = length(sedonapopulation) #or you can just calculate the number of height measurements mean = sum/n; mean #divide sum by number ## [1] 5.142857 This formula is simple, but sometimes with more complex formulas, I will solve the equations by hand, to make sure that I understand what is happening! The formula for variance is: \\(S^{2} = \\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(S^{2}\\) is the sample variance; \\(\\mu\\) is the sample mean (remember from above); \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations In other words: #We determine how much each observation varies from the mean. diffobs1 = mean - 3 diffobs2 = mean - 3 diffobs3 = mean - 3 diffobs4 = mean - 3 diffobs5 = mean - 7 diffobs6 = mean - 8 diffobs7 = mean - 9 #Then we square each of these. diffobj1_sq = diffobs1^2 diffobj2_sq = diffobs2^2 diffobj3_sq = diffobs3^2 diffobj4_sq = diffobs4^2 diffobj5_sq = diffobs5^2 diffobj6_sq = diffobs6^2 diffobj7_sq = diffobs7^2 Why do we square the differences rather than just adding them up? Because differences will be positive and negative. If we added them without squaring, sample differences would negate each other. We want an estimate of the absolute differences of samples from the mean. #Then we add the differences up. sumofsquares = sum(diffobj1_sq, diffobj2_sq, diffobj3_sq, diffobj4_sq, diffobj5_sq, diffobj6_sq, diffobj7_sq) #Divide the sum of squares by n - 1. variance = sumofsquares/(n-1); variance ## [1] 7.47619 Why n - 1 instead of n? One reason is that, theoretically, because we are taking the mean of a sample, rather than all individuals, we underestimate the variance, so taking n-1 corrects that bias. Consider it a penalty for measuring a sample, not the entire population! Another practical reason is that dividing by n-1 makes the variance of a single sample undefined (unsolvable) rather than zero (solvable) For standard deviation, we just take the square root of the variance, to remove the effect of squaring the differences when calculating the variance, and thus contextualizing our estimate of variation with regard to the mean. For example, the variance for the Sedona population is 7.48, larger than the sample mean of 5.12; while the standard deviation is 2.73, indicating that you would expect most observations to be 5.12 +/- 2.73 (we’ll get to quantiles in a minute). The formula for standard deviation is: \\(\\sigma = \\sqrt\\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(\\sigma\\) is the sample variance; \\(\\mu\\) is the sample mean; \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations. Finally, standard error and confidence intervals (we’ll get to confidence intervals later) are the most common metrics of variance presented in journals. The formula for standard error is: \\(SE = \\frac{\\sigma}{\\sqrt n}\\) where \\(SE\\) is standard error of the sample; \\(\\sigma\\) is the standard deviation; and \\(n\\) is the number of samples. Why do we divide the standard deviation by the square root of the sample size to get standard error? While standard deviation measures the variation of the sample, standard error is meant to estimate the variation of the entire population of samples, if we could measure all individuals accurately. By dividing by the \\(\\sqrt n\\), the larger the sample size, the lower the error, because you have a more complete estimate of the true mean. In other words, standard deviation is just a measure of the variation of our sample, while standard error also incorporates information about our sampling process (how many individuals we have sampled). Want to delve deep into standard error and deviation (me neither - ha)?: Google central limit theorem + standard error / standard deviation. Means and variance measures are the most common way to describe quantitative data. However, several other metrics are useful for understanding the nature of your data and making decisions about analyses. A comprehensive understanding of your dataset includes describing these four features: Location (Mean, Median) Spread (Variability) Shape (Normal, skewed) Outliers We’ve talked about means. The median is just the central number in the dataset, and helps you identify skewness. #an example of an unskewed population sedona_unskewed &lt;- c(1, 2, 3, 4, 5, 6, 7) mean(sedona_unskewed) ## [1] 4 median(sedona_unskewed) ## [1] 4 #previous sedona population; skewed sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) mean(sedonapopulation) ## [1] 5.142857 median(sedonapopulation) ## [1] 3 In an unskewed population, the mean will equal the median. Skew may not seem important, but it has statistical ramifications, AND it tells us something meaningful about the data. For instance, what if I said that mean price of a home in Flagstaff is 350K, but the median price of a home is 300K? We would know the that average house prices are driven up by a smaller number of expensive homes. We can quantify skew by comparing means and medians (mean &gt; median = right-skewed; median &gt; mean = left-skewed), but it is helpful to visualize the shape of data with a histogram. A histogram is a graph of the frequency of different measurements. Let’s add a few more observations to our Sedona populations (skewed and unskewed) and check out the look of the data! sedona_unskewed &lt;- c(7, 2, 2, 3, 3, 3, 3, 6, 6, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 0.5) mean(sedona_unskewed) ## [1] 3.975 median(sedona_unskewed) ## [1] 4 #I&#39;m renaming sedonapopulation, sedona_skewed for this example sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2) mean(sedona_skewed) ## [1] 4.454545 median(sedona_skewed) ## [1] 4 In this relatively unskewed example, the tails are approximately even. This shape is also referred to as a normal or Gaussian distribution. Here, we superimposed the bellshaped Normal or Gaussian distribution. In this example of skewed data, the tail tapers to the right, indicated that the data is skewed to the right. In order to explain outliers, we need to look at quantiles! Quantiles are proportions of your data, in other words a way to break your data into chunks to understand spread. You can break your data into as many quantiles as you would like, but it is most common to break your data into 4 parts, also called quartiles. (If you break data into 5 parts, the components are called quintiles, 10 parts = deciles, 100 parts = percentiles). When you break data into quartiles, roughly 25 percent of the data occurs within each data chunk. The first chunk of the dataset contains 25% of the data (25th percentile; 25% of the data fall at or below this cut-off) is called the first quartile, the 50th percentile is called the sample median or the second quartile, the 75th percentile is called the third quartile. Box and whisker plots are commonly used to quickly examine quartiles. Let’s check out our plant height data again, using a box and whisker plot. In the plot shown here, the box encapsulates the Interquartile Range (IQR); the center of the data ranging from the 25th percentile to the 75th. The black line in the middle of the box is the median (also called the 50th percentile, because it bisects the dataset; half of the data occur above the median and half below). The lines emerging from the box (whiskers) indicate the extent of the first and third quartiles, and usually corresponding with the minimum and maximum values of the dataset, unless there are outliers. An outlier is a datapoint that occurs outside of the 1st or 3rd quantile. Let’s add one to our Sedona dataset, and see how it is represented on the box and whisker plot. #Let&#39;s add a plant height of 20. sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2, 20) boxplot(sedona_skewed, main=&quot;Skewed&quot;, ylab=&quot;Plant height (cm)&quot;) The outlier appears as a dot on the box and whisker plot, and is the maximum value of the dataset. One other thing to note: Standard deviation also breaks data into meaningful segments, but is only used when data conform to a normal distribution; the mean +/- 1 SD accounts for 68% of the data, +/-2 SDs contains 95% of data, and +/- 3SD includes 99% of data. That said, I’ve never presented standard deviation in a manuscript; it is much more common to include standard error or confidence intervals (discussed later). We’ve played around a lot with data, but what do you actually need to take away from this?: Data types (Categorical, Numerical discrete, Numerical continuous, Ordinal) Why? We will select analyses based on data type. The two basic questions that most statistical analyses answer. Why? This will help you define what statistics can and can’t do and bound our learning space! Ways to describe numerical continuous data (Location, Spread, Shape, Outliers). Why? You will describe your results using these concepts in write-up AND these concepts will be important for certain analyses. Know how to calculate mean, median, and standard error. Why? These are typical ways to describe data in results sections. Start to familiarize yourself with mathematical annotation. Why? You may need to include equations in your methods section. Start to familiarize yourself with R code. Why? Most researchers now use R to analyze, describe, and visualize their data. *Be able to interpret a histogram and box-whisker plot. Why? These are commonly used ways to visualize data. "],["selecting-statistical-tests.html", "Chapter 16 Selecting statistical tests 16.1 A foray into statistics 16.2 Pick the explanatory and response variable 16.3 Variable types refresher 16.4 More examples 16.5 The decision matrix 16.6 A note on assumptions 16.7 Learning goals 16.8 Downloads for this class 16.9 In-class practice 16.10 Assignment: Choosing and Running the Right Test 16.11 Statistical analyses for your species interaction lab", " Chapter 16 Selecting statistical tests 16.1 A foray into statistics We’ve talked about data types, describing data, and basic hypothesis testing. This week we are applying these concepts to run a statistical analysis. When conducting an analysis, a dataset will contain one or more response variables (aka y-variables, dependent variables) and one or more explanatory variables (aka x-variables, independent variables). Explanatory variables are used to explain variation in response variables. The data type of both the explanatory and response variables determines which statistical test we use. Selecting the right test is important because it ensures that we’re asking a question our data can actually answer. 16.2 Pick the explanatory and response variable Imagine that we want to identify areas that support high numbers of plants from the genus Mitella. We hypothesize that Mitella occurrence is positively related to water supply (i.e., the number of Mitella plants goes up as water availability increases). In this example the: Response Variable (Y) is the number of Mitella plants in a specific area (continuous count data). Explanatory Variable (X) is the Water availability (continuous). In this case, both the explanatory and response variables are continuous, so we might test their relationship using regression. 16.3 Variable types refresher Variable Type Examples Notes Categorical (nominal) Species identity, treatment group (control vs. watered) Categories with no natural order Categorical (ordinal) Low/medium/high shade Ordered categories Continuous Height, biomass, rainfall (measured on a scale) Quantitative, can take on many values Count Number of seedlings, number of visits by a pollinator Discrete values (0, 1, 2, …), often treated separately in statistics 16.4 More examples Example 1: Categorical explanatory → continuous response - Question: Do soil nitrogen levels differ between burned vs. unburned plots? - Test: ANOVA (a one way ANOVA is basically equivalent to a two-sample t-test, which we discussed in the chapter on basic statistical testing) Example 2: Categorical explanatory → categorical response - Question: Is survival (alive vs. dead) related to treatment (control vs. watered)? - Test: G-test (a type of Chi-square test) Example 3: Continuous explanatory → continuous response - Question: Does plant biomass increase with light availability? - Test: Regression. Example 4: Continuous explanatory → categorical response - Question: Does plant biomass increase survivorship of duckweed? - Test: Logistic regression. 16.5 The decision matrix Below is a simple decision matrix for selecting statistical analyses. How to use it: Identify your explanatory and response variables. Decide whether each is categorical, continuous, or count. Follow the matrix to the test. Example: Students conducted an experiment by manipulating three levels of competition: low, medium, and high, and evaluated the growth of a species of native pea. Since the explanatory variable is categorical and the response variable is continuous, you would perform an ANOVA. 16.6 A note on assumptions Choosing a test is only step one. Most tests also have assumptions (e.g., data are normally distributed, groups have equal variance, observations are independent). If assumptions are not met, we either transform the data or use a non-parametric alternative. We won’t perform transformations here, but it is important to understand that this is important when conducting statistics for peer-reviewed research. 16.7 Learning goals By the end of this module, you should be able to: Correctly identify explanatory and response variables. Match data types to the appropriate statistical test. Run a statistical test 16.8 Downloads for this class Download the R file Completing your species interactions final project and need more help? Watch the YouTube tutorial here 16.9 In-class practice Let’s practice these statistical tests in R (these examples are preloaded in your R file)! G-test (Categorical Response and Categorical Explanatory Variable) Scenario: You are studying bird nest preferences in a forest. You want to know if birds prefer nesting in different tree species (oak, pine, or maple). Response variable: Nest presence (Yes/No) Explanatory variable: Tree species (oak, pine, maple) Run the code in R. t-test and ANOVA (Continuous Response and Categorical Explanatory Variable) t-test Scenario: You want to compare the weight of two species of frogs (Species A and Species B) to see if there’s a significant difference in weight between them. Response variable: Frog weight (grams) Explanatory variable: Species (A or B) ANOVA (Continuous Response and Categorical Explanatory Variable with More Than Two Categories) Scenario: You are studying the growth of plants in three different habitats: Desert, Forest, and Wetland. You want to compare plant height across these habitats. Response variable: Plant height (cm) Explanatory variable: Habitat (Desert, Forest, Wetland) Linear Regression (Continuous Response and Continuous Explanatory Variable) Scenario: You are studying how the number of fish in a river changes with water temperature. You want to model the relationship between water temperature (°C) and fish count. Response variable: Fish count Explanatory variable: Water temperature (°C) Logistic Regression (Categorical Response and Continuous Explanatory Variable) Scenario: You want to study the probability of a specific bird species’ presence in different areas based on elevation. The response is whether the bird is present or absent. Response variable: Bird presence (Yes/No) Explanatory variable: Elevation (meters) Skip this section if you are using this chapter to run your analyses for your species interaction project. 16.10 Assignment: Choosing and Running the Right Test Next, let’s practice on your own. For each scenario: Read the description carefully. Decide which statistical test is most appropriate. Modify the code from the examples we’ve covered in class to run the test in R. Interpret the output using proper results statements. Scenario 1: Comparing Two Groups A biologist measures the leaf nitrogen content (%) in plants from two different habitats: Sunny vs. Shady. Question: What test should you use to compare nitrogen between habitats? Scenario 2: More Than Two Groups An ecologist measures the average number of pollinator visits to flowers of three species: Aster, Goldenrod, and Sunflower. Question: What test should you use to compare mean visits among these three species? Scenario 3: Relationship Between Two Variables A forester records tree diameter (cm) and age (years) for a sample of trees. Question: What test should you use to test whether tree diameter predicts age? Scenario 4: Categorical Data A conservationist records whether birds are Present or Absent at two sites: Restored and Unrestored. Question: What test should you use to see if bird presence differs between restored and unrestored sites? 16.10.1 Deliverables For each of the 4 scenarios above, run the appropriate statistical test, and provide: Results statements including: The correct test statistics Associated figures with correct figure legends. Start here again if using this chapter to analyze data for your species interaction lab 16.11 Statistical analyses for your species interaction lab Using the statistical tests provided here, select your statistical test based on the data type for your response and explanatory variable, run a statistical test, record your results, and create a figure! "],["basic-statistical-testing.html", "Chapter 17 Basic statistical testing 17.1 A short statistical review 17.2 Hypothesis testing review 17.3 Downloads for this module 17.4 Objectives 17.5 Tailed tests 17.6 Drawing conclusions from statistics 17.7 Reporting results 17.8 Assignment", " Chapter 17 Basic statistical testing 17.1 A short statistical review 17.1.1 What can statistics tell us? Welcome to our statistical exploration of the natural world! Almost all statistical analysis boils down to answering 1 of 2 questions: Do these groups differ? Is there a relationship between these variables? These seem like relatively simple questions to answer, perhaps just by looking at our data, so Why do we need statistics? The short answer is: error and sampling! Whenever we collect data, we introduce error; our instruments are imprecise and do not capture an exact measure of whatever you are measuring (e.g., height, weight), and humans make mistakes during measurement collection. Secondly, we are always measuring a sub-sample of the true population (true population meaning all representatives of whatever you are trying to measure; this can be grass, marbles, or the tibia of humans). Not only is it intractable in most cases to measure all individuals of whatever you are interested in, even when it is possible to attempt to measure all individuals (like in the case of rare plant work), statistics acknowledges that it is still unlikely that we are able to do so, since individuals may be dormant or challenging to locate. If we could measure all individuals of our focal population with perfect accurately, we could calculate population parameters, or quantities describing populations like averages and variation, rather than estimating these metrics, and just compare them. In this way, statistics is inherently practical, and asks: What can we say about whatever we are looking at, given our numerous flaws? 17.1.2 Sampling populations After a few classes, we will explore sampling methodology in greater depth in order to design appropriate experiments that test a statistical hypothesis. Let’s quickly talk about sampling now so that we have a shared understanding and vocabulary to build on - after all, statistics really centers around estimating characteristics of a true population from a sample. The really, truly amazing thing is that by properly applying statistics, we can learn practically anything about almost any population using samples! In statistics, a population refers to the all units of the thing that you are interested (i.e., all suriname frogs, all grains of sand, all aspen leaves from a genotype found in southern Arizona). Note: Population in statistics differs from the term population in population ecology, where a population refers to a group of individuals in a particular area that interbreed. A sample is a subset of the population that we measure to infer something about the population. Statistical analysis is only one part of presenting your research results. Generally, a results section in a manuscript includes: statistical results, data description (e.g., describing means, ranges, maxima, minima of groups of interest), and data visualization (i.e., creating beautiful figures). 17.2 Hypothesis testing review Ahhhh the scientific process: A researcher makes observations about the natural world, generates a hypothesis to test, tests the hypothesis, rejects or fails to reject the hypothesis, and reports these findings. A simple, yet glorious process that has led to incredible discoveries! Statistical hypothesis testing answers very simple questions, while scientists work in very complex knowledge environments. For beginning researchers, it is important to understand what statistics can tell us, and how this builds information to address amazing and very interesting research questions. Hypotheses allow us to articulate exactly what we are testing in statistics and to organize thoughts and analyses. 17.3 Downloads for this module Download this file to the folder you created for this lab: Download the R file. As you read the tutorial, follow along in the R code. Then, use the code to finish your assignment. 17.4 Objectives We will highlight the basic components of a statistical test with a very simple statistical ‘tailed’ test. Today, we will: State a hypothesis Calculate a test statistic Determine the p-value Interpret results The null hypothesis (\\(H_0\\)) is a statement about a population parameter that would be interesting to reject. The null hypothesis typically asserts that there is no effect or relationship or that results will not deviate from established knowledge. For instance: The mean height of giraffes in captivity and in the wild do NOT differ. The incidence of toenail fungus is the SAME in the control group and the group given anti-fungal medicine. There is NO relationship between sea grass height and the number of sea snails. The mean human body temperature is 98.6 degrees Fahrenheit. Null hypotheses are paired with alternative hypotheses (\\(H_A\\)) that represent ALL other possibilities other than that stated in the null hypothesis. For instance: The mean height of giraffes in captivity and in the wild differs. The incidence of toenail fungus is different in the control group and the group given anti-fungal medicine. There is a relationship between sea grass height and the number of sea snails. The mean human body temperature is not 98.6 degrees Fahrenheit. Note that the null hypothesis is very specific, while the alternative hypothesis is general. Statistical tests are designed to either reject or fail to reject the null hypothesis. 17.5 Tailed tests Tailed tests are very simple tests for comparing means or proportions, and are great for illustrating the basic components of a frequentist statistical analysis. Let’s walk through an example! Handedness is common in humans. Around 90% of humans preferentially use their right hand. You’ve been watching your cat, Geraldo, play with his toy mouse, and you notice that he preferentially uses his right paw to bat the mouse around. You start to wonder if cats display handedness like humans! You run around visiting cats and observing their paw usage and determine that 14 cats of the 18 you observe appear to be right-pawed, while only 4 preferentially use their left paw. Is this enough evidence to suggest that cats display ‘handedness’ or did this pattern just emerge by chance? 17.5.1 Generate hypotheses What is the null hypothesis in this case? Remember it must be specific so that we can either reject or fail to reject the null! \\(H_0\\): Left and right-pawed cats are equally frequent in the population (i.e., Cats are not right or left-pawed). Note that this null hypothesis is very specific. If we would describe this mathematically, we would say that we expect half the cats (9 / 18) to use their right paws and half to use their left paws. If we express this as a proportion, (\\(p\\)), we are testing whether \\(p\\) = 0.5. Very specific. What is the alternative hypothesis? \\(H_A\\): Left and right-pawed cats are not equally frequent in the population. Note that the alternative hypothesis is very broad and encompasses all other possibilities. Because, in theory, we could observe proportions below 0.5 (1/18 cats are right-handed) or above 0.5 (16/19 cats are right-handed), we refer to this as two-tailed. In a two-tailed test, the alternative hypothesis includes parameters on both sides of the value specified by the null hypothesis. Before we move on, can you think of an example of a 1-tailed test? Don’t look before guessing! Here are some examples: Did you score better than the class average? Is the time to getting to the student union less than 10 minutes when you avoid driving through campus? Note the difference with the 2-tailed test: we are only interested in values in one direction. In the first example, we are interested in whether your score is &gt;80% (class average). In the second, we are interested in whether your drive time is &lt;10 minutes (time to the student union driving through campus from your house). How could you phrase the first example to be a 2-sided test? Don’t look before guessing! It could be something like this: Was my score different than the class average? In this case, your score could be higher or lower. 17.5.2 Calculate a test statistic We generated our hypotheses. Let’s calculate a test statistic. What is a test statistic? A test statistic is a quantity calculated from that data used in statistical analysis to evaluate the null hypothesis. For this simple test, our test statistic will be 14, since this is the number of right-handed cats we observed. We want to ask whether observing 14 out of 18 cats using their right paw is truly different from the null (9 out of 18 cats using their right paw), or did this pattern occur by chance in our sample? 17.5.3 Determine the p-value Frequentists statistics is based on the concept of statistical distributions. If we run many trials, we can determine the likelihood of certain events occurring by chance. We refer to the patterns of occurrence of trials as frequency distributions. Let’s illustrate using the data above. A cat can either be right-handed or left-handed (in this case there are no ambidextrous cats). To determine the likelihood that our pattern arose by chance, we conduct numerous trials like a coin toss. We would randomly flip a coin 18 times and record the outcome of each trial; heads being right-pawed, and tails being left-pawed. In class: Each student took a coin. Flipped the coin 18 times and recorded number of heads. Divided by total number of trials (in this case students) to derive relative frequency for each event. If we would flip the coins many times, we probably generated something that looks like the figure generated by running the code below (run in your R code to generate the figure). This is referred to as a probability distribution and expresses the relative frequency of particular events occurring. Frequentist statistics derives its name from this probability distribution. ## quartz_off_screen ## 2 Figure 17.1: Binomial probability distribution Here is a table of those probabilities: probability &lt;- dbinom(paws, 18, 0.5) N &lt;- 0:18 pawtable &lt;- cbind(N, probability) pawtableF &lt;- as.data.frame(pawtable); pawtableF ## N probability ## 1 0 3.814697e-06 ## 2 1 6.866455e-05 ## 3 2 5.836487e-04 ## 4 3 3.112793e-03 ## 5 4 1.167297e-02 ## 6 5 3.268433e-02 ## 7 6 7.081604e-02 ## 8 7 1.213989e-01 ## 9 8 1.669235e-01 ## 10 9 1.854706e-01 ## 11 10 1.669235e-01 ## 12 11 1.213989e-01 ## 13 12 7.081604e-02 ## 14 13 3.268433e-02 ## 15 14 1.167297e-02 ## 16 15 3.112793e-03 ## 17 16 5.836487e-04 ## 18 17 6.866455e-05 ## 19 18 3.814697e-06 Take a look at the chart. What is the probability of observing right pawedness in 14 out of 18 cats? Is this difference from the null (9 cats are right-handed, no better than random) big enough to reject the null? To determine this we calculate a p-value. A p-value is the probability of obtaining the data that we observe if the null hypothesis were true. In this case, we will generate a p-value for a two-tailed test. To do this, we will add the probabilities of observing 14 right pawed cats or more by chance AND for the possibility of observing 4 or fewer right paws, which would indicate left pawedness. P-value = Pr[14] + Pr[15] + Pr[16] + Pr[17] + Pr[18] + Pr[4] + Pr[3] + Pr[2] + Pr[1] + Pr[0] Recall that we can add these probabilities up, since, in our example, we say that being right or left pawed are mutually exclusive events. pvalue &lt;- (0.0117 + 0.0031 + 0.0006 + 0.00007 + 0.000004)*2; pvalue ## [1] 0.030948 We generate a P-value of 0.031. In most sciences, we have agreed on a threshold of 0.05 for establishing statistical significance. If p-values are less than or equal to 0.05, we reject the null hypothesis. If larger, we fail to reject. The significance level, \\(\\alpha\\), is a probability used as a criterion for rejecting the null hypothesis. This significance level is important. In the sciences, we would rather err on the side of not identifying a pattern, rather than saying there is a pattern, when there it doesn’t actually exist. This concept is included in the in the discussion of *statistical errors**. A Type I error is when you reject a true null hypothesis. You are saying there is a difference, when actually, if could perfectly measure your focal population, there is no difference. By establishing a significance level (\\(\\alpha\\)) of 0.05, we are saying that we are willing to accept that 5% of the time, we will say there is an effect when there isn’t one. A Type II error is failing to find a pattern or a difference when there actually is one. If you reduce your \\(\\alpha\\) to reduce your likelihood of making a Type I, you increase the likelihood of committing a Type II error. The probability of committing a Type II error is more challenging to quantify and is related to the concept of statistical power. A study with high power has a low likelihood of committing a Type II error. Statistical power depends on several things, including sample size, the magnitude of the effect of the treatment, and variation within the sample. A study with a LARGE sample size, a BIG treatment effect, and SMALL variation within samples will have high statistical power. We will talk about calculating statistical power later. 17.6 Drawing conclusions from statistics In this case, we reject the null hypothesis, and state that our results support the alternative hypothesis that there is handedness in cats. Note that we ‘support’ the alternative hypothesis, rather than saying that there is pawedness in cats or accepting the alternative hypothesis. Statements about statistics are phrased to reflect that we are dealing in probabilities, and there is always a chance that our findings are incorrect. Additionally, statistical tests specifically test the null hypothesis, not the alternative (for which there are often many possibilities). What would we say if we didn’t reject the null? We would state that we failed to reject the null hypothesis. Failing to reject the null indicates that our sample did not provide sufficient evidence to conclude that the effect exists, but lack of evidence doesn’t prove that the effect does not exist. For this reason, we never accept the null. 17.7 Reporting results When we report findings, we will provide: A statement of findings The test statistic The P-value A description of differences, if differences exist A visualization of differences, if differences exist Here is how we might report the written results of our previous test: Cats displayed higher levels of handedness than expected by chance (t = 14, p = 0.03). Around 78% of cats preferentially use their right paw (Fig. 1). Note that it is common to include up to 2 decimal places in the results statements.If p-values are less than 0.01, it is common to report the p-value as p &lt; 0.01. 17.8 Assignment We will now apply the tailed-test to a new question! You think that your dog, Rupert, prefers blue to red. You want to know: Do dogs prefer the color blue? Provide the following information in a document and turn into your TA: What is your null hypothesis? What is your alternative hypothesis? You invite all your friends with dogs, place both red and blue balls on the ground, and see if how many times the dogs select the blue ball out of a series of 10 trials. Ten of friends with dogs participate and you record the number of times that the dogs select the blue ball. Run the t-test in R! Provide a corrected crafted results statement describing the outcome of the test. Please correctly structure your results statements, and make sure that you have included the 5 components mentioned above. For your figure, please include a properly formatted figure legend. Recall from last lesson, the key parts of the figure legend: A description of what the figure is showing you. For complex figures with multiple panels, an orientation to the structure of the figure Explanation of any symbols, colors, and/or lines Description of how variance is quantified Definitions of axes or units, if unclear Acknowledgment of data source, if data source requires attribution Implications of the figure (optional) "],["generalized-linear-models-glms.html", "Chapter 18 Generalized Linear Models (GLMs) 18.1 Linear models", " Chapter 18 Generalized Linear Models (GLMs) 18.1 Linear models What is a linear model? A linear model is a model where the data and parameters of interest interact only via addition and multiplication. Most commonly, the term ‘linear model’ refers to statistical models that involve linear regression. Clearly, linear models include linear regression in all its beautiful forms, like ANCOVA, and logistic regression. However, ANOVA is actually considered a linear model as well, since it meets our basic definition. Though it may not seem so from the outset, ANOVA and regression, statistically are related. Here’s an example: Let’s pretend we are looking at SLA (Specific Leaf Area) measurements of 3 different populations of plants, one population from Flagstaff, one from Sedona, and one from Camp Verde. library(tidyverse) data &lt;- tribble(~Population, ~SLA, &quot;Flagstaff&quot;, 2, &quot;Flagstaff&quot;, 1, &quot;Flagstaff&quot;, 2, &quot;Sedona&quot;, 5, &quot;Sedona&quot;, 6, &quot;Sedona&quot;, 7, &quot;CampV&quot;, 10, &quot;CampV&quot;, 11, &quot;CampV&quot;, 10) pop &lt;- group_by(data, Population) SLAtable &lt;- summarise(pop, meanSLA = mean(SLA)); SLAtable ## # A tibble: 3 × 2 ## Population meanSLA ## &lt;chr&gt; &lt;dbl&gt; ## 1 CampV 10.3 ## 2 Flagstaff 1.67 ## 3 Sedona 6 #ANOVA model1 &lt;- aov(SLA ~ Population, data=data) summary(model1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Population 2 112.67 56.33 101.4 2.37e-05 *** ## Residuals 6 3.33 0.56 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #ANOVA run as a linear model model2 &lt;- lm(SLA ~ Population, data=data) summary(model2) ## ## Call: ## lm(formula = SLA ~ Population, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0000 -0.3333 0.0000 0.3333 1.0000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.3333 0.4303 24.01 3.43e-07 *** ## PopulationFlagstaff -8.6667 0.6086 -14.24 7.50e-06 *** ## PopulationSedona -4.3333 0.6086 -7.12 0.000386 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7454 on 6 degrees of freedom ## Multiple R-squared: 0.9713, Adjusted R-squared: 0.9617 ## F-statistic: 101.4 on 2 and 6 DF, p-value: 2.373e-05 #in this simple model, #notice that the Intercept is the mean SLA of the #reference group #then population Flagstaff Coefficient #is 10.333 - 8.667 = 1.67 (mean of the Flagstaff pop) #Sedona population = 10.3333 - 4.3333 #6 = mean SLA of the Sedona population In other words, ANOVA compares means and provides a p-value that tells us that at least two groups are different, while the linear model form reports 1 mean for the reference group (intercept), and p-values indicate whether each group is different from the reference group. Well, hopefully that was an interesting aside and served to connect a variety of different statistical techniques. Now, let’s have a b***ing session about old-school linear models, like ANOVA. They have SO many assumptions that need to be met - in particular, linear models assume a normal distribution of residuals. Then, if that assumption isn’t met, you have to transform your dependent variable, and back transform your error bars, and on and on until you achieve normality, which - let’s be honest - may never happen. If only there was an easy way to deal with the assumption of normality of residuals! Enter a new(ish) generation of models - Generalized Linear Models (GLMS)! "],["generalized-linear-models.html", "Chapter 19 Generalized Linear Models 19.1 Link functions 19.2 GLMs in R", " Chapter 19 Generalized Linear Models A Generalized Linear Model (GLM) is an flexible statistical framework that allows us to model relationships between variables when the assumptions of ordinary linear regression are not met. Generalized Linear Models makes linear regression generalizable by using a link function to relate the linear model (i.e., relationship between x and y; systematic component) to the error (random component), allowing the magnitude of the variance for each measurement to be a function of the mean value and allowing us to specify different types of error distributions. Practically, GLMs allow you to analyze a variety of regression models, including linear regression, ANOVA, models for examining count data, models for predicting likelihood of events, under one statistical umbrella. Model assumptions What are the assumptions of GLMs? The data are independent. No problem - this is always important! The residuals do NOT need to be normally distributed, but you do need to specify a distribution from an exponential family that best fits your data (i.e., normal/Gaussian, binomial, Poisson, etc.) The homogeneity of variance does NOT need to be satisfied. Wow! This is great - let’s go over the components of GLMs - like what is this “link” function that everyone is talking about? A little aside Don’t confused Generalized linear models with General linear models. The term “general” linear model (GLM) usually refers to a linear regression models that assumes a Gaussian (normal) distribution, while generalized linear models allow you to specify other distribution from the exponential family (a set of distributions which include normal, Poisson, gamma and other commonly used distributions) for residuals. Parameter estimation uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS). Remember from our previous discussion of linear regression, that we determine the line of best fit for our data points by using ordinary least squares. Maximum likelihood estimation is Components of the GLM The linear predictor: This is the function that describes the relationship between the independent variable/s and the dependent variable. This essentially has the same structure as a linear model: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + … \\(\\beta_{p}X_{ip}\\) Where \\(\\eta_{i}\\) is the equivalent of y; the linear predictor - the predicted point on the y-axis according to the coefficients of predictors in combination with . \\(\\beta\\) values indicate coefficients of the predictors and x values indicate values of the predictors. The error or random component. The link function which brings together the linear predictor and the error distribution. How do link functions work? Let’s start with the formula for a line. \\(y =\\beta_{0} + \\beta_{1}*x\\) where y is the y-value (point along the y-axis); x is the value along the x-axis; \\(\\beta_{1}\\) (aka m) is the slope, or how much the line rises for 1 unit increase in x; \\(\\beta_{0}\\) is the intercept, or the value of y, when x = 0. In GLMs, the y term is \\(\\eta_{i}\\), so: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + … \\(\\beta_{p}X_{ip}\\) You can keep adding predictor variables (i.e., explanatory variables, independent variables) to the model as \\(\\beta_{2}\\) and so on! You can also specify non-linear relationships, like polynomial relationships, by including the second order term \\(\\beta_{2}X_{i2}^2\\) like so: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + \\(\\beta_{2}X_{i2}^2\\) For our classic regression models, you obtain an equation for the line of best fit presented in the syntax above. These classic linear regression models make several important assumptions: Additive relationships: Model variables have an additive relationship with each other, rather than multiplicative. Homoskedastic data: Constant variance, in order words, variance does not increase or decrease as a function of the mean. Normally distributed errors (residuals): Residuals are normally distributed, with mean 0 Non-correlated variables: Variables are independent. In standard linear model analysis, we use transformations to meet these assumptions, but GLMs are really cool, because we can avoid using transformation, by applying the link function. Through the beauty of link functions and conditional probabilities, we do not need to worry about homoskedasticity, normal distribution of residuals, or additive relations. 19.1 Link functions Let’s talk link functions, as this is what modifies our regression models, depending on the error distribution of our response variable. You specify the link function based on error distribution of your response variables, let’s go over the most common functions. Keep in mind that statisticians have developed many, many distributions! Some interesting ones include Pareto distribution, often applied to model Gross Domestic Product, and the von Mises distribution, for circular data, applied to days of the year! We will go over the most common link functions and their formulas used in the ecological sciences. Error distribution = Gaussian or Normal Link name = Identity This is the generalized linear model corresponding to a Gaussian distribution, in other words, regression/ANOVA. We do not need to transform the data in anyway, so the link is called identity. Link function = Revisiting the standard equation for a line, \\(y =\\beta_{0} + \\beta_{1}*x\\), we are saying that the mean y value will be what is calculated by the predicted model; we are not transforming anything. This is sometimes indicated with the following equation: \\(g(\\pi)=\\pi\\) where g indicates the link function, and \\(\\pi\\) indicates the mean y. Error distribution = Binomial Link name = Logit Link function = \\(g(\\pi_i)=ln(\\frac{\\pi_i}{1-\\pi_i})\\) This function can be rewritten to solve for y, as: \\(\\pi_i=ln(\\frac{e^{\\pi_i\\beta}}{1+e^{\\pi_i\\beta}})\\) Why would you want to do this? Back in the day, I used this function to create the line of best fit for logistic regressions! See excel example from my very first publication ever! Error distribution = Poisson Count data cannot be less than 0, so we use the Poisson distribution, so we transform the y variable by taking the natural log. Link name = Log Link function = \\(g(\\pi_i)=ln(\\pi_i)\\) This function can be rewritten to solve for y, as: \\(\\pi_i=e^{\\pi_i\\beta}\\) Error distribution = Gamma Used for data that are continuous and positive but may have skewed distributions. Often uses for lengths, durations or amounts (i.e., time to death). Link name = Reciprocal Link function = \\(g(\\pi_i)=1/pi_i)\\) This function can be rewritten to solve for y, as: 19.2 GLMs in R Let’s generate some code for statistical analysis, and create some figures! First, we will start by examining data with a Gaussian/normal distribution. data(iris) #Is petal width related to petal length? #model &lt;- glm(y-value ~ x-values, family = specifylinkingfunctions, data = dataset) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 &lt;2e-16 *** ## Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.2286808) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 33.845 on 148 degrees of freedom ## AIC: 208.35 ## ## Number of Fisher Scoring iterations: 2 #for comparison run a linear regression for comparison iris_modelR &lt;- lm(Petal.Length ~ Petal.Width, data = iris) #y data is continuous, use gaussian summary(iris_modelR) ## ## Call: ## lm(formula = Petal.Length ~ Petal.Width, data = iris) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.33542 -0.30347 -0.02955 0.25776 1.39453 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 &lt;2e-16 *** ## Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4782 on 148 degrees of freedom ## Multiple R-squared: 0.9271, Adjusted R-squared: 0.9266 ## F-statistic: 1882 on 1 and 148 DF, p-value: &lt; 2.2e-16 When we call the summary, you can see several interesting things. First, the first species alphabetically is represented by the intercept - essentially each species is compared against this first species. Then, you see the dispersion parameter (smaller the better), and AIC for model comparison (smaller the better). The dispersion parameter is a measure of variance - how the actual data points scatter around a mean, similar to the sum of squares in a linear regression. The AIC or the Akaike Information Criterion is usually calculated for model comparison. Here, it is presented as a general assessment of goodness of fit. AIC = 2K – 2ln(L) where: K: The number of model parameters. ln(L): The log-likelihood of the model. This tells us how likely the model is, given the data. Let’s take a direct look at the results of a statistical test using the Anova function in the ‘car’ package. library(car) #glm #iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) #y data is continuous, use gaussian Anova(iris_model) ## Analysis of Deviance Table (Type II tests) ## ## Response: Petal.Length ## LR Chisq Df Pr(&gt;Chisq) ## Petal.Width 1882.5 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #for comparison run a linear regression for comparison #iris_modelR &lt;- lm(Petal.Length ~ Petal.Width, data = iris) #y data is continuous, use gaussian Anova(iris_modelR) ## Anova Table (Type II tests) ## ## Response: Petal.Length ## Sum Sq Df F value Pr(&gt;F) ## Petal.Width 430.48 1 1882.5 &lt; 2.2e-16 *** ## Residuals 33.84 148 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #Look at residuals res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) The residuals should have a random pattern, yet here we see a distinctive shape in which they increase at mid-size values and decrease, particularly at the largest values. We could try a different error distribution. iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = Gamma (), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = Gamma(), data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.532340 0.017386 30.62 &lt;2e-16 *** ## Petal.Width -0.172682 0.008915 -19.37 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Gamma family taken to be 0.08000084) ## ## Null deviance: 44.655 on 149 degrees of freedom ## Residual deviance: 12.444 on 148 degrees of freedom ## AIC: 412.86 ## ## Number of Fisher Scoring iterations: 5 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian (link=&quot;log&quot;), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(link = &quot;log&quot;), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.59485 0.04195 14.18 &lt;2e-16 *** ## Petal.Width 0.54740 0.02283 23.98 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.4808902) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 71.172 on 148 degrees of freedom ## AIC: 319.85 ## ## Number of Fisher Scoring iterations: 7 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian (link=power(0.25)), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(link = power(0.25)), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.133377 0.012699 89.25 &lt;2e-16 *** ## Petal.Width 0.198171 0.007213 27.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.4035011) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 59.718 on 148 degrees of freedom ## AIC: 293.53 ## ## Number of Fisher Scoring iterations: 6 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) All of this to point out that you can in essence perform transformations within the link and you can use the AIC values to compare different models and select the best one for your data (lowest AIC value). In the end, our first model was the best fit to our data, though it wasn’t perfect. Over Dispersion is measured by comparing variance of the response variable to the variance of the linear predictors, when the variance of the response variable is larger than that of the linear predictor, we have overdispersion, meaning those data are more weidley spread than the explanatory variables, and indicates that additional covariates need to be identified. At this time, let’s assume that we don’t have additional variables to add to our GLM model. Let’s run this and generate a nice plot! iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) If you want to make predictions: add this info if you want to helpful summary page 507. "],["mixed-effects-models.html", "Chapter 20 Mixed Effects Models 20.1 Examples in R", " Chapter 20 Mixed Effects Models Observations of data aren’t always independent, violating an assumption of our GLMs. Never fear, there are statistical models that deal with that; namely, our aforementioned mixed effects models. Let’s first cite some examples of non-independent observations: Time-series data, in which we are resampling the same points multiple times. Blocked data. For example, plants within a plot. We might expect individuals within 1 plot to respond similarly given higher likelihood of relatedness or greater similarity in microsite conditions, relative to plants in other plots. *Nested data. For example, multiple blood samples taken from an individual. We’d want to indicate that these data are non-independent and likely to be more similar to each other than to samples taken from another individual. Why call these models ‘mixed effects’? Because these models contain both fixed and random effects. Fixed effects = Variables of interest. We are interested in how these factors affect our response variable. Factors and levels of factors have been specifically chosen, and are replicable in future experiments. Random effects = Variables that may explain variation, but that we are not interested in and that we are not interested in replicating in future experiments. For instance, we don’t care if we have the same exact block or we sample blood from the same exact person or we collect data in the same year. 20.1 Examples in R Let’s take a look at running mixed effects models in R. Since agricultural researchers are the royals of blocking, we will take a look at the oat dataset. Be sure to load the lmerTest package, since this package will actually generate p-values. Want to read some snarky statistics back and forth? Check out commentary on developers of the lmer package on why they don’t include p-values… sigh… #load libraries and datasets suppressWarnings(library(&#39;faraway&#39;)) suppressWarnings(library(&#39;lmerTest&#39;)) suppressWarnings(library(&#39;lme4&#39;)) suppressWarnings(library(&#39;tidyverse&#39;)) suppressWarnings(library(&#39;emmeans&#39;)) suppressWarnings(library(&#39;multcomp&#39;)) data(&#39;oatvar&#39;, package=&#39;faraway&#39;) First, let’s talk about oats. The oats dataset ‘Data from an experiment to compare 8 varieties of oats. The growing area was heterogeneous and so was grouped into 5 blocks. Each variety was sown once within each block and the yield in grams per 16ft row was recorded.’ - Official description see ?faraway::oats When we are blocking, I find it really helpful to draw out the statistical design (Draw out what is happening). For now, let’s just take a look at the data. ggplot(oatvar, aes(y=yield, x=block, color=variety)) + geom_point() + geom_line(aes(x=as.integer(block))) Let’s just ask how does variety affect yield. The oat-folks have planted the varieties in 5 replicate blocks. This is a smart thing to do, since variation in microsite conditions will cause differences in yield, and they want their yield estimates to reflect this. While microsite effects are interesting, keep in mind, this is not the variable of interest and they would not try to precisely place the same plots. In other words, the blocks are a random variable. We would expect individuals within blocks to respond more similarly to each other than to those plants outside and individuals block, so let’s account for that variation! The syntax is simple. model &lt;- lmer(responsevariable ~ predictorvariable + (1|block), data=dataset). oatmodel.1 &lt;- lmer( yield ~ variety + (1|block), data=oatvar) anova(oatmodel.1) ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## variety 77524 11075 7 28 8.2839 1.804e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This equation basically says let yield means vary by block. There is a statistically significant effect of variety. So let’s do a post-hoc test to see which varieties are different from the other. oatmodel.1 &lt;- lmerTest::lmer( yield ~ variety + (1|block), data=oatvar) dispairwise1 &lt;- emmeans::emmeans(oatmodel.1, ~variety, type = &quot;response&quot;); dispairwise1 ## variety emmean SE df lower.CL upper.CL ## 1 334 21 15.2 290 379 ## 2 377 21 15.2 332 421 ## 3 363 21 15.2 318 407 ## 4 287 21 15.2 242 332 ## 5 439 21 15.2 395 484 ## 6 331 21 15.2 286 375 ## 7 318 21 15.2 274 363 ## 8 384 21 15.2 339 429 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 dis_glht &lt;- glht(oatmodel.1, mcp(variety = &quot;Tukey&quot;)) #need to fix the below line #LetterResults &lt;- multcomp::cld(dis_glht, alpha=0.05, Letters = LETTERS) Add content on nested designs - need to find a decent dataset #why can&#39;t i use the oat dataset from MASS? #model &lt;- lmer(yield ~ variety + Fertilizer + (1|plot/subplot), data=oats) Add content crossed design Add content random slope and intercept "],["before-after-control-impact.html", "Chapter 21 Before-After-Control-Impact 21.1 Which design 21.2 BACI Design 2", " Chapter 21 Before-After-Control-Impact 21.1 Which design Four standard BACI DesignsFour standard BACI designs: 1. Single impact site; single control site; one year before; oneyear after 2. Single/multiple impact site; multiple control sites; one yearbefore; one year after 3. Single impact site; single control site; multiple yearsbefore; multiple years after. 4. Single impact site; multiple control sites; multiple yearsbefore; multiple years after See this tutorial 21.2 BACI Design 2 #test1 &lt;- lmer(responsevariable ~ GrazingTreatment+Time+GrazingTreatment:Time, random~1|Plot/Time, data=yourdata) "],["time-is-a-flat-circle.html", "Chapter 22 Time is a flat circle", " Chapter 22 Time is a flat circle "],["describing-ecological-patterns.html", "Chapter 23 Describing ecological patterns 23.1 When to use model selection? 23.2 Step 1: Identifying predictor variables or co-variates of importance 23.3 Step 2: Removing colinear variables 23.4 Example: Reducing colinear climate variables 23.5 Step 3: Select the best model", " Chapter 23 Describing ecological patterns When working at landscape-scales, we often need to employ model selection techniques to identify important predictor variables or co-variates to explain response patterns. There are several discrete steps and important considerations when completing such analyses, but before that, let’s talk a little about the goals of model selection. 23.1 When to use model selection? Put simply, model selection is used when you have multiple competing hypotheses or models and want to: Identify the best-supported model give the data Quantify the relative support for each model Avoid overfitting by penalizing overly complex models Now, competing hypotheses can mean many things. Typically, I have strong hypothesis related to a research question, but less understanding of what covariates could mediate, enhance, or otherwise alter the effect of the predictor variables on the response variable. However, you can be more strategic in your tests, exploring whether data conform better to particular hypotheses or others. In this tutorial, we will examine a dataset related to understanding resilience to drought in the Southwest. From 2020-2021, the Southwestern US experienced an extreme drought event that resulted in widespread die-offs several woody species. To derive models that predict resilience or recovery in Emory oak woodlands, we collected demographic and community data for overstory and understory communities at 100 plots across Emory oak’s range. We measured resilience or recovery in two ways. First, we calculated a metric of community divergence between over- and understory communities, and second, we retrieved remotely sensed data that estimates productivity on the landscape. Building on resilience theory, we hypothesized that stands that were better connected and more diverse would exhibit higher resilience or recovery. Additionally, those sites experiencing lower climatic stress, before, during and after the drought would perform better (i.e., seedling communities exhibit less divergence from the adult plant community, and productivity returns to or exceeds pre-drought levels). However, there are many, many ways to describe climate, and many climatic variables are correlated, and in complex systems, one pillar of resilience (connectivity, diversity) may drive recovery. For this reason, we applied standard model selection techniques to appropriately model resilience/recovery in this system. The results of these models were used to identify stands for restoration treatment likely to be resilient to perturbations like drought. 23.2 Step 1: Identifying predictor variables or co-variates of importance In this example, we identified several predictor variables based on resilience theory. However, climatic covariates could also reveal patterns of stress experienced by oaks. Given the numerous ways that climatic data can be summarized, we first identified variables that could be important for our system. Semi-arid regions of the Southwest are water limited, so we wanted to include a variety of precipitation metrics. Since precipitation patterns are bimodal (we receive roughly half our precipitation in the winter, often as snow, and the other half during the summer monsoons), we wanted to include both annual summaries of climate as well as monsoon specific summaries (including winter precipitation would be a strategic idea as well). Additionally, temperatures influence drought stress as well as respiration rates, affecting tree performance. Maximum and minimum temperatures may affect distinct physiological processes. For instance, minimum temperatures occur primarily at night, and affect the energy balance of trees, since higher temperatures increase respiration rates during a time when trees are photosynthesizing. This can lead to a loss of energetic stores to allocate to growth, reproduction and tissue maintenance and repair. Maximum temperatures, mostly occurring during the day, affect the ability to photosynthesize and maintain water balance. To reduce complexity, we decided to summarize only mean temperatures, rather than mean minimum or maximum temperatures, since we felt temperature would be less important that precipitation in this system. When identifying covariates for your system, think through likely drivers of performance, which in addition to climate could include information on soils or disturbances, like grazing, fires, and human activity. 23.3 Step 2: Removing colinear variables When two or more predictor variables are highly collinear (i.e., strongly correlated with each other), they essentially carry the same information. This can confuse your model in several ways: Unstable estimates: The model struggles to decide how much each variable contributes, which can lead to inflated or inconsistent coefficient estimates. Reduced interpretability: It’s harder to understand the effect of each variable because their influence overlaps — they “share the credit.” Misleading significance tests: Collinearity can make some variables appear non-significant, even if they’re actually important, because their shared information is spread across multiple predictors. Poor model generalization: Models with collinear variables are more likely to overfit to your data and perform worse when applied to new situations. By removing or combining collinear variables, you help the model focus on independent sources of information, making it more stable, interpretable, and accurate. So let’s do that! First, we will want to select a method to remove correlated variables. We have two major options - We can either automate variable removal or use expertise to select variables. 23.3.1 Automated Variable Removal Using statistical metrics like correlation thresholds or Variance Inflation Factor (VIF) to reduce multicollinearity. 23.3.1.1 Merits: • Objective &amp; reproducible: Provides consistent results across datasets. • Handles high-dimensional data: Especially useful when there are many predictor variables. • Improves model stability: Reduces inflated standard errors and overfitting risk in regression models. • Compatible with model selection workflows: Can be integrated with stepwise selection, LASSO, or random forest importance. Note: I only completely automate variable selection when I’m batch processing loads of data and the objective of the analysis is to look broadly across numerous comparisons. As an example, I automate variable removal when I’m generating a large number of Species Distribution Models to explore richness landscape-level patterns. 23.3.1.2 Limitations: • Ignores ecological meaning: May discard biologically relevant or interpretable variables. • Over-reliance can lead to information loss: For example, two drought metrics may both be predictive, even if correlated, because they represent different climate processes (input vs. deficit). • Thresholds are somewhat arbitrary: Why r &gt; 0.7 or VIF &gt; 10? Different fields use different cutoffs. 23.3.2 Expert Knowledge-Driven Selection Manually selecting variables based on ecological theory, prior studies, or local knowledge. 23.3.2.1 Merits: • Maintains interpretability: You keep variables with clear ecological meaning. • Aligns with study goals: You can prioritize variables that are hypothesized drivers of your response. • Supports story-driven science: Especially useful when communicating with land managers, policymakers, or interdisciplinary teams. 23.3.2.2 Limitations: • May retain collinearity: Which can destabilize models if unaddressed. • Subjectivity: Different experts may choose different variables. • Less scalable: Can be slow or inconsistent across many datasets or repeated analyses. 23.3.3 Blended Strategy (Recommended) Use expert knowledge to define the pool of candidate predictors, then apply statistical tools to reduce redundancy within that pool. Workflow: 1. Start with expert-justified variables. 2. Check for high correlations or high VIFs. 3. If two variables are strongly collinear, decide which is more interpretable or central to your ecological question. 4. Optionally test models with and without each to evaluate performance/stability. 23.4 Example: Reducing colinear climate variables Let’s remove colinear climate variables! First, we can use a fully automated method, then we will transition to the blended strategy. We can contrast these approaches with each other, and with a dataset we would have put together with no statistical information on covariance! We divided the climatic environment into three categories: 1) Pre-drought baseline conditions, 2) Climatic change rates, and 3) Post-drought recovery conditions. Sectioning different categories of variables that you suspect a priori influence the response variable is a strategy that allows you to capture different ecological processes, while reducing colinearity of predictors. library(car) library(dplyr) library(purrr) library(tibble) # # Load directly from Google Drive (readr-style) # library(readr) # # data &lt;- read_csv(&quot;https://drive.google.com/uc?export=download&amp;id=1Yap0vVnrf-5nJemsFQ8sSIH3RNLxU5WF&quot;) # # # Select only numeric predictors and drop rows with missing values # numeric_predictors &lt;- data %&gt;% # dplyr::select(where(is.numeric)) # # # Visualize # library(corrplot) # cor_matrix &lt;- cor(numeric_predictors, use = &quot;complete.obs&quot;) # corrplot(cor_matrix, method = &quot;color&quot;, type = &quot;lower&quot;, tl.cex = 0.7) # # climatechange_df &lt;- read_csv(&quot;climate_change_allvariables.csv&quot;) # # # Select only numeric predictors and drop rows with missing values # numeric_predictors &lt;- climatechange_df %&gt;% # dplyr::select(where(is.numeric)) # # # Remove identifier column # predictor_data &lt;- resilience_clean %&gt;% dplyr::select(-Plot_ID) # # # Loop over each variable and calculate max VIF # vif_results &lt;- map_dfr(names(predictor_data), function(var) { # # Build formula: var ~ all other variables # formula &lt;- as.formula(paste(var, &quot;~ .&quot;)) # # Create modeling dataset: use current var as response, others as predictors # model_data &lt;- predictor_data %&gt;% # dplyr::select(-all_of(var)) %&gt;% # mutate(response = predictor_data[[var]]) # # Fit the model # model &lt;- lm(response ~ ., data = model_data) # # Get VIFs # vif_vals &lt;- vif(model) # tibble(response_var = var, max_vif = max(vif_vals, na.rm = TRUE)) # }) # # print(vif_results) What happened here? Let’s repeat the process. Repeat for the other suites of climatic variables: climate change and post-drought conditions. Then, merge all datasets, and calculate VIFs again. That’s it! We have our final set of climatic predictors! I repeated this process again for other types of variables, including diversity estimates and connectivity. As you can see, generating a biologically-grounded, statistically sound predictor dataset is an iterative process, but worth the effort! 23.5 Step 3: Select the best model Now that we have assembled a dataset of climate predictors, we will want to select the model that best explains variation in our response variable, in this case a measure of community dissimilarity (labeled ‘bray_curtis’ in the dataset). Model selection is the process of identifying the best model(s) from a set of candidates that explain or predict a response variable based on a set of predictors. Below are the major approaches, their definitions, benefits, drawbacks, and primary applications in ecology and related disciplines. Model selection is a hotly debated topic in statistics, with disagreements about when and how it should be used. Some argue it’s essential for identifying the best-supported models, while others caution that it can be misused, leading to overfitting or misinterpretation if not grounded in strong theory and careful reasoning. As an ecologist working in complex systems, I typically choose to use some sort of model selection tool. Here’s why: Complex systems often need simplification: In ecology (and many other fields), there are often many plausible predictors. Model selection helps identify which ones meaningfully contribute to explaining patterns, rather than relying solely on intuition or arbitrary choices. It guards against overfitting: By comparing models using criteria like AIC, BIC, or cross-validation error, model selection balances fit with complexity, helping you avoid models that explain your current data perfectly but perform poorly on new data. It enables hypothesis comparison: You can formally compare models that reflect different ecological hypotheses — e.g., does drought or disturbance better explain recovery? — rather than testing each variable in isolation. Let’s explore several popular methods of model selection. 23.5.1 Major Types of Model Selection: Overview, Benefits, Drawbacks, and Applications 23.5.1.1 Information-Theoretic Approaches (e.g., AIC, BIC) What it is: • Compares multiple models based on goodness of fit penalized by model complexity. • AIC (Akaike Information Criterion) focuses on minimizing information loss. • BIC (Bayesian Information Criterion) penalizes complexity more harshly and favors simpler models as sample size increases. Benefits: • Allows comparison of non-nested models. • Emphasizes parsimony (balancing fit with simplicity). • Useful in exploratory studies with many competing hypotheses. Drawbacks: • Can favor overly complex models if predictors are correlated or sample size is small (AIC). • Results depend on the candidate model set — unconsidered models are ignored. Applications: • Ecology, epidemiology, evolutionary biology. • Useful when comparing alternative ecological hypotheses or predictor sets. 23.5.1.2 Stepwise Regression (Forward, Backward, Bidirectional) What it is: • Automatically adds or removes predictors based on p-values or information criteria (e.g., AIC). • Forward: starts with no predictors; adds variables one at a time. • Backward: starts with all variables; removes one at a time. Benefits: • Easy to implement. • Reduces large variable sets quickly. Drawbacks: • Ignores model uncertainty. • Inflated Type I error rates. • Final model can be unstable (small changes in data can lead to different models). Applications: • Often used in exploratory analyses. • Sometimes used in automated workflows, though not recommended for inference. 23.5.1.3 All-Subsets Regression (aka Best Subsets Selection) What it is: • Evaluates all possible combinations of predictors and ranks models based on a selection criterion (AIC, BIC, R-squared, etc.). Benefits: • Thorough exploration of model space. • Helps identify the best model given a criterion. Drawbacks: • Computationally intensive, especially with many predictors. • High risk of overfitting without careful constraints. Applications: • Model exploration when the number of predictors is moderate (&lt;20). • Common in applied ecological modeling where model space is small and well-defined. 23.5.1.4 Cross-Validation (CV) What it is: • Divides the dataset into training and testing subsets repeatedly. • Evaluates model performance based on predictive accuracy (e.g., RMSE, classification error). • K-fold CV is common (e.g., 5- or 10-fold). Benefits: • Focuses on model predictive performance. • Helps avoid overfitting. Drawbacks: • Does not provide information about explanatory power. • More computationally demanding. Applications: • Machine learning, predictive modeling. • Useful in ecological forecasting, SDMs, or models aimed at out-of-sample prediction. 23.5.1.5 Bayesian Model Selection What it is: • Uses Bayes factors or posterior probabilities to compare models. • Accounts for model uncertainty explicitly. Benefits: • Incorporates prior knowledge. • Quantifies model uncertainty. • Can average over multiple models (Bayesian model averaging). Drawbacks: • Requires strong computational resources. • Sensitive to choice of priors. Applications: • Hierarchical models, small-sample inference, decision analysis. • Growing use in ecological and conservation decision-making. 23.5.1.6 Regularization Methods (e.g., Lasso, Ridge, Elastic Net) What it is: • Shrinks coefficients by adding a penalty term to the loss function. • Lasso (L1) can set some coefficients to zero (variable selection). • Ridge (L2) shrinks coefficients but keeps all predictors. Benefits: • Handles multicollinearity well. • Useful in high-dimensional datasets. Drawbacks: • Less interpretable coefficients. • Choice of tuning parameter (lambda) requires validation. Applications: • Genomics, remote sensing, high-dimensional ecological models. • When predictor &gt; sample size. 23.5.1.7 Summary of model selection techniques For most applications, I use AIC-based approaches. They offer a nice balance between model fit and complexity, and you can average across top models to incorporate model uncertainty (explained more below). Here are a couple of exceptions: • If I had very high-dimensional data (e.g., genomics, remote sensing), I’d switch to LASSO (Least Absolute Shrinkage and Selection Operator). Regularization technique that performs variable selection and regularization simultaneously, so it is computationally efficient. • If the goal was out-of-sample prediction, I’d rely on cross-validation or machine learning methods with holdout sets. I use these techniques often when creating species distribution models and I’m trying to extrapolate suitable habitat across the landscape. • If I needed to quantify uncertainty explicitly (e.g., in decision analysis), I’d consider Bayesian model selection or Bayesian model averaging. 23.5.2 Stepwise regression based on AIC (Akaike Information Criterion). library(MASS) #full_model &lt;- glm(response ~ ., data = data_reduced, family = binomial) #stepwise_model &lt;- stepAIC(full_model, direction = &quot;both&quot;) #summary(stepwise_model) LASSO (Least Absolute Shrinkage and Selection Operator) Regularization technique that performs variable selection and regularization simultaneously. Benefits: Automatic Variable Selection: LASSO can automatically shrink some coefficients to zero, effectively performing variable selection and reducing model complexity. Handles High Dimensionality: Particularly useful when the number of predictors is much larger than the number of observations. Regularization: Helps prevent overfitting by adding a penalty to the magnitude of coefficients. Interpretability: The resulting model is often simpler and easier to interpret, as it includes only a subset of the predictors. Computational Efficiency: Computationally efficient and can be solved using convex optimization methods. Drawbacks: Bias: The shrinkage can introduce bias into the estimates of the coefficients. Model Assumptions: Assumes linear relationships between predictors and the response variable. Choice of Penalty Parameter: The performance depends on the choice of the penalty parameter (lambda), which requires cross-validation to tune. Cannot Handle Multicollinearity Well: While LASSO can select variables, it might not perform well in the presence of high multicollinearity compared to other techniques like ridge regression. library(glmnet) #x &lt;- model.matrix(response ~ ., data_reduced)[, -1] #y &lt;- data_reduced$response #lasso_model &lt;- cv.glmnet(x, y, alpha = 1, family = &quot;binomial&quot;) #best_lambda &lt;- lasso_model$lambda.min #best_model &lt;- glmnet(x, y, alpha = 1, family = &quot;binomial&quot;, lambda = best_lambda) #coef(best_model) Best Subset Selection; Evaluate all possible subsets of predictors and select the best model based on a criterion like AIC, BIC, or adjusted R-squared. Benefits: Exhaustive Search: Considers all possible combinations of predictors, ensuring the best possible model according to a specified criterion (e.g., AIC, BIC). Model Performance: Often provides the best fit in terms of the criterion used for selection. Flexibility: Can be used with any type of regression model and can include interactions and polynomial terms. Drawbacks: Computationally Intensive: Becomes impractical with a large number of predictors due to the exponential increase in the number of models to be evaluated. Overfitting: Risk of overfitting, especially when the number of predictors is large relative to the number of observations. Multicollinearity: Does not address multicollinearity among predictors, which can lead to unstable coefficient estimates. library(leaps) #best_subset &lt;- regsubsets(response ~ ., data = data_reduced, nbest = 1, really.big = TRUE) #summary(best_subset) Model Averaging; Perform model averaging to account for model uncertainty. Benefits: Accounts for Model Uncertainty: By averaging over multiple models, it incorporates model uncertainty into the final predictions. Improved Predictive Performance: Often leads to better predictive performance by averaging out the errors of individual models. Flexibility: Can be applied to various types of models and selection criteria. Stability: Provides more stable estimates by considering multiple models rather than relying on a single best model. Drawbacks: Complexity: Results in a more complex model that can be harder to interpret compared to selecting a single best model. Computationally Intensive: Requires fitting and averaging a large number of models, which can be computationally demanding. Weight Selection: The choice of weights for averaging (e.g., based on AIC, BIC, or cross-validation errors) can influence the final model and may not always be straightforward. Potential for Overfitting: If not carefully managed, averaging over too many models can still lead to overfitting, particularly if the individual models are not regularized. library(MuMIn) options(na.action = &quot;na.fail&quot;) #global_model &lt;- glm(response ~ ., data = data_reduced, family = binomial) #dredged_models &lt;- dredge(global_model) #averaged_model &lt;- model.avg(dredged_models, subset = delta &lt; 2) #summary(averaged_model) "],["plot-establishment.html", "Chapter 24 Plot establishment", " Chapter 24 Plot establishment One other thing to consider, is the placement of plots across the landscape. Though this is step one of the process, since many folks will have previously established plots, we will discuss here! Spatially balanced random sampling offers several benefits, particularly in ecological and environmental studies. Here are some of the key advantages: Improved Representativeness Coverage: Ensures that the sample points are spread out evenly across the study area, which helps in capturing the spatial heterogeneity of the environment. Reduction of Bias: Minimizes the chances of over-sampling or under-sampling specific areas, leading to more accurate and generalizable results. Enhanced Statistical Efficiency Reduced Variance: By evenly distributing sample points, spatially balanced sampling often reduces the variance of the estimates compared to simple random sampling. Better Inference: Provides better estimates of population parameters and improves the precision of spatially explicit models. Flexibility and Adaptability Multiple Scales: Can be applied at various spatial scales, making it suitable for different types of studies ranging from local to regional levels. Integration with GIS: Easily integrated with Geographic Information Systems (GIS) to facilitate sample design and data collection. Cost-Effectiveness Efficient Use of Resources: Reduces travel time and costs associated with fieldwork by ensuring that sample locations are optimally distributed. Focused Sampling Effort: Enables targeted sampling in areas of interest while still maintaining a representative coverage. Robustness to Spatial Autocorrelation Handling Spatial Dependencies: Helps in accounting for spatial autocorrelation by ensuring that samples are not clustered, which can lead to more reliable statistical analyses. Examples of Applications Ecological Monitoring: Used to monitor biodiversity, habitat quality, and species distributions across large landscapes. Environmental Assessment: Applied in studies assessing soil contamination, water quality, and air pollution to ensure comprehensive spatial coverage. Resource Management: Useful in forestry, agriculture, and fisheries to assess the distribution and abundance of resources. Key Methods and Tools Spatially Balanced Sampling Algorithms: Such as the Generalized Random-Tessellation Stratified (GRTS) design. R Packages: spsurvey package in R provides tools for implementing spatially balanced sampling designs. library(spsurvey) # Define the study area and number of sample points #study_area &lt;- as.spatialPolygons(my_shapefile) #n_samples &lt;- 100 # Generate spatially balanced sample points #sample_points &lt;- grts(study_area, n = n_samples) # Plot the sample points #plot(study_area) #points(sample_points, col = &quot;red&quot;) "],["bootstrapping-and-resampling.html", "Chapter 25 Bootstrapping and resampling", " Chapter 25 Bootstrapping and resampling "],["population-sensation.html", "Chapter 26 Population sensation 26.1 Population characteristics 26.2 Planning a census 26.3 Life cycle diagrams 26.4 Population demographic models 26.5 Integral projection models 26.6 An example: Population ecology of an endangered plant 26.7 Putting it all together 26.8 Generating confidence intervals 26.9 Different life histories", " Chapter 26 Population sensation Populations contain multitudes - numerous interacting individuals of the same species with slightly different genetic backgrounds, sharing genes, colonizing new areas, responding to environmental stimuli. Populations are hot-pots of evolution and essential for understanding species viability, especially when species are rare. Population-level studies have contributed fundamental ecological knowledge in evolution, range dynamics, and species conservation. Now that we are all jazzed about populations, let’s learn about how to describe them and their dynamics quantitative! May your knowledge acquisition be exponential! 26.1 Population characteristics In population ecology, we commonly describe populations in terms of size and structure. Size is simply the number of individuals in a population and structure refers to the proportion of individuals across age or size classes. For rare species or species with low population sizes, population size can be directly estimated through a census. Just as it seems, a census is when each individual is counted. We often collect information pertinent to understanding demographic vital rates of individuals that are censused - just like we do in the U.S. census. For plants, rather than collect information on religious background or age as we would for populations of humans, we typically record the size of the plant and other salient characteristics derived from an understanding of the species’ breeding system, dispersal mechanism, life history, and ecology. When species are abundant, we use other methods to estimate population size, such as density (i.e., how many individuals occur within a particular area) or sub-sampling (i.e., collecting census data within a plot). If a species if cryptic, meaning hard to observe (as is the case for most animals), we use mark-recapture or occupancy modeling to estimate population size and structure. 26.2 Planning a census Censuses are the ideal method for collecting demographic data, since it allows in-depth and comprehensive examination of the population (and it’s dynamics!). Let’s discuss some considerations for establishing a census protocol. When conducting a census, you want to plan on capturing critical life events and ensure that you are able to capture those life events through time (for multiple years). Let’s look at an example and establish a plan to census individuals within a population of this hypothetical species. The figure above shows a typical phenological pattern for an understory plant species in the eastern deciduous forest. These plants are dormant throughout the winter when temperatures are cold enough to freeze plant tissue. All plants, adults and new seedlings, emerge in the spring, and grow to their full size for the summer over a few week period in early spring. Then, they begin flowering and seed development in late summer, then disperse seeds into the fall. The first census indicated in this figure takes place after emergence in the spring once plants have reached their final size for the growing season. The census is planned to occur as early as possible post-growth in order to assess recruitment (new seedlings that enter the population), since seedlings tend to start to die-off through time. Seeds of this species require an 18-month stratification period prior to germination. In order to census across all members of the population, including seeds, we need to include the second census to quantify the number of seeds present at census 1, since counting seeds post-dispersal is almost impossible. Note that we could capture individuals across all important classes, adult plants, seedlings and seeds, if we conducted a single census at time point 2. Why not conduct a single census? In this case, the researchers were interested in causes of mortality of plants, particularly new germinants, across the growing season. By conducting the census in the spring, they were able to identify all plants that emerged that year and note if those plants were lost during the growing season and in many cases ascribe a reason for the mortality of the plant. 26.3 Life cycle diagrams In the above example, the census was timed to measure the performance and fate of important classes within the population. A useful tool for developing census protocols and demographic models is called a life cycle diagram. A life cycle diagram indicates important life stages and possible transitions among those stages. Continuing with our example above, we develop the following life history diagram. Here, you will note several important demographic characteristics of this species. First, on the right hand side of the diagram, you can see that the researchers have classified plants into several groups: new seedlings, &gt;1 year old seedlings, juveniles, small adults and large adults. These categories were selected because individuals within the categories share similar rates of reproduction and survival (vital rates). On the left hand side of the diagram, you will see that this species forms a seedbank and that seeds within this seed back persist around 45 months. 26.4 Population demographic models 26.5 Integral projection models Instead of binning individuals into stages, Integral Projection Models (IPMs) are built upon linear models that relate a state variable (usually a metric of size in plants) to important vital rates. 26.6 An example: Population ecology of an endangered plant Pectis imberbis is an endangered plant species endemic to southern Arizona. In 2019, several researchers from NAU traveled to the largest population of P. imberbis in the state located on the Coronado National Memorial. They tagged, mapped and measured a sub-sample of this population in order to identify an appropriate state variable for P. imberbis. Using model selection tools (i.e., Aikaike Information Criterion (AIC)), the size metric that best explained variation in growth, survival and reproduction was selected. For P. imberbis, researchers explored a variety of state variables, including number of leaves, length of the longest leaf, stem number, height, and composite variables based on this metrics (like leaf number*number of leaves to estimate total plant foliage). In this case, height was the best predictor of performance and will serve as the state variable for demographic analyses. First, let’s load a few important packages and set our working directory. #Note that you have to go to the CRAN website to install IPMpack for the first time: #install.packages(&quot;IPMpack&quot;, repos = &quot;http://R-Forge.R-project.org&quot;, type = &quot;source&quot;) #devtools::install_github(&quot;CRAN/IPMpack&quot;) #Load packages #library(IPMpack) library(fields) library(car) library(tidyverse) library(grid) library(gridExtra) library(ggthemes) #remember in your own work that is it really convenient to set up a working directory! Here is an example: #setwd(&quot;/Users/sks379/Desktop/pectisanalyses/FinalPectisAnalyses&quot;) #laptop Once a state variable was identified, the team went back the next several years and collected demographic data on all plants. Let’s build our model for the first pair of transition years. #read in data (it needs to be imported as a dataframe names pectisdata) #pectisdata &lt;- read.csv(&quot;/Users/sks379/Desktop/pectisanalyses/FinalPectisAnalyses/FinalTransitionMatrices/exampleIPMendangeredplant.csv&quot;, header=TRUE) url &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=10vtDeB4yXtic7lLa8oTpCDQft10vtYDM&quot; pectisdata &lt;- read.csv(url) #exclude poor quality data #pectisipm &lt;- dplyr::filter(pectisdata, Exclude == &quot;0&quot;) #prepare the dataset pectis &lt;- as.data.frame(pectisdata) pectis$size &lt;- as.numeric(as.character(pectis$size)) pectis$sizeNext &lt;- as.numeric(as.character(pectis$sizeNext)) head(pectis) ## id size surv sizeNext fec1 fec2 Site DeerBrowse2020 BrowseLevel2020 Cover2020 ## 1 1 69.3 0 NA 1 154.5 CNM N &lt;NA&gt; L ## 2 4 57.7 1 58.4 1 30.9 CNM Y L L ## 3 6 68.5 1 48.3 1 72.1 CNM N &lt;NA&gt; BG ## 4 7 101.6 1 57.4 1 257.5 CNM Y L L ## 5 8 57.9 1 68.0 1 370.8 CNM Y L BG ## 6 10 84.7 1 18.5 1 1339.0 CNM N &lt;NA&gt; BG ## ProtectedFRBrowse2020 Notes2020 Notes2021 ## 1 N ## 2 N ## 3 N INSECT DAMAGE ## 4 N ## 5 N ## 6 N Notice the structure of the dataset! This dataframe tracks the fate of all individuals in the population from time 1 to time 2. The ‘id’ column corresponds with the tag number for each plant. The ‘size’ column contains sizes (in this case heights) of individuals in time 1, while ‘sizeNext’ indicates the size at time 2. In the ‘surv’ column, the fate of the individual at time 2 is indicated by either a 0 (died) or 1 (survived). For individuals that died, we place an ‘NA’ in the sizeNext column, since that individual didn’t exist that year! Reproduction is always the most complex part of demographic modeling for plant species. Often, a reproductive cycle includes cryptic stages (seeds!) that are hard to track, may include vegetative and sexual reproductive components, and may involve several processes (like flower production and seed production) that may be important to examine to understand why population growth rates vary! Pectis imberbis forms a seed bank with seeds remaining viable for at least 3 years (this was determined through a seed cage experiment). We do not include seed bank dynamics in this model, since seed dynamics are difficult to track across multiple sites and years, and manipulating seeds seems to affect their fate (germination, viability). For this reason, we have built the models such that seeds produced in year 1 has the potential to germinate in year 2 or perish. Luckily, ignoring the seed bank for species with high rates of seed production has negligible affects on population growth, and this pattern (higher rates of viability in the year following seed production) reflects the biology of this species. The ‘IPM package’ recognizes seedlings as seedlings based on the data structure. A new seedling won’t have a size, survival or reproductive values in year 1 (NAs are added to this column), but will have a measurement in the ‘sizeNext’ column. We’ve broken reproduction into two components, fec1 and fec2. If an individual reproduced, we mark a ‘1’ in fec1, if the individual didn’t reproduce, then we add a ‘0’ to the fec1 column. For those individuals that did reproduce, the fec2 column contains the number of seeds produced. Again notice that if an individual didn’t reproduce, we place an ‘NA’ in the fec2 column. Finally, we’ve documented other observations for each individual that we think might explain population growth rates, like whether a plant has been browsed by deer or is in competition with other vegetation. IPMs are only as good as the linear models that comprise them! As a critical first step in analyses, we have to take a look at the relationship between our state variable and growth, reproduction and survival. We want to be sure to address any issues with normality and unequal variance. First, examine variance; if variation depends on the state variable, include this in the model (we’ll do this in a minute). It is fairly common in plants to see, for instance, that growth rates are more variable in larger individuals. #evaluating data for IPM construction growth &lt;- lm(sizeNext ~ size, na.action = na.omit, data=pectis) resid &lt;- residuals(growth) shapiro.test(resid) ## ## Shapiro-Wilk normality test ## ## data: resid ## W = 0.29287, p-value &lt; 2.2e-16 plot(fitted(growth), residuals(growth)) abline(lm(residuals(growth)~fitted(growth))) This figure is showing a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis. We use these scatterplots to detect non-linearity, unequal error variances, and outliers. The residuals should “bounce randomly” around the 0 line, indicating that the assumption that the relationship is linear is reasonable. You also show see that the residuals roughly form a “horizontal band” around the 0 line, indicating that the variances of the error terms are equal. Finally, we looking for a dataset in which no one residual “stands out” from the basic random pattern of residuals. Let’s look at these residuals another way and use label the outliers so that we can remove them if necessary! id.n = length(pectis$id) qqPlot(growth, distribution = &quot;norm&quot;, id.method=&quot;y&quot;, id.cex = 0.6, id.n=id.n, id.col = &quot;blue&quot;, id.location = &quot;ab&quot;) ## [1] 551 628 A quantile-quantile plot, often abbreviated as Q-Q plot, is a graphical tool used to assess whether a dataset follows a particular theoretical distribution, such as the normal distribution. It compares the quantiles of the observed data against the quantiles of the expected theoretical distribution. Here’s how to interpret a Q-Q plot: The x-axis of the Q-Q plot represents the theoretical quantiles from a specified distribution (e.g., the normal distribution). The y-axis represents the quantiles of the observed data. If the points on the Q-Q plot fall approximately along a straight line, it suggests that the data follows the theoretical distribution. Deviations from the straight line indicate departures from the assumed distribution. If points are above the line, it suggests that the observed values are higher than expected for that quantile. If points are below the line, it suggests that the observed values are lower than expected for that quantile. The ends of the Q-Q plot are often of particular interest. Deviations in the tails can indicate differences in tail behavior. Note to self: (In this example, there is no pattern to the residuals, so we don’t need to include size based variance models, but in final tutorial, maybe add a picture of size based variation (can grab pic from mee312146)). Uh oh. Our slope is wonky and there are those darn outliers. From a brief once-over, the outliers maybe driving the slope issue that we are observing. It is good practice to try to determine whether it is legitimate to remove outliers from any statistical analysis. In demographic studies, there are so many plants and many reasonable possibilities for why we may observe a strange transition from one year to the next. For example: 1) In the first year, someone measured the plant, but it had already been browsed by a deer and so was extra short, and then appears to grow like wild in the following year 2) Someone took data on the wrong space on the datasheet 3) Someone couldn’t find a mama plant, who actually died, so accidentally measured a baby that had germinated in a nearby spot Given this, unlike with standard statistical analyses, we tend to be less stringent about when we remove outliers. Let’s take a look at those residuals. row_index &lt;- 161 value &lt;- pectis[row_index,] print(value) ## id size surv sizeNext fec1 fec2 Site DeerBrowse2020 BrowseLevel2020 Cover2020 ## 161 191 71 1 47.3 1 154.5 CNM N &lt;NA&gt; PG ## ProtectedFRBrowse2020 Notes2020 Notes2021 ## 161 N #or you can generate the id and use that to subset (just looking at the id number from above) target_id &lt;- 68 row_data_index &lt;- pectis[pectis$ID == target_id, ] print(row_data_index) ## [1] id size surv sizeNext ## [5] fec1 fec2 Site DeerBrowse2020 ## [9] BrowseLevel2020 Cover2020 ProtectedFRBrowse2020 Notes2020 ## [13] Notes2021 ## &lt;0 rows&gt; (or 0-length row.names) #check out the other outlier row_index &lt;- 84 value &lt;- pectis[row_index,] print(value) #note id number is 627 ## id size surv sizeNext fec1 fec2 Site DeerBrowse2020 BrowseLevel2020 Cover2020 ## 84 106 30.2 1 38.7 1 30.9 CNM Y M PG ## ProtectedFRBrowse2020 Notes2020 Notes2021 ## 84 Y Unsurprisingly, there is no ready reason why individuals 161 and 84 would be acting strangely BUT they do behave in weird ways!!! (Did someone miss a decimal point?) AND I want to favor the the numerous individuals that conform to the model. Let’s remove those one or more outliers! I take a gentle hand with this removal of outliers and will start with just removing 161. pectis &lt;- pectis[-c(161),] growth &lt;- lm(sizeNext ~ size, na.action = na.omit, data=pectis) par(mfrow=c(1,2),mar=c(4,4,2,1)) id.n = length(pectis$id) plot(sizeNext ~ size, xlab=&quot;Height (cm) year 1&quot;, ylab=&quot;Height (cm) year 2&quot;, data=pectis) qqPlot(growth, distribution = &quot;norm&quot;, id.method=&quot;y&quot;, id.cex = 0.6, id.n=id.n, id.col = &quot;blue&quot;, id.location = &quot;ab&quot;) ## 551 628 ## 550 627 abline(lm(residuals(growth)~fitted(growth))) Uh oh. Still not normal. Let’s remove additional outliers. pectis &lt;- pectis[-c(82, 84),] growth &lt;- lm(sizeNext ~ size, na.action = na.omit, data=pectis) resid &lt;- residuals(growth) shapiro.test(resid) ## ## Shapiro-Wilk normality test ## ## data: resid ## W = 0.29196, p-value &lt; 2.2e-16 par(mfrow=c(1,2),mar=c(4,4,2,1)) id.n = length(pectis$id) plot(sizeNext ~ size, xlab=&quot;Height (cm) year 1&quot;, ylab=&quot;Height (cm) year 2&quot;, data=pectis) qqPlot(growth, distribution = &quot;norm&quot;, id.method=&quot;y&quot;, id.cex = 0.6, id.n=id.n, id.col = &quot;blue&quot;, id.location = &quot;ab&quot;) ## 551 628 ## 548 625 abline(lm(residuals(growth)~fitted(growth))) Yay! This is looking better now. While we are looking at size data, let’s take a look set a couple of parameters that we will need to build an IPM. Set bounds for IPM============================ To integrate the kernel, we will need: 1) boundary points (the edges of the cells defining the matrix) 2) mesh points (the centers of the cells defining the matrix and the points at which the matrix is evaluated for the midpoint rule of numerical integration) 3) step size (the widths of the cells) Boundary points==== Because size based predictions are generated from regressions, you can sometimes get projected sizes that are biologically dubious. For this reason, we create bounds on how big or small plants can become. To do this, I use the size based data from the population, and create a max and min limits that coorespond to the min/max +/- 1 standard deviation minimumsize1 &lt;- min(pectis$size, na.rm=T); minimumsize1 ## [1] 23 minimumsize2 &lt;- min(pectis$sizeNext, na.rm=T); minimumsize2 ## [1] 8.7 maximumsize1 &lt;- max(pectis$size, na.rm=T); maximumsize1 ## [1] 116.4 maximumsize2 &lt;- max(pectis$sizeNext, na.rm=T); maximumsize2 ## [1] 631 standarddev &lt;- sd(pectis$size, na.rm=T); standarddev ## [1] 15.1035 minSize &lt;- minimumsize2; minSize #true minimum ## [1] 8.7 maxSize &lt;- maximumsize2 + standarddev; maxSize #1 standard deviation all adult plants year 1 ## [1] 646.1035 nBigMatrix = 100 #dictates bin size x&lt;-seq(from=0,to=135,length=1001) #Seems fairly standard to create a matrix with these dimensions x0&lt;-data.frame(size=x,size2=x*x) Alrighty, now let’s explore relationships that will form the rest of the model! Let’s start with survival. We will use the DHARMa package to test for deviation from a binomial distribution and identify outliers. #create a glm to predict survival survival &lt;- glm(surv ~ size, na.action = na.omit, family = &quot;binomial&quot;, data=pectis) # Install and load the DHARMa package #install.packages(&quot;DHARMa&quot;, dependencies = TRUE) library(DHARMa) residuals &lt;- residuals(survival, type = &quot;response&quot;) test &lt;- testResiduals(survival) #if you need to identify outliers object1 &lt;- simulateResiduals(fittedModel = survival) outliers(object1, lowerQuantile = 0, upperQuantile = 1, return = c(&quot;index&quot;, &quot;logical&quot;)) ## integer(0) #you can do this for flowering, but this year everything flowered so you will get an error flowering &lt;- glm(fec1 ~ size, na.action = na.omit, family = &quot;binomial&quot;, data = pectis) residuals &lt;- residuals(flowering, type = &quot;response&quot;) #test &lt;- testResiduals(flowering) Everything looks good with the survival (deviation and outlier tests are non-significant (n.s.))! Now, let’s look at seed production, which is count-based and conforms to a poisson distribution. The package below isn’t working - don’t worry about it at this time - it is unusual to do this anyway! reproduction &lt;- filter(pectis, fec1 == &quot;1&quot;) seeds &lt;- glm(fec2 ~ size, na.action = na.omit, family = &quot;poisson&quot;, data = reproduction) residuals &lt;- residuals(seeds, type = &quot;response&quot;) qqnorm(residuals) qqline(residuals) test_seeds &lt;- testResiduals(seeds) object2 &lt;- simulateResiduals(fittedModel = seeds) outliers(object2, lowerQuantile = 0, upperQuantile = 1, return = c(&quot;index&quot;, &quot;logical&quot;)) ## [1] 1 2 3 4 6 7 8 9 10 11 13 14 15 16 17 18 19 20 21 22 23 24 ## [23] 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 ## [45] 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 68 69 70 ## [67] 71 72 73 74 75 76 77 78 79 80 81 83 84 85 86 88 89 90 91 92 93 94 ## [89] 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 113 114 115 116 117 ## [111] 118 119 120 121 122 123 124 125 126 128 129 130 131 132 133 134 135 136 137 138 139 140 ## [133] 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 ## [155] 163 164 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181 182 183 184 185 ## [177] 186 187 188 189 190 191 192 193 194 195 197 198 199 200 202 203 204 205 206 207 208 209 ## [199] 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 226 227 228 229 230 231 232 ## [221] 233 234 235 236 237 239 240 241 242 243 244 245 246 247 249 250 251 252 253 254 255 256 ## [243] 257 258 259 260 262 263 264 265 266 267 268 269 270 271 273 274 275 276 277 278 279 280 ## [265] 281 282 283 284 285 286 287 288 289 290 292 293 294 295 296 297 298 299 300 301 302 303 ## [287] 304 305 306 307 309 310 311 312 313 314 315 316 317 318 319 322 323 324 325 326 327 328 ## [309] 331 332 333 335 336 337 338 339 340 342 343 344 345 346 347 348 349 350 351 352 353 354 ## [331] 355 356 357 358 359 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 ## [353] 378 379 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 397 398 399 400 402 ## [375] 403 404 405 406 408 409 410 411 413 414 415 417 418 419 420 421 422 423 425 426 428 429 ## [397] 430 432 433 434 436 437 438 439 440 441 442 443 444 445 447 448 449 450 451 452 453 455 ## [419] 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 ## [441] 478 480 481 482 483 484 485 486 487 488 490 491 492 493 494 495 496 497 498 499 500 501 ## [463] 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 ## [485] 524 525 526 527 528 529 531 532 534 535 536 537 538 539 540 541 542 543 545 546 547 548 ## [507] 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 567 568 569 570 572 ## [529] 573 574 575 576 577 578 579 580 581 582 583 584 585 586 588 589 590 591 592 593 594 595 ## [551] 596 597 598 599 600 601 602 603 604 606 607 608 609 610 611 612 614 615 616 617 618 619 ## [573] 621 622 623 624 625 626 627 629 630 632 633 634 635 637 638 639 640 641 642 643 644 646 ## [595] 647 648 649 650 651 652 653 655 656 658 659 660 661 662 664 665 666 667 669 670 671 672 ## [617] 673 674 675 676 677 678 679 680 682 684 686 687 688 689 690 691 692 693 694 695 696 697 ## [639] 698 699 700 Let’s take a comprehensive look at our different regressions that will be used to build the IPM. #explore different regression models for relating growth, survival and reproduction to state variable #============================================= #explore vital rate data par(mfrow=c(3,2),mar=c(4,4,2,1)) plot(pectis$size,jitter(pectis$surv),xlab=&quot;Size (t)&quot;, ylab=&quot;Survival to t+1&quot;) plot(pectis$size,pectis$sizeNext,xlab=&quot;Size (t)&quot;,ylab=&quot;Size (t+1)&quot;) plot(pectis$size,jitter(pectis$fec1),xlab=&quot;Size (t)&quot;, ylab=&quot;Flowering probability&quot;) plot(pectis$size,pectis$fec2,xlab=&quot;Size (t)&quot;,ylab=&quot;Flower Head Number&quot;) hist(pectis$sizeNext[is.na(pectis$size)], xlab=&quot;Recruit Size&quot;, main=&quot;&quot;) All of these relationships look good. While we will retain the same state variable across all years, the nature of the relationship may change annually. For this reason, each year that we build a model, we will need to run model comparisons and select the most appropriate model. Let’s start with growth! #install.packages(&quot;IPMpack&quot;, repos = &quot;http://R-Forge.R-project.org&quot;, type = &quot;source&quot;) #devtools::install_github(&quot;CRAN/IPMpack&quot;) #see https://levisc8.github.io/ipmr/articles/ipmr-introduction.html #Load packages library(IPMpack) #growth model constuction growthModelComp(dataf = pectis, makePlot = TRUE, legendPos = &quot;bottomright&quot;, mainTitle = &quot;Growth&quot;) ## $summaryTable ## Exp. Vars Reg. Type AIC ## 1 sizeNext ~ 1 constantVar 5927.06461395333 ## 2 sizeNext ~ size constantVar 5920.14756906622 ## 3 sizeNext ~ size + size2 constantVar 5921.98357878777 ## ## $growthObjects ## $growthObjects[[1]] ## An object of class &quot;growthObj&quot; ## Slot &quot;fit&quot;: ## ## Call: ## lm(formula = Formula, data = dataf) ## ## Coefficients: ## (Intercept) ## 60.6 ## ## ## Slot &quot;sd&quot;: ## [1] 37.60413 ## ## ## $growthObjects[[2]] ## An object of class &quot;growthObj&quot; ## Slot &quot;fit&quot;: ## ## Call: ## lm(formula = Formula, data = dataf) ## ## Coefficients: ## (Intercept) size ## 39.8024 0.3132 ## ## ## Slot &quot;sd&quot;: ## [1] 37.35147 ## ## ## $growthObjects[[3]] ## An object of class &quot;growthObj&quot; ## Slot &quot;fit&quot;: ## ## Call: ## lm(formula = Formula, data = dataf) ## ## Coefficients: ## (Intercept) size size2 ## 32.075502 0.556869 -0.001828 ## ## ## Slot &quot;sd&quot;: ## [1] 37.37822 This handy piece of code quickly compares different model fits, the slope, a linear fit, and a polynomial fit. Since the lowest AIC value indicates the model-of-best-fit, then we will choose the 2nd order polynomial model. Now, let’s build our growth model! We also know from our previous analyses that the variation was equal, so we select ‘constantVar’. Finally size is continuous, so we select ‘gaussian’. #select best model - model with lowest values #go &lt;-makeGrowthObj(dataf = pectis, Formula = sizeNext~size + size2, regType = &quot;constantVar&quot;, Family=&quot;gaussian&quot;) Let’s compare survival models now! #pectis_clean &lt;- na.omit(pectis_surv) #survModelComp(dataf = pectis_clean, makePlot = TRUE, legendPos = &quot;bottomright&quot;, mainTitle = &quot;Survival&quot;) #survModelComp(dataf = pectis, makePlot = TRUE, legendPos = &quot;bottomright&quot;, mainTitle = &quot;Survival&quot;) Here, the model of best fit is the first order model. Let’s build the survival object. #select best model - model with lowest values #so &lt;- makeSurvObj(dataf = pectis_clean, Formula = surv~size+size2) The process for creating fecundity objects is not quite as streamlined, so let’s develop our own code to compare fecundity models. For P. imberbis, we break reproduction into two components: 1) whether a plant reproduces, and 2) if a plant reproduces, how many seeds are produced as a function of size. We will select the linear model. Now let’s look at seed production. #Test various fertility models to select best model #Seed production of reproductive plants Now let’s build the fecundity kernel. I will explain all of this later - all you need to do is change the formula structure following the ‘fo &lt;-’ code to reflect the models of best fit. 26.7 Putting it all together 26.8 Generating confidence intervals We will rerun it all over again - remember to update your models! #create dataframe to store results 26.9 Different life histories Let’s develop an IPM that includes both vegetative and sexual reproduction. We will use the endangered species, Stenogyne angustifolia, a species of mint endemic to Hawai’i, as an example. "],["permuting-your-brains-out.html", "Chapter 27 Permuting your brains out", " Chapter 27 Permuting your brains out "],["spatial-data.html", "Chapter 28 Spatial data", " Chapter 28 Spatial data Working with Spatial Data Introduction: Why Spatial Data Matters in Ecology Almost all ecological data has a spatial component “Everything is related to everything else, but near things are more related than distant things” (Tobler’s First Law) Spatial context influences sampling, analysis, and interpretation Ignoring spatial structure can lead to pseudoreplication and biased inference Types of Spatial Data Vector data Points — sample locations, species occurrences, sensor stations Lines — transects, streams, roads, animal movement paths Polygons — study area boundaries, habitat patches, management units Raster data Grid cells with continuous values Examples: elevation (DEMs), temperature, precipitation, NDVI, land cover Resolution matters: cell size determines detail and file size When to use which Vector for discrete features and sample locations Raster for continuous environmental surfaces Many analyses require both Visual comparison: Same landscape represented as vector vs. raster Common Spatial File Formats Vector formats FormatExtensionProsConsShapefile.shp (+ .dbf, .shx, .prj)Universal compatibilityMultiple files, 2GB limit, field name limitsGeoPackage.gpkgSingle file, no size limit, modernLess universal (but growing)GeoJSON.geojsonHuman-readable, web-friendlyLarge file sizes, less preciseKML/KMZ.kml/.kmzGoogle Earth compatibleLimited attribute supportGPS Exchange.gpxGPS device standardLimited to points/tracks Raster formats FormatExtensionProsConsGeoTIFF.tifUniversal, supports metadataCan be largeASCII Grid.ascHuman-readableVery large, slowNetCDF.ncGreat for time series, climate dataComplex structureERDAS Imagine.imgCommon in remote sensingProprietary Recommendation: GeoPackage for vector, GeoTIFF for raster when possible Coordinate Reference Systems (CRS) Why CRS matters The Earth is round; maps are flat Different systems optimize for different purposes Mismatched CRS = misaligned data = errors Geographic vs. Projected CRS Geographic (unprojected) Units: degrees (latitude/longitude) Common system: WGS84 (EPSG:4326) Good for: storing raw coordinates, GPS data, global datasets Limitation: distances and areas distorted Projected Units: meters or feet Examples: UTM zones, State Plane, Albers Equal Area Good for: measuring distances, calculating areas, local/regional analysis Limitation: distortion increases away from projection center EPSG codes Standardized numeric codes for CRS Common codes to know: 4326 = WGS84 (GPS coordinates) 4269 = NAD83 (North America) 32612 = UTM Zone 12N (Arizona/Utah region) How to check CRS in R st_crs(my_shapefile) crs(my_raster) Transforming between CRS st_transform(my_data, crs = 32612) project(my_raster, “EPSG:32612”) Common CRS problems and solutions Data won’t overlay → check and match CRS Distance calculations wrong → project to appropriate local CRS Area calculations wrong → use equal-area projection “NA” or missing CRS → assign with st_set_crs() (only if you know the correct CRS!) Reading and Writing Spatial Data in R The sf package (vector data) Modern standard, tidy-friendly st_read() and st_write() Works with dplyr verbs library(sf) "],["read.html", "Chapter 29 Read", " Chapter 29 Read plots &lt;- st_read(“sampling_plots.shp”) study_area &lt;- st_read(“boundary.gpkg”) "],["check-structure.html", "Chapter 30 Check structure", " Chapter 30 Check structure class(plots) st_geometry_type(plots) st_crs(plots) "],["write.html", "Chapter 31 Write", " Chapter 31 Write st_write(plots, “output.gpkg”) The terra package (raster data) Successor to raster package rast() to read, writeRaster() to write library(terra) "],["read-1.html", "Chapter 32 Read", " Chapter 32 Read elevation &lt;- rast(“dem.tif”) "],["check-properties.html", "Chapter 33 Check properties", " Chapter 33 Check properties res(elevation) ext(elevation) crs(elevation) "],["write-1.html", "Chapter 34 Write", " Chapter 34 Write writeRaster(elevation, “output.tif”) Worked example: Load study area boundary, sampling points, and elevation raster; verify all share the same CRS Basic Spatial Operations Vector operations Buffering — st_buffer() Clipping/intersection — st_intersection() Spatial joins — st_join() Calculating area — st_area() Calculating distances — st_distance() Raster operations Cropping — crop() Masking — mask() Extracting values at points — extract() Resampling — resample() Reclassifying — classify() Vector-raster interactions Extract raster values at point locations Zonal statistics within polygons Converting between formats Worked example: Extract elevation, slope, and aspect values for vegetation sampling plots Visualizing Spatial Data Quick plots for exploration plot(st_geometry(study_area)) plot(elevation) Publication-quality maps with ggplot2 + sf ggplot() + geom_sf(data = study_area, fill = “lightgray”) + geom_sf(data = plots, aes(color = treatment)) + theme_minimal() Adding basemaps ggmap for Google/Stamen tiles maptiles for OpenStreetMap Interactive maps with leaflet or mapview Great for data exploration and sharing mapview(plots) Spatial Autocorrelation What is spatial autocorrelation? Nearby locations tend to have similar values Positive autocorrelation: similar values cluster (most common in ecology) Negative autocorrelation: dissimilar values cluster (rare) Zero autocorrelation: spatial randomness Why it matters for statistics Violates independence assumption Inflates effective sample size Increases Type I error (false positives) Standard errors are too small Ecological examples Soil nutrients clustered by parent material Species abundance clustered by dispersal limitation Disease prevalence clustered by transmission Detecting spatial autocorrelation Visual methods Map residuals from your model Look for spatial clustering of positive/negative residuals Moran’s I Most common test Ranges from -1 (dispersed) to +1 (clustered), 0 = random Requires defining spatial neighbors/weights library(spdep) "],["create-neighbor-list.html", "Chapter 35 Create neighbor list", " Chapter 35 Create neighbor list coords &lt;- st_coordinates(plots) nb &lt;- dnearneigh(coords, d1 = 0, d2 = 1000) # neighbors within 1km weights &lt;- nb2listw(nb, style = “W”) "],["test-residuals.html", "Chapter 36 Test residuals", " Chapter 36 Test residuals moran.test(residuals(my_model), weights) Variograms Shows how variance changes with distance Useful for determining range of autocorrelation Key parameters: nugget, sill, range library(gstat) vario &lt;- variogram(response ~ 1, data = plots) plot(vario) Correlograms Moran’s I calculated at multiple distance classes Shows at what scales autocorrelation occurs Dealing with Spatial Autocorrelation Design-based solutions (prevention) Increase spacing between samples Stratified or systematic sampling GRTS sampling (balances spatial spread) Model-based solutions (accommodation) Include spatial covariates Add coordinates as predictors (crude but sometimes sufficient) Add spatially-structured environmental variables Spatial regression models Spatial lag models — autocorrelation in response Spatial error models — autocorrelation in residuals spatialreg package Geostatistical models Model the correlation structure explicitly Kriging for prediction gstat package Mixed models with spatial correlation Add spatial correlation structure to residuals nlme::lme() with correlation = corSpatial() glmmTMB with spatial random effects Generalized Least Squares gls() with spatial correlation structures Decision framework: When to worry about spatial autocorrelation Always check residuals spatially If significant autocorrelation exists, consider: Scale of autocorrelation vs. scale of inference Purpose of model (prediction vs. hypothesis testing) Available sample size for more complex models Special Considerations for Ecological Field Data GPS accuracy and precision Consumer GPS: ± 3-5 meters typical Differential GPS: sub-meter Canopy cover reduces accuracy Always record metadata about GPS equipment Datum shifts NAD27 vs NAD83 can differ by tens of meters Always document and verify datum Scale and extent Grain: finest spatial resolution Extent: total area covered Ecological patterns are scale-dependent Match analysis scale to question scale Edge effects Sampling near boundaries can bias results Buffer study areas when possible Modifiable Areal Unit Problem (MAUP) Results can change depending on how you aggregate spatial data Be consistent and justify choices Key Takeaways Always check and document your CRS Match CRS before combining datasets Use projected CRS for distance and area calculations Spatial autocorrelation violates independence — check your residuals Prevention (good sampling design) is easier than cure (complex models) The sf and terra packages are your friends Test Your Knowledge Conceptual questions What is the difference between geographic and projected coordinate systems? Why does spatial autocorrelation inflate Type I error rates? When would you use vector vs. raster data? Applied exercises Given two datasets that won’t overlay, diagnose the CRS problem Calculate Moran’s I on model residuals and interpret results Create a variogram and identify the range of spatial autocorrelation Assignment For your project data: Document the CRS of all spatial datasets Create a map showing sampling locations and study area If applicable, extract environmental covariates from rasters at your sample points After fitting a preliminary model, map residuals and test for spatial autocorrelation Discuss implications for your analysis "],["species-distribution-modeling.html", "Chapter 37 Species Distribution Modeling 37.1 Introduction 37.2 A brief review of niche theory 37.3 Downloads for this lab 37.4 Objectives 37.5 Methods", " Chapter 37 Species Distribution Modeling 37.1 Introduction Species distribution models (a.k.a.; ecological niche models, habitat models) relate environmental predictors like climate, elevation, or soil characteristics to species presence or abundance. These relationships are used to project likelihood of occurrence across space, by calculating the likelihood of occurrence across the study area using values associated with raster maps of the environmental variables in the model (Fig. 1). Most SDMs are correlative models that mathematically describe observed patterns of occurrence, and that do not incorporate underlying mechanisms in model projections. Understanding the limitations of correlative models (discussed below) is important for deciding when to use these models and interpreting your results. Figure 1. Raster layers are stacked to predict likely habitat. 37.2 A brief review of niche theory In spatial and population ecology, we define a species’ niche as all the conditions under which populations of a species maintain growth rates that are at or exceed replacement rates. The niche is often defined in n dimensional space, since so many factors contribute to the performance of a species (Fig. 2). In ecology, there tends to be a lot of confusion about spatial niche concepts, since ecology students often first learn about species niches from an evolutionary standpoint. In evolutionary ecology, a species’ niche is defined by a suite of traits possessed by an organism related to how this species ‘makes its living’ (attains food, nutrients, water). However, niche concepts and definitions are inherently related, and broadly describe the role of species within ecosystems. Figure 2. Species niches are complex. In theory, we could describe the niche of a species by adding N number of axes and create a cloud representing all the habitats where a species could persist. Ecologists break a species niche into two components: the fundamental niche and the realized niche. The fundamental niche is similar to the Grinnellian niche concept (Introduced by Joseph Grinnell in is 1917 paper, The niche relationships of the California Thrasher) niche concept. The fundamental niche of the species describes all the abiotic conditions that a species can physiologically tolerate and maintain population growth at or above replacement rates (we don’t count areas where species persist, but are not maintaining themselves; these area are known as demographic sinks). The realized niche refers to all of the areas that we actually observe a species on the landscape. The concept emerged out of the work of Elton, who highlighted the importance of species interactions in defining species distributions. The realized niche, therefore, reflects the combined effects of the abiotic and biotic environment on persistence across the landscape. Typically, the fundamental niche is larger than the realized niche. In other words, a species can be found in a lot of places, but processes such as competition for resources or predation, reduce the total area occupied by a species. In some cases, the realized niche can be larger than the fundamental niche. This occurs when positive species interactions, like mutualisms or facilitation, allow a species to overcome some sort of environmental resistance and occupy sites that would be inhospitable for the species without ‘help from a friend’. Finally, stochastic events, like disturbances, or landscape features, such as barriers to dispersal, can influence where as a species is found on the landscape. The distinction between fundamental and realized niches is important in order to understand the limitation of correlative SDMs, since these models cannot distinguish between the fundamental and realized niche of a species. Recall that species distribution models relate environmental factors to current occupation of a species. In most cases, habitat suitability is predicted using abiotic factors, including climate, soils, topographic information; all of which essentially describe the fundamental niche of a species (i.e., physiological tolerance to abiotic characteristics). However, the data used to build these models quantifies the current occupation of a species on the landscape, or the realized niche. This presents several issues: While we can learn generally about the abiotic factors that affect a species range, it is not a perfect picture of these tolerances, since distribution is affected by a variety of factors not included in the model. When a species fundamental niche and realized niche are really different due to factors not included in the model, current habitat projects can be inaccurate. This is a common problem when modeling habitat suitability for wild-harvested species, since they are underrepresented in suitable habitat, because those habitats are targeted for harvest. Using these models to predict future suitability should be interpreted skeptically. Future habitat suitability predictions are strong working hypotheses for ecological investigations or management actions. We don’t actually expect many species to track their bioclimatic niches, since many of the factors that influence a species range aren’t directly measured when building SDMs. SDMs are particularly unreliable when factors that shape a species niche change as a function of climate change. For instance, species interactions shape species distributions, and since species respond idiosyncratically to climate change, represent a major source of uncertainty in model predictions. These caveats and limitations, particularly related to your data, should be included in the discussion of your results. All of that said, SDMs can provide us with a lot of information with relatively little effort, and are often the best hypothesis on which to base decisions. 37.3 Downloads for this lab Create a file on your desktop called ‘speciesdistributionmodels’ and place the following files within it: R script for creating the SDM Occurrence data Worksheet to turn-in 37.4 Objectives Project the effects of climate change on Pinus ponderosa in Arizona. 37.5 Methods 37.5.1 Let’s get modeling Now, let’s walk through an example to discuss the various considerations and options for creating SDMs. For this exercise, we will use bioclimatic variables as environmental predictors. Bioclimatic variables are derived from downscaled climate models and created to be more more ecologically relevant compared to simple temperature and precipitation means. Bioclimatic variables are a great first step in model building, but depending on your study species and area, you may need to download finer scale layers or include other factors, like soil data. Resolution Raster layers are spatially mapped grids comprised of hundreds, thousands, or millions of cells (aka pixels) with values related to a variable assigned to each pixel. The smaller the pixel, the higher the resolution, but this greatly affects processing speed and may exceed computer storage. Map projections Different methods are used to project the 3D earth into a 2D map. We have to specify the projection of the layers used in our models or our data layers will not align properly. In the example below, we will specify a coordinate reference system (CRS), which defines, with the help of coordinates, how the projected map relates to locations on the earth. A CRS contains the following information: Coordinate system: The X, Y grid that defines where a point is located in space. Horizontal and vertical units: The units used to define the grid along the x, y (and z) axis. Datum: A modeled version of the shape of the Earth which defines the origin used to place the coordinate system in space. You will learn this further below. Projection Information: The mathematical equation used to flatten objects that are on a round surface (e.g. the Earth) so you can view them on a flat surface (e.g. your computer screens or a paper map). Luckily, we can pull all of this information from a spatial object, use the CRS function and reproject our data so that we are working with all data using the same CRS. Let’s start by installing and loading the libraries that we will need for our analysis, and by importing both current climate and future climate projections. For this exercise, we will download bioclimatic variables to characterize current climate. Bioclimatic variables are variables derived from mean, maximum and minimum temperature and precipitation data summarized from weather station data from across the globe, then interpolated based on various landscape features, most importantly elevation, in order to assign climatic values to locations with no climate stations. These bioclimatic variables have been created in order to represent climate data in a way that is biologically-relevant. Specifically, these bioclimatic include: Annual Mean Temperature (bio1) Mean Diurnal Range (Mean of monthly (max temp - min temp); bio2) Isothermality (bio3), Temperature Seasonality (standard deviation ×100; bio4) Max Temperature of Warmest Month (bio5) Min Temperature of Coldest Month (bio6) Temperature Annual Range (bio7) Mean Temperature of Wettest Quarter (bio8) Mean Temperature of Driest Quarter (bio9) Mean Temperature of Warmest Quarter (bio10) Mean Temperature of Coldest Quarter (bio11) Annual Precipitation (bio12) Precipitation of Wettest Month (bio13) Precipitation of Driest Month (bio14) Precipitation Seasonality (Coefficient of Variation; bio13) Precipitation of Wettest Quarter (bio16) Precipitation of Driest Quarter (bio17) Precipitation of Warmest Quarter (bio18) Precipitation of Coldest Quarter (bio19). Additionally, we will download climate projections. Climate projections are generated by Global Climate Models, which predict future climatic conditions based on complex algorithms describing the atmosphere. In order to project future species distributions, we need to select a particular climate model and a time period for which we are making predictions. Here, we are projecting suitable habitat for the time period 2061-2080. Since several facilities equipped with climate models generate climatic projections, we also have selected the CNRM-CM6-1 modeling group. Finally, we select the ‘socio-economic pathway’ utilized by our climate model. The degree of warming that occurs depends primarily on decisions that humans make around fossil fuel use and other climate mitigation strategies. The Intergovermental Panel on Climate Change (IPCC) works with social scientists, legislators and other to generate possible carbon use futures, which are then used to generate climate predictions. Here, we will use the Shared Socio-economic Pathway (SSP) ‘585’. Take a minute to search SSP 585. Record the answers to these questions on your worksheet: Provide a description of SSP 585. How do countries respond to climate change in this scenario? What climate-related technologies are assumed to be used in this future? Is a low, middle-of-the-road, or high degree of warming predicted in this scenario? If you were to repeat this exercise, which SSP would you choose and why? 37.5.2 Run the R code Load your R file run and walk through the exercise. Now that we’ve loaded our current and future climate models, let’s input our occurrence data. For our data on species occurrence, we will use data from the Global Biodiversity Information Facility (GBIF), a repository for species observations and locations derived from multiple sources, including citizen science, herbarium and museum collections. The GBIF data are biased by observer behavior, since many observations are derived from citizen science projects. Humans tend to collect data from easily accessed areas around roads, popular hiking trails or congregating areas. One way to reduce bias in presence only data is to use spatial thinning to reduce weighting observations from heavily trafficked areas more than observations made in other areas. There is no standard thinning distance, but it is typical to require a minimum of 5 km between observations. If you are working at smaller or larger scales, you could reduce or increase this distance! Also, if you are using presence and absence data or have employed an unbiased sampling strategy to collect data, you can skip this next step. While there are various quality control measures used by GBIF to ensure high data quality, we will run a few other data cleaning codes to remove anomalous points. This step is not necessary if using nonGBIF data! However, when producing your own spatial datasets, some form of data quality control is necessary. For this exercise, we will investigate whether models predict that Ponderosa pine forests that surround Flagstaff are predicted to persist as climate changes. Let’s download occurrence data for Ponderosa pine (Pinus ponderosa). Great! Now we have data! Let’s build an SDM. Our first decision point on model construction is based on the response variable. In this case, we have presence-only data; in other words, no one went out to the field to confirm locations where a species is absent across the landscape. Since location information often suffers from absence of absence data (ha), researchers have found statistical workarounds, which produce amazingly similar results to models fitted with presence or absence data. The method most commonly used to model habitat suitability with presence-only data involves generated numerous background points across your study area to compare with areas where your species is present. Note that your focal species could occur at any one of these background points, but that doesn’t matter. Essentially your model is characterizing habitat available to the species and the habitat of known occurrence to identify the environmental factors that best distinguish occupied habitat. Let’s breakdown the major model types used for SDMs: Profile techniques Profile techniques are simple algorithms that use environmental distance to known sites of occurrence to ‘profile’ habitat characteristics. These techniques are rarely used any more, so I won’t discuss further! Profile techniques include: Mahalanobis distance Ecological niche factor analysis (ENFA) Isodar analysis Bioclim Regression-based approaches You are familiar with regression based approaches from other statistical analyses! All regression approaches build upon standard regression models (Fig. 3), but differ in subtle ways to address common challenges to data modeling, like issues of nonnormality or heterogeneity of variance. Figure 3. Regression basics. Term y is related to term x. If the slope of the line differs significantly from 0, then there is a relationship between the variables. Error terms are derived from the residuals of the model; how much each individual point deviates from the line of best fit. The best fit is determined by repeatedly mapping lines across the data to identify that which most reduces error. Regression-based techniques include: Generalized Linear Modeling (GLM) (parametric) Flexible Discriminant Analysis (FDA) (parametric) Multivariate Adaptive Regression Splines (MARS) (nonparametric) Generalized Additive Modeling (GAM) (nonparametric) Generalized Linear Models are a flexible form of regression models. GLMs are ‘generalized’ by using a link function to relate the linear model to the response variable (which can be binomial, continuous, count data or other) and by relativizing the variance of each model term to its predicted value. Generalized Additive Models incorporate ‘smoothing functions’ to allow nonparametric estimates to be generated using a Bayesian approach. Multivariate Adaptive Regression Splines automatically models data nonlinearities and interactions between variables. Flexible Discriminant Analysis uses optimal scoring to transform the response variable so that the data are in a better form for linear separation. Machine learning approaches: Machine learning techniques use training data to ‘learn’ about the dataset in order to make predictions. Machine learning approaches include: Random Forest (RF) Boosted Regression Trees (BRT) Maximum Entropy (MaxEnt) There are other machine learning techniques, like Artificial Neural Networks (ANN), but the list above is most commonly used for distribution modeling! Random forest and boosted regression trees are similar, in that they create different ‘trees’ by iteratively bifurcating the dataset using predictor factors and identifying the tree that best predicts species occurrence. Figure 4. An illustration of random forest tree construction. MaxEnt models are a little different. According to the principle of maximum entropy, high entropy is when the probability distribution best represents the current state of knowledge about a system, in the context of precisely stated prior data. These models evaluate the set of all trial probability distributions that would encode the prior data and select the distribution with maximal information entropy. 37.5.2.1 Model selection The world of species distribution modeling is a contentious one! Many leaders in the field have their own ‘pet’ models that invariably they helped to develop software or methodology for! The general consensus is that each of the different modeling techniques has various strengths and weaknesses, and they should be combined into ensemble models for habitat predictions. However, other approaches exist. One line of thinking in distribution modeling is to use solely GLMs, spending great care to identify critical predictor variables in a way that is tied to current ecological understanding and that reduces nonlinearities among these variables. By taking these steps, models are created, which in theory, should provide better inferential power for both current and future habitats. For presence only data, maximum entropy models are generally considered an excellent model choice. In my experience, there is no perfect model, rather model accuracy varies from species to species. For this reason, I typically build ensemble models to integrate the strengths of different model types. 37.5.2.2 Build an SDM Deal with environmental predictor colinearity In general, it is recommended to avoid having correlated features (variables that have different numbers, but are following the same pattern) in your dataset. Indeed, a group of highly correlated features will not bring additional information to our analyses, but will increase the complexity of the algorithm, thus increasing the risk of errors. Including highly correlated variables in models also, in essence, weights the correlated variables more than independent variables, again leading to less accurate model outputs. In other words, we need to remove highly correlated variables. We will do this by generating Variable Inflation Factor (VIF) values, a measure of collinearity, for all predictor variables. Then, we will remove one of the two correlated variables. Build the dataframe for the SDM Building the SDM, requires two additional steps. In the first, we assemble the final dataset to be used in the model. Using the sdmData function, we indicate the following: The column that contains presence data. The environmental predictors. Absence data or how to create background data. Specify model evaluation parameters When we build the final model using the SDM function, we specify replication. Replication is the method used to partition the dataset into training and test data. Ideally, we would have collected completely independent training and test datasets; however, I’ve never actually seen this done, except for researchers who are investigating SDM methods. Ninety nine point nine percent of the time, datasets are split into test and training datasets. As the names imply, training data are used to build the model, and then test data are used to measure how good our predictions are by quantifying how often our model correctly predicts presence or absence. Splitting or partitioning data into test and training datasets is often conducted several times, since outcomes may depend on the test or training data used to build and evaluate models. There are several methods to create training and test datasets. The three available in the package that we will use are subsampling (sub), crossvalidation (cv), bootstrapping (boot). For sub and boot, you must indicate what proportion of test and training data. A 30% test data, 70% training data split is common (test.percent=30). Finally, you will also the models how many times to repeat evaluations using the n equals code. This can eat up a lot of memory, so I typically use an n of 5. Choosing the evaluation model Crossvalidation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, in most methods, multiple rounds of crossvalidation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to give an estimate of the model’s predictive performance. Crossvalidation does not rely on random sampling, but rather splits the dataset into k unique subsets. This is the preferred method for spatial model evaluation and estimating generalization capability. Note that you have to select the number of ‘folds’ or data partitions, which is typically set at 5. Bootstrapping iteratively creates separate datasets from randomly sampling with replacement. Bootstrapping it is not as strong as crossvalidation when it is used for model validation, since it contains repeated elements in every subset. Bootstrapping is typically repeated 30 times in SDM model evaluation! Subsampling randomly splits the dataset into training and test datasets, but doesn’t maintain the independence of the datasets. In other words, due to random sampling, you might wind up with similar training and test datasets in each trial. For this reason, the more structured crossvalidation method is typically preferred. Build the SDM Once the data is appropriately compiled, we use the sdm function to build the actual model. Within this function, we specify: The column that contains presence or presence or absence The dataframe that we are using (d1) The types of models that we are using Replication type (cv), number of folds (5), how many times to repeat partitioning (1) THIS STEP WILL TAKE SOME TIME - JUST LET THE PROGRAM RUN! The model object (m1) tells you several things. First, it gives a brief summary of the model you ran. You can double check this to be sure that the model did what you told it to do. Here, everything seems fine: We ran a model for one species, we used two modeling methods, glm and maxent, we used cross_validation with 5 partitions. The model runs were successful (100% each). Finally, we are provided with 4 measures of model performance: AUC, COR, TSS, and Deviance. What types of models are we using to predict habitat suitability for Ponderosa pines (i.e., machine learning, regression, profile techniques)? 37.5.2.3 Model evaluation explained AUC stands for Area Under the Curve. AUC refers to a ROC plot, which plots sensitivity over 1 minus specificity. An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. AUC is desirable for SDM model evaluation for two main reasons: AUC is scale invariant. AUC is classification threshold invariant. It measures the quality of the model’s predictions irrespective of what classification threshold is chosen. This curve plots two parameters: True Positive Rate (Sensitivity): the proportion of presences correctly predicted as presence, False Positive Rate (1 minus Specificity): The specificity denotes the proportion of absences that are correctly predicted as absence, so the false positive rate indicates how many times the model predicted an occurrence when there was none. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. As a rule, an AUC &gt; 0.75 indicates a high performing model. SDMs predict a probability of occurrence across the landscape. Different thresholds can be used to create a cutoff to predict presences or absences. For instance, we could say that if there is a 90% chance or more that a pixel is suitable habitat, then we consider those areas as occupied. We want to identify a cutoff that maximizes true presences, while minimizes false positives (i.e., areas that you incorrectly say contain a population, but don’t). You can see that as you decrease the cutoff, from say 90% to 70%, then your likelihood of correctly predicting presences goes up, BUT so does your likelihood of false positives. So, let’s check out the ROC plot below. Looking at AUC, a common form of model performance assessment, which is the best performing model? Generally, there is strong agreement between the test and the training data. As you increase the cutoff threshold, the likelihood that you correctly assign presence goes up, but so does the false positive rate (Fig. 5). Note that on the far right hand side of each ROC plot, if the cutoff is high enough, you will have a 100% true positive rate, and a 100% false positive rate (the cutoff is so low, that all habitats are predicted to support the focal species). Alternatively, with a low enough cutoff (left hand side of the ROC plot), you won’t have any positives or any false positives! This AUC cutoff will be important for building ensemble models; explained below! Figure 5 This figure (lifted from an ARCGIS website) shows the relationship between omission rates and ROC plots. So if we want an Omission Rate that is slightly less than 10%, we can use 0.29 as the Cutoff instead, and in this case, we will pick up 20.48% background points as potential presence locations, which is also a good rate. Like AUC, True Skill Statistic (TSS) values are calculated across the range of possible thresholds for classifying model scores.The TSS similarly incorporates sensitivity and specificity comparing models against random, yielding values that range from negative 1 to positive 1, where positive 1 indicates perfect prediction and greater than or equal to 0 indicates a model that performs no better than random. TSS is typically considered a better indicator of model performance for presence only models. A TSS of 0.5 or higher indicates high model performance. Pearson correlation (COR) between the predicted likelihood of presence and the presence or absence testing data. Deviance Lastly, if a model is interpreted as estimating species’ probability of presence, rather than just giving an index of habitat suitability, then the model predictions can be evaluated using deviance, defined as 2 times the log probability of the test data. 37.5.2.4 Ensemble model assembly Finally, we will merge models into an ensemble model. You may want to exclude models that didn’t have high predictive performance. We will give higher weights to the models with higher accuracy, in this cause using the TSS score. 37.5.2.5 Investigating model components We can run code to look at the model components that best predict presence. According this figure, which climatic variable best predicts habitat suitability for Ponderosa pine? 37.5.2.6 Convert to presence or absense predictions We use the test statistics to identify a threshold that maximized true positives and reduced false negatives. In order to do this, we will create a new raster and populate it with predictions of presence, using that threshold. 37.5.2.7 Plotting and predictions Let’s take a quick look at the predictions we have created for the current time period. To predict response of your focal species to future climate, just plug the novel climate conditions into the model! Let’s run this model. Now, let’s plot this prediction against our original! First, we’ll take a zoomed out look, then we will focus into our region! Let’s convert to predicted occurrence and plot! According to these maps, how will the amount of suitable habitat for Pinus ponderosa in Flagstaff change if climate change continues along the SSP 585 projection? How certain are you of these projections? Why might these models NOT be accurate? What type of vegetation do you think might be more common around Flagstaff as climate changes? Submit your answers to the questions presented throughout this tutorial and the figures that you generated (Occurrence of Pinus ponderosa currently and in the future) to your TA. "],["diversity-statistics.html", "Chapter 38 Diversity statistics 38.1 iNext 38.2 Coverage‐based R/E sampling curves 38.3 Data manipulation", " Chapter 38 Diversity statistics How do we describe the variety of species, traits or phylogenies in a particular area? With diversity statistics! Simple species counts, or species richness, is a time-old method for describing diversity. Since the olden days of creating ‘species lists’ for every habitat under the sun, new methods have emerged to describe the variety of life within ecological communities. These statistics attempt to deal with a problem inherent to diversity assessments: It is really hard to find all the species within an ecosystem and the more you look, the more species you find! There are a variety of different diversity statistics, which vary in terms of how much they weight relative abundances of species. These metrics are: Species richness: Simple counts of species in an area. Common species and rare species are given the same weight, since each species no matter how abundant it is, increases species richness by 1 unit! Includes no measure of evenness. Evenness is a measure of relative abundance of species at a site. The more equal species are in proportion to each other the greater the evenness of the site. The Shannon diversity index is a diversity index based on both richness (species counts) and evenness (relative abundance). The Simpson diversity index, like the Shannon diversity index, combines richness and evenness, but more strongly weights evenness relative to richness. These three metrics, richness, Shannon diversity and Simpson diversity index can be expressed as Hill numbers, or the effective number of species. The advantage of using Hill numbers, rather than generating diversity metrics using other indices, is that they are more easily interpreted, since they follow the doubling rule, and more easily compared to better understand diversity in a system. Hill numbers are parameterized by a diversity order q, which determines the measures’ sensitivity to species relative abundances. Hill numbers include the three most widely used species diversity measures as special cases: species richness (q = 0), Shannon diversity (q = 1) and Simpson diversity (q = 2). Specifically: \\[^qD = \\left(\\sum_{i=1}^{S} p_i^q\\right)^{1/(1-q)}\\] When q = 0, \\(^0D\\) is simply species richness, which counts species equally without regard to their relative abundances. For q = 1, the equation above is undefined, since 1/0, but the limit as q tends to 1 is the exponential of the familiar Shannon index, referred to as Shannon diversity. The measure for q = 1 counts individuals equally and thus counts species in proportion to their abundances; the measure \\(^1D\\) can be interpreted as the effective number of common species in the assemblage. The measure for q = 2 (\\(^2D\\)), referred to as Simpson diversity, discounts all but the dominant species and can be interpreted as the effective number of dominant species in the assemblage. The doubling rule refers to the fact that as a species assemblage goes from 8 species to 16 the calculated Hill numbers double. This seems like, of course, that would be the case, BUT diversity indices like the Shannon entropy (“Shannon-Wiener index”) and the Gini-Simpson index do not follow the doubling rule! By calling all of these indices “diversities” and treating them as if they were interchangeable in formulas or analyses requiring diversities, we will often generate misleading results.So, Hill numbers are true diversities (also referred to as the effective number of species), rather than just indices of diversity, unanchored to the actual diversity at a site. In other words, a community with eight equally-common species has a diversity of eight species, or a community with S equally-common species has a diversity of S species. This definition behaves as we expect of a diversity; the diversity of a community of sixteen equally-common species is double that of a community with eight equally-common species. One reason to calculate the effective number of species rather than diversity indices is that it allows straightforward and intuitive comparisons among communities. The goal in many diversity analyses is to make fair comparison of diversities across multiple assemblages that may vary in the size of their species pools or in the way in which they are sampled. Diversity metrics are strongly affected by both search time and search area. Even when researchers standardize search effort, both in terms of time spent surveying a plot and by plot area, diversity metrics are extremely sensitive to the diversity of the community itself. A more diverse community with high unevenness (i.e., lots of rare species) would require more search effort to estimate true diversity relative to a low diversity community with high evenness. For that reason, even when we’ve established appropriate sampling stategies, we have to standardize communities in order to compare them. For this reason, community ecologists use statistical techniques like extrapolation and rarefaction to estimate the ‘true’ number of species within an area based on your sample. Rarefaction deals with unequal sampling by down-sampling the larger samples until they contain the same number of observed individuals or sampling units as the smallest sample. In the past, rarefaction was the principal means to compare assemblages. When using rarefaction, you lose data, since you cull your other assemblages to be equivalently comparable with your “worst” sample. For this reason, many community ecologists now choose to generate asymptotic estimates of diversity, which involves combining rarefaction with extrapolation. To calculate asymptotic diversity estimates, you first generate a rarefaction/extrapolation sampling curve (R/E curve) that estimates diversity over a series of sampling units. Diversity estimates below your sample’s observed diversity estimate is derived from rarefaction (referred to as the sample-size-based approach to standardize data based on sample effort), and estimates above the observed diversity are derived from extrapolation. There are several ways of extrapolating diversity data beyond your actual sample. Parametric methods extend the species accumulation curve by fitting parametric functions. Most commonly, however, a non-parametric method that uses the frequency of rare species in a sample is used for extrapolating samples (a method developed by Alan Turing when designing the enigma machine). This approach standardizes data based on sample completeness, an estimated assemblage characteristic. Sampling completeness is the ratio between the detected and estimated diversity and indicates the proportion of detected species. The comparison between detected and estimated diversity is made by calculating and comparing sample coverage (thus these methods for extrapolating data are referred to as coverage-based approaches), or the total relative abundances of the observed species. The sample completeness curve provides a bridge between the size- and coverage-based R/E sampling curves. In other words, since sample completeness can be calculated for rarefied samples (i.e., use your actual data to compare detected to estimated diversity), sample completeness can be used to anchor and unite the rarefaction and extrapolation curves. By combining R/E curves to estimate of diversity and expressing diversity estimates as Hill numbers, iNEXT is a great all around package to compare diversity among assemblages of ecological data. This framework allows ecologists to compare of the species diversity of different assemblages in time or space, with reliable statistical inferences about these comparisons. 38.1 iNext What type of data do you have? The first decision to make is to determine what type of data you will analyze. For calculating diversity statistics, there are two principle forms of diversity data: Abundance data are data that include a measure of abundance - This could be data with counts of species or that includes cover data. When R/E curves are generated, the sampling unit is an individual. For example, to generate rarefaction curves, rarefied assemblages are created by randomly removing individuals within an assemblage. Note that many ecological studies collect abundance data within a plot or quadrat. In these cases, species are not independently sampled, and many ecologist recommend converting these datasets to incidence data (discussed below) to calculate diversity estimates, while others simply treat it as abundance data. Currently, statisticians are deriving methods to deal with sample-based abundance data (see Chui 2023) again using Turing’s methods of estimate completeness - hopefully, these new equations are integrated into the iNEXT package soon! Sample-based incidence data are data that note whether a give species is present or absent, and does not include information on how abundant that species is within an assemblage. In these cases the sampling unit is a trap, net, quadrat, plot, or timed survey. For sample-based incidence data, the sampling units (i.e., plots, quadrats, etc.), rather than individuals, are removed to generate rarefied diversity estimates. Note that for both abundance data and incidence data, the rarefaction process is repeated numerous times, allowing us to calculate confidence intervals (described in more detail below). There are two kinds of incidence input data for iNEXT: (1) incidence-raw data: for each assemblage, input data consist of a species-by-sampling-unit matrix; when there are N assemblages, input data consist of N matrices via a list object, with each matrix being a species-by-sampling-unit matrix. In iNEXT, this type of data is specified by datatype=“incidence_raw”. (2) Incidence-frequency data: input data for each assemblage consist of the number of sampling units (T) followed by the observed incidence frequencies (Y1, Y2, …, YS). Let’s check out a few of these examples. First, we will begin with the abundance dataset, spider. The spider dataset was collected at Harvard Experimental Forest. Researchers killed hemlock trees using two different methods (girdling or logging), in order to observe the effect of hemlock loss on the remnant community. Here, Sackett et al. (2011) provides abundance data for spiders collected on trees killed by girdling the trunk or by logging. library(iNEXT) library(tidyverse) #or #library(devtools) #install_github(&#39;AnneChao/iNEXT&#39;) #First let&#39;s check out two abundance datasets #Individual‐based abundance data (datatype=&quot;abundance&quot;): Input data for each assemblage/site include species abundances in an empirical sample of n individuals (“reference sample”). When there are N assemblages, input data consist of an S by N abundance matrix, or N lists of species abundances. #Check out spider data(&quot;spider&quot;); spider ## $Girdled ## [1] 46 22 17 15 15 9 8 6 6 4 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 ## ## $Logged ## [1] 88 22 16 15 13 10 8 8 7 7 7 5 4 4 4 3 3 3 3 2 2 2 2 1 1 1 1 1 1 ## [30] 1 1 1 1 1 1 1 1 #The spider dataset consists of abundance data from two canopy manipulation treatments (“Girdled” and “Logged”) of hemlock. Counts of individuals for species are provided for girdled and logged trees. #Go ahead and estimate diversity out &lt;- iNEXT(spider, q=c(0, 1, 2), datatype=&quot;abundance&quot;, endpoint=500) ggiNEXT(out, type=1, facet.var=&quot;Assemblage&quot;) The iNEXT functions calculates our R/E curve. There are several components of this function (taken from the package information): 1. The first term in the iNEXT function specifies the dataset. 2. Argument q allows you to select the type of diversity estimate that you are interested in. Here, we have chosen to calculate Hill numbers q = 0 (richness), 1 (Shannons), and 2 (Simpsons). 3. The argument datatype allows you to specify which type of data you are inputting (“abundance”, “incidence_raw” or “incidence_freq”). 4. The argument size to specify sample sizes for which diversity estimates are computed. If NULL, then diversity estimates will be calculated for those sample sizes determined by the specified/default endpoint and knots. 5. Argument endpoint is an integer specifying the sample size that is the endpoint for R/E calculation; If NULL, then endpoint=double the sample size of your assemblage (total sample size for abundance data; total sampling units for incidence data). As a general rule of thumb, for species richness, the size in the R/E curve can be extrapolated to at most double or triple the minimum observed sample size, guided by an estimated asymptote. For Shannon diversity and Simpson diversity, if the data are not too sparse, the extrapolation can be reliably extended to infinity to attain the estimated asymptote. 6. Knots an integer specifying the number of equally‐spaced knots between size 1 and the endpoint; default is 40. se a logical variable to calculate the bootstrap standard error and conf confidence interval. nboot an integer specifying the number of bootstrap replications; default is 50. Let’s take a look at another abundance dataset and use this next analysis to discuss the components of the output from the iNEXT function. The bird dataset consists of abundance tallies for birds at two sites: North site and South site. #Check out the other abundance dataset, called &#39;bird&#39; data(&quot;bird&quot;); bird ## North.site South.site ## Acanthiza_lineata 0 3 ## Acanthiza_nana 0 18 ## Acanthiza_pusilla 41 31 ## Acanthorhynchus_tenuirostris 0 2 ## Alisterus_scapularis 3 1 ## Cacatua_galerita 1 2 ## Cacomantis_flabelliformis 5 5 ## Calyptorhynchus_funereus 4 1 ## Colluricincla_harmonica 4 6 ## Cormobates_leucophaea 11 32 ## Corvus_coronoides 1 0 ## Dacelo_novaeguineae 2 0 ## Eopsaltria_australis 5 5 ## Gerygone_mouki 12 10 ## Leucosarcia_melanoleuca 1 1 ## Lichenostomus_chrysops 0 4 ## Malurus_cyaneus 0 6 ## Malurus_lamberti 0 6 ## Manorina_melanophrys 0 9 ## Meliphaga_lewinii 11 18 ## Menura_novaehollandiae 9 5 ## Monarcha_melanopsis 1 10 ## Neochmia_temporalis 0 9 ## Oriolus_sagittatus 1 0 ## Pachycephala_olivacea 0 2 ## Pachycephala_pectoralis 16 15 ## Pachycephala_rufiventris 0 3 ## Pardalotus_punctatus 15 17 ## Petroica_rosea 1 1 ## Phylidonyris_niger 0 2 ## Platycercus_elegans 2 7 ## Psophodes_olivaceus 7 7 ## Ptilonorhynchus_violaceus 2 2 ## Ptiloris_paradiseus 0 3 ## Rhipidura_albicollis 18 20 ## Rhipidura_rufifrons 8 14 ## Sericornis_citreogularis 0 2 ## Sericornis_frontalis 2 6 ## Strepera_graculina 3 4 ## Zoothera_lunulata 0 1 ## Zosterops_lateralis 16 17 #calculate diversity metrics for the bird dataset birdtest &lt;- iNEXT(bird, q=c(0,1,2), datatype=&quot;abundance&quot;, size=NULL, endpoint=NULL, knots=40, se=TRUE, conf=0.95, nboot=50) birdtest$AsyEst ## Assemblage Diversity Observed Estimator s.e. LCL UCL ## 1 North.site Species richness 27.00000 31.47772 5.827105 27.00000 42.89864 ## 2 North.site Shannon diversity 16.53585 17.96568 1.178756 15.65536 20.27600 ## 3 North.site Simpson diversity 11.84785 12.52375 1.195299 10.18101 14.86649 ## 4 South.site Species richness 38.00000 40.07655 4.524314 38.00000 48.94404 ## 5 South.site Shannon diversity 25.44707 27.25065 1.244804 24.81087 29.69042 ## 6 South.site Simpson diversity 19.63930 20.91318 1.445089 18.08086 23.74550 #plot your bird data ggiNEXT(birdtest, type=1, se=TRUE, facet.var=&quot;None&quot;, color.var=&quot;Assemblage&quot;, grey=FALSE) The iNEXT() function returns the “iNEXT” object, which includes three output lists (taken from the iNEXT package documentation): 1. $DataInfo for summarizing data information; 2. $iNextEst for showing size- and coverage-based diversity estimates along with related statistics for a series of rarefied and extrapolated samples; 3. $AsyEst for showing asymptotic diversity estimates along with related statistics. 4. $DataInfo, as shown below, returns basic data information including the reference sample size (n), observed species richness (S.obs), sample coverage estimate for the reference sample (SC), and the first ten frequency counts (f1‐f10). This part of output can also be computed by the function DataInfo() You can take a look at the entire output by calling ‘birdtest’ or you can grab the data that you will use in your analyses (like we did above), by calling ‘birdtest$AsyEst’. For each estimate, 95% confidence intervals are calculated by bootstrapping samples. In the size-based standardization (i.e., rarefaction), the sample size is fixed in each regenerated bootstrap sample. In the coverage-based standardization (i.e., extrapolated), for a given standardized coverage value, bootstrapping is again used, but using random draws based on simulated data. The result is that the sampling uncertainty is greater in the coverage-based standardization and the resulting confidence interval is wider than that in the corresponding size-based standardization. The bootstrapping default is 50, and since it is a random process expect CI to differ each time you calculate them. Now let’s look at incidence data. First let’s look at the tropical ant data (in the dataset ant included in the package) at five elevations (50m, 500m, 1070m, 1500m, and 2000m) collected by Longino &amp; Colwell (2011) from Costa Rica. The 5 lists of incidence frequencies are shown below. The first entry of each list must be the total number of sampling units, followed by the species incidence frequencies. #incidence dataset data(ant) str(ant) ## List of 5 ## $ h50m : num [1:228] 599 330 263 236 222 195 186 183 182 129 ... ## $ h500m : num [1:242] 230 133 131 123 78 73 65 60 60 56 ... ## $ h1070m: num [1:123] 150 99 96 80 74 68 60 54 46 45 ... ## $ h1500m: num [1:57] 200 144 113 79 76 74 73 53 50 43 ... ## $ h2000m: num [1:15] 200 80 59 34 23 19 15 13 8 8 ... Look at the second incidence dataset. The ciliates data were collected from three coastal dune habitats to demonstrate the use of the input datatype=“incidence_raw”. The data set (ciliates) included in the package is a list of three species-by-plot matrices. data(ciliates) str(ciliates) ## List of 3 ## $ EtoshaPan : int [1:365, 1:19] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:19] &quot;x53&quot; &quot;x54&quot; &quot;x55&quot; &quot;x56&quot; ... ## $ CentralNamibDesert : int [1:365, 1:17] 0 0 0 0 0 1 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:17] &quot;x31&quot; &quot;x32&quot; &quot;x34&quot; &quot;x35&quot; ... ## $ SouthernNamibDesert: int [1:365, 1:15] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:15] &quot;x9&quot; &quot;x17&quot; &quot;x19&quot; &quot;x20&quot; ... #Run the following commands to get the output as shown below. out.raw &lt;- iNEXT(ciliates, q = 0, datatype=&quot;incidence_raw&quot;, endpoint=150) 38.2 Coverage‐based R/E sampling curves You can derive a single measure of diversity for the same coverage/sample to compare among communities using estimateD. #The following command returns the species diversity with a specified level of sample coverage of 98.5% for the ant data. For some assemblages, this coverage value corresponds to rarefaction (i.e., less than the coverage of the reference sample), while for the others it corresponds to extrapolation (i.e., greater than the coverage of the reference sample), as indicated under the method column of the output. estimateD(ant, datatype=&quot;incidence_freq&quot;, base=&quot;coverage&quot;, level=0.985, conf=0.95) ## Assemblage t Method Order.q SC qD qD.LCL qD.UCL ## 1 h50m 327.1646 Rarefaction 0 0.985 197.487977 186.910316 208.065637 ## 2 h50m 327.1646 Rarefaction 1 0.985 78.052670 76.079161 80.026178 ## 3 h50m 327.1646 Rarefaction 2 0.985 50.461029 49.022384 51.899673 ## 4 h500m 342.8592 Extrapolation 0 0.985 268.725933 241.615371 295.836494 ## 5 h500m 342.8592 Extrapolation 1 0.985 103.847150 99.789790 107.904509 ## 6 h500m 342.8592 Extrapolation 2 0.985 64.758264 61.543636 67.972893 ## 7 h1070m 158.9508 Extrapolation 0 0.985 123.608792 111.015456 136.202128 ## 8 h1070m 158.9508 Extrapolation 1 0.985 59.591818 57.227497 61.956140 ## 9 h1070m 158.9508 Extrapolation 2 0.985 41.775173 40.005324 43.545023 ## 10 h1500m 125.9590 Rarefaction 0 0.985 50.478877 41.886404 59.071350 ## 11 h1500m 125.9590 Rarefaction 1 0.985 26.248998 24.633972 27.864024 ## 12 h1500m 125.9590 Rarefaction 2 0.985 18.648902 17.413283 19.884520 ## 13 h2000m 104.6306 Rarefaction 0 0.985 12.909623 10.310238 15.509008 ## 14 h2000m 104.6306 Rarefaction 1 0.985 7.710717 6.907520 8.513915 ## 15 h2000m 104.6306 Rarefaction 2 0.985 5.794580 5.116469 6.472690 38.3 Data manipulation Scripts from the iNEXT package are fairly straightforward and easy to run. The challenge with these datasets is wrangling the data into the correct format for analysis. Since diversity statistics are often paired with NMDS data, let’s start with an example in which we wrangle data formatted for the Vegan package. library(readr) # Download and read the first dataset url1 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1c1guQTQwGNfA5Kx-xNPKRDsSJrBR-HxW&quot; env_matrix &lt;- read_csv(url1) # Download and read the second dataset url2 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1jCqfJPEuEWo4uNZfxW43VkSvEDDtayF5&quot; species_matrix &lt;- read_csv(url2) This data is incidence data collected at 3 replicate control plots and 6 treatment plots before and after disturbance. # Load necessary libraries library(tidyverse) print(colnames(species_matrix)) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; ## [3] &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; ## [5] &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; ## [9] &quot;Aristida.purpurea&quot; &quot;Aristida.schiedeana.var.orcuttiana&quot; ## [11] &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; ## [15] &quot;Asclepias.nyctaginifolia&quot; &quot;Astragalus.sp&quot; ## [17] &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; ## [21] &quot;Bothriochloa.ischaemum&quot; &quot;Bouteloua.curtipendula&quot; ## [23] &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; ## [27] &quot;Brickellia.betonicifolia&quot; &quot;Brickellia.californica&quot; ## [29] &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; ## [33] &quot;Calliandra.humilis&quot; &quot;Calliandra.humilis.var.reticulata&quot; ## [35] &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; ## [39] &quot;Coleogyne.ramosissima&quot; &quot;Collinsia.parviflora&quot; ## [41] &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; ## [45] &quot;Cyperus.fendlerianus&quot; &quot;Cyperus.sp&quot; ## [47] &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; ## [51] &quot;Desmanthus.cooleyi&quot; &quot;Desmodium.batocaulon&quot; ## [53] &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; ## [57] &quot;Eragrostis.curvula&quot; &quot;Eragrostis.intermedia&quot; ## [59] &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; ## [63] &quot;Eriogonum.wrightii&quot; &quot;Escobaria.sp&quot; ## [65] &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; ## [69] &quot;Euphorbia.serpyllifolia&quot; &quot;Evolvulus.sericeus&quot; ## [71] &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; ## [75] &quot;Glandularia.bipinnatifida&quot; &quot;Glandularia.gooddingii&quot; ## [77] &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; ## [81] &quot;Heterosperma.pinnatum&quot; &quot;Houstonia.wrightii&quot; ## [83] &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; ## [87] &quot;Lepidium.lasiocarpum&quot; &quot;Lonicera.arizonica&quot; ## [89] &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; ## [93] &quot;Mimosa.aculeaticarpa&quot; &quot;Mimosa.biuncifera&quot; ## [95] &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; ## [99] &quot;Muhlenbergia.longiligula&quot; &quot;Muhlenbergia.sp&quot; ## [101] &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; ## [105] &quot;Packera.neomexicana&quot; &quot;Pediomelum.tenuiflorum&quot; ## [107] &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; ## [111] &quot;Phemeranthus.parviflorus&quot; &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; ## [113] &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; ## [117] &quot;Polygonum.douglasii&quot; &quot;Portulaca.umbraticola&quot; ## [119] &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; ## [123] &quot;Rhus.trilobata&quot; &quot;richness_aggregated&quot; ## [125] &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; ## [129] &quot;Symphyotrichum.falcatum&quot; &quot;Tradescantia.sp&quot; ## [131] &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; ## [135] &quot;Vulpia.octoflora&quot; &quot;Xanthisma.gracile&quot; print(colnames(env_matrix)) ## [1] &quot;...1&quot; &quot;Year&quot; &quot;PlotN&quot; &quot;Treatment&quot; ## [5] &quot;Treatment_status&quot; # combine the datasets, by hand or with code! combined_data &lt;- inner_join(species_matrix, env_matrix, by = c(&quot;...1&quot; = &quot;...1&quot;)) # Split the data into different groups control_pre &lt;- combined_data %&gt;% filter(Treatment == &quot;Control&quot; &amp; Treatment_status == &quot;PreTreatment&quot;) #remove unnecessary columns colnames(control_pre) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; ## [3] &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; ## [5] &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; ## [9] &quot;Aristida.purpurea&quot; &quot;Aristida.schiedeana.var.orcuttiana&quot; ## [11] &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; ## [15] &quot;Asclepias.nyctaginifolia&quot; &quot;Astragalus.sp&quot; ## [17] &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; ## [21] &quot;Bothriochloa.ischaemum&quot; &quot;Bouteloua.curtipendula&quot; ## [23] &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; ## [27] &quot;Brickellia.betonicifolia&quot; &quot;Brickellia.californica&quot; ## [29] &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; ## [33] &quot;Calliandra.humilis&quot; &quot;Calliandra.humilis.var.reticulata&quot; ## [35] &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; ## [39] &quot;Coleogyne.ramosissima&quot; &quot;Collinsia.parviflora&quot; ## [41] &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; ## [45] &quot;Cyperus.fendlerianus&quot; &quot;Cyperus.sp&quot; ## [47] &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; ## [51] &quot;Desmanthus.cooleyi&quot; &quot;Desmodium.batocaulon&quot; ## [53] &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; ## [57] &quot;Eragrostis.curvula&quot; &quot;Eragrostis.intermedia&quot; ## [59] &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; ## [63] &quot;Eriogonum.wrightii&quot; &quot;Escobaria.sp&quot; ## [65] &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; ## [69] &quot;Euphorbia.serpyllifolia&quot; &quot;Evolvulus.sericeus&quot; ## [71] &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; ## [75] &quot;Glandularia.bipinnatifida&quot; &quot;Glandularia.gooddingii&quot; ## [77] &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; ## [81] &quot;Heterosperma.pinnatum&quot; &quot;Houstonia.wrightii&quot; ## [83] &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; ## [87] &quot;Lepidium.lasiocarpum&quot; &quot;Lonicera.arizonica&quot; ## [89] &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; ## [93] &quot;Mimosa.aculeaticarpa&quot; &quot;Mimosa.biuncifera&quot; ## [95] &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; ## [99] &quot;Muhlenbergia.longiligula&quot; &quot;Muhlenbergia.sp&quot; ## [101] &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; ## [105] &quot;Packera.neomexicana&quot; &quot;Pediomelum.tenuiflorum&quot; ## [107] &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; ## [111] &quot;Phemeranthus.parviflorus&quot; &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; ## [113] &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; ## [117] &quot;Polygonum.douglasii&quot; &quot;Portulaca.umbraticola&quot; ## [119] &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; ## [123] &quot;Rhus.trilobata&quot; &quot;richness_aggregated&quot; ## [125] &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; ## [129] &quot;Symphyotrichum.falcatum&quot; &quot;Tradescantia.sp&quot; ## [131] &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; ## [135] &quot;Vulpia.octoflora&quot; &quot;Xanthisma.gracile&quot; ## [137] &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; control_pre &lt;- dplyr::select(control_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1)) control_pret &lt;- t(control_pre) control_post &lt;- combined_data %&gt;% filter(Treatment == &quot;Control&quot; &amp; Treatment_status == &quot;PostTreatment&quot;) colnames(control_post) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; ## [3] &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; ## [5] &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; ## [9] &quot;Aristida.purpurea&quot; &quot;Aristida.schiedeana.var.orcuttiana&quot; ## [11] &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; ## [15] &quot;Asclepias.nyctaginifolia&quot; &quot;Astragalus.sp&quot; ## [17] &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; ## [21] &quot;Bothriochloa.ischaemum&quot; &quot;Bouteloua.curtipendula&quot; ## [23] &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; ## [27] &quot;Brickellia.betonicifolia&quot; &quot;Brickellia.californica&quot; ## [29] &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; ## [33] &quot;Calliandra.humilis&quot; &quot;Calliandra.humilis.var.reticulata&quot; ## [35] &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; ## [39] &quot;Coleogyne.ramosissima&quot; &quot;Collinsia.parviflora&quot; ## [41] &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; ## [45] &quot;Cyperus.fendlerianus&quot; &quot;Cyperus.sp&quot; ## [47] &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; ## [51] &quot;Desmanthus.cooleyi&quot; &quot;Desmodium.batocaulon&quot; ## [53] &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; ## [57] &quot;Eragrostis.curvula&quot; &quot;Eragrostis.intermedia&quot; ## [59] &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; ## [63] &quot;Eriogonum.wrightii&quot; &quot;Escobaria.sp&quot; ## [65] &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; ## [69] &quot;Euphorbia.serpyllifolia&quot; &quot;Evolvulus.sericeus&quot; ## [71] &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; ## [75] &quot;Glandularia.bipinnatifida&quot; &quot;Glandularia.gooddingii&quot; ## [77] &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; ## [81] &quot;Heterosperma.pinnatum&quot; &quot;Houstonia.wrightii&quot; ## [83] &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; ## [87] &quot;Lepidium.lasiocarpum&quot; &quot;Lonicera.arizonica&quot; ## [89] &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; ## [93] &quot;Mimosa.aculeaticarpa&quot; &quot;Mimosa.biuncifera&quot; ## [95] &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; ## [99] &quot;Muhlenbergia.longiligula&quot; &quot;Muhlenbergia.sp&quot; ## [101] &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; ## [105] &quot;Packera.neomexicana&quot; &quot;Pediomelum.tenuiflorum&quot; ## [107] &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; ## [111] &quot;Phemeranthus.parviflorus&quot; &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; ## [113] &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; ## [117] &quot;Polygonum.douglasii&quot; &quot;Portulaca.umbraticola&quot; ## [119] &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; ## [123] &quot;Rhus.trilobata&quot; &quot;richness_aggregated&quot; ## [125] &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; ## [129] &quot;Symphyotrichum.falcatum&quot; &quot;Tradescantia.sp&quot; ## [131] &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; ## [135] &quot;Vulpia.octoflora&quot; &quot;Xanthisma.gracile&quot; ## [137] &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; control_post &lt;- dplyr::select(control_post, -c(Year, PlotN, Treatment, Treatment_status, ...1)) control_postt &lt;- t(control_post) treatment_pre &lt;- combined_data %&gt;% filter(Treatment == &quot;Treatment&quot; &amp; Treatment_status == &quot;PreTreatment&quot;) colnames(treatment_pre) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; ## [3] &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; ## [5] &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; ## [9] &quot;Aristida.purpurea&quot; &quot;Aristida.schiedeana.var.orcuttiana&quot; ## [11] &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; ## [15] &quot;Asclepias.nyctaginifolia&quot; &quot;Astragalus.sp&quot; ## [17] &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; ## [21] &quot;Bothriochloa.ischaemum&quot; &quot;Bouteloua.curtipendula&quot; ## [23] &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; ## [27] &quot;Brickellia.betonicifolia&quot; &quot;Brickellia.californica&quot; ## [29] &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; ## [33] &quot;Calliandra.humilis&quot; &quot;Calliandra.humilis.var.reticulata&quot; ## [35] &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; ## [39] &quot;Coleogyne.ramosissima&quot; &quot;Collinsia.parviflora&quot; ## [41] &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; ## [45] &quot;Cyperus.fendlerianus&quot; &quot;Cyperus.sp&quot; ## [47] &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; ## [51] &quot;Desmanthus.cooleyi&quot; &quot;Desmodium.batocaulon&quot; ## [53] &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; ## [57] &quot;Eragrostis.curvula&quot; &quot;Eragrostis.intermedia&quot; ## [59] &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; ## [63] &quot;Eriogonum.wrightii&quot; &quot;Escobaria.sp&quot; ## [65] &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; ## [69] &quot;Euphorbia.serpyllifolia&quot; &quot;Evolvulus.sericeus&quot; ## [71] &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; ## [75] &quot;Glandularia.bipinnatifida&quot; &quot;Glandularia.gooddingii&quot; ## [77] &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; ## [81] &quot;Heterosperma.pinnatum&quot; &quot;Houstonia.wrightii&quot; ## [83] &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; ## [87] &quot;Lepidium.lasiocarpum&quot; &quot;Lonicera.arizonica&quot; ## [89] &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; ## [93] &quot;Mimosa.aculeaticarpa&quot; &quot;Mimosa.biuncifera&quot; ## [95] &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; ## [99] &quot;Muhlenbergia.longiligula&quot; &quot;Muhlenbergia.sp&quot; ## [101] &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; ## [105] &quot;Packera.neomexicana&quot; &quot;Pediomelum.tenuiflorum&quot; ## [107] &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; ## [111] &quot;Phemeranthus.parviflorus&quot; &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; ## [113] &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; ## [117] &quot;Polygonum.douglasii&quot; &quot;Portulaca.umbraticola&quot; ## [119] &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; ## [123] &quot;Rhus.trilobata&quot; &quot;richness_aggregated&quot; ## [125] &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; ## [129] &quot;Symphyotrichum.falcatum&quot; &quot;Tradescantia.sp&quot; ## [131] &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; ## [135] &quot;Vulpia.octoflora&quot; &quot;Xanthisma.gracile&quot; ## [137] &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; treatment_pre &lt;- dplyr::select(treatment_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1)) treatment_pret &lt;- t(treatment_pre) treatment_post &lt;- combined_data %&gt;% filter(Treatment == &quot;Treatment&quot; &amp; Treatment_status == &quot;PostTreatment&quot;) colnames(treatment_post) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; ## [3] &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; ## [5] &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; ## [9] &quot;Aristida.purpurea&quot; &quot;Aristida.schiedeana.var.orcuttiana&quot; ## [11] &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; ## [15] &quot;Asclepias.nyctaginifolia&quot; &quot;Astragalus.sp&quot; ## [17] &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; ## [21] &quot;Bothriochloa.ischaemum&quot; &quot;Bouteloua.curtipendula&quot; ## [23] &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; ## [27] &quot;Brickellia.betonicifolia&quot; &quot;Brickellia.californica&quot; ## [29] &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; ## [33] &quot;Calliandra.humilis&quot; &quot;Calliandra.humilis.var.reticulata&quot; ## [35] &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; ## [39] &quot;Coleogyne.ramosissima&quot; &quot;Collinsia.parviflora&quot; ## [41] &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; ## [45] &quot;Cyperus.fendlerianus&quot; &quot;Cyperus.sp&quot; ## [47] &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; ## [51] &quot;Desmanthus.cooleyi&quot; &quot;Desmodium.batocaulon&quot; ## [53] &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; ## [57] &quot;Eragrostis.curvula&quot; &quot;Eragrostis.intermedia&quot; ## [59] &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; ## [63] &quot;Eriogonum.wrightii&quot; &quot;Escobaria.sp&quot; ## [65] &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; ## [69] &quot;Euphorbia.serpyllifolia&quot; &quot;Evolvulus.sericeus&quot; ## [71] &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; ## [75] &quot;Glandularia.bipinnatifida&quot; &quot;Glandularia.gooddingii&quot; ## [77] &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; ## [81] &quot;Heterosperma.pinnatum&quot; &quot;Houstonia.wrightii&quot; ## [83] &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; ## [87] &quot;Lepidium.lasiocarpum&quot; &quot;Lonicera.arizonica&quot; ## [89] &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; ## [93] &quot;Mimosa.aculeaticarpa&quot; &quot;Mimosa.biuncifera&quot; ## [95] &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; ## [99] &quot;Muhlenbergia.longiligula&quot; &quot;Muhlenbergia.sp&quot; ## [101] &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; ## [105] &quot;Packera.neomexicana&quot; &quot;Pediomelum.tenuiflorum&quot; ## [107] &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; ## [111] &quot;Phemeranthus.parviflorus&quot; &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; ## [113] &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; ## [117] &quot;Polygonum.douglasii&quot; &quot;Portulaca.umbraticola&quot; ## [119] &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; ## [123] &quot;Rhus.trilobata&quot; &quot;richness_aggregated&quot; ## [125] &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; ## [129] &quot;Symphyotrichum.falcatum&quot; &quot;Tradescantia.sp&quot; ## [131] &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; ## [135] &quot;Vulpia.octoflora&quot; &quot;Xanthisma.gracile&quot; ## [137] &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; treatment_post &lt;- dplyr::select(treatment_post, -c(Year, PlotN, Treatment, Treatment_status, ...1)) treatment_postt &lt;- t(treatment_post) #combine matrices, control_pre, control_post, treatment_pre, treatment_post, in a matrix of N lists combined_list &lt;- list(control_pre = control_pre, control_post = control_post, treatment_pre = treatment_pre, treatment_post = treatment_post) lapply(combined_list, head) ## $control_pre ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 ## 2 0 0 0 0 ## 3 0 0 0 0 ## 4 0 1 0 0 ## 5 0 0 0 0 ## 6 0 0 0 1 ## # ℹ 131 more variables: Arctostaphylos.pringlei &lt;dbl&gt;, Arctostaphylos.pungens &lt;dbl&gt;, ## # Arenaria.lanuginosa.var.saxosa &lt;dbl&gt;, Aristida.purpurea &lt;dbl&gt;, ## # Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, ## # Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, Bahia.biternata &lt;dbl&gt;, ## # Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, ## # Bouteloua.curtipendula &lt;dbl&gt;, Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, … ## ## $control_post ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 ## 2 0 0 0 0 ## 3 0 0 0 0 ## 4 0 0 0 0 ## 5 0 0 0 0 ## 6 0 0 0 0 ## # ℹ 131 more variables: Arctostaphylos.pringlei &lt;dbl&gt;, Arctostaphylos.pungens &lt;dbl&gt;, ## # Arenaria.lanuginosa.var.saxosa &lt;dbl&gt;, Aristida.purpurea &lt;dbl&gt;, ## # Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, ## # Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, Bahia.biternata &lt;dbl&gt;, ## # Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, ## # Bouteloua.curtipendula &lt;dbl&gt;, Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, … ## ## $treatment_pre ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 ## 2 0 0 0 0 ## 3 0 0 0 0 ## 4 0 0 0 0 ## 5 0 0 0 0 ## 6 0 0 0 0 ## # ℹ 131 more variables: Arctostaphylos.pringlei &lt;dbl&gt;, Arctostaphylos.pungens &lt;dbl&gt;, ## # Arenaria.lanuginosa.var.saxosa &lt;dbl&gt;, Aristida.purpurea &lt;dbl&gt;, ## # Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, ## # Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, Bahia.biternata &lt;dbl&gt;, ## # Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, ## # Bouteloua.curtipendula &lt;dbl&gt;, Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, … ## ## $treatment_post ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 ## 2 0 0 0 0 ## 3 0 0 0 0 ## 4 0 0 0 0 ## 5 0 0 0 0 ## 6 0 0 0 0 ## # ℹ 131 more variables: Arctostaphylos.pringlei &lt;dbl&gt;, Arctostaphylos.pungens &lt;dbl&gt;, ## # Arenaria.lanuginosa.var.saxosa &lt;dbl&gt;, Aristida.purpurea &lt;dbl&gt;, ## # Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, ## # Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, Bahia.biternata &lt;dbl&gt;, ## # Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, ## # Bouteloua.curtipendula &lt;dbl&gt;, Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, … combined_list &lt;- lapply(combined_list, function(x) { if(is.data.frame(x)) as.matrix(x) else x }) str(combined_list) ## List of 4 ## $ control_pre : num [1:6, 1:135] 0 0 0 0 0 0 0 0 0 1 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ control_post : num [1:6, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ treatment_pre : num [1:16, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ treatment_post: num [1:16, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... Now that we have the data in the correct format, let’s analyze! library(iNEXT) # Example of running iNEXT on incidence_raw data results &lt;- suppressWarnings({iNEXT(combined_list, q=0, datatype=&quot;incidence_raw&quot;)}) # Plot the results plot(results) Let’s transform an abundance dataset! This dataset consists of observations of pollinators within an ecoregion for two time periods. Far more observations were collected after the development of cell phones and app-based species identification software like iNaturalist. In order to compare the two assemblages, you must calculate asymptotic diversity estimates using R/E curves. The dataset has been cleaned and spatially-thinned, so that we assume that each observation indicates a distinct individual and thus we have an estimate of abundance within this ecoregion. First, check out the dataset. Here, each row corresponds to an observation. In order to run analyses on this data, we must transform the data into either an S by N abundance matrix (bird data), or N lists of species abundances (spider data). Let’s transform our data into the list structure. #you have to adjust the code to port in this datasets! library(readr) url3 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1bpLmtDDEPAdSaTPFPNg33hyj6y0viqxk&quot; arcticlocs &lt;- read_csv(url3) #time periods arcticlocsTP1 &lt;- filter(arcticlocs, year &gt;= 1939 &amp; year &lt; 1979) arcticlocsTP2 &lt;- filter(arcticlocs, year &gt;= 1980 &amp; year &lt; 2021) obsTP1 &lt;- length(arcticlocsTP1$genus) obsTP2 &lt;- length(arcticlocsTP2$genus) lengthsofobs &lt;- c(obsTP1, obsTP2) #Time period 1 arcticlocsTP1sum &lt;- plyr::count(arcticlocsTP1, &#39;genus&#39;) arcticlocsTP1unitnum &lt;- length(arcticlocsTP1$genus) arcticlocsTP1V &lt;- c(arcticlocsTP1unitnum, arcticlocsTP1sum$freq) arcticlocsTP1Vn &lt;- as.numeric(arcticlocsTP1V) #Time period 2 arcticlocsTP2sum &lt;- plyr::count(arcticlocsTP2, &#39;genus&#39;) arcticlocsTP2unitnum &lt;- length(arcticlocsTP2$genus) arcticlocsTP2V &lt;- c(arcticlocsTP2unitnum, arcticlocsTP2sum$freq) arcticlocsTP2Vn &lt;- as.numeric(arcticlocsTP2V) arctic &lt;- list(&quot;TimePeriod1&quot; = arcticlocsTP1Vn, &quot;TimePeriod2&quot; = arcticlocsTP2Vn) str(arctic) ## List of 2 ## $ TimePeriod1: num [1:11] 13 1 2 1 1 1 3 1 1 1 ... ## $ TimePeriod2: num [1:163] 365 3 4 1 1 1 2 2 3 3 ... Now, our data consists of two lists - one for time period one and one describing time period two. Let’s run our analyses. Note that ggiNEXT is a wrapper for the standard ggplot function, and can be manipulated just like ggplot. #establish the max extrapolation number (two times the largest sample) and the knots manually maxrun &lt;- (max(obsTP1, obsTP2)*2) t &lt;- seq(1, maxrun, by=1) out.inc &lt;- iNEXT(arctic, q=c(0,1,2), datatype=&quot;incidence_freq&quot;, size=t, nboot=200) arcticfigure &lt;- ggiNEXT(out.inc, facet.var=&quot;Order.q&quot;, se =TRUE, grey = TRUE) + ylab(&quot;Generic diversity&quot;) + ggtitle(&quot;Arctic cordillera&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)); arcticfigure Wonderful! You’ve transformed your data into the iNEXT format according to your data type. Now, work through an example with your own data! Put your data into the correct format based on your data, and analyze away. "],["ordination-station.html", "Chapter 39 Ordination station", " Chapter 39 Ordination station "],["what-are-structural-equation-models.html", "Chapter 40 What are structural equation models? 40.1 Anatomy of a Structural Equation Model 40.2 Building Multivariate Models 40.3 From Concept to Model 40.4 Common Structures in Causal Diagrams 40.5 Chapter 5: Covariance-Based Estimation in SEM 40.6 Getting Started with lavaan – Model Specification, Estimation, and Interpretation", " Chapter 40 What are structural equation models? Structural Equation Modeling (SEM) is a statistical technique that enables the modeling of complex causal relationships among variables. It extends regression by allowing: Simultaneous estimation of multiple equations Inclusion of both observed and latent (unmeasured) variables Specification of indirect effects and feedback loops Assessment of model fit against observed data SEM is often visualized as a path diagram, where arrows represent hypothesized relationships between variables. 40.0.1 When Should You Use SEM? Use SEM when: You have multiple dependent variables that may influence one another You want to estimate direct and indirect effects between variables You need to account for measurement error in survey or ecological constructs You are testing a theory or conceptual model with multiple pathways Your system includes latent constructs like “habitat quality” or “disturbance pressure” inferred from several indicators SEM is ideal when a single regression model is too simplistic to capture the interdependent relationships in your system. 40.0.2 How is SEM Different from Multiple Regression? Feature Multiple Regression SEM Number of equations One Many simultaneously Latent variables ❌ Not allowed ✅ Allowed Indirect effects ❌ Manual calculation ✅ Modeled explicitly Measurement error (in predictors) ❌ Ignored ✅ Can be modeled Model fit assessment R², AIC, etc. Chi-square test, RMSEA, CFI, TLI, etc. In multiple regression, you can only estimate one equation at a time, with no ability to model feedback loops or measurement error. In contrast, SEM treats your whole system as a network, testing how well your full model fits the data. 40.0.3 Summary SEM is a flexible and powerful framework for: Exploring and testing theoretical models Modeling complex causal chains Incorporating unobservable constructs It provides more rigorous insights into systems where variables are interdependent, influenced by hidden factors, and subject to error. 40.1 Anatomy of a Structural Equation Model Structural Equation Modeling (SEM) provides a flexible framework for representing complex causal relationships between variables. In this chapter, we break down the structure of an SEM into its key components. 40.1.1 Types of Variables SEM uses two main types of variables: Observed variables: Directly measured values (e.g., soil nitrogen, species richness). Latent variables: Not directly observed, but inferred from multiple observed indicators (e.g., a latent “Disturbance Pressure” factor inferred from road density, fire frequency, and grazing). Each variable also plays one of two roles in the model: Variable Role Description Exogenous Predictor variables not explained by any other variables in the model. Endogenous Response variables influenced by one or more other variables in the model. Note: Endogenous variables can act as both outcomes and predictors of other endogenous variables. 40.1.2 Path Diagrams Path diagrams are a central feature of SEM. They visually represent the hypothesized relationships between variables using arrows: Single-headed arrows (→) represent causal/predictive paths Double-headed arrows (↔︎) represent covariances (associations not assumed to be causal) 40.2 Building Multivariate Models 40.2.1 What is Causality? Causality refers to understanding the directional effect one variable has on another. In SEM, causal relationships are explicitly modeled, unlike in multiple regression where they may be implied but not specified. Judea Pearl’s Ladder of Causation is a framework for understanding levels of causal reasoning: 1. Observation — association reasoning (“what is”) 2. Intervention — action-based reasoning (“what if I do”) 3. Counterfactuals — imagining alternate realities (“what if I had done”) We ascend the ladder by incorporating more assumptions and a model of the system. 40.2.2 Why move beyond Multiple Regression? Multiple regression models: • Estimate associations while “controlling for” other variables • Assume independence among predictors • Do not explicitly encode causal structure Causal models (via SEM): • Represent direction and strength of causal pathways • Account for mediators, confounders, and latent variables • Enable testing of hypotheses about mechanisms 40.2.3 Meta-Modeling Your System Before diving into data, build a conceptual model: 1. Define your research Purpose: • Discovery: Are you exploring patterns or relationships for the first time? • Hypothesis Testing: Are you evaluating a specific theoretical prediction? • Prediction: Are you aiming to forecast outcomes under new conditions? Tip: Discovery-based models might be more flexible or exploratory, while hypothesis testing demands tighter causal logic and pre-specified relationships. 2. Identify the Focus: What role do your variables play in the system?: • Drivers: Variables that initiate causal change (e.g., treatments, environmental context). • Responses: Outcome variables (e.g., pollinator abundance). • Mediators: Variables that transmit effects from causes to outcomes (e.g., plant cover). Make sure the pieces of your model are causal! Avoid throwing in all your variables just because you measured them — each should have a theorized role. 3. Determine Span of Inference: Are your findings meant to be context-specific or to inform broader generalizations?: • Local/System-Specific: Targeted insights for a particular site or management action. • Generalizable Process: Testing broad ecological principles or multi-site patterns. • Theory Testing: Are you evaluating a known causal pathway or testing a novel ecological hypothesis? This choice influences how you frame your model structure and what covariates (like “site”) you might treat as fixed or random. 40.3 From Concept to Model Once your meta-model is constructed: • Reify with data availability in mind • Ensure your DAG closes appropriate backdoors • Align structure with your research purpose Make sure the pieces of your model are causal! 40.4 Common Structures in Causal Diagrams In structural equation modeling (SEM) and causal inference, understanding the basic building blocks of causal diagrams is crucial. These structures form the foundation for determining what to control for and what to avoid controlling for. Below are the most common structures you’ll encounter in Directed Acyclic Graphs (DAGs), with brief explanations and examples. 40.4.1 Chains (Mediation Paths) Structure: Cause → Mediator → Effect Interpretation: • The mediator is an intermediate variable through which the cause affects the effect. • If you control for the mediator, you block the indirect path, potentially underestimating the total effect of the cause. Example: Fire frequency → Canopy cover → Soil moisture • If you control for canopy cover, you might miss the full effect that fire frequency has on soil moisture via changes in canopy cover. Visual: library(dagitty) library(ggdag) dag &lt;- dagify( SoilMoisture ~ CanopyCover, CanopyCover ~ Fire, labels = c(Fire = &quot;Fire Frequency&quot;, CanopyCover = &quot;Canopy Cover&quot;, SoilMoisture = &quot;Soil Moisture&quot;), exposure = &quot;Fire&quot;, outcome = &quot;SoilMoisture&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 40.4.2 Colliders Structure: Cause1 → Collider ← Cause2 Interpretation: • A collider is a variable that is influenced by two (or more) variables. • Controlling for the collider opens a path between the two causes, creating spurious associations where none may exist. Example: Soil nitrogen → Plant growth ← Pathogen load • Both soil nitrogen and pathogen load affect plant growth. If you control for plant growth (the collider), it might look like soil nitrogen and pathogens are correlated—even if they’re not. Visual: dag &lt;- dagify( PlantGrowth ~ SoilNitrogen + PathogenLoad, labels = c(SoilNitrogen = &quot;Soil N&quot;, PathogenLoad = &quot;Pathogens&quot;, PlantGrowth = &quot;Plant Growth&quot;), exposure = &quot;SoilNitrogen&quot;, outcome = &quot;PathogenLoad&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 40.4.3 Forks (Confounding Paths) Structure: CommonCause → Cause, CommonCause → Effect Interpretation: • This is a confounding structure, where the common cause explains the observed correlation between two variables. • Controlling for the common cause blocks the backdoor path, helping isolate the causal effect. Example: Soil type → Invasive species cover Soil type → Native species richness • If you don’t control for soil type, you may falsely conclude that invasive cover affects native richness, when both are simply driven by the soil. Visual: dag &lt;- dagify( InvasiveCover ~ SoilType, NativeRichness ~ SoilType, labels = c(SoilType = &quot;Soil Type&quot;, InvasiveCover = &quot;Invasive Cover&quot;, NativeRichness = &quot;Native Richness&quot;), exposure = &quot;InvasiveCover&quot;, outcome = &quot;NativeRichness&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 40.4.4 Descendants of Colliders Key Point: • Controlling for descendants of colliders can also open spurious paths. Example: Imagine you control for a variable like Plant biomass, which is a descendant of a collider. This can reintroduce bias just like controlling for the collider itself. 40.4.5 Summary of strcutures Structure Do You Control For It? Why? Chain (mediator) ❌ (if estimating total effect) Controls block indirect paths Collider ❌ Conditioning opens spurious paths Fork (common cause) ✅ Controls block confounding Descendant of Collider ❌ Opens collider paths indirectly Understanding these structures helps you build better SEMs, choose correct adjustment sets, and avoid introducing bias into your models. 40.4.6 Identifying Causality You don’t need to know all mechanisms to make causal claims. But you do need to: • Map the system (e.g., using DAGs) • Identify and control for confounders • Avoid controlling for mediators 40.4.7 Backdoor Criterion To estimate a causal effect of X → Y, block all backdoor paths (those that flow into X) by conditioning on appropriate variables not affected by X. 40.4.8 Frontdoor Criterion Useful when you can’t block all backdoor paths. Identify a mediator that: • Is affected by X • Affects Y • Is not affected by any confounders of X and Y 40.4.9 Build your own DAG: SEM Case Study on Pollinator Impacts of Vegetation Management This research project explores how different Integrated Vegetation Management (IVM) treatments conducted by Arizona Public Service (APS) on powerline rights-of-way (ROWs) affect pollinator communities, using Structural Equation Modeling (SEM) to untangle direct and indirect effects. 40.4.9.1 Study Context APS manages vegetation beneath powerlines for safety and access, using a mix of: • Mechanical removal • Herbicide application • Combined Mechanical + Herbicide • Untreated (Control) plots Understanding how these treatments influence floral resources is key to predicting changes in pollinator abundance and diversity. 40.4.9.2 Data Collection At 3 sites, treatments were applied in a randomized block design across plots categorized as: • Control • Herbicide • Mechanical • Mechanical + Herbicide Researchers want to test whether management effects on pollinators are mediated through floral resources, or whether there are residual (direct) effects of treatment type beyond vegetation structure. 40.4.9.3 Key Variables and Their Roles Exogenous (Independent) Variables: • Treatment (main predictor—e.g., herbicide, mowing) • Soil substrate (moderator/stratifier of treatment effects) • Cattle presence (a confounder—not caused by treatment) Plant Community Mediators: • Plant richness • Plant cover • Plant height • Ceanothus presence/abundance • Woody debris Pollinator Response Variables: • Pollinator abundance • Pollinator richness library(dagitty) library(ggdag) library(tidyverse) # Define the DAG ivm_dag &lt;- dagitty(&quot; dag { Treatment Soil_Substrate Cattle Plant_Richness Plant_Cover Plant_Height Ceanothus Woody_Debris Pollinator_Richness Pollinator_Abundance Treatment -&gt; Plant_Richness Treatment -&gt; Plant_Cover Treatment -&gt; Plant_Height Treatment -&gt; Ceanothus Treatment -&gt; Woody_Debris Soil_Substrate -&gt; Treatment Soil_Substrate -&gt; Plant_Richness Soil_Substrate -&gt; Plant_Cover Soil_Substrate -&gt; Woody_Debris Cattle -&gt; Plant_Richness Cattle -&gt; Plant_Cover Cattle -&gt; Pollinator_Abundance Cattle -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Abundance Plant_Cover -&gt; Pollinator_Richness Plant_Cover -&gt; Pollinator_Abundance Plant_Height -&gt; Pollinator_Richness Plant_Height -&gt; Pollinator_Abundance Ceanothus -&gt; Pollinator_Richness Ceanothus -&gt; Pollinator_Abundance Woody_Debris -&gt; Pollinator_Richness Woody_Debris -&gt; Pollinator_Abundance } &quot;) node_roles &lt;- tibble( name = c( &quot;Treatment&quot;, &quot;Soil_Substrate&quot;, &quot;Cattle&quot;, &quot;Plant_Richness&quot;, &quot;Plant_Cover&quot;, &quot;Plant_Height&quot;, &quot;Ceanothus&quot;, &quot;Woody_Debris&quot;, &quot;Pollinator_Richness&quot;, &quot;Pollinator_Abundance&quot; ), role = c( &quot;Treatment&quot;, &quot;Context&quot;, &quot;Context&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Pollinator&quot;, &quot;Pollinator&quot; ) ) # Get layout and merge roles dag_df &lt;- tidy_dagitty(ivm_dag, layout = &quot;nicely&quot;) %&gt;% left_join(node_roles, by = &quot;name&quot;) # Plot using ggplot2 with corrected edge structure ggplot() + geom_segment( data = dag_df %&gt;% filter(!is.na(xend)), aes(x = x, y = y, xend = xend, yend = yend), arrow = arrow(length = unit(0.02, &quot;npc&quot;)), color = &quot;grey40&quot; ) + geom_point( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, color = role), size = 8, alpha = 0.85 ) + geom_text( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, label = name), color = &quot;black&quot;, size = 4 ) + scale_color_manual(values = c( &quot;Treatment&quot; = &quot;#FB7E21FF&quot;, &quot;Context&quot; = &quot;#A91601FF&quot;, &quot;Plant&quot; = &quot;#18DDC2FF&quot;, &quot;Pollinator&quot; = &quot;#00468BFF&quot; )) + labs( title = &quot;Hypothesized DAG for Pollinator Response to IVM Treatment&quot;, color = &quot;Variable Type&quot; ) + theme_void() 40.4.10 Adjustment Sets An adjustment set is a group of variables you control for (include as covariates) in order to estimate the causal effect of one variable (say, Treatment) on another (say, Pollinator_Richness) without bias. In short, it blocks backdoor paths — those sneaky alternative routes through which spurious associations can travel. To find variables to condition on: # adjustmentSets(ivm_dag, exposure = &quot;Treatment&quot;, outcome = &quot;Pollinator_Richness&quot;) # adjustmentSets(ivm_dag, exposure = &quot;Treatment&quot;, outcome = &quot;Pollinator_Abundance&quot;) Interpretation: To estimate the total causal effect of Treatment on Pollinator_Richness, you only need to adjust for Soil_Substrate. This means: • Soil_Substrate is a backdoor variable — it opens a non-causal path because it influences both Treatment and plant variables that, in turn, influence pollinators. • Controlling for Soil_Substrate blocks that spurious path and gives you an unbiased estimate of the effect of Treatment. Do not control for: • Mediators, like Plant_Richness, Plant_Cover, or Woody_Debris, if you want the total effect of treatment. • Colliders, such as anything caused by both Treatment and another variable (you don’t have a clear collider in this DAG, but good to keep in mind). Example in a model: • model &lt;- lm(Pollinator_Richness ~ Treatment + Soil_Substrate, data = your_data) GREG HERE YOU NEED TO CREATE YOUR FINAL DATASET BY SUMMARIZING THE VEG DATA AND ADDING YOUR POLLINATOR DATA PER PLOT. THEN WE CAN ADJUST THE CODE BELOW TO TEST WHETHER YOU REPLICATION / DATA ARE OK AND THEN MOVE ONTO NEXT STEPS 40.5 Chapter 5: Covariance-Based Estimation in SEM # library(lavaan) # library(mvtnorm) # library(mvnormtest) # library(psych) # library(Matrix) 40.5.1 What is Covariance-Based SEM? Structural Equation Modeling (SEM) using covariance-based maximum likelihood estimation fits parameters so that the model-implied covariance matrix matches the observed covariance matrix as closely as possible. Unlike individual regression models: SEM accounts for how estimation of one parameter affects others. SEM allows for modeling feedbacks and latent variables. SEM is based on maximum likelihood estimation (MLE). 40.5.2 Maximum Likelihood Estimation In SEM, MLE identifies parameters that maximize the likelihood of observing the data, given the model. This involves: Exploring the parameter space iteratively. Estimating model fit using a fitting function like ML. Computationally intensive with more parameters. 40.5.3 Assumptions Behind ML Estimation Multivariate normality (use mvnormtest::mshapiro.test()) # Load necessary package # if (!requireNamespace(&quot;mvnormtest&quot;, quietly = TRUE)) { # install.packages(&quot;mvnormtest&quot;) # } # library(mvnormtest) # # # Simulate multivariate normal data # set.seed(123) # data &lt;- data.frame( # x1 = rnorm(100), # x2 = rnorm(100), # x3 = rnorm(100) # ) # # # Apply Mardia-Shapiro-Wilk test (requires transpose) # mshapiro.test(t(data)) No severe skew or missing data No redundant variables (covariance matrix must be positive definite) # # Check skew and kurtosis # psych::describe(data) # # # Check for missing data # summary(is.na(data)) # Should be all FALSE Sufficient sample size relative to parameters # # Load the lavaan package # if (!requireNamespace(&quot;lavaan&quot;, quietly = TRUE)) { # install.packages(&quot;lavaan&quot;) # } # library(lavaan) # # # Define a simple SEM model # model &lt;- &#39; # y1 ~ x1 + x2 # y2 ~ y1 # &#39; # # # Simulate data # set.seed(123) # data &lt;- data.frame( # x1 = rnorm(100), # x2 = rnorm(100), # y1 = rnorm(100), # y2 = rnorm(100) # ) # # # Fit the model # fit &lt;- sem(model, data = data) # # # Print summary # summary(fit) # # # Count parameters # n_params &lt;- lavInspect(fit, &quot;npar&quot;) # Number of free parameters # n_obs &lt;- nrow(data) # # # Portnoy&#39;s rule # portnoy_value &lt;- n_params^(3/2) / n_obs # portnoy_value 40.5.4 Identifiability Before fitting a SEM, you must ensure it is identified — meaning you have enough unique information to estimate all model parameters. 40.5.4.1 Key Rules T-rule: Number of parameters ≤ unique entries in covariance matrix. # # Number of unique observed covariances # p &lt;- ncol(data) # n_cov &lt;- p * (p + 1) / 2 # # # Compare to number of free parameters # n_cov # lavInspect(fit, &quot;npar&quot;) # Should be ≤ n_cov Order condition: For each endogenous variable, incoming paths ≤ connected variables. There’s no direct test — but: • Draw your DAG. • Count how many arrows go into each endogenous variable. • Make sure that number ≤ number of variables related to it. Rank condition: Variables in feedback loops must be influenced by different causes. • For feedback loops: ensure that each variable has at least one unique exogenous predictor. • Use DAG tools (ggdag or dagitty) to visualize and confirm. If these rules are violated, the model is underidentified and cannot be estimated. 40.5.5 Degrees of Freedom DF = number of observed variances/covariances – number of estimated parameters Just-identified models (DF = 0): Can’t test fit Overidentified models (DF &gt; 0): Preferred — allows model fit evaluation # library(lavaan) # # # define model as a lavaan-style string # model &lt;- &#39; # cover ~ age + elev # firesev ~ age + cover # &#39; # # fit &lt;- sem(model, data = keeley) # fitMeasures(fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;pvalue&quot;, &quot;cfi&quot;, &quot;rmsea&quot;)) 40.5.6 Sample Size Considerations A model’s complexity is limited by your sample size: Rule of thumb: ≥ 5 observations per estimated parameter Preferably: ≥ 20 observations per parameter Use Portnoy’s rule: ρ3/2 / n → 0 Account for: Exogenous variable variances/covariances (often directly estimated from data) Endogenous variable error variances (often derived, not estimated directly) 40.5.7 Summary Covariance-based SEM is powerful but demands careful model design: Check identifiability before estimation Be aware of sample size constraints Use model diagnostics to evaluate fit after estimation 40.5.8 Chapter 6: Structural Equation Modeling in R with lavaan 40.6 Getting Started with lavaan – Model Specification, Estimation, and Interpretation Setting Up Before you begin, make sure the lavaan and lavaanPlot packages are installed: What is lavaan? • lavaan stands for Latent Variable Analysis. • Developed by Yves Rosseel (2010). • Syntax is similar to regression in R using formulas. • It supports latent and observed variables, covariance-based SEM, mediation, path analysis, and more. Example: Post-Fire Plant Recovery We’ll analyze a dataset from Keeley et al. (2006) studying how stand age, fire severity, and other factors affect plant cover. Step 1: Start Simple – A Regression as SEM # Load dataset # Example: keeley &lt;- read.csv(&quot;path/to/your/keeley_data.csv&quot;) # Fit SEM #model1 &lt;- &#39;cover ~ age&#39; #fit1 &lt;- sem(model1, data = keeley) #summary(fit1, standardized = TRUE, rsquare = TRUE) Intercepts and Mean Structures To explicitly estimate intercepts: #fit1_mean &lt;- sem(model1, data = keeley, meanstructure = TRUE) #summary(fit1_mean) Viewing the Model #lavaanPlot(model = fit1, coefs = TRUE, stand = TRUE) Standardized Estimates standardizedSolution(fit1) This gives standardized coefficients and helps compare the relative strength of predictors. Mediation Example: Indirect Effects #model2 &lt;- &#39; # firesev ~ age # cover ~ firesev + age #&#39; #fit2 &lt;- sem(model2, data = keeley) #summary(fit2, standardized = TRUE, rsquare = TRUE) Direct, Indirect, and Total Effects #model3 &lt;- &#39; # firesev ~ af*age # cover ~ fc*firesev + ac*age # Derived # indirect := af * fc # total := ac + (af * fc) #&#39; #fit3 &lt;- sem(model3, data = keeley) #standardizedSolution(fit3) Warnings: Variance Scaling #varTable(fit3) If you get a warning about variances differing by orders of magnitude, consider rescaling your variables or using standardized solutions. Visualizing Complex Models #lavaanPlot( # model = fit3, # coefs = TRUE, # stand = TRUE, # sig = 0.05, # graph_options = list(layout = &quot;circo&quot;) #) Final Exercise Prompt Try fitting the following model: #model_final &lt;- &#39; # rich ~ distance + abiotic + hetero # hetero ~ distance # abiotic ~ distance # abiotic ~~ hetero #&#39; #fit_final &lt;- sem(model_final, data = keeley) #summary(fit_final, standardized = TRUE) 40.6.1 Chapter 7:Assessing Fit and Normality # library(lavaan) # library(mvnormtest) # library(MVN) Overview In this tutorial, we learn how to evaluate model fit and test for normality, key assumptions in covariance-based SEM. We’ll cover: • Standard fit indices (e.g., RMSEA, CFI) • Residuals and modification indices • Normality diagnostics • Remedies for assumption violations Example: Fully Mediated SEM #model_full &lt;- &#39; # firesev ~ age # cover ~ firesev #&#39; #fit_full &lt;- sem(model_full, data = keeley, meanstructure = TRUE) #summary(fit_full, fit.measures = TRUE) Interpretation: • Chi-square (p &gt; 0.05) → Model is not significantly different from the observed data. • Check additional fit indices: RMSEA, CFI, SRMR, AIC, BIC. Fit Indices (Kline 2023 Recommendations) Fit Measure Interpretation Chi-square test Prefer p &gt; 0.05 RMSEA 90% CI lower bound &lt; 0.05 CFI &gt; 0.90 SRMR &lt; 0.10 Diagnosing Misfit with Residuals #residuals(fit_full, type = &quot;cor&quot;) # residual correlations #modificationIndices(fit_full, standardized = FALSE, sort. = TRUE) • Large residuals or modification indices &gt; 3.84 suggest misfit. • Inspect residual correlation between rich and distance. Testing Normality of Residuals # library(MVN) # Step 1: Get residuals from lavaan model #resids &lt;- lavPredict(fit_full, type = &quot;ov&quot;) # residuals for observed variables # Optional: check univariate normality visually #apply(resids[, 1:2], 2, function(x) { # qqnorm(x); qqline(x) #}) # Step 2: Multivariate Shapiro-Wilk (for n ≤ 50) #mshapiro.test(t(resids[, 1:2])) # Step 3: Mardia&#39;s test for multivariate normality #MVN::mvn(data = resids[, 1:2], mvn_test = &quot;mardia&quot;) # Step 1: Get residuals from lavaan model #tryCatch({ # resids &lt;- lavPredict(fit_full, type = &quot;ov&quot;) # Make sure residuals are numeric and have no missing values # if (!is.null(resids) &amp;&amp; is.matrix(resids) &amp;&amp; all(is.finite(resids[, 1:2]))) { # Step 2: Multivariate Shapiro-Wilk (for n ≤ 50) # print(mshapiro.test(t(resids[, 1:2]))) # Step 3: Mardia&#39;s test # print(MVN::mvn(data = resids[, 1:2], mvn_test = &quot;mardia&quot;)) # } else { # message(&quot;Residuals are missing, not numeric, or contain NA/Inf values.&quot;) # } #}, error = function(e) { # message(&quot;MVN test failed: &quot;, conditionMessage(e)) #}) ⸻ If Assumptions Are Violated… Option 1: Satorra-Bentler Correction #fit_sb &lt;- sem(model_full, data = keeley, test = &quot;Satorra.Bentler&quot;) #summary(fit_sb) Option 2: Bollen-Stine Bootstrap #fit_bs &lt;- sem(model_full, data = keeley, test = &quot;bollen.stine&quot;, se = &quot;boot&quot;, bootstrap = 1000) #summary(fit_bs) Summary: • Use fit indices and residuals to assess model performance. • Check assumptions of normality; consider corrections if violated. • Explore modification indices to identify potential improvements. 40.6.2 Chapter 8: Comparing Models and Testing Mediation This section introduces two major approaches for comparing SEM models: • Likelihood Ratio Tests (LRTs) for nested models. • Information Criteria (e.g., AIC, AICc) for both nested and non-nested models. We also explore mediation, which refers to how a relationship between two variables is explained by one or more intervening variables. # Load required libraries # library(lavaan) # library(AICcmodavg) # # # Fully Mediated Model # fullMedModel &lt;- &#39; # firesev ~ age # cover ~ firesev # &#39; # fullMedSEM &lt;- sem(fullMedModel, data = keeley) # # # Partially Mediated Model # partialMedModel &lt;- &#39; # firesev ~ age # cover ~ firesev + age # &#39; # partialMedSEM &lt;- sem(partialMedModel, data = keeley) # # # Likelihood Ratio Test (nested models) # anova(partialMedSEM, fullMedSEM) Interpretation: A non-significant LRT suggests that the simpler (fully mediated) model fits the data about as well as the more complex model. AIC-Based Model Comparison # # install.packages(&quot;AICcmodavg&quot;) # library(AICcmodavg) # # # AICc model comparison # aictab( # cand.set = list(fullMedSEM, partialMedSEM), # modnames = c(&quot;Full&quot;, &quot;Partial&quot;) # ) Interpretation: Models within 2 ΔAICc units are considered roughly equivalent. Higher AIC weight (AICcWt) indicates stronger support for that model. Additional Example: Distance and Species Richness Key Takeaways: • Use LRT for nested models; lower chi-square and higher p-value = simpler model may suffice. • Use AICc for broader comparisons; lower AICc and higher weight = better. • Mediation is central to SEM and can be tested with both approaches. • Fully vs. Partially Mediated models differ by whether direct paths bypass mediators. 40.6.3 Chapter 8: Latent Variables as Drivers What is a Latent Variable? Latent variables are unobserved constructs that we infer from multiple observed indicators. They represent abstract concepts like intelligence, disturbance, or biodiversity. • In SEM, latent variables are drawn as circles. • Observed indicators are squares or rectangles. • Latent variables are typically estimated through Confirmatory Factor Analysis (CFA). Confirmatory Factor Analysis (CFA) CFA allows you to test whether certain observed variables co-vary in ways consistent with an underlying theoretical construct. Example: Aposematism in Poison Frogs # Sample covariance matrix from Santos &amp; Cannatella (2011) # santosCov &lt;- read.table(&quot;https://raw.githubusercontent.com/username/santosCov.txt&quot;, na.strings = #&quot;.&quot;) #santosCov &lt;- as.matrix(santosCov) # # Create covariance matrix manually (example values) # santosCov &lt;- matrix(c( # 1.00, 0.45, 0.38, # 0.45, 1.00, 0.50, # 0.38, 0.50, 1.00 # ), nrow = 3, byrow = TRUE) # # # Add row and column names (must match your CFA model exactly) # colnames(santosCov) &lt;- rownames(santosCov) &lt;- c(&quot;Alkaloid.quantity&quot;, &quot;Alkaloid.diversity&quot;, &quot;Conspicuous.coloration&quot;) # # # Specify CFA model # santosCFA1 &lt;- &#39; # Aposematism =~ Alkaloid.quantity + Alkaloid.diversity + Conspicuous.coloration # &#39; # # # Fit the model # santosFit1 &lt;- sem(santosCFA1, sample.cov = santosCov, sample.nobs = 21) # summary(santosFit1, standardized = TRUE) Why Use Latent Variables? • Increase accuracy by pooling information across multiple imperfect indicators. • Reduce measurement error. • Enable modeling of unobservable constructs. Identification Rules (How to Know Your Model Can Be Estimated): 1. T-Rule: Number of estimated parameters ≤ number of unique elements in the covariance matrix. 2. Three-indicator rule: Each latent variable has ≥ 3 uncorrelated indicators → SUFFICIENT. 3. Two-indicator rule: Works for multiple latent variables if indicators don’t share variance → SUFFICIENT. 4. Fixing scale: • Set variance of latent = 1.0, or • Set one loading to 1.0 to put latent on that indicator’s scale. Models with 2 indicators and shared error may be underidentified. Fit a Second Latent Variable: Body Size #santosSize &lt;- &#39; # Size =~ Log.Mass + Log.RMR + Log.Scope #&#39; #santosSizeFit &lt;- sem(santosSize, sample.cov = santosCov, sample.nobs = 21) #summary(santosSizeFit, standardized = TRUE) Combine Latent Variables You can model multiple latent variables and test how they relate to each other. #santosCFA2 &lt;- &#39; # Aposematism =~ Alkaloid.quantity + Alkaloid.diversity + Conspicuous.coloration + #Ant.Mite.Specialization + log.Prey # Scale =~ Log.Mass + Log.RMR + Log.Scope + Conspicuous.coloration #&#39; #santosFit2 &lt;- sem(santosCFA2, sample.cov = santosCov, sample.nobs = 21) #summary(santosFit2, standardized = TRUE) Summary: • Latent variables allow you to estimate unobservable concepts. • CFA is the method used to define latent variables in SEM. • Identification is critical—use the rules to check if your model can be estimated. • Measurement error is reduced by leveraging multiple indicators. 40.6.4 Chapter 10: Latent Responses and Measurement Error # library(lavaan) # library(semPlot) Overview In this section, we explore how latent variables can be modeled as responses and how to account for measurement error in observed indicators. Latent variables are constructs that cannot be measured directly (e.g., biodiversity, ecosystem health, intelligence), but are inferred from multiple observed indicators. Key Concepts Latent Variables as Responses Latent variables can be endogenous (influenced by other variables in the model). For instance: • A latent construct such as “Habitat Quality” could be influenced by soil moisture, disturbance, and vegetation cover. • Each latent construct is defined by observed indicators, which are imperfect and contain measurement error. Measurement Error SEM is powerful because it separates true score variance from error variance. Each observed variable has two components: • The true score linked to the latent construct. • The error term (random noise or instrument error). Accounting for measurement error prevents biased parameter estimates and inflated correlations. Example: Latent Response Model with Measurement Error We model a latent response Performance, influenced by an observed predictor Treatment, and measured via three indicators: perf1, perf2, perf3. # # Define the SEM # model &lt;- &#39; # # Measurement model # Performance =~ perf1 + perf2 + perf3 # # # Structural model # Performance ~ Treatment # &#39; # # # Simulate data # set.seed(123) # n &lt;- 200 # Treatment &lt;- rnorm(n) # perf1 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # perf2 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # perf3 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # data &lt;- data.frame(Treatment, perf1, perf2, perf3) # # # Fit the SEM # fit &lt;- sem(model, data = data) # summary(fit, standardized = TRUE) Visualizing the SEM #semPaths(fit, &quot;std&quot;, layout = &quot;tree&quot;, whatLabels = &quot;std&quot;) Why Model Latent Responses? • More reliable constructs by combining multiple indicators. • Reduces noise from any single observed variable. • Better reflects theoretical constructs (e.g., stress, biodiversity). Key Assumptions • Indicators are unidimensional (reflect one latent factor). • Measurement errors are uncorrelated. • Sufficient variation and correlation among indicators. Takeaway Modeling latent responses allows you to capture complex, unobserved constructs while accounting for error in measurements. SEM enables estimation of both the relationships among constructs and their measurement structure. "],["piecewise-sems.html", "Chapter 41 Piecewise SEMs 41.1 Overview 41.2 Why Use Piecewise SEM, instead of a covariance SEM? 41.3 SEM Example: Resilience to Drought in Arizona 41.4 Part 1: What is Piecewise SEM? 41.5 Overview 41.6 Example with Powerline Data", " Chapter 41 Piecewise SEMs 41.1 Overview This chapter introduces local (piece wise) SEM — an approach that decomposes a full SEM into a series of local linear models. It contrasts with global covariance-based SEM in both assumptions and evaluation. We will compare and contrast the two approaches, then perform an SEM. 41.2 Why Use Piecewise SEM, instead of a covariance SEM? Structural Equation Modeling (SEM) is a powerful framework for testing hypotheses about complex systems with multiple interrelated variables. In ecology and related fields, researchers often choose between covariance-based SEM (e.g., lavaan) and piecewise SEM (e.g., piecewiseSEM package in R). The choice depends on data structure, sample size, distributional assumptions, and model complexity. 41.2.1 Comparison of SEM Approaches Feature Covariance-Based SEM (lavaan) Piecewise SEM (piecewiseSEM) Data assumptions Assumes multivariate normality Robust to non-normal and non-independent data Model structure All relationships modeled simultaneously Model split into a series of (G)LMs or mixed models Fit assessment Global fit indices: χ², RMSEA, CFI, SRMR Local fit via D-separation and AIC Handling of missing data Can use FIML or imputation Depends on method used in each submodel Sample size requirements High; often N &gt; 200 recommended More flexible with small N Handling of hierarchical data Difficult to include random effects Allows mixed models with random effects Ease of interpreting indirect effects Straightforward via standardized estimates Requires manual calculation of indirect effects Measurement error modeling Supports latent variables Does not support latent variables Modularity and flexibility Limited to standard SEM frameworks Very flexible, especially for ecological or field data 41.2.2 Benefits of Covariance-Based SEM Ideal for testing complex, theory-driven models with latent variables. Provides global fit indices to assess how well the model captures the covariance structure. Useful for confirmatory modeling, especially in psychology, sociology, and tightly controlled experimental settings. 41.2.3 Benefits of Piecewise SEM More robust to violations of normality, independence, and small sample size. Supports hierarchical, nested, or repeated-measures data using mixed models. Offers modular modeling, which makes it easier to fit ecologically realistic models (e.g., with random effects, Poisson/binomial responses). Better suited to observational field data with complex structure. 41.2.4 When to Use Each Approach Use Covariance SEM (lavaan) when: You have a large sample size and want to model latent variables or measurement error. Your data meet assumptions of multivariate normality and independence. You’re interested in global fit metrics and standardized path coefficients. Use Piecewise SEM when: Your data are non-normal, hierarchical, or have small sample sizes. You need to model random effects, non-Gaussian outcomes, or temporal/spatial structure. You’re focusing on causal structure, not measurement error. 41.2.5 Models differ in approach Covariance-based SEM estimates all paths simultaneously by fitting a single model to the entire covariance matrix, providing global fit indices like chi-square (χ²) and RMSEA to assess how well the model reproduces the observed data. In contrast, piecewise SEM fits each path as a separate (G)LM or mixed model, and assesses overall model fit using D-separation tests, which evaluate whether any unmodeled relationships (i.e., conditional independencies) remain between variables—offering a more flexible, modular approach to complex or non-normal ecological data. 41.3 SEM Example: Resilience to Drought in Arizona This dataset combines climate, topographic, and biodiversity indicators to evaluate ecological resilience across sites in Arizona following a period of drought. The central research question is: What environmental and community-level factors predict ecological recovery or resilience in post-drought southwestern ecosystems? Data were compiled from NOAA climate records and field observations, and are structured at the plot level. Key variables include: Climate trends: Change in growing season temperature (gs_temp_slope) and precipitation (ppt_slope) Post-recovery climate: Including growing season mean maximum temperature (gs_tmax_mean), total monsoonal precipitation averaged over 2022-2023 (monsoon_ppt_mean), total winter precipitation averageed over 2022-2023 post-recovery time period (winter_ppt_mean) Drought indicators: Standardized indices including PET (potential evapotranspiration), DDD (drought duration), and DSI (drought severity index), and SWA (Soil Water Availability) Site disturbance history: Time since last fire (TSLF_imputed) Topographic factors: Slope and Aspect Community attributes: Taxonomic diversity (Diversity_q1), connectivity (dist_km) Recovery outcomes: Compositional dissimilarity (bray_curtis) and a remotely sensed recovery index (Recovery_Index) As always, a first step is to remove colinear variables from your dataset. When two or more predictors in your model are highly correlated, they share overlapping information about the response variable. This makes it harder for the model to determine which variable is actually responsible for changes in the response. We removed colinear variables in Chapter 11 - Model selection. After finalizing a dataset, we can build a path diagram and and SEM. We hypothesize that: Recovery (here modeled as bray_curtis) will depend on recent climatic trends (temp_slope, ppt_slope), the strength of the drought (PET, DDD, DSI, SWA), post-drought climatic recovery conditions (gs_tmax_mean, monsoon_ppt_mean, winter_ppt_mean), which could be mediated by the location of the community (Slope, Aspect) and affected by disturbance history (TSLF_imputed). Finally, we expect communities that are more diverse (Diversity_q1) and connected (dist_km) to demonstrate higher levels of recovery. Similarly, overall site diversity (Diversity_q1) will be affected by connectivity (dist_km), as well as recent climatic trends (temp_slope, ppt_slope), the strength of the drought (PET, DDD, DSI, SWA), post-drought climatic recovery conditions (gs_tmax_mean, monsoon_ppt_mean, winter_ppt_mean), which could be mediated by the location of the community (Slope, Aspect) and affected by disturbance history (TSLF_imputed). We expect that the strength of the drought (PET, DDD, DSI, SWA) will depend on its landscape position (Slope, Aspect), as well as recent climate change (temp_slope, ppt_slope). Go over causal chains, mediators, etc. Directed Separation (D-sep) D-sep tests whether missing paths in your model are truly unnecessary. It evaluates conditional independence assumptions implied by the model. Understanding D-separation • Two variables are D-separated if they are conditionally independent, given a set of other variables. • D-sep claims are testable and form the basis set of the model. # Define DAG g &lt;- dagitty(&quot;dag { x -&gt; y2 -&gt; y1 x -&gt; y1 }&quot;) # View conditional independencies implied by the DAG impliedConditionalIndependencies(g) Model Fit via Fisher’s C library(piecewiseSEM) # Simulate example data set.seed(123) n &lt;- 100 x &lt;- rnorm(n) y2 &lt;- 0.5 * x + rnorm(n) y1 &lt;- 0.6 * x + 0.4 * y2 + rnorm(n) example_data &lt;- data.frame(x, y1, y2) # Fit piecewise SEM mod_list &lt;- psem( lm(y2 ~ x, data = example_data), lm(y1 ~ x + y2, data = example_data) ) # ✅ Get model fit statistics (replaces sem.fit) fisherC(mod_list) ## Fisher.C df P.Value ## 1 NA 0 NA # ✅ Get standardized path coefficients (replaces sem.coefs) stdCoefs(mod_list) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate sig ## 1 y2 x 0.4475284 0.10687862 98 4.187258 6.172903e-05 0.3895619 *** ## 2 y1 x 0.4549228 0.11372501 97 4.000200 1.236720e-04 0.3509054 *** ## 3 y1 y2 0.4238113 0.09899469 97 4.281152 4.371472e-05 0.3755510 *** # ✅ Optional: View DAG plot(getDAG(mod_list)) Interpretation: • p &gt; 0.05 → model is not rejected, D-sep claims hold. • p &lt; 0.05 → model is rejected, missing paths may be important. Summary: • Piecewise SEM is ideal when: • Data violate global SEM assumptions. • Sample size is too small for global SEM. • You want to understand model fit using D-sep logic. • Use dagitty to derive implied independencies. • Use sem.fit() and sem.coefs() for piecewise evaluation. 41.3.1 Chapter 12: Introduction to Piecewise SEM in R Learning Objectives By the end of this tutorial, you will be able to: • Understand how piecewise SEM differs from traditional covariance-based SEM. • Fit a multi-equation SEM using the psem() function. • Evaluate model fit using d-separation tests and Fisher’s C statistic. • Extract path coefficients and R² values. • Visualize model structure and relationships using visreg, DiagrammeR, or plot(). 41.4 Part 1: What is Piecewise SEM? Piecewise SEM uses a local estimation approach: each equation is estimated separately using standard regression (e.g., lm, lmer). This provides greater flexibility, such as: • Including non-normal or mixed-effect models. • Dealing with small sample sizes or nested structures. • Assessing model fit through d-sep tests (Shipley’s test of directed separation). Limitations: • Can’t handle latent variables. • Not suitable for cyclical feedback loops. • Difficult to interpret in overidentified models with correlated errors. Part 2: Load Packages and Data # Load libraries library(piecewiseSEM) library(visreg) library(DiagrammeR) data(keeley) # from piecewiseSEM and work through this information Part 3: Specify and Fit Your Model # Fit individual models mod1 &lt;- lm(abiotic ~ distance, data = keeley) mod2 &lt;- lm(hetero ~ distance, data = keeley) mod3 &lt;- lm(rich ~ abiotic + hetero, data = keeley) # Combine into a psem object keeley_sem &lt;- psem(mod1, mod2, mod3) Evaluate Model Fit # Directed separation test #dSep(keeley_sem) # Fisher&#39;s C statistic #fisherC(keeley_sem) Interpret: • A non-significant p-value (&gt; 0.05) = model fits. • Significant missing paths → consider adding them and reassessing fit. Part 5: Summarize Coefficients and R² # Coefficients coefs(keeley_sem) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 abiotic distance 0.3998 0.0823 88 4.8562 0e+00 0.4597 *** ## 2 hetero distance 0.0045 0.0013 88 3.4593 8e-04 0.3460 *** ## 3 rich abiotic 0.8136 0.1746 87 4.6586 0e+00 0.4136 *** ## 4 rich hetero 45.0702 11.6797 87 3.8589 2e-04 0.3426 *** # R-squared values rsquared(keeley_sem) ## Response family link method R.squared ## 1 abiotic gaussian identity none 0.2113455 ## 2 hetero gaussian identity none 0.1197074 ## 3 rich gaussian identity none 0.3667967 Part 6: Plot Your Model Option A: Quick Base R Plot keeley_sem &lt;- psem( lm(firesev ~ age + cover, data = keeley), lm(cover ~ age + elev + firesev, data = keeley), data = keeley ) plot(keeley_sem) #Option B: Refined Graph with DiagrammeR # Optional customization plot(keeley_sem, node_attrs = list( x = c(2.5, 2.5, 4, 1), y = c(3, 1, 2, 2), shape = &quot;rectangle&quot;, fillcolor = &quot;white&quot; )) Part 7: Mediation Example mod_firesev &lt;- lm(firesev ~ age, data = keeley) mod_cover &lt;- lm(cover ~ firesev, data = keeley) firesev_model &lt;- psem(mod_firesev, mod_cover) summary(firesev_model) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of firesev_model ## ## Call: ## firesev ~ age ## cover ~ firesev ## ## AIC ## 364.696 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## cover ~ age + ... coef 87 -1.8018 0.075 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 3.297 with P-value = 0.069 and on 1 degrees of freedom ## Fisher&#39;s C = 5.18 with P-value = 0.075 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## firesev age 0.0597 0.0125 88 4.7781 0 0.4539 *** ## cover firesev -0.0839 0.0184 88 -4.5594 0 -0.4371 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## firesev none 0.21 ## cover none 0.19 dSep(firesev_model) ## | | | 0% | |===================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 cover ~ age + ... coef 87 -1.80184 0.07503437 rsquared(firesev_model) ## Response family link method R.squared ## 1 firesev gaussian identity none 0.2059938 ## 2 cover gaussian identity none 0.1910867 Bonus: Visualize with Covariates Held Constant # Visualize fire severity&#39;s effect on cover # visreg(firesev_model[[2]], xvar = &quot;firesev&quot;) Wrap-Up Piecewise SEM offers flexibility and clarity for causal inference in ecology. By evaluating each path independently while testing the full model’s coherence through d-sep and Fisher’s C, you gain both transparency and statistical rigor. 41.4.1 Chapter 13: Nonlinearity and Interaction in SEM Overview In this tutorial, we’ll cover: • Nonlinearities (e.g., polynomial terms) • Centering variables to reduce multicollinearity • Interaction terms • Implementing these in SEM frameworks Example 1: Nonlinear Effects (Cardinale et al. 2009) Load and Prepare Data # Download data url &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1oHBul4_JcqlPFZgYsH3WOIZJRQRw1O4F&quot; cardinale &lt;- read.csv(url) # Check it loaded head(cardinale) ## Stream Well N Chl SR SA ## 1 Adobe Creek 1 0e+00 0.0094 105 26 ## 2 Adobe Creek 5 1e-06 0.0100 105 24 ## 3 Adobe Creek 3 1e-04 0.0613 105 20 ## 4 Adobe Creek 4 1e-02 0.1003 105 23 ## 5 Adobe Creek 2 1e+00 0.2000 105 20 ## 6 Adobe Creek 1 0e+00 0.0377 105 21 # Log-transform variables cardinale$logN &lt;- log10(cardinale$N + 1e-6) cardinale$logN2 &lt;- cardinale$logN^2 cardinale$logChl &lt;- log10(cardinale$Chl) #Fit SEM with piecewiseSEM model1 &lt;- psem( lm(SA ~ logN + logN2 + SR, data = cardinale), lm(logChl ~ SA + logN + logN2, data = cardinale), logN %~~% logN2, data = cardinale ) summary(model1) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of model1 ## ## Call: ## SA ~ logN + logN2 + SR ## logChl ~ SA + logN + logN2 ## logN ~~ logN2 ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN -2.9944 1.5375 123 -1.9476 0.0537 -0.5044 ## SA logN2 -0.4742 0.2424 123 -1.9568 0.0526 -0.5067 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN 0.1168 0.0953 123 1.2258 0.2226 0.3858 ## logChl logN2 0.0032 0.015 123 0.2108 0.8334 0.0664 ## ~~logN ~~logN2 -0.9685 - 125 -43.4652 0.0000 -0.9685 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Reducing Collinearity via Centering # Center predictors cardinale$logN.cen &lt;- scale(cardinale$logN, scale = FALSE) cardinale$logN2.cen &lt;- cardinale$logN.cen^2 # Check correlation cor(cardinale$logN.cen, cardinale$logN2.cen) ## [,1] ## [1,] 0.5126311 Refit Model with Centered Predictors model2 &lt;- psem( lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale), lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale), logN.cen %~~% logN2.cen, data = cardinale ) summary(model2) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of model2 ## ## Call: ## SA ~ logN.cen + logN2.cen + SR ## logChl ~ SA + logN.cen + logN2.cen ## logN.cen ~~ logN2.cen ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN.cen 0.3668 0.446 123 0.8223 0.4125 0.0618 ## SA logN2.cen -0.4742 0.2424 123 -1.9568 0.0526 -0.1470 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN.cen 0.0944 0.0275 123 3.4320 0.0008 0.3116 *** ## logChl logN2.cen 0.0032 0.015 123 0.2108 0.8334 0.0193 ## ~~logN.cen ~~logN2.cen 0.5126 - 125 6.6752 0.0000 0.5126 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Try lavaan for the Same Model Example 2: Interaction Effects (Keeley et al.) Center and Create Interaction url2 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1YTsFP1T__Hn13hTvj9TVOK-wbGDxLd01&quot; # Try to read the CSV directly keeley &lt;- read.csv(url2) keeley$age_cent &lt;- scale(keeley$age, scale = FALSE) keeley$fire_cent &lt;- scale(keeley$firesev, scale = FALSE) keeley$int_term &lt;- keeley$age_cent * keeley$fire_cent Fit SEM with Interaction in piecewiseSEM keeley_int &lt;- psem( lm(cover ~ age_cent * fire_cent, data = keeley), lm(fire_cent ~ age_cent, data = keeley), data = keeley ) summary(keeley_int) ## ## Structural Equation Model of keeley_int ## ## Call: ## cover ~ age_cent * fire_cent ## fire_cent ~ age_cent ## ## AIC ## 362.993 ## ## --- ## Tests of directed separation: ## ## No independence claims present. Tests of directed separation not possible. ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0 with P-value = 1 and on 0 degrees of freedom ## Fisher&#39;s C = NA with P-value = NA and on 0 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## cover age_cent -0.0050 0.0027 86 -1.8810 0.0634 -0.1985 ## cover fire_cent -0.0684 0.0203 86 -3.3752 0.0011 -0.3561 ** ## cover age_cent:fire_cent -0.0021 0.0014 86 -1.5263 0.1306 -0.1438 ## fire_cent age_cent 0.0597 0.0125 88 4.7781 0.0000 0.4539 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## cover none 0.24 ## fire_cent none 0.21 Optional: Fit Interaction SEM with lavaan Final Notes: • Polynomial terms allow us to model curvature. • Centering reduces collinearity and changes interpretation. • Interaction terms help model conditional effects. • Both lavaan and piecewiseSEM support these techniques. 41.4.2 Chapter 14: GLMs with SEM using PiecewiseSEM This section integrates Generalized Linear Models (GLMs) into Structural Equation Modeling, especially using piecewiseSEM. It also introduces important adjustments for working with non-normal data, and compares latent theoretic (LT) and observed error (OE) approaches for standardizing coefficients. 41.5 Overview In this tutorial, we’ll: • Learn how to incorporate GLMs into SEM using piecewiseSEM • Understand how to deal with non-normality and directed separation warnings • Compute standardized coefficients using both Latent Theoretic (LT) and Observed Error (OE) approaches Data from Anderson et al. 2010 Example # Simulated structure to mimic Anderson et al. set.seed(42) anderson &lt;- data.frame( biomass.kg = rnorm(100, mean = 10, sd = 2), leafN = rnorm(100, mean = 3, sd = 0.5), landscape = sample(0:1, 100, replace = TRUE), hotspotYN = rbinom(100, 1, 0.4) ) Model: Using GLM in psem library(piecewiseSEM) anderson.sem &lt;- psem( lm(leafN ~ biomass.kg, data = anderson), glm(hotspotYN ~ leafN + biomass.kg + landscape, family = &quot;binomial&quot;, data = anderson) ) summary(anderson.sem) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of anderson.sem ## ## Call: ## leafN ~ biomass.kg ## hotspotYN ~ leafN + biomass.kg + landscape ## ## AIC ## 270.381 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## leafN ~ landscape + ... coef 97 1.1151 0.2676 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 1.274 with P-value = 0.259 and on 1 degrees of freedom ## Fisher&#39;s C = 2.637 with P-value = 0.268 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## leafN biomass.kg 0.0068 0.0219 98 0.3098 0.7574 0.0313 ## hotspotYN leafN -0.1212 0.4652 96 -0.2604 0.7945 -0.0301 ## hotspotYN biomass.kg 0.0374 0.1005 96 0.3720 0.7099 0.0428 ## hotspotYN landscape -0.1553 0.4181 96 -0.3715 0.7103 -0.0427 ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## leafN none 0 ## hotspotYN nagelkerke 0 Directed Separation &amp; Non-Normality # Add the &#39;conserve = TRUE&#39; argument to be conservative in tests summary(anderson.sem, conserve = TRUE) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of anderson.sem ## ## Call: ## leafN ~ biomass.kg ## hotspotYN ~ leafN + biomass.kg + landscape ## ## AIC ## 270.381 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## leafN ~ landscape + ... coef 97 1.1151 0.2676 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 1.274 with P-value = 0.259 and on 1 degrees of freedom ## Fisher&#39;s C = 2.637 with P-value = 0.268 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## leafN biomass.kg 0.0068 0.0219 98 0.3098 0.7574 0.0313 ## hotspotYN leafN -0.1212 0.4652 96 -0.2604 0.7945 -0.0301 ## hotspotYN biomass.kg 0.0374 0.1005 96 0.3720 0.7099 0.0428 ## hotspotYN landscape -0.1553 0.4181 96 -0.3715 0.7103 -0.0427 ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## leafN none 0 ## hotspotYN nagelkerke 0 If the model includes non-normal endogenous variables (e.g., binary hotspotYN), the direction of independence tests matters. Use: dSep(anderson.sem, direction = c(&quot;hotspotYN &lt;- leafN&quot;)) ## | | | 0% | |===================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 leafN ~ landscape + ... coef 97 1.115091 0.2675663 Or specify a correlated error structure: anderson.sem2 &lt;- update(anderson.sem, hotspotYN %~~% leafN) dSep(anderson.sem2) ## | | | 0% | |===================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 leafN ~ landscape + ... coef 97 1.115091 0.2675663 Standardizing Coefficients Latent Theoretic (LT) Approach anderson.glm &lt;- anderson.sem[[2]] Betas &lt;- coefs(anderson.sem)[2:4, 3] # GLM coefficients preds &lt;- predict(anderson.glm, type = &quot;link&quot;) sd.y.LT &lt;- sqrt(var(preds) + pi^2/3) sd.x &lt;- sapply(anderson[, c(&quot;leafN&quot;, &quot;biomass.kg&quot;, &quot;landscape&quot;)], sd) Betas.LT &lt;- Betas * sd.x / sd.y.LT Betas.LT ## leafN biomass.kg landscape ## -0.03014129 0.04284880 -0.04271486 Observed Error (OE) Approach preds_response &lt;- predict(anderson.glm, type = &quot;response&quot;) R &lt;- cor(anderson$hotspotYN, preds_response) sd.y.OE &lt;- sqrt(var(preds_response)) / R Betas.OE &lt;- Betas * sd.x / sd.y.OE Betas.OE ## leafN biomass.kg landscape ## -0.1089265 0.1548496 -0.1543656 Compare LT vs OE Approaches # Indirect effect: leafN → hotspotYN (through biomass.kg) Beta.leafN &lt;- coefs(anderson.sem)$Std.Estimate[1] indirect_LT &lt;- Beta.leafN * Betas.LT[1] indirect_OE &lt;- Beta.leafN * Betas.OE[1] c(LT = indirect_LT, OE = indirect_OE) ## LT.leafN OE.leafN ## -0.0009434225 -0.0034093982 Summary: • Use glm() in psem() for binary or count outcomes. • Add conserve = TRUE for directed separation when variables are non-normal. • Use both LT and OE standardization to interpret effect sizes. 41.5.1 Chapter 15: Categorical Predictors &amp; Multigroup SEM # library(lme4) # library(piecewiseSEM) # library(emmeans) # library(lavaan) Overview In this tutorial, we explore: • Using categorical predictors in SEM. • Accounting for random effects (e.g., genotype). • Conducting multigroup SEM across different contexts or study sites. Categorical Predictors and Random Effects Example: Bowen et al. (2017) tested whether Phragmites genotype affects soil microbes and productivity. library(multcompView) # Simulated structure: Genotype nested within Phragmites status (e.g., native, invasive) set.seed(1) n &lt;- 90 bowen &lt;- data.frame( status = factor(rep(c(&quot;native&quot;, &quot;invasive&quot;, &quot;introduced&quot;), each = 30)), Genotype = rep(paste0(&quot;G&quot;, 1:9), each = 10), observed_otus = rnorm(n, mean = 2500, sd = 100), RNA.DNA = rnorm(n, 0.7, 0.05), below.C = rnorm(n, 43, 1), abovebiomass_g = rnorm(n, 2, 0.5) ) # Mixed models for each component div_mod &lt;- lmer(observed_otus ~ status + (1 | Genotype), data = bowen) activity_mod &lt;- lmer(RNA.DNA ~ status + observed_otus + (1 | Genotype), data = bowen) carbon_mod &lt;- lmer(below.C ~ observed_otus + status + (1 | Genotype), data = bowen) biomass_mod &lt;- lmer(abovebiomass_g ~ RNA.DNA + observed_otus + below.C + status + (1 | Genotype), data = bowen) # Build piecewise SEM bowen_mod &lt;- psem(div_mod, activity_mod, carbon_mod, biomass_mod, data = bowen) summary(bowen_mod) ## | | | 0% ## | |===================================================================================| 100% ## ## Structural Equation Model of bowen_mod ## ## Call: ## observed_otus ~ status ## RNA.DNA ~ status + observed_otus ## below.C ~ observed_otus + status ## abovebiomass_g ~ RNA.DNA + observed_otus + below.C + status ## ## AIC ## 1251.338 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## below.C ~ RNA.DNA + ... coef 85 -0.1384 0.8902 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 3.513 with P-value = 0.061 and on 1 degrees of freedom ## Fisher&#39;s C = 0.233 with P-value = 0.89 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value ## observed_otus status - - 2.0000 0.0237 0.9766 ## observed_otus status = native 2508.2458 16.3598 6.0000 153.3172 0.0000 ## observed_otus status = introduced 2511.0278 16.3598 6.0000 153.4872 0.0000 ## observed_otus status = invasive 2513.2775 16.3598 6.0000 153.6247 0.0000 ## RNA.DNA observed_otus 0 1e-04 84.2102 -0.3354 0.7381 ## RNA.DNA status - - 2.0000 2.0441 0.2111 ## RNA.DNA status = invasive 0.6835 0.0104 5.9386 65.7032 0.0000 ## RNA.DNA status = native 0.7056 0.0104 5.9389 67.8238 0.0000 ## RNA.DNA status = introduced 0.7119 0.0104 5.9365 68.4304 0.0000 ## below.C observed_otus -4e-04 0.0012 86.0000 -0.3219 0.7483 ## below.C status - - 2.0000 0.7820 0.4997 ## below.C status = invasive 42.763 0.1857 5.9128 230.2879 0.0000 ## below.C status = introduced 43.0245 0.1857 5.9100 231.7263 0.0000 ## below.C status = native 43.0658 0.1857 5.9132 231.9142 0.0000 ## abovebiomass_g RNA.DNA 0.1948 1.1068 84.0000 0.1760 0.8607 ## abovebiomass_g observed_otus 2e-04 6e-04 84.0000 0.4172 0.6776 ## abovebiomass_g below.C -0.1292 0.0523 84.0000 -2.4692 0.0156 ## abovebiomass_g status - - 2.0000 0.2393 0.7943 ## abovebiomass_g status = introduced 2.0074 0.0911 5.8667 22.0333 0.0000 ## abovebiomass_g status = native 2.0829 0.0905 5.7339 23.0193 0.0000 ## abovebiomass_g status = invasive 2.0871 0.0927 6.2237 22.5236 0.0000 ## Std.Estimate ## - ## - *** ## - *** ## - *** ## - ## - ## - *** ## - *** ## - *** ## - ## - ## - *** ## - *** ## - *** ## - ## - ## - * ## - ## - *** ## - *** ## - *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method Marginal Conditional ## observed_otus none 0.00 0.00 ## RNA.DNA none 0.06 0.10 ## below.C none 0.02 0.02 ## abovebiomass_g none 0.07 0.07 Visualizing Categorical Effects Estimated Marginal Means by status: lapply(bowen_mod[-length(bowen_mod)], emmeans, specs = ~status) ## [[1]] ## status emmean SE df lower.CL upper.CL ## introduced 2511 16.4 6 2471 2551 ## invasive 2513 16.4 6 2473 2553 ## native 2508 16.4 6 2468 2548 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[2]] ## status emmean SE df lower.CL upper.CL ## introduced 0.712 0.0104 5.94 0.686 0.737 ## invasive 0.684 0.0104 5.94 0.658 0.709 ## native 0.706 0.0104 5.94 0.680 0.731 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[3]] ## status emmean SE df lower.CL upper.CL ## introduced 43.0 0.186 5.91 42.6 43.5 ## invasive 42.8 0.186 5.91 42.3 43.2 ## native 43.1 0.186 5.91 42.6 43.5 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[4]] ## status emmean SE df lower.CL upper.CL ## introduced 2.01 0.0911 5.87 1.78 2.23 ## invasive 2.09 0.0927 6.22 1.86 2.31 ## native 2.08 0.0905 5.73 1.86 2.31 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 # Post-hoc Tests (Tukey) generic_tukey &lt;- function(x) emmeans(x, list(pairwise ~ status)) lapply(bowen_mod[-length(bowen_mod)], generic_tukey) ## [[1]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 2511 16.4 6 2471 2551 ## invasive 2513 16.4 6 2473 2553 ## native 2508 16.4 6 2468 2548 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive -2.25 23.1 6 -0.097 0.9948 ## introduced - native 2.78 23.1 6 0.120 0.9921 ## invasive - native 5.03 23.1 6 0.217 0.9744 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[2]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 0.712 0.0104 5.94 0.686 0.737 ## invasive 0.684 0.0104 5.94 0.658 0.709 ## native 0.706 0.0104 5.94 0.680 0.731 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive 0.02831 0.0147 5.94 1.924 0.2130 ## introduced - native 0.00624 0.0147 5.94 0.424 0.9072 ## invasive - native -0.02207 0.0147 5.94 -1.500 0.3560 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[3]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 43.0 0.186 5.91 42.6 43.5 ## invasive 42.8 0.186 5.91 42.3 43.2 ## native 43.1 0.186 5.91 42.6 43.5 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive 0.2615 0.263 5.91 0.996 0.6061 ## introduced - native -0.0413 0.263 5.91 -0.157 0.9865 ## invasive - native -0.3029 0.263 5.92 -1.153 0.5204 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[4]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 2.01 0.0911 5.87 1.78 2.23 ## invasive 2.09 0.0927 6.22 1.86 2.31 ## native 2.08 0.0905 5.73 1.86 2.31 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive -0.07972 0.132 6.41 -0.603 0.8234 ## introduced - native -0.07557 0.128 5.67 -0.592 0.8295 ## invasive - native 0.00415 0.131 6.21 0.032 0.9994 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates Multigroup SEM in lavaan Fit the same SEM model to different groups and test whether path coefficients differ. # Create simulated dataset group_df &lt;- data.frame( site = rep(c(&quot;A&quot;, &quot;B&quot;), each = 50), x = rnorm(100), m = rnorm(100), y = rnorm(100) ) # Define a simple SEM model sem_model &lt;- &#39; m ~ a*x y ~ b*m + c*x &#39; # Fit multi-group SEM fit_multi &lt;- lavaan::sem(sem_model, data = group_df, group = &quot;site&quot;) # View summary summary(fit_multi, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6-19 ended normally after 12 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## Number of equality constraints 3 ## ## Number of observations per group: ## A 50 ## B 50 ## ## Model Test User Model: ## ## Test statistic 0.790 ## Degrees of freedom 3 ## P-value (Chi-square) 0.852 ## Test statistic for each group: ## A 0.498 ## B 0.292 ## ## Model Test Baseline Model: ## ## Test statistic 2.093 ## Degrees of freedom 6 ## P-value 0.911 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) -0.131 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -293.784 ## Loglikelihood unrestricted model (H1) -293.389 ## ## Akaike (AIC) 609.568 ## Bayesian (BIC) 638.225 ## Sample-size adjusted Bayesian (SABIC) 603.484 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.130 ## P-value H_0: RMSEA &lt;= 0.050 0.874 ## P-value H_0: RMSEA &gt;= 0.080 0.098 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.029 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [A]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) -0.011 0.099 -0.116 0.908 -0.011 -0.009 ## y ~ ## m (b) -0.105 0.095 -1.106 0.269 -0.105 -0.128 ## x (c) 0.031 0.101 0.310 0.757 0.031 0.031 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.144 0.170 0.844 0.398 0.144 0.119 ## .y 0.076 0.139 0.544 0.586 0.076 0.077 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 1.445 0.289 5.000 0.000 1.445 1.000 ## .y 0.960 0.192 5.000 0.000 0.960 0.983 ## ## ## Group 2 [B]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) -0.011 0.099 -0.116 0.908 -0.011 -0.014 ## y ~ ## m (b) -0.105 0.095 -1.106 0.269 -0.105 -0.088 ## x (c) 0.031 0.101 0.310 0.757 0.031 0.031 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m -0.116 0.134 -0.860 0.390 -0.116 -0.124 ## .y -0.240 0.160 -1.506 0.132 -0.240 -0.215 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.872 0.174 5.000 0.000 0.872 1.000 ## .y 1.234 0.247 5.000 0.000 1.234 0.991 Constraining Parameters Across Groups You can test whether coefficients differ across groups: A significant p-value means the unconstrained model fits better — i.e., group differences do matter. Summary: • Use lme4 and piecewiseSEM for models with random effects. • lavaan enables multigroup comparisons to test generality across systems. • Post-hoc tools like emmeans help interpret categorical predictors. 41.5.2 Chapter 16: Multigroup SEM in R library(lavaan) What is Multigroup SEM? Multigroup SEM allows you to: • Test whether path coefficients differ between groups. • Assess whether a model holds equally well across groups. • Investigate measurement invariance (i.e., whether constructs are perceived similarly). Example Model Setup We’ll build a simple mediation model where group is a binary factor (“A” vs “B”). # Simulate data set.seed(123) n &lt;- 100 group &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = n) x &lt;- rnorm(2 * n) m &lt;- 0.5 * x + rnorm(2 * n) y &lt;- 0.6 * m + 0.3 * x + rnorm(2 * n) data &lt;- data.frame(group, x, m, y) Define the SEM model &lt;- &#39; m ~ a*x y ~ b*m + c*x &#39; Fit Multigroup SEM fit_multi &lt;- sem(model, data = data, group = &quot;group&quot;) summary(fit_multi, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6-19 ended normally after 13 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## Number of equality constraints 3 ## ## Number of observations per group: ## A 100 ## B 100 ## ## Model Test User Model: ## ## Test statistic 6.839 ## Degrees of freedom 3 ## P-value (Chi-square) 0.077 ## Test statistic for each group: ## A 3.618 ## B 3.220 ## ## Model Test Baseline Model: ## ## Test statistic 131.688 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.969 ## Tucker-Lewis Index (TLI) 0.939 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -556.173 ## Loglikelihood unrestricted model (H1) -552.754 ## ## Akaike (AIC) 1134.347 ## Bayesian (BIC) 1170.628 ## Sample-size adjusted Bayesian (SABIC) 1135.779 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.113 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.228 ## P-value H_0: RMSEA &lt;= 0.050 0.139 ## P-value H_0: RMSEA &gt;= 0.080 0.755 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.083 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [A]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) 0.453 0.075 6.064 0.000 0.453 0.401 ## y ~ ## m (b) 0.542 0.068 7.947 0.000 0.542 0.460 ## x (c) 0.295 0.078 3.756 0.000 0.295 0.222 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.125 0.094 1.323 0.186 0.125 0.122 ## .y 0.116 0.098 1.178 0.239 0.116 0.096 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.885 0.125 7.071 0.000 0.885 0.840 ## .y 0.958 0.135 7.071 0.000 0.958 0.657 ## ## ## Group 2 [B]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) 0.453 0.075 6.064 0.000 0.453 0.387 ## y ~ ## m (b) 0.542 0.068 7.947 0.000 0.542 0.504 ## x (c) 0.295 0.078 3.756 0.000 0.295 0.235 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m -0.041 0.104 -0.397 0.691 -0.041 -0.037 ## .y -0.048 0.094 -0.513 0.608 -0.048 -0.040 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 1.074 0.152 7.071 0.000 1.074 0.850 ## .y 0.874 0.124 7.071 0.000 0.874 0.599 Test for Invariance To test for invariance, you can constrain parameters to be equal across groups. # Constrain &#39;a&#39; and &#39;b&#39; to be equal across groups model_constrained &lt;- &#39; m ~ c(a, a)*x y ~ c(b, b)*m + c*x &#39; fit_constrained &lt;- sem(model_constrained, data = data, group = &quot;group&quot;) anova(fit_multi, fit_constrained) # Chi-square test for invariance ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit_multi 3 1134.3 1170.6 6.8386 ## fit_constrained 3 1134.3 1170.6 6.8386 0 0 0 Interpretation: • If the constrained model does not significantly worsen fit, the paths a and b are likely invariant. • If the fit gets significantly worse, the relationship differs between groups and should be modeled separately. Visualizing Standardized Results # library(semPlot) # semPaths(fit_multi, &quot;std&quot;, layout = &quot;tree&quot;, whatLabels = &quot;std&quot;, edge.label.cex = 1.2) Summary Multigroup SEM lets you: • Evaluate moderation by group. • Test for measurement invariance. • Gain deeper insight into context-dependent pathways. 41.5.3 Chapter 17: Mixed models in piecewise SEM, covering: • Fixed vs. random effects • Adding group-level predictors • Understanding R² and model comparison • Dealing with hierarchical structure and sample size Introduction This tutorial introduces how to incorporate mixed effects into Structural Equation Modeling using the piecewiseSEM package. Mixed models are essential when your data are hierarchically structured (e.g., plots within sites, streams within watersheds). Step 1: Load Data and Create Variables # Log-transform predictors cardinale$logN &lt;- log10(cardinale$N + 1e-6) cardinale$logN2 &lt;- cardinale$logN^2 cardinale$logChl &lt;- log10(cardinale$Chl) # Centering predictors to reduce multicollinearity cardinale$logN.cen &lt;- scale(cardinale$logN, scale = FALSE) cardinale$logN2.cen &lt;- scale(cardinale$logN^2, scale = FALSE) Step 2: Fit Fixed Effects SEM cardinale.sem &lt;- psem( lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale), lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale), logN.cen %~~% logN2.cen, data = cardinale ) summary(cardinale.sem) ## | | | 0% | |===================================================================================| 100% ## ## Structural Equation Model of cardinale.sem ## ## Call: ## SA ~ logN.cen + logN2.cen + SR ## logChl ~ SA + logN.cen + logN2.cen ## logN.cen ~~ logN2.cen ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN.cen -2.9944 1.5375 123 -1.9476 0.0537 -0.5044 ## SA logN2.cen -0.4742 0.2424 123 -1.9568 0.0526 -0.5067 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN.cen 0.1168 0.0953 123 1.2258 0.2226 0.3858 ## logChl logN2.cen 0.0032 0.015 123 0.2108 0.8334 0.0664 ## ~~logN.cen ~~logN2.cen -0.9685 - 125 -43.4652 0.0000 -0.9685 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Step 3: Add Random Effects with lme() #cardinale.mixed &lt;- psem( # lme(SA ~ logN.cen + logN2.cen + SR, random = ~1 | Stream, data = cardinale), # lme(logChl ~ SA + logN.cen + logN2.cen, random = ~1 | Stream, data = cardinale), # logN.cen %~~% logN2.cen, # data = cardinale #) #summary(cardinale.mixed) Step 4: Compare Models # Compare R-squared #rsquared(cardinale.sem) #rsquared(cardinale.mixed) • Marginal R²: Variance explained by fixed effects. • Conditional R²: Variance explained by both fixed and random effects. Step 5: Optional — Add Group-Level Predictors To address possible Simpson’s paradox or correlated random effects: # Example if &quot;site_mean&quot; were available # cardinale$stream_mean_logN &lt;- ave(cardinale$logN, cardinale$Stream) # cardinale$deviation_logN &lt;- cardinale$logN - cardinale$stream_mean_logN This lets you include: • stream_mean_logN (group-level predictor) • deviation_logN (individual-level deviation) Step 6: Basis Set and Fisher’s C #fisherC(cardinale.mixed) Summary: • Mixed models let you account for non-independence among groups. • Use piecewiseSEM with lme() to include random effects. • Be cautious of group-level confounding — use centering and group-level predictors. • Use rsquared() and fisherC() for model comparison and goodness-of-fit. 41.6 Example with Powerline Data library(readr) # Read CSV directly into R powerline_plants &lt;- read.csv(&quot;https://drive.google.com/uc?export=download&amp;id=1MVlaEshEn7M2g8rOiJ8fWPPozn3WgNck&quot;) We are starting with our original DAG (below): library(dagitty) library(ggdag) library(tidyverse) # Define the DAG ivm_dag &lt;- dagitty(&quot; dag { Treatment Soil_Substrate Cattle Plant_Richness Plant_Cover Plant_Height Ceanothus Woody_Debris Pollinator_Richness Pollinator_Abundance Treatment -&gt; Plant_Richness Treatment -&gt; Plant_Cover Treatment -&gt; Plant_Height Treatment -&gt; Ceanothus Treatment -&gt; Woody_Debris Soil_Substrate -&gt; Treatment Soil_Substrate -&gt; Plant_Richness Soil_Substrate -&gt; Plant_Cover Soil_Substrate -&gt; Woody_Debris Cattle -&gt; Plant_Richness Cattle -&gt; Plant_Cover Cattle -&gt; Pollinator_Abundance Cattle -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Abundance Plant_Cover -&gt; Pollinator_Richness Plant_Cover -&gt; Pollinator_Abundance Plant_Height -&gt; Pollinator_Richness Plant_Height -&gt; Pollinator_Abundance Ceanothus -&gt; Pollinator_Richness Ceanothus -&gt; Pollinator_Abundance Woody_Debris -&gt; Pollinator_Richness Woody_Debris -&gt; Pollinator_Abundance } &quot;) node_roles &lt;- tibble( name = c( &quot;Treatment&quot;, &quot;Soil_Substrate&quot;, &quot;Cattle&quot;, &quot;Plant_Richness&quot;, &quot;Plant_Cover&quot;, &quot;Plant_Height&quot;, &quot;Ceanothus&quot;, &quot;Woody_Debris&quot;, &quot;Pollinator_Richness&quot;, &quot;Pollinator_Abundance&quot; ), role = c( &quot;Treatment&quot;, &quot;Context&quot;, &quot;Context&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Pollinator&quot;, &quot;Pollinator&quot; ) ) # Get layout and merge roles dag_df &lt;- tidy_dagitty(ivm_dag, layout = &quot;nicely&quot;) %&gt;% left_join(node_roles, by = &quot;name&quot;) # Plot using ggplot2 with corrected edge structure ggplot() + geom_segment( data = dag_df %&gt;% filter(!is.na(xend)), aes(x = x, y = y, xend = xend, yend = yend), arrow = arrow(length = unit(0.02, &quot;npc&quot;)), color = &quot;grey40&quot; ) + geom_point( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, color = role), size = 8, alpha = 0.85 ) + geom_text( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, label = name), color = &quot;black&quot;, size = 4 ) + scale_color_manual(values = c( &quot;Treatment&quot; = &quot;#FB7E21FF&quot;, &quot;Context&quot; = &quot;#A91601FF&quot;, &quot;Plant&quot; = &quot;#18DDC2FF&quot;, &quot;Pollinator&quot; = &quot;#00468BFF&quot; )) + labs( title = &quot;Hypothesized DAG for Pollinator Response to IVM Treatment&quot;, color = &quot;Variable Type&quot; ) + theme_void() Then, we need to create linear models, treating each “node” as its own regression model. First, we have to summarize our data in a way that can be input into the linear models. library(piecewiseSEM) # List all variables used across all models sem_vars &lt;- c( &quot;Species_Richness&quot;, &quot;Treatment&quot;, &quot;Q_Substrate_BareSoil&quot;, &quot;Plot_DungCount&quot;, &quot;Q_Substrate_PerennialVeg&quot;, &quot;Height_cm&quot;, &quot;Q_Substrate_WoodyDebris&quot; ) # Remove all rows with NA in any of the SEM variables sem_data &lt;- powerline_plants %&gt;% dplyr::select(all_of(sem_vars)) %&gt;% na.omit() # Ensure Treatment is a factor sem_data$Treatment &lt;- as.factor(sem_data$Treatment) # Check structure to confirm str(sem_data) ## &#39;data.frame&#39;: 811 obs. of 7 variables: ## $ Species_Richness : int 10 10 11 10 12 11 7 7 12 2 ... ## $ Treatment : Factor w/ 4 levels &quot;Control&quot;,&quot;Herbicide&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## $ Q_Substrate_BareSoil : num 0 5 7 0 0 10 2 0 2 0 ... ## $ Plot_DungCount : int 5 5 5 5 5 0 0 0 0 0 ... ## $ Q_Substrate_PerennialVeg: num 70 10 8 5 10 40 25 50 40 30 ... ## $ Height_cm : num 28 19.1 38.6 37.2 22 ... ## $ Q_Substrate_WoodyDebris : num 0 30 5 70 2 4 5 1 10 0 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:57] 186 187 188 189 190 191 192 193 195 200 ... ## ..- attr(*, &quot;names&quot;)= chr [1:57] &quot;186&quot; &quot;187&quot; &quot;188&quot; &quot;189&quot; ... sem_data$Treatment &lt;- droplevels(as.factor(sem_data$Treatment)) # Fit models using this cleaned dataset mod1 &lt;- lm(Species_Richness ~ Treatment + Q_Substrate_BareSoil + Plot_DungCount, data = sem_data) mod2 &lt;- lm(Q_Substrate_PerennialVeg ~ Species_Richness + Treatment + Q_Substrate_BareSoil + Plot_DungCount, data = sem_data) mod3 &lt;- lm(Height_cm ~ Q_Substrate_PerennialVeg + Treatment, data = sem_data) mod4 &lt;- lm(Q_Substrate_WoodyDebris ~ Height_cm + Treatment + Q_Substrate_BareSoil, data = sem_data) # You can now also safely fit mod6 and mod7 using the same sem_data: # mod6 &lt;- lm(Pollinator_Richness ~ Species_Richness + Q_Substrate_PerennialVeg + Height_cm + Ceanothus + Q_Substrate_WoodyDebris + Plot_DungCount, data = sem_data) # mod7 &lt;- lm(Pollinator_Abundance ~ Species_Richness + Q_Substrate_PerennialVeg + Height_cm + Ceanothus + Q_Substrate_WoodyDebris + Plot_DungCount, data = sem_data) # Assemble SEM mods &lt;- list(mod1, mod2, mod3, mod4) lapply(mods, function(m) summary(m)$coefficients) ## [[1]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.45334250 0.289907535 25.709378 6.893932e-107 ## TreatmentHerbicide 0.48512839 0.352320044 1.376954 1.689094e-01 ## TreatmentMech_Herb 0.62503883 0.349579557 1.787973 7.415638e-02 ## TreatmentMechanical 0.55821899 0.349940535 1.595182 1.110639e-01 ## Q_Substrate_BareSoil -0.01678677 0.008023078 -2.092310 3.672344e-02 ## Plot_DungCount 0.12104150 0.013556336 8.928777 2.878250e-18 ## ## [[2]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 35.4547726 2.19617613 16.1438657 5.408706e-51 ## Species_Richness -0.5979172 0.19785399 -3.0220122 2.590654e-03 ## TreatmentHerbicide -5.8459701 1.98011740 -2.9523351 3.245600e-03 ## TreatmentMech_Herb -3.3269277 1.96629833 -1.6919750 9.103821e-02 ## TreatmentMechanical -1.7501657 1.96753433 -0.8895223 3.739885e-01 ## Q_Substrate_BareSoil -0.2827075 0.04516078 -6.2600221 6.258592e-10 ## Plot_DungCount -0.5791996 0.07977940 -7.2600139 9.140497e-13 ## ## [[3]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 18.3949479 3.69826014 4.973946 8.020316e-07 ## Q_Substrate_PerennialVeg 0.4754358 0.07599831 6.255872 6.411886e-10 ## TreatmentHerbicide 0.6336287 4.59697384 0.137836 8.904044e-01 ## TreatmentMech_Herb -8.5325534 4.52497644 -1.885657 5.970059e-02 ## TreatmentMechanical -8.2148870 4.48866890 -1.830139 6.759835e-02 ## ## [[4]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 17.123628791 1.32713403 12.9027124 9.334527e-35 ## Height_cm -0.003170525 0.01291842 -0.2454267 8.061886e-01 ## TreatmentHerbicide -2.448347212 1.71763567 -1.4254171 1.544243e-01 ## TreatmentMech_Herb -9.527420893 1.70339367 -5.5931996 3.054932e-08 ## TreatmentMechanical -4.985879621 1.68835021 -2.9531075 3.237464e-03 ## Q_Substrate_BareSoil -0.134960227 0.03912324 -3.4496179 5.905788e-04 # Rebuild the SEM with standardized estimates sem_model &lt;- psem(mod1, mod2, mod3, mod4) # Summary with standardization explicitly requested summary(sem_model, standardize = &quot;scale&quot;) ## | | | 0% | |============== | 17% | |============================ | 33% | |========================================== | 50% | |======================================================= | 67% | |===================================================================== | 83% | |===================================================================================| 100% ## ## Structural Equation Model of sem_model ## ## Call: ## Species_Richness ~ Treatment + Q_Substrate_BareSoil + Plot_DungCount ## Q_Substrate_PerennialVeg ~ Species_Richness + Treatment + Q_Substrate_BareSoil + Plot_DungCount ## Height_cm ~ Q_Substrate_PerennialVeg + Treatment ## Q_Substrate_WoodyDebris ~ Height_cm + Treatment + Q_Substrate_BareSoil ## ## AIC ## 26815.430 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## Height_cm ~ Q_Substrate_BareSoil + ... coef 805 -0.0972 0.9226 ## Height_cm ~ Plot_DungCount + ... coef 805 -1.8759 0.0610 ## Q_Substrate_WoodyDebris ~ Plot_DungCount + ... coef 804 5.5138 0.0000 ## Height_cm ~ Species_Richness + ... coef 803 -2.6518 0.0082 ## Q_Substrate_WoodyDebris ~ Species_Richness + ... coef 803 -1.2738 0.2031 ## Q_Substrate_WoodyDebris ~ Q_Substrate_PerennialVeg + ... coef 802 -9.6809 0.0000 ## ## ## ## *** ## ** ## ## *** ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 131.991 with P-value = 0 and on 6 degrees of freedom ## Fisher&#39;s C = 145.828 with P-value = 0 and on 12 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value ## Species_Richness Q_Substrate_BareSoil -0.0168 0.008 805 -2.0923 0.0367 ## Species_Richness Plot_DungCount 0.121 0.0136 805 8.9288 0.0000 ## Species_Richness Treatment - - 3 1.2817 0.2795 ## Species_Richness Treatment = Control 8.2476 0.2538 805 32.4946 0.0000 ## Species_Richness Treatment = Herbicide 8.7327 0.2455 805 35.5697 0.0000 ## Species_Richness Treatment = Mechanical 8.8058 0.2377 805 37.0411 0.0000 ## Species_Richness Treatment = Mech_Herb 8.8726 0.2394 805 37.0675 0.0000 ## Q_Substrate_PerennialVeg Species_Richness -0.5979 0.1979 804 -3.0220 0.0026 ## Q_Substrate_PerennialVeg Q_Substrate_BareSoil -0.2827 0.0452 804 -6.2600 0.0000 ## Q_Substrate_PerennialVeg Plot_DungCount -0.5792 0.0798 804 -7.2600 0.0000 ## Q_Substrate_PerennialVeg Treatment - - 3 3.1825 0.0234 ## Q_Substrate_PerennialVeg Treatment = Herbicide 17.0791 1.3782 804 12.3919 0.0000 ## Q_Substrate_PerennialVeg Treatment = Mech_Herb 19.5981 1.3443 804 14.5791 0.0000 ## Q_Substrate_PerennialVeg Treatment = Mechanical 21.1749 1.3348 804 15.8639 0.0000 ## Q_Substrate_PerennialVeg Treatment = Control 22.925 1.4273 804 16.0614 0.0000 ## Height_cm Q_Substrate_PerennialVeg 0.4754 0.076 806 6.2559 0.0000 ## Height_cm Treatment - - 3 2.5277 0.0562 ## Height_cm Treatment = Mech_Herb 19.4516 3.1101 806 6.2543 0.0000 ## Height_cm Treatment = Mechanical 19.7692 3.0711 806 6.4371 0.0000 ## Height_cm Treatment = Control 27.9841 3.2834 806 8.5229 0.0000 ## Height_cm Treatment = Herbicide 28.6178 3.2007 806 8.9411 0.0000 ## Q_Substrate_WoodyDebris Height_cm -0.0032 0.0129 805 -0.2454 0.8062 ## Q_Substrate_WoodyDebris Q_Substrate_BareSoil -0.135 0.0391 805 -3.4496 0.0006 ## Q_Substrate_WoodyDebris Treatment - - 3 11.5674 0.0000 ## Q_Substrate_WoodyDebris Treatment = Mech_Herb 6.2042 1.1687 805 5.3088 0.0000 ## Q_Substrate_WoodyDebris Treatment = Mechanical 10.7458 1.1506 805 9.3395 0.0000 ## Q_Substrate_WoodyDebris Treatment = Herbicide 13.2833 1.1961 805 11.1051 0.0000 ## Q_Substrate_WoodyDebris Treatment = Control 15.7316 1.2336 805 12.7526 0.0000 ## Std.Estimate ## - * ## - *** ## - ## - *** ## - *** ## - *** ## - *** ## - ** ## - *** ## - *** ## - * ## - *** ## - *** ## - *** ## - *** ## - *** ## - ## - *** ## - *** ## - *** ## - *** ## - ## - *** ## - *** ## - *** ## - *** ## - *** ## - *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## Species_Richness none 0.09 ## Q_Substrate_PerennialVeg none 0.15 ## Height_cm none 0.05 ## Q_Substrate_WoodyDebris none 0.06 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
