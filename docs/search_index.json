[["index.html", "Applied Statistics for the Natural Sciences Chapter 1 Introduction 1.1 Learning Objectives 1.2 Using R in This Course 1.3 How to use this online manual 1.4 Course structure", " Applied Statistics for the Natural Sciences Sara Souther Chapter 1 Introduction Welcome to our statistical exploration of the natural world! My goal is for you to develop an intuitive understanding of statistical analysis—how to choose the right test, understand its assumptions, visualize and interpret results, and communicate findings clearly in a report. By the end of this course, I hope you’ll feel confident tackling any analytical situation you encounter. Let’s get one thing out of the way early: we are not statisticians—whew! We are ecologists and social scientists. Our goal is not to master the theoretical mathematics behind statistics, but rather to apply statistical tools appropriately and thoughtfully. For this reason, we won’t spend much time on the underlying equations or proofs, but instead focus on practical application, critical interpretation, and making our data tell a clear story. For this reason, I will not spend much space describing the mathematical understanding of statistics! 1.1 Learning Objectives By the end of this course, you will be able to: Select appropriate statistical tests based on the type of data (categorical, continuous, ordinal), the structure of your study design, and the research question being asked (e.g., comparing groups, testing relationships, evaluating change over time). Properly run statistical analyses using R, including data cleaning, assumption checking, and the implementation of common tests such as t-tests, ANOVA, chi-squared tests, correlation, linear regression, and basic non-parametric alternatives. Report and interpret statistical results in clear, publication-ready language. This includes summarizing findings with appropriate measures of central tendency and variation (mean, median, standard error), reporting test statistics and p-values, and interpreting both statistical and biological/social significance. Visualize data effectively using plots and figures that aid interpretation and communicate key findings to scientific and non-scientific audiences. Understand the assumptions behind common statistical methods and recognize when those assumptions are violated, along with strategies for addressing or adjusting for these issues. Develop confidence and critical thinking in applying statistical tools to real-world ecological and social science data, with a focus on transparency, reproducibility, and responsible data use. 1.2 Using R in This Course In this course, we use R as a practical tool for ecological and social science data analysis. The focus is not on mathematical theory, but on learning how to choose appropriate statistical tests, check assumptions, visualize data, and interpret results clearly and responsibly. By working with real datasets in R, you will build confidence in reproducible, transparent analysis and develop the skills needed to tackle the kinds of statistical questions you will encounter in research and professional practice. To get started, we will go over a few R-best practices for organizing and running code in our first class lecture! 1.2.1 What you need to use R You need two programs: R (does the calculations) RStudio (helps you write and organize code) Think of R as the engine, and RStudio as the dashboard. Install R: Go to: https://www.r-project.org Click Download R from CRAN Choose any mirror (it truly does not matter) Download the version for your operating system (Mac, Windows, or Linux) Install using the default options Install RStudio: Go to: https://posit.co/download/rstudio-desktop/ Download RStudio Desktop (Free) Install using the default options RStudio will automatically find R once both are installed When you open RStudio, you’ll see four panes: Console is where R runs code Source is where you write and save code Environment shows what data you have loaded Plots/Files/Help is where figures and help appear You can move the order in which these panes appear. 1.2.2 Create an R file What is an R file? An R file is a script or a plain text file that contains R code. R files allow you to write, save, and rerun analyses step by step, which is essential for reproducible science. Instead of typing commands one-by-one into the Console (where they disappear), an R file lets you: Keep a permanent record of your work Add comments explaining what you’re doing Edit and rerun code easily Share your analysis with others Think of an R file as your lab notebook, written in code. How to open (create) an R file in RStudio: Open RStudio Go to File → New File Choose R Script A new tab will open with a blank file. This is a standard R script, usually saved with the extension .R. Save it right away: File → Save As Give it a clear, descriptive name (e.g., data_exploration.R) Hint: Create a folder for this course (you could organize by subfolders for each chapter) and store all of your data and R files in this folder. 1.2.3 Using working directories and opening files RStudio allows you to open files and perform other actions using drop down menus. However, it is far more efficient to set working directories and import files using script within your R file. When you are asked to revisit work for a big project, using working directories allows you to jump right back into the project, because the pertinent data files are linked (this is super great when you have to do revisions, for instance). Datasets are created in Excel and saved as .csv files that are readable by R. 1.2.4 R Packages R comes with built-in functions, but most ecological work uses packages—collections of tools made by other scientists. Using libraries takes two steps. The first time you use a new package, you will install that package, and then load the package. You will need to load packages every time that you use R. 1.2.5 Other information about R code Anything after a # is ignored by R. It is good practice to use hashtags to add information to your code. Use comments to explain: what the code does why you wrote it anything future-you will forget You will encounter issues with your R code. When you do this, your best friends are AI language models, like ChatGPT and Claude. Explain the error, providing the error code, and your code, and the AI assistant will help you. I cannot overstate how jealous I am of all young scientists - debugging used to take hours as you combed over the R documentation looking for hints as to why your code is breaking. 1.2.6 Getting started with R Some of you may be R experts, but for those who are new or need a refresher, check out this R code and import the associated csv file. Formatted R script csv file to import If you need a refresher on working directories and libraries, follow this link 1.3 How to use this online manual Within this manual, we have created chapters for key topics in the application of statistics to the natural world. Chapters contain broad explanations, R code, ecological examples, and assignments, and they are designed to be worked through with RStudio open beside your browser. So within each chapter: Copy the code. Run it. Change the numbers. Break it. Fix it. The learning is in the doing, not the reading. 1.3.1 How this manual fits into the course This manual contains the core concepts, R code, ecological examples, and detailed explanations. It is the reference you return to throughout the semester and beyond. Every chapter builds on previous chapters, so if something in a later chapter feels unfamiliar, look back—the foundation is here. Recorded lectures provide the narrative arc and motivation for each chapter. They hit the key ideas, walk through the reasoning, and connect concepts to the bigger picture. Watch the lecture first, then work through the corresponding chapter at your own pace. Canvas is where you submit assignments, take quizzes, check grades, and find course announcements. Assignment prompts appear at the end of each chapter in this book, but you will submit your work through Canvas. GitHub hosts the source code for this entire book. Every .Rmd file that produces these chapters is visible in the repository. You are welcome to explore it, clone it, or use it as a reference for your own projects. If you spot a typo or error, you can even submit a pull request—that is how open-source resources improve over time. 1.3.2 Tips for getting the most out of this book Run every code chunk yourself. Do not just read the output printed in the book. The act of running code, seeing it work (or fail), and tweaking it is where the learning happens. Experiment freely. Change the sample size. Swap the probability. Add noise. See what breaks. You cannot damage anything by running code in your own R session, and every “mistake” teaches you something about how R and statistics work. Read with RStudio open. The book and RStudio should be side by side. If you are reading on a laptop, split the screen. If you have a second monitor, even better. Use the search function. This book is a website, and your browser’s search (Ctrl+F or Cmd+F) works on every page. If you need to find where we introduced a concept, search for it. Come back to earlier chapters. Statistical concepts build on each other. If something in Chapter 8 feels unclear, the answer is often in Chapter 3 or 4. The chapters are designed to be revisited, not just read once. Use the reference tables. Several chapters include reference tables (such as the data type → distribution → model table in Chapter 4). You do not need to memorize these. Bookmark them and return to them as needed. 1.3.3 A note on R code in this book All code in this book is written in R and is designed to run in a standard R or RStudio environment. We primarily use base R to keep dependencies minimal, with occasional use of common packages like ggplot2 or knitr when they add clarity. If a code chunk requires a package you have not installed, R will tell you. You can install any missing package with: install.packages(&quot;package_name&quot;) If you encounter an error you cannot resolve, copy the error message and search for it—chances are good that someone else has had the same problem and the answer is on Stack Overflow or the RStudio Community forums. Learning to troubleshoot R errors is itself a valuable skill. 1.4 Course structure This course has been designed to be ‘flipped’. Watch the lecture before you come to class. Then, treat class like a workshop to work through quizzes, assignments, and most importantly your work for your thesis. Whether you are developing the methods for your proposal or conducting your final analysis, this course is meant to support you as you actually perform statistics. "],["back-to-the-basics.html", "Chapter 2 Back to the basics 2.1 Watch the video 2.2 What can statistics tell us? 2.3 The Frequentist Framework 2.4 Bayesian statistics 2.5 Fundaments of frequentist statistics 2.6 What is a model? 2.7 Assignment", " Chapter 2 Back to the basics 2.1 Watch the video Watch the chapter video 2.2 What can statistics tell us? Almost all statistical analysis boils down to answering one of two questions: 1. Do these groups differ? 2. Is there a relationship between these variables? These seem like simple questions — in theory you might just “look at the data” to answer the questions — so why do we need statistics? The short answer is: sampling. We are always measuring a subset of the true population. Even when we try to measure every individual (e.g., rare plant censuses), some individuals may be dormant, hidden, or unreachable. If we were omniscient, we would simply compute the true population parameters (mean, variance, etc.), compare them directly, and skip statistics entirely. But in the real world, we estimate these values from samples and quantify the uncertainty around them. Statistics is practical: it asks, what can we say given imperfect measurements, “small” samples (relative to the true population), and noisy biological systems? 2.3 The Frequentist Framework The statistics we use most commonly in ecology — t-tests, ANOVA, linear models, GLMs, mixed models — are all built within the frequentist or parametric framework. Frequentist statistics assumes: There is a true but unknown parameter The population mean, variance, slope, etc. are fixed constants — but we don’t know their values. Your sample is one of many possible samples you could have taken If you collected data again under the same conditions, you’d get a different sample and different estimates. Variation in your estimates comes from sampling error The parameter does not vary — it varies because you sampled imperfectly. Uncertainty is therefore in the estimator, not the parameter. Probability statements describe long-run frequencies of repeated sampling In other words, frequentist statistics asks: “If we repeated this experiment many times, how often would our method work?” A 95% confidence interval means that 95% of intervals generated this way would contain the true parameter. Once an interval is calculated, the true value is either inside it or not—there is no probability attached to that specific interval. What does “parametric” mean? Parametric tests assume the data follow a particular probability distribution (e.g., normal, Poisson, binomial). These assumptions influence: which model we choose how we estimate uncertainty what kinds of inferences we can make 2.4 Bayesian statistics The main alternative statistical framework to frequentist or parametric statistics is Bayesian statistics. Bayesian statistics is based on Bayes’ Theorem, which provides a mathematical way to update our beliefs in light of new data. In this framework, we start with a prior distribution representing what we believe about a parameter before collecting data. We then combine this prior with the likelihood (the information contained in the data) to obtain a posterior distribution, which reflects our updated beliefs after seeing the evidence. This allows us to make intuitive probability statements about parameters—such as the probability that a parameter lies within a certain range—and provides a flexible foundation for modeling uncertainty, especially in hierarchical and ecological systems. We (and most other ecologists) will learn frequentist methods first, because: Most classical ecological statistics (t-tests, ANOVA, GLMs) use the frequentist framework. Frequentist thinking aligns with standard experimental design. Historically, Bayesian methods were computationally difficult. Most journals still expect p-values and confidence intervals. 2.4.1 When might you choose Bayesian statistics? Although we begin with frequentist methods for their simplicity and historical use in ecology, there are many situations where Bayesian approaches offer clear advantages. Ecologists often choose Bayesian statistics when: Data are sparse, noisy, or imbalanced. Bayesian priors help stabilize estimates when sample sizes are small or data contain many zeros (common in rare species monitoring or demographic studies). Hierarchical or multilevel structure is important. Many ecological datasets have natural grouping—plots within sites, individuals within populations, years within climate regimes. Bayesian methods handle hierarchical models gracefully and provide full uncertainty estimates for every level.You want to incorporate prior information. In wildlife ecology, population modeling, or long-term monitoring, previous studies often contain valuable information that can inform current estimates. Priors allow you to formally combine past research with new data. You care more about parameter uncertainty than about p-values. Bayesian posterior distributions provide intuitive quantities such as: “There is a 94% probability that survival increased after treatment.” This is often more interpretable than a traditional p-value. Models are too complex for frequentist methods.Nonlinear state–space models, integrated population models, hierarchical occupancy models, and many SDM frameworks are more stable and easier to fit using Bayesian tools like Stan, JAGS, or NIMBLE. You need robust propagation of uncertainty. Bayesian methods naturally propagate uncertainty across multiple model components, which is critical for forecasting, resilience modeling, and structured decision making. In short, Bayesian statistics shines when ecological questions involve complex models, low sample sizes, hierarchical structure, prior knowledge, or full uncertainty estimation. 2.5 Fundaments of frequentist statistics 2.5.1 Statistical error Statistical error is the discrepancy between what we observe and the true value we seek to estimate. In statistics, error does not necessarily mean a mistake - it refers to unavoidable variation introduced by sampling, measurement, and natural processes. Whenever we collect data, we introduce error, because: – our instruments have limits – humans make mistakes – environmental conditions vary – biological systems are inherently noisy Frequentist statistical approaches classify and handle error in different ways. 2.5.1.1 Sampling error Sampling error (variation in estimates) arises because different random samples from the same population produce different estimates, even when the underlying population does not change. Imagine: There is a true population mean (fixed but unknown). You take a random sample and calculate the sample mean. You repeat this process many times. What happens? Each sample produces a slightly different sample mean. That variability among sample means is sampling error. 2.5.1.2 Process error Process variability reflects true heterogeneity in the system itself: Individuals differ Environments differ Years differ This variability exists even if you observed the entire population. Key characteristics: Does not disappear with larger sample size Reflects ecological mechanisms Example: Some trees grow faster than others because of microsite conditions. We are sometimes able to reduce process error by accounting for and measuring variables that drive process error, but often we can’t, because the driver of this error is unknown, too complex, or difficult to measure. 2.5.1.3 Measurement error Measurement error arises anytime imperfect humans with imperfect instruments (the situation all the time) measure a sample and can include error introduced by: Imprecise instruments Observer differences 2.5.1.4 Model misspecification Model misspecification occurs when the statistical model does not correctly represent the true data-generating process, arising from: Missing predictors: A relevant variable that influences the response is omitted from the model. Ecological example: Modeling plant growth without including soil moisture. Wrong functional form (linear vs non-linear): The relationship between predictor and response is modeled incorrectly (e.g., linear when nonlinear). Ecological example: Assuming linear temperature effects when responses are unimodal. Ignored interactions: The effect of one predictor depends on another, but this dependency is not modeled. Ecological example: Fire effects differing by precipitation regime. In theory, these are avoidable forms of error, but, particularly in the case of missing predictors, it is often extremely challenging to collect all the relevant predictors in a complex system. When planning an experiment, however, it is really important to think about the underlying processes in your system in order to capture the most important predictors of the variable that you are interested in. 2.5.1.5 Systematic error Systematic error refers to consistent, directional error that causes estimates to be biased in the same way across observations or samples. Unlike random error, systematic error does not average out with increased sample size. Examples include: Biased sampling (e.g., sampling only accessible sites) Consistent measurement bias (e.g., miscalibrated instruments; measuring all plants in the ambient treatment with a device is calibrated such at it adds .1 cm to each measure) Observer bias Why it matters: Systematic error leads to biased estimates and misleading conclusions, even when statistical uncertainty appears small. Because systematic error introduces bias, it should be minimized through design (mostly through randomization and careful consideration of experimental design) rather than absorbed into model error. Sampling error, and all unavoidable types of error (process, measurement, model misspecification) are specified in the error component of a statistical model. 2.6 What is a model? A statistical model is a mathematical expression that describes how a response variable changes as a function of one or more predictors. Since we are taking a frequentist approach, models we will use in this course follow the same structure: Response = Deterministic component + Random variation The deterministic component represents the systematic pattern we want to explain. For example, if asking how plant height changes with grazing treatment, the deterministic component is the grazing treatment (and, of course, the response is plant height!). The random variation component represents the noise or uncertainty that remains after accounting for the predictors, and it follows a probability distribution (We will talk about this in the next chapter). Recall that the other name for frequentist statistics is parametric statistics, which refers to the use of probability distributions. In the next chapter, we will explore probability distributions — the mathematical tools that allow us to represent different types of error and uncertainty in ecological data. 2.7 Assignment Decide your general approach to your statistical analyses. Will frequentists statistics generally work? Are there analysis for which you would like to use Bayesian statistics? "],["probability-the-language-of-uncertainty.html", "Chapter 3 Probability: The Language of Uncertainty 3.1 Watch the video 3.2 Probability is everywhere, and we often get it wrong 3.3 From uncertainty to inference 3.4 Defining the sample space 3.5 Probability as long-run frequency 3.6 Conditional probability and dependence 3.7 From probability to statistical thinking 3.8 Where probability appears in ecology and statistics 3.9 Summary 3.10 Assignment: Probability thinking in your research system", " Chapter 3 Probability: The Language of Uncertainty 3.1 Watch the video Watch the chapter video Across philosophy, physics, ecology, and statistics, “randomness” does not mean the same thing. Sometimes it reflects true unpredictability, sometimes incomplete knowledge, and sometimes the limits of measurement. One of the most interesting panels that I attended as a graduate student was a debate between scientific and religious philosophers over the meaning of randomness. There were a range of viewpoints; the theologian believed that randomness was where the divine could work; at the other extreme, the science philosopher believed that there is no such thing as random, only that we haven’t developed the capacity to measure what we perceive as random, and that everything we experience is a deterministic outcome of physics manifest in the world around us. Statistics does not try to resolve why variation exists. In statistics, randomness has a specific and practical meaning: it refers to situations in which outcomes cannot be predicted with certainty, but where each possible outcome has a known probability of occurring. Importantly, statistics does not distinguish between “true” randomness and unpredictability arising from incomplete information or measurement limitations. Instead, all sources of uncertainty are treated the same way. But probability is not just an abstract statistical concept—it shapes how science communicates with the rest of the world, and misinterpreting it has real consequences. 3.2 Probability is everywhere, and we often get it wrong Consider these statements: “It is extremely likely (95–100% probability) that human activities caused more than half of the observed increase in global mean surface temperature from 1951 to 2010.” — IPCC Fifth Assessment Report “There is a 30% chance of rain tomorrow.” “The probability of local extinction of this population within 50 years is 0.40.” Each of these communicates uncertainty using probability, and each is routinely misunderstood. The IPCC statement does not mean that scientists are 95% sure climate change is happening—it means that in 95–100% of the analyses, human influence exceeded natural variability. A 30% chance of rain does not mean 30% of the area gets wet, or that it will rain for 30% of the day—it means that under similar atmospheric conditions, about 30% of days produce measurable rainfall. An extinction probability of 0.40 does not mean the population will go extinct or won’t—it means that if we ran the future 1,000 times under the same conditions, roughly 400 of those futures would result in extinction. Getting probability right matters. Policy decisions about endangered species, climate adaptation, and public health all depend on whether decision-makers correctly interpret probabilistic statements. And as scientists, producing and interpreting those statements correctly is a core part of our job. 3.3 From uncertainty to inference The difference between the true value of a quantity (such as the mean height of giraffes or the strength of a relationship between snail shell length and movement speed) and the value we observe from a sample is called error. Error is not a mistake; it is the inevitable result of sampling and measurement in complex, variable systems. Statistical models are designed to separate systematic patterns in the data (such as treatment effects or relationships between variables) from this background uncertainty. Because error is unavoidable, statistics replaces certainty with probability. When conducting a statistical analysis, we use probability to evaluate how likely it is that an observed pattern could arise by chance alone. This single idea—comparing what we observed to what chance alone would produce—is the engine that drives almost all of statistical inference. It is what connects this chapter to every analysis you will do in this course. To make that connection, we need to understand a few core probability concepts. We will develop them primarily through ecological examples, using coins and dice only briefly as familiar scaffolding when a new idea needs a simple illustration. 3.4 Defining the sample space The first step in any probability calculation is to define the sample space: the complete set of all possible outcomes of an experiment, observation, or process. If the sample space is defined incorrectly, any probability calculation that follows will also be incorrect. In simple cases, the sample space is obvious. Flip a fair coin: the sample space is {heads, tails}. Roll a die: the sample space is {1, 2, 3, 4, 5, 6}. In ecological applications, defining the sample space requires more thought—and the question you ask determines the answer. Ecological example: You survey a set of plots to determine whether a focal plant species is present. For each plot, the outcome is either present or absent. The sample space consists of two possible outcomes. Importantly, the sample space does not include abundance, biomass, or flowering status—unless those outcomes are explicitly part of your question. Now suppose instead you are counting individuals in each plot. The sample space changes: it becomes {0, 1, 2, 3, …}, in principle extending to infinity. This is a fundamentally different question, and it will lead to different probability calculations and different statistical models. Presence/absence data and count data look different, behave differently, and require different analytical tools—and that distinction starts here, with the sample space. Defining the sample space forces you to be precise about what you are studying. Asking “Is the species present?” is not the same as asking “How many individuals are there?”, which is not the same as asking “What proportion of plots are occupied?” Each question defines a different sample space, and each leads to a different statistical framework. 3.5 Probability as long-run frequency In statistics, probability is commonly interpreted as a long-run frequency: the proportion of times an event would occur if the same process were repeated many times under identical conditions. Suppose you estimate seed germination by planting 100 seeds from the same species under identical greenhouse conditions. Even though the conditions are controlled, not all seeds germinate. If 30 out of 100 seeds germinate, we estimate the probability of germination as 0.30. But what does this number mean? It means that if you repeated this experiment many, many times—planting 100 seeds each time under the same conditions—the proportion of seeds that germinate would converge toward 0.30. In any single trial, the result might be 25, or 33, or 28. But as the number of trials increases, the average settles down. This idea—that estimates stabilize with more data—is one of the most important intuitions in statistics. Let’s see it in action. 3.5.1 Simulation: watching probability stabilize To build intuition, let’s use a simple example first: flipping a fair coin. We know the theoretical probability of heads is 0.5. But in small samples, the observed proportion can look nothing like 0.5. set.seed(226) # Flip a coin many times and track the running proportion of heads n_flips &lt;- 2000 flips &lt;- sample(c(&quot;H&quot;, &quot;T&quot;), size = n_flips, replace = TRUE) running_proportion &lt;- cumsum(flips == &quot;H&quot;) / (1:n_flips) plot(1:n_flips, running_proportion, type = &quot;l&quot;, col = &quot;steelblue&quot;, lwd = 1.5, xlab = &quot;Number of flips&quot;, ylab = &quot;Proportion of heads&quot;, main = &quot;Probability stabilizes with more observations&quot;, ylim = c(0, 1)) abline(h = 0.5, lty = 2, col = &quot;firebrick&quot;) text(n_flips * 0.8, 0.54, &quot;True probability = 0.5&quot;, col = &quot;firebrick&quot;, cex = 0.9) Figure 3.1: As the number of coin flips increases, the observed proportion of heads converges toward the true probability of 0.5. With few flips, estimates are noisy; with many flips, they stabilize. Notice the pattern: early on, the observed proportion swings wildly. With only 10 flips, you might see 70% heads or 30% heads, and neither would be surprising. But as the number of flips grows, the line settles toward 0.5. This is the law of large numbers in action, and it is the reason that larger samples give more reliable estimates. This same logic applies directly to ecological sampling. If the true probability of seed germination is 0.30, then planting 10 seeds gives a noisy estimate (you might see 1 or 5 germinate), while planting 500 seeds gives a much more stable one. This is not just a theoretical nicety—it is the practical reason that sample size matters in every ecological study. 3.5.2 What long-run frequency means for your research In real ecological studies, we rarely get to repeat the exact same experiment thousands of times. But we still rely on long-run frequency reasoning. When we say “the survival probability of juveniles is 0.65,” we mean: if we could observe the survival process for this species many times under these conditions, about 65% of juveniles would survive. Our observed data are one realization of this process, and probability describes the behavior we expect across many such realizations. This interpretation connects directly to ecological rates like survival, recruitment, germination, and flowering probability—all of which are estimated from repeated observations rather than single outcomes. 3.6 Conditional probability and dependence Many ecological processes are not isolated events. Whether a plant flowers depends on whether it survived the winter. Whether you detect a species depends on whether it is actually present. Whether a seed germinates may depend on whether it experienced a fire. These are all cases where the probability of one event depends on another. 3.6.1 How knowing one thing changes what we expect Conditional probability describes situations in which the probability of one event depends on whether another event has occurred. It is written as \\(P(A \\mid B)\\), read as “the probability of A given B,” and is calculated as: \\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\\] where \\(P(A \\cap B)\\) is the probability that both events occur simultaneously. The formula looks abstract, so let’s work through an ecological example. Example: flowering probability in a perennial plant Consider a perennial plant population that you have monitored for two years. In year one, you tagged 200 individuals. By spring of year two, you recorded whether each plant (a) survived the winter and (b) flowered. Here are the results: # Simulated monitoring data set.seed(42) n_plants &lt;- 200 survived &lt;- sample(c(TRUE, FALSE), n_plants, replace = TRUE, prob = c(0.7, 0.3)) flowered &lt;- ifelse(survived, sample(c(TRUE, FALSE), sum(survived), replace = TRUE, prob = c(0.4, 0.6)), FALSE) plant_data &lt;- data.frame( survived = survived, flowered = flowered ) # Summarize the data cat(&quot;Total plants tagged:&quot;, n_plants, &quot;\\n&quot;) ## Total plants tagged: 200 cat(&quot;Survived winter:&quot;, sum(survived), &quot;\\n&quot;) ## Survived winter: 129 cat(&quot;Flowered:&quot;, sum(flowered), &quot;\\n&quot;) ## Flowered: 37 cat(&quot;Died and flowered:&quot;, sum(!survived &amp; flowered), &quot;(should be 0)\\n&quot;) ## Died and flowered: 0 (should be 0) Now let’s calculate two different probabilities: # P(flowered): probability of flowering across ALL tagged plants p_flower &lt;- mean(plant_data$flowered) cat(&quot;P(flowered) =&quot;, round(p_flower, 3), &quot;\\n&quot;) ## P(flowered) = 0.185 # P(flowered | survived): probability of flowering GIVEN survival p_flower_given_survived &lt;- mean(plant_data$flowered[plant_data$survived]) cat(&quot;P(flowered | survived) =&quot;, round(p_flower_given_survived, 3), &quot;\\n&quot;) ## P(flowered | survived) = 0.287 These are different numbers, and the difference matters. \\(P(\\text{flowered})\\) treats all 200 plants the same—including the ones that died, which had zero chance of flowering. \\(P(\\text{flowered} \\mid \\text{survived})\\) restricts attention to the plants that were actually “eligible” to flower. The conditional probability is higher because knowing that a plant survived changes the sample space we are considering. This distinction is not just mathematical bookkeeping. In population ecology, the probability of reproduction is almost always conditional on survival. If you estimate \\(P(\\text{flowered})\\) without accounting for survival, you will underestimate the reproductive capacity of surviving plants. Stage-structured population models, life tables, and matrix projection models all depend on conditional probabilities like these. 3.6.2 Independence: when knowing one thing changes nothing Two events are independent if the occurrence of one does not affect the probability of the other. Mathematically, events A and B are independent if: \\[P(A \\mid B) = P(A)\\] In other words, learning that B happened tells you nothing new about the probability of A. When independence is reasonable: The survival of two plants growing far apart in similar habitat may be approximately independent. Whether it rains in Tucson today is independent of whether a coin lands heads. When independence is unreasonable: The survival of the same plant across consecutive years is almost certainly not independent—a plant that survived year one is likely healthier, larger, or in a better microsite, all of which increase its probability of surviving year two. For independent events, the probability of both occurring is the product of their individual probabilities: \\[P(A \\cap B) = P(A) \\times P(B)\\] This is the multiplication rule for independent events. It only works when the events truly are independent. # Two independent events: flipping two separate coins p_heads_coin1 &lt;- 0.5 p_heads_coin2 &lt;- 0.5 p_both_heads &lt;- p_heads_coin1 * p_heads_coin2 cat(&quot;P(heads on both coins) =&quot;, p_both_heads, &quot;\\n&quot;) ## P(heads on both coins) = 0.25 # Two dependent events: survival across years p_survive_yr1 &lt;- 0.70 p_survive_yr2_given_yr1 &lt;- 0.85 # higher because survivors are healthier p_survive_both &lt;- p_survive_yr1 * p_survive_yr2_given_yr1 cat(&quot;P(survive both years) =&quot;, p_survive_both, &quot;\\n&quot;) ## P(survive both years) = 0.595 # Compare: if we INCORRECTLY assumed independence p_survive_yr2_marginal &lt;- 0.70 # ignoring dependence p_survive_both_wrong &lt;- p_survive_yr1 * p_survive_yr2_marginal cat(&quot;P(survive both years), assuming independence =&quot;, p_survive_both_wrong, &quot;\\n&quot;) ## P(survive both years), assuming independence = 0.49 cat(&quot;Error from assuming independence:&quot;, round(p_survive_both - p_survive_both_wrong, 3), &quot;\\n&quot;) ## Error from assuming independence: 0.105 Assuming independence when events are dependent leads to incorrect conclusions. In this example, ignoring the dependence between years underestimates two-year survival. This is why statistical analyses often account for repeated measures, spatial structure, or shared environments—these are all forms of dependence that violate the independence assumption. Why this matters for your statistics: Many statistical tests assume that observations are independent. Violating this assumption—for example, by treating repeated measurements on the same individual as independent data points—is one of the most common mistakes in ecological statistics. Recognizing when events are dependent is not just a probability concept; it is a practical skill that will affect every analysis you run. 3.7 From probability to statistical thinking So far, we have built a vocabulary: sample spaces, long-run frequency, conditional probability, independence. These concepts matter, but they serve a larger purpose: they are the building blocks of statistical inference. This section shows how they come together. The key question in most statistical analyses is deceptively simple: Could the pattern I observed have arisen by chance alone? Answering that question requires three things: (1) a model of what “chance alone” looks like, (2) a way to describe the range of outcomes that chance could produce, and (3) a way to measure how surprising our actual observation is. Probability provides all three. 3.7.1 Probability distributions: the full picture of uncertainty In the previous sections, we talked about the probability of single events: the probability of germination, the probability of survival. But in practice, we usually care about the distribution of outcomes—not just whether a single seed germinates, but how many out of 50 germinate. A probability distribution describes all possible outcomes and how likely each one is. It is a complete picture of uncertainty for a given process. Let’s build one from scratch. Suppose the probability of seed germination for a particular species is 0.30. You plant 50 seeds. How many do you expect to germinate? The intuitive answer is \\(50 \\times 0.30 = 15\\). But you won’t always get exactly 15. Sometimes you’ll get 12, sometimes 18, occasionally 8 or 22. The question is: what is the full range of plausible outcomes, and how likely is each one? We can answer this with simulation: set.seed(226) # Simulate planting 50 seeds, 10000 times n_seeds &lt;- 50 p_germ &lt;- 0.30 n_reps &lt;- 10000 germination_counts &lt;- rbinom(n_reps, size = n_seeds, prob = p_germ) hist(germination_counts, breaks = seq(-0.5, max(germination_counts) + 0.5, by = 1), col = &quot;lightgreen&quot;, border = &quot;darkgreen&quot;, xlab = &quot;Number of seeds germinated (out of 50)&quot;, ylab = &quot;Frequency&quot;, main = &quot;Distribution of germination outcomes\\n(p = 0.30, n = 50 seeds)&quot;) abline(v = n_seeds * p_germ, lty = 2, lwd = 2, col = &quot;firebrick&quot;) text(n_seeds * p_germ + 3, n_reps * 0.12, &quot;Expected: 15&quot;, col = &quot;firebrick&quot;, cex = 0.9) Figure 3.2: If the true germination probability is 0.30 and we plant 50 seeds, this is the distribution of outcomes we would expect across many repetitions. The dashed line marks the expected value of 15. This histogram is a binomial distribution: it describes the number of “successes” (germinations) in a fixed number of independent trials (seeds), each with the same probability of success. You just built it by simulation; R has a built-in function that does the same thing analytically: # Compare simulation to the theoretical binomial distribution theoretical_probs &lt;- dbinom(0:n_seeds, size = n_seeds, prob = p_germ) # Most likely outcomes likely_range &lt;- which(theoretical_probs &gt; 0.01) - 1 # subtract 1 because index starts at 1 cat(&quot;Outcomes with &gt;1% probability:&quot;, paste(range(likely_range), collapse = &quot; to &quot;), &quot;\\n&quot;) ## Outcomes with &gt;1% probability: 8 to 22 cat(&quot;Expected value:&quot;, n_seeds * p_germ, &quot;\\n&quot;) ## Expected value: 15 cat(&quot;Standard deviation:&quot;, round(sqrt(n_seeds * p_germ * (1 - p_germ)), 2), &quot;\\n&quot;) ## Standard deviation: 3.24 The binomial distribution is just one probability distribution. Different kinds of ecological data call for different distributions—counts of individuals in quadrats often follow a Poisson distribution, continuous measurements like body mass often follow a normal distribution. We will meet these in later chapters. For now, the important idea is that a probability distribution gives us a way to describe what “normal variation” looks like for a given process. And that is exactly what we need to build a null model. 3.7.2 Null models: what does chance alone look like? Here is the central move in statistical thinking: once you can describe what chance alone would produce, you can ask whether your data look like they came from that process or whether something more interesting is going on. A null model is a probability model that represents the hypothesis of “no effect” or “nothing interesting happening.” It defines what we would expect to see if, for example, a treatment had no impact, two groups were identical, or a pattern were generated by chance. Ecological example: You are testing whether a restoration treatment increases seed germination. You set up an experiment with two groups: Treatment: 50 seeds planted in restored soil Control: 50 seeds planted in unrestored soil You observe that 22 out of 50 seeds germinate in the treatment group and 13 out of 50 in the control group. The difference in germination rates is \\(22/50 - 13/50 = 0.44 - 0.26 = 0.18\\). That seems like a meaningful difference. But could it have happened by chance, even if the treatment did nothing? To answer this, we need a null model. The null hypothesis is: the treatment has no effect on germination. Under this hypothesis, the 35 seeds that germinated would have germinated regardless of which group they were in. The group labels are meaningless. This gives us a strategy: shuffle the labels and see what happens. 3.7.3 A permutation test: building a null distribution A permutation test (also called a randomization test) works by: Combining all observations into a single pool (ignoring group labels). Randomly reassigning observations to groups. Calculating the difference between groups for each random assignment. Repeating many times to build a null distribution—the distribution of differences we would see if group membership were random. # Our observed data treatment &lt;- c(rep(1, 22), rep(0, 28)) # 22 germinated out of 50 control &lt;- c(rep(1, 13), rep(0, 37)) # 13 germinated out of 50 # Combine into one dataset germinated &lt;- c(treatment, control) group &lt;- c(rep(&quot;treatment&quot;, 50), rep(&quot;control&quot;, 50)) # Observed difference in germination rates obs_diff &lt;- mean(germinated[group == &quot;treatment&quot;]) - mean(germinated[group == &quot;control&quot;]) cat(&quot;Observed difference in germination rate:&quot;, obs_diff, &quot;\\n&quot;) ## Observed difference in germination rate: 0.18 Now we build the null distribution by shuffling group labels: set.seed(226) n_perms &lt;- 10000 perm_diffs &lt;- numeric(n_perms) for (i in 1:n_perms) { shuffled_group &lt;- sample(group) # randomly reassign labels perm_diffs[i] &lt;- mean(germinated[shuffled_group == &quot;treatment&quot;]) - mean(germinated[shuffled_group == &quot;control&quot;]) } # Plot the null distribution hist(perm_diffs, breaks = 40, col = &quot;grey80&quot;, border = &quot;grey50&quot;, xlab = &quot;Difference in germination rate (treatment - control)&quot;, ylab = &quot;Frequency&quot;, main = &quot;Null distribution: what chance alone produces&quot;) abline(v = obs_diff, col = &quot;firebrick&quot;, lwd = 2, lty = 2) abline(v = -obs_diff, col = &quot;firebrick&quot;, lwd = 2, lty = 2) text(obs_diff + 0.02, n_perms * 0.06, &quot;Observed\\ndifference&quot;, col = &quot;firebrick&quot;, cex = 0.85, adj = 0) Figure 3.3: The null distribution shows the range of differences in germination rate we would expect if the treatment had no effect. The red dashed line marks our observed difference. Values as extreme or more extreme than our observation are rare under the null model, suggesting the treatment had a real effect. Most of the null distribution is clustered near zero—which makes sense, because if the treatment does nothing, the difference between groups should be small. Our observed difference of 0.18 sits out in the tail of the distribution. 3.7.4 The p-value: measuring surprise The p-value is simply the proportion of the null distribution that is as extreme as, or more extreme than, what we actually observed. It answers the question: if the treatment truly had no effect, how often would chance alone produce a difference this large? # Two-sided p-value: proportion of permutations with |difference| &gt;= |observed| p_value &lt;- mean(abs(perm_diffs) &gt;= abs(obs_diff)) cat(&quot;p-value:&quot;, p_value, &quot;\\n&quot;) ## p-value: 0.0361 A small p-value means our observation would be unusual if nothing were going on. That’s it. It does not prove the treatment works. It does not measure the size of the effect. It does not tell us whether the result is ecologically important. It quantifies surprise under a specific assumption—the assumption that the null model is true. Let’s put all three pieces together: summary_df &lt;- data.frame( Concept = c(&quot;Null model&quot;, &quot;Null distribution&quot;, &quot;p-value&quot;), Definition = c(&quot;A probability model representing &#39;no effect&#39;&quot;, &quot;The distribution of outcomes under the null model&quot;, &quot;The probability of observing a result as extreme as ours, if the null model were true&quot;), In_our_example = c(&quot;Treatment has no effect on germination&quot;, &quot;Histogram of differences from 10,000 random shuffles&quot;, paste0(p_value, &quot; of shuffled differences were as extreme as ours&quot;)) ) knitr::kable(summary_df, col.names = c(&quot;Concept&quot;, &quot;What it means&quot;, &quot;In our example&quot;), caption = &quot;The three components of a statistical test&quot;) Table 3.1: The three components of a statistical test Concept What it means In our example Null model A probability model representing ‘no effect’ Treatment has no effect on germination Null distribution The distribution of outcomes under the null model Histogram of differences from 10,000 random shuffles p-value The probability of observing a result as extreme as ours, if the null model were true 0.0361 of shuffled differences were as extreme as ours This logic—build a null model, generate a null distribution, ask where your data fall—is the foundation of hypothesis testing. Every statistical test you encounter in this course, from t-tests to regression to ANOVA, follows this same structure. The tests differ in the specific null model they use and how they calculate the null distribution, but the reasoning is always the same. 3.8 Where probability appears in ecology and statistics The concepts from this chapter are not an isolated topic. They are the foundation for virtually everything that follows in this course and in quantitative ecology more broadly. Here is a brief roadmap of where these ideas reappear: Hypothesis testing formalizes the null model logic we developed in the previous section. Every test you will learn—t-tests, ANOVA, chi-square tests, regression significance tests—asks the same question: how surprising is my result under a null model? The tests differ in what null model they assume and how they compute the null distribution, but the reasoning is identical. Regression and linear models estimate relationships between variables, and every coefficient in a regression model has a probability distribution. Testing whether a coefficient “differs from zero” is a direct application of null model thinking: we ask how likely the observed coefficient would be if the true relationship were zero. Population modeling and Population Viability Analysis (PVA) rely on probability at every level. Survival probabilities, reproduction probabilities, and transition probabilities between life stages are all estimated from data and used to project population dynamics into the future. These models are often stochastic, meaning they incorporate randomness to generate distributions of possible outcomes (like the extinction probability example from the beginning of this chapter). Stage-structured population models use conditional probabilities across time steps—these are Markov chains, where the probability of being in a particular state next year depends on your current state, exactly as flowering probability depended on survival in our earlier example. Bayesian inference takes the conditional probability formula from this chapter and flips it. Instead of asking \\(P(\\text{data} \\mid \\text{hypothesis})\\)—which is what a p-value gives us—Bayesian methods ask \\(P(\\text{hypothesis} \\mid \\text{data})\\). This “flip” is Bayes’ theorem, and it is nothing more than the conditional probability formula applied in a new direction. If you choose to use Bayesian methods later, the concepts from this chapter are exactly what you need. Occupancy models separate two processes that are often conflated: whether a species is truly present at a site, and whether you detected it during your survey. The probability of detection given presence, \\(P(\\text{detected} \\mid \\text{present})\\), is a conditional probability. Occupancy models use this to estimate the true occurrence rate from imperfect survey data. You do not need to understand all of these yet. The point is that probability is not a standalone topic—it is the language that connects everything we will do this semester. 3.9 Summary Randomness and variability are unavoidable features of natural systems. In statistics, we do not attempt to explain why variation exists; instead, we develop tools to reason about uncertainty in the presence of that variation. The difference between a true population value and what we observe in a sample is called error. Error is not a mistake—it is an inherent consequence of sampling complex systems. Probability provides the language for reasoning about error and uncertainty. Key concepts from this chapter: The sample space defines all possible outcomes. Being explicit about what outcomes are possible—and what question you are asking—is essential for translating ecological questions into statistical ones. Probability as long-run frequency means that a probability represents the proportion of times an event would occur across many repetitions. Larger samples give more stable estimates. Conditional probability formalizes how probabilities change when additional information is available. Many ecological processes are conditional: reproduction depends on survival, detection depends on presence, and future states depend on current ones. Independence means that knowing one event tells you nothing about another. Assuming independence when events are dependent—such as repeated measurements on the same individual—is a common source of error in statistical analyses. A probability distribution describes the full range of possible outcomes and their likelihoods. It is the basis for building null models. A null model represents the hypothesis that nothing interesting is happening. The null distribution shows the range of outcomes we would expect under that hypothesis. The p-value is the proportion of the null distribution as extreme as or more extreme than our observed result. It quantifies surprise under a specific assumption—not the probability that the hypothesis is true. These concepts form the foundation for hypothesis testing, regression models, population modeling, and Bayesian inference, all of which will be developed in later chapters. Key takeaway: Probability does not remove uncertainty from ecological science—it allows us to work with it transparently and rigorously. 3.10 Assignment: Probability thinking in your research system Goal: Apply core probability concepts from this chapter to your own research system, without requiring advanced mathematics. Instructions: Answer the following questions using your thesis system (or a proposed research project if you are early-stage). Short answers are sufficient (1–3 sentences per question unless otherwise noted). 3.10.1 Part 1: Defining the sample space Identify one ecological outcome you measure or plan to measure (e.g., survival, presence/absence, flowering, infection). Explicitly define the sample space for this outcome. What outcomes are possible? What outcomes are not included? 3.10.2 Part 2: Probability as long-run frequency If you repeated your study many times under the same conditions, what does the probability of your chosen outcome represent? What would increasing your sample size change about your probability estimate? 3.10.3 Part 3: Conditional probability Identify one outcome in your system that depends on another condition (e.g., reproduction depends on survival, detection depends on presence, germination depends on fire). Explain the difference between \\(P(A)\\) and \\(P(A \\mid B)\\) in the context of your research question (e.g., “P(flowering) vs. P(flowering | survived winter)”). 3.10.4 Part 4: Independence and dependence Identify two events in your system that are likely dependent. Briefly explain why assuming independence would be inappropriate in this case. What might go wrong statistically? 3.10.5 Part 5: Null model thinking Describe a null model for one comparison or question in your research. What would you expect to see if there were no treatment effect, no relationship, or no difference? If you simulated data under this null model many times, what would the distribution of outcomes look like? (Describe in words—you do not need to run a simulation.) 3.10.6 Part 6: Connecting to your analyses Name one statistical analysis you plan to use (or expect to use) in your research. Which probability concept from this chapter does it rely on most heavily? Examples to get you started: If you plan to use logistic regression, it models conditional probability. If you plan to use a t-test, it relies on null model logic. If you plan to build a population model, it uses conditional (transition) probabilities across time steps. "],["data-types-and-why-they-matter.html", "Chapter 4 Data Types and Why They Matter 4.1 Types of variables 4.2 From data to residuals 4.3 Normal vs. non-normal error 4.4 Linking data types to distributions and models 4.5 Common statistical distributions 4.6 Summary 4.7 Assignment", " Chapter 4 Data Types and Why They Matter In the previous chapter, we built a binomial distribution by simulating seed germination 10,000 times. That distribution described the range of outcomes we would expect for a binary process (germinate or not) with a known probability. But the binomial is just one distribution for one kind of data. If we had been counting the number of seedlings per plot instead of asking whether each seed germinated, we would need a different distribution. If we had been measuring seedling height, we would need yet another. This is the core idea of this chapter: the type of data you collect determines the probability distribution, which determines the statistical model you should use. \\[\\text{Data type} \\rightarrow \\text{Distribution} \\rightarrow \\text{Model choice}\\] This connection is not optional—it is the reason why different ecological questions require different statistical approaches. A t-test assumes one kind of error structure; a Poisson regression assumes another. Choosing the wrong model for your data type doesn’t just give you a less precise answer—it can give you the wrong answer entirely. Before we learn any specific test, we need to understand the raw material we are working with. 4.1 Types of variables Ecological data come in several forms, and recognizing which form your data take is the first step toward choosing an appropriate analysis. 4.1.1 Categorical variables Categorical variables classify observations into groups or categories. The values are labels, not numbers, and arithmetic operations on them are meaningless. Examples: habitat type (forest, grassland, wetland), species identity (ponderosa pine, Douglas fir, white fir), treatment group (control, fertilized, burned), presence or absence of a species. Categorical variables with only two levels—such as present/absent, alive/dead, or germinated/not—are called binary variables. These are among the most common response variables in ecology, and they connect directly to the binomial distribution you built in Chapter 3. 4.1.2 Numerical variables Numerical variables represent measured quantities and come in two forms: Discrete (counts): These are whole numbers representing how many of something you observed. Counts cannot be negative, and fractions don’t make sense. If you are counting the number of insects in a pitfall trap, the number of flowers on a plant, or the number of seedlings in a quadrat, you are working with discrete data. Counts often follow Poisson or negative binomial distributions. Continuous: These are measurements that can take any value within a range, including fractions and decimals. Height, biomass, temperature, growth rate, and leaf area are all continuous variables. Continuous data often follow a normal (Gaussian) distribution, though not always—biomass, for instance, is always positive and often right-skewed. 4.1.3 Ordinal variables Ordinal variables have a meaningful order, but the distance between categories is not necessarily equal. A Likert scale response of “strongly disagree, disagree, neutral, agree, strongly agree” is ordinal: the categories have a clear ranking, but the difference between “agree” and “strongly agree” is not necessarily the same as between “disagree” and “neutral.” Examples: damage severity ratings (none, light, moderate, severe), Braun-Blanquet cover classes, stream condition indices. Ordinal data require specialized methods (such as cumulative link models) because treating them as either purely categorical or purely numerical can lead to incorrect conclusions. 4.2 From data to residuals Once you know your data type, the next question is: how do we evaluate whether a statistical model is doing a good job? The answer involves residuals. 4.2.1 What is a residual? When we fit a statistical model, the model generates a predicted value for each observation. The residual is the difference between what we actually observed and what the model predicted: \\[\\text{Residual} = \\text{Observed value} - \\text{Predicted value}\\] Residuals represent the variation that the model does not explain. If a model captures the major patterns in the data, residuals should be small and centered around zero. Think of it like throwing darts at a bullseye. Each throw lands slightly off center, but the pattern of misses forms a cloud around the target. The center of the cloud estimates the true target, while the spread of the cloud represents error. A good model puts the bullseye in the right place; residuals describe the scatter around it. 4.2.2 Why the shape of residuals matters Residuals are not just leftovers—they carry critical information about whether a model is appropriate. Statistical inference relies on assumptions about how residuals behave. If those assumptions are violated, our estimates of uncertainty, confidence intervals, and p-values may be misleading. When we examine residuals, we ask: Are they centered around zero? Are positive and negative residuals roughly balanced? Does the variability of residuals stay consistent across the range of predicted values? Do they follow the distribution we assumed? Patterns in residuals—such as systematic curvature, increasing spread, or heavy tails—signal that something about the model is wrong. Maybe a predictor is missing, maybe the relationship is nonlinear, or maybe the assumed error distribution doesn’t match the data. Residual diagnostics are a key part of responsible statistical analysis, not an optional afterthought. We will practice these diagnostics extensively when we begin fitting models. 4.3 Normal vs. non-normal error Many statistical models assume that residuals follow a normal (Gaussian) distribution: most residuals are small, extreme deviations are rare, and the distribution is symmetric around zero. This assumption often works well for continuous traits like height, biomass, or growth rates, where many small, independent factors add together to produce the observed value. However, not all data behave this way. The sample space matters—and this is where Chapter 3’s lessons become directly relevant: Count data (0, 1, 2, 3, …) cannot be negative and are often right-skewed, especially when the average count is small. They typically follow Poisson or negative binomial distributions. Binary data (0 or 1) can only take two values. Normal error makes no sense here; we use the binomial distribution instead. Proportion data are bounded between 0 and 1. Normal distributions can predict values outside these bounds, which is meaningless. Using a model that assumes normal error for non-normal data can produce biased estimates and incorrect inferences. Recognizing your data type—and choosing a model with the appropriate error structure—is one of the most consequential decisions you will make in any analysis. 4.4 Linking data types to distributions and models The table below is a reference that connects data types to the distributions and models commonly used in ecology. You do not need to memorize this table. Bookmark it. We will return to it repeatedly throughout the course, and each time we encounter a new analysis, I will point you back to the relevant row. For now, the goal is to see the pattern: different data types lead to different distributions, which lead to different models. Every row in this table represents a deliberate choice that a researcher must make based on the structure of their data. Table 4.1: Reference: Data types, distributions, and models commonly used in ecology. Bookmark this table—we will return to it throughout the course. Data Type Distribution Link Ecological Example Typical Models Continuous Normal (Gaussian) Identity Do burned plots have taller seedlings? t-test, ANOVA, linear regression, LMM Continuous (positive, skewed) Gamma Log Does fertilizer increase biomass (always &gt; 0)? Gamma GLM, Gamma GLMM Continuous (bounded 0–1) Beta Logit / log–log What proportion of cover is bare soil? Beta regression, Beta GLMM Counts (integers ≥ 0) Poisson Log Does precipitation affect pitfall-trapped insects? Poisson GLM, Poisson GLMM Counts with overdispersion Negative Binomial Log Does nutrient addition affect flower counts (variance &gt; mean)? Negative Binomial GLM, NB GLMM Counts with many zeros Zero-inflated Poisson / NB Log Do invasive grasses produce many zero seedling counts? ZIP / ZINB, hurdle models Binary outcomes (0/1) Binomial (Bernoulli) Logit / probit Does shade increase seedling survival probability? Logistic regression, Binomial GLM/GLMM Proportions from counts Binomial Logit What proportion of seeds germinate per treatment? Binomial GLM, logistic regression Categorical (unordered) Multinomial Logit Do grazing treatments shift vegetation type frequencies? Multinomial logistic, Chi-square Ordinal (ordered categories) Ordinal logistic Logit / probit Does grazing intensity affect seedling vigor ranks? Proportional odds (CLM/CLMM) Time-to-event Exponential / Weibull Log How long do seedlings survive under drought? Survival analysis, Cox regression Nonlinear continuous Non-normal, unknown Identity or specialized Is the relationship between age and growth curved? GAM, GAMM 4.5 Common statistical distributions Now let’s look at some of the distributions from the table above. For each one, we will simulate data in R so you can see the shape of the distribution and build intuition for what each one represents. 4.5.1 The normal distribution The normal distribution is the classic bell curve. It arises from the Central Limit Theorem: when many small, independent factors add together—genetics, microclimate, measurement error, nutrient availability—their combined effect tends to be normally distributed. This is why so many continuous biological measurements are approximately normal. Ecological examples: seedling height, tree diameter (DBH), leaf nitrogen content, body mass, daily temperature. set.seed(1) heights &lt;- rnorm(1000, mean = 10, sd = 2) hist(heights, breaks = 20, col = &quot;lightblue&quot;, border = &quot;steelblue&quot;, main = &quot;Simulated Normal Distribution&quot;, xlab = &quot;Height (cm)&quot;, ylab = &quot;Frequency&quot;) abline(v = 10, lty = 2, lwd = 2, col = &quot;firebrick&quot;) Figure 4.1: The normal distribution is symmetric and bell-shaped. Most values cluster near the mean, with fewer observations in the tails. The normal distribution is defined by two parameters: the mean (center) and the standard deviation (spread). Many common statistical tests—t-tests, ANOVA, linear regression—assume that residuals follow this distribution. 4.5.2 The binomial distribution You already built this distribution in Chapter 3 when you simulated seed germination. The binomial distribution arises when there are two possible outcomes (success or failure), each trial has the same probability of success, and you repeat the trial a fixed number of times. Ecological examples: seed germination (germinated / not), survival (alive / dead), flowering (reproductive / not), species presence or absence at survey points. set.seed(1) germination &lt;- rbinom(1000, size = 10, prob = 0.6) hist(germination, breaks = seq(-0.5, 10.5, by = 1), col = &quot;lightgreen&quot;, border = &quot;darkgreen&quot;, main = &quot;Simulated Binomial Distribution&quot;, xlab = &quot;Number of seeds germinated (out of 10)&quot;, ylab = &quot;Frequency&quot;) abline(v = 10 * 0.6, lty = 2, lwd = 2, col = &quot;firebrick&quot;) Figure 4.2: The binomial distribution describes the number of successes in a fixed number of trials. Here, we simulate germination of 10 seeds with a 60% probability of success. The binomial distribution is defined by two parameters: the number of trials (\\(n\\)) and the probability of success (\\(p\\)). The expected value is \\(n \\times p\\). When you use logistic regression to model binary outcomes, you are estimating \\(p\\) as a function of predictor variables. 4.5.3 The Poisson distribution The Poisson distribution describes counts of events that happen independently, with a constant average rate, over a fixed period of time or area of space. It often appears in ecology because many biological events behave like random arrivals. Ecological examples: number of flowers per plant, number of birds detected per point count, number of insects in a pitfall trap, seedling recruitment counts per quadrat. set.seed(1) flower_counts &lt;- rpois(1000, lambda = 4) hist(flower_counts, breaks = seq(-0.5, max(flower_counts) + 0.5, by = 1), col = &quot;salmon&quot;, border = &quot;brown&quot;, main = &quot;Simulated Poisson Distribution&quot;, xlab = &quot;Number of flowers&quot;, ylab = &quot;Frequency&quot;) abline(v = 4, lty = 2, lwd = 2, col = &quot;firebrick&quot;) Figure 4.3: The Poisson distribution describes the number of events occurring in a fixed interval. It is right-skewed when the mean is small and becomes more symmetric as the mean increases. A key property of the Poisson distribution is that the mean equals the variance. When this assumption is violated—specifically, when the variance is much larger than the mean—the data are overdispersed, and the Poisson model is no longer appropriate. 4.5.4 The negative binomial distribution When count data are more variable than the Poisson allows, we say they are overdispersed. Overdispersion frequently arises in ecology because individuals vary in productivity, organisms are spatially clustered, or environmental conditions change across the study area. The negative binomial distribution adds an extra parameter that allows the variance to exceed the mean. Ecological examples: insect counts in patchy habitat, seed production with high individual variation, flower counts with many zeros and a few very high values. set.seed(1) nb_counts &lt;- rnbinom(1000, size = 2, mu = 4) hist(nb_counts, breaks = seq(-0.5, max(nb_counts) + 0.5, by = 1), col = &quot;tan&quot;, border = &quot;sienna&quot;, main = &quot;Simulated Negative Binomial Distribution&quot;, xlab = &quot;Count&quot;, ylab = &quot;Frequency&quot;) abline(v = 4, lty = 2, lwd = 2, col = &quot;firebrick&quot;) Figure 4.4: The negative binomial distribution accommodates overdispersion—more variability than the Poisson allows. Notice the longer right tail compared to the Poisson. Compare this histogram to the Poisson above: both have a mean of 4, but the negative binomial has a much longer right tail. If you fit a Poisson model to overdispersed data, your standard errors will be too small, your p-values too optimistic, and your confidence intervals too narrow. Recognizing overdispersion—and switching to a negative binomial—is a practical skill you will use often. 4.5.5 The uniform distribution The uniform distribution assigns equal probability to all values within a range. It is relatively rare as a model for ecological data, but it plays an important role behind the scenes. Uses in ecology and statistics: simulating randomness, generating null models (as we did in Chapter 3’s permutation test), creating starting conditions for stochastic population models, and serving as a “non-informative” prior in Bayesian analysis. set.seed(1) uniform_vals &lt;- runif(1000, min = 0, max = 1) hist(uniform_vals, breaks = 20, col = &quot;gray80&quot;, border = &quot;gray50&quot;, main = &quot;Simulated Uniform Distribution&quot;, xlab = &quot;Value&quot;, ylab = &quot;Frequency&quot;) Figure 4.5: The uniform distribution assigns equal probability to all values. It is useful for simulation and null models, but rarely describes ecological data directly. 4.6 Summary The type of data you collect determines everything that follows in a statistical analysis: Categorical, numerical (discrete and continuous), and ordinal variables each require different treatment. Recognizing what kind of data you have is the first step toward choosing an appropriate model. Residuals are the portion of variation that a model does not explain. Their shape tells you whether your model is appropriate. Residual diagnostics are an essential part of every analysis. Different data types produce different error structures. Continuous data often produce normally distributed residuals; counts produce Poisson or negative binomial error; binary data produce binomial error. Using the wrong error structure gives wrong answers. The reference table in this chapter maps data types to distributions and models. You do not need to memorize it now—we will refer to it throughout the course as we encounter new analyses. Everything in this course builds on the chain: data type \\(\\rightarrow\\) distribution \\(\\rightarrow\\) model choice. Understanding this chain is more important than memorizing any single test. 4.7 Assignment Make a list of the response variables you plan to measure for your research project. For each variable, identify: The data type (categorical, discrete count, continuous, ordinal, binary). The most appropriate error distribution (normal, binomial, Poisson, negative binomial, etc.). A brief explanation (1–2 sentences) of why you chose that distribution. What features of your data led you to this choice? Hint: Refer to the reference table in this chapter. If you are unsure about a variable, describe what the data look like (e.g., “always positive, right-skewed, many zeros”) and reason from there. "],["data-exploration-and-assumption-checking.html", "Chapter 5 Data Exploration and Assumption Checking 5.1 Describing data", " Chapter 5 Data Exploration and Assumption Checking Introduction: Why Explore Before You Analyze? The “look at your data first” principle EDA catches errors, reveals patterns, and guides model choice Assumptions aren’t just technicalities — violating them affects inference The goal: no surprises when you run your model Getting to Know Your Data Initial data checks str(), summary(), head(), dim() Checking for missing values (is.na(), naniar package) Identifying data entry errors (impossible values, typos in factor levels) Ecological example: Import a messy vegetation dataset and clean it Quick reference table: Common data problems and how to spot them Visualizing Distributions Univariate exploration Histograms — shape, skew, modes Density plots — smoother view of distribution Boxplots — median, spread, potential outliers QQ plots — comparing data to theoretical distribution R code examples with ecological data Seedling height (continuous) Species counts (discrete) Cover estimates (proportion) Multivariate exploration Scatterplots and scatterplot matrices (pairs(), GGally::ggpairs()) Correlation matrices Visualizing relationships between predictors and response Key questions to ask: Is the distribution roughly symmetric or skewed? Are there gaps or multiple modes? Do relationships look linear? Assumptions of Parametric Tests Why assumptions matter Models make predictions based on assumed data structure Violations can inflate Type I error or reduce power Some violations matter more than others The Big Four for linear models Normality of residuals What it means (residuals, not raw data!) How to check: histogram of residuals, QQ plot, Shapiro-Wilk test When it matters most (small samples) Homoscedasticity (equal variance) What it means: spread of residuals constant across fitted values How to check: residuals vs. fitted plot, Levene’s test, Breusch-Pagan test Common patterns: fan shape, trumpet shape Independence What it means: observations don’t influence each other How to check: study design review, residuals vs. time/space plots, Durbin-Watson test Common violations: repeated measures, spatial clustering, temporal autocorrelation Linearity What it means: relationship between predictors and response is linear How to check: residuals vs. fitted plot, component-residual plots What non-linearity looks like Visual guide: Example diagnostic plots showing “good” vs. “problematic” patterns Checking Assumptions in R Base R approach plot(model) — the four default diagnostic plots Interpreting each plot Using the performance package check_model() — visual dashboard check_normality(), check_heteroscedasticity() Using the DHARMa package (for GLMs) Simulated residuals for non-normal models simulateResiduals(), plot() Worked example: Fit a linear model to plant biomass data, walk through full diagnostic workflow Identifying and Handling Outliers What is an outlier? Statistical definition vs. ecological reality Outliers in predictor space vs. response space Influential points vs. just unusual values Detection methods Visual: boxplots, scatterplots, residual plots Statistical: Cook’s distance, leverage values, studentized residuals Rule of thumb thresholds (Cook’s D &gt; 4/n, etc.) What to do with outliers Investigate first — data entry error? Measurement issue? Real biology? Document decisions transparently Options: correct, remove (with justification), use robust methods, transform Never delete just to “improve” results Ecological example: An unusually large tree in a seedling dataset — error or legacy tree? When Assumptions Are Violated Transformation approaches Log, square root, arcsine-square root When transformations help vs. when to use a different model Back-transformation for interpretation Switch to appropriate GLM Skewed positive data → Gamma Counts → Poisson or Negative Binomial Proportions → Beta or Binomial Non-parametric alternatives Brief mention (covered in later chapter on permutation methods) Robust regression When useful, brief overview Decision flowchart: Assumption violated → what are your options? Putting It All Together: An EDA Workflow Step-by-step checklist Import and inspect data structure Check for missing values and errors Visualize each variable individually Explore relationships between variables Fit preliminary model Run diagnostic checks Address any issues Proceed with analysis Complete worked example: Forest plot data from import to model-ready Key Takeaways Always explore before modeling Check residuals, not raw data, for most assumptions Visualization is your most powerful tool Document your decisions about outliers and transformations When in doubt, try a different model rather than forcing transformations Test Your Knowledge Conceptual questions Why do we check normality of residuals rather than raw data? What does a “fan shape” in a residuals vs. fitted plot indicate? Name two ways to detect influential outliers. Applied exercises Given diagnostic plots, identify the assumption violation Import a dataset, conduct full EDA, report findings Identify and justify handling of outliers in a provided dataset Assignment Conduct a complete EDA on your project dataset: Report summary statistics and missing data Visualize distributions of key variables Create scatterplots of response vs. predictors Fit a preliminary model and check assumptions Document any issues found and your plan to address them 5.1 Describing data First, let’s take a spin with data description. We are starting here to introduce a few concepts that will be important to understand, as we launch into statistical analysis. We will start by describing continuous data. Let’s use a simplified version of a dataset that I’m working with right now to look at the performance of several species of pollinator-friendly native species in agricultural gardens. Eventually, we’d like to develop seed to provide to restorationists for restoration of arid and semiarid grasslands. To do this, we need to understand how reliable these species are at establishing, producing seed, and attracting pollinators. Initially, we are conducting experiments with multiple populations of each species to determine how consistently plants grow, reproduce, and perform. Here, We will take a look at the initial heights of 1 population of one species, Asclepias subverticulata. When doing an actual research write-up, I ask myself ‘What is the most important information for my audience to know about this dataset?’ to guide what descriptions of the data to include. Here, we are just going to play around with numbers and R code! #create vector of heights (cm) of one population of A. subverticulata sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) #take the mean mean(sedonapopulation) ## [1] 5.142857 #calculate variance var(sedonapopulation) ## [1] 7.47619 #calculate standard deviation sd(sedonapopulation) ## [1] 2.734262 #calculate standard error #base r doesn&#39;t have this function #so we have to write our own std_error &lt;- function(x) sd(x)/sqrt(length(x)) std_error(sedonapopulation) ## [1] 1.033454 Most of the time when writing up results, you present a mean (sum of numbers divided by the number of observations), and an estimate of variation (a measure of how different the observations are). Here, we calculated three estimates variation, variance, standard deviation, and standard error. Since you will occasionally need to include equations in your write-ups, let’s get use to mathematical syntax, with these simple examples. The formula for the sample mean is: \\(\\mu = \\frac{\\Sigma x_i}{n}\\); where \\(\\mu\\) indicates the sample mean (sample = group of numbers we are looking at); \\(\\Sigma\\) means to add what ever follows; \\(x_{i}\\) is the value of one observation; (subscript i is often used to indicate that the action should be repeated for all values); \\(n\\) is the number of observations Why didn’t we just use \\(\\bar{x}\\) to indicate the mean? Because statisticians typically use \\(\\bar{x}\\) to indicate the true mean of the population, and \\(\\mu\\) to indicate the sample mean! Just to show you, what the mean() function is doing, let’s run: sum = 3+3+3+3+7+8+9 #add all the numbers in the sample n = length(sedonapopulation) #or you can just calculate the number of height measurements mean = sum/n; mean #divide sum by number ## [1] 5.142857 This formula is simple, but sometimes with more complex formulas, I will solve the equations by hand, to make sure that I understand what is happening! The formula for variance is: \\(S^{2} = \\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(S^{2}\\) is the sample variance; \\(\\mu\\) is the sample mean (remember from above); \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations In other words: #We determine how much each observation varies from the mean. diffobs1 = mean - 3 diffobs2 = mean - 3 diffobs3 = mean - 3 diffobs4 = mean - 3 diffobs5 = mean - 7 diffobs6 = mean - 8 diffobs7 = mean - 9 #Then we square each of these. diffobj1_sq = diffobs1^2 diffobj2_sq = diffobs2^2 diffobj3_sq = diffobs3^2 diffobj4_sq = diffobs4^2 diffobj5_sq = diffobs5^2 diffobj6_sq = diffobs6^2 diffobj7_sq = diffobs7^2 Why do we square the differences rather than just adding them up? Because differences will be positive and negative. If we added them without squaring, sample differences would negate each other. We want an estimate of the absolute differences of samples from the mean. #Then we add the differences up. sumofsquares = sum(diffobj1_sq, diffobj2_sq, diffobj3_sq, diffobj4_sq, diffobj5_sq, diffobj6_sq, diffobj7_sq) #Divide the sum of squares by n - 1. variance = sumofsquares/(n-1); variance ## [1] 7.47619 Why n - 1 instead of n? One reason is that, theoretically, because we are taking the mean of a sample, rather than all individuals, we underestimate the variance, so taking n-1 corrects that bias. Consider it a penalty for measuring a sample, not the entire population! Another practical reason is that dividing by n-1 makes the variance of a single sample undefined (unsolvable) rather than zero (solvable) For standard deviation, we just take the square root of the variance, to remove the effect of squaring the differences when calculating the variance, and thus contextualizing our estimate of variation with regard to the mean. For example, the variance for the Sedona population is 7.48, larger than the sample mean of 5.12; while the standard deviation is 2.73, indicating that you would expect most observations to be 5.12 +/- 2.73 (we’ll get to quantiles in a minute). The formula for standard deviation is: \\(\\sigma = \\sqrt\\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(\\sigma\\) is the sample variance; \\(\\mu\\) is the sample mean; \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations. Finally, standard error and confidence intervals (we’ll get to confidence intervals later) are the most common metrics of variance presented in journals. The formula for standard error is: \\(SE = \\frac{\\sigma}{\\sqrt n}\\) where \\(SE\\) is standard error of the sample; \\(\\sigma\\) is the standard deviation; and \\(n\\) is the number of samples. Why do we divide the standard deviation by the square root of the sample size to get standard error? While standard deviation measures the variation of the sample, standard error is meant to estimate the variation of the entire population of samples, if we could measure all individuals accurately. By dividing by the \\(\\sqrt n\\), the larger the sample size, the lower the error, because you have a more complete estimate of the true mean. In other words, standard deviation is just a measure of the variation of our sample, while standard error also incorporates information about our sampling process (how many individuals we have sampled). Want to delve deep into standard error and deviation (me neither - ha)?: Google central limit theorem + standard error / standard deviation. Means and variance measures are the most common way to describe quantitative data. However, several other metrics are useful for understanding the nature of your data and making decisions about analyses. A comprehensive understanding of your dataset includes describing these four features: Location (Mean, Median) Spread (Variability) Shape (Normal, skewed) Outliers We’ve talked about means. The median is just the central number in the dataset, and helps you identify skewness. #an example of an unskewed population sedona_unskewed &lt;- c(1, 2, 3, 4, 5, 6, 7) mean(sedona_unskewed) ## [1] 4 median(sedona_unskewed) ## [1] 4 #previous sedona population; skewed sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) mean(sedonapopulation) ## [1] 5.142857 median(sedonapopulation) ## [1] 3 In an unskewed population, the mean will equal the median. Skew may not seem important, but it has statistical ramifications, AND it tells us something meaningful about the data. For instance, what if I said that mean price of a home in Flagstaff is 350K, but the median price of a home is 300K? We would know the that average house prices are driven up by a smaller number of expensive homes. We can quantify skew by comparing means and medians (mean &gt; median = right-skewed; median &gt; mean = left-skewed), but it is helpful to visualize the shape of data with a histogram. A histogram is a graph of the frequency of different measurements. Let’s add a few more observations to our Sedona populations (skewed and unskewed) and check out the look of the data! sedona_unskewed &lt;- c(7, 2, 2, 3, 3, 3, 3, 6, 6, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 0.5) mean(sedona_unskewed) ## [1] 3.975 median(sedona_unskewed) ## [1] 4 #I&#39;m renaming sedonapopulation, sedona_skewed for this example sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2) mean(sedona_skewed) ## [1] 4.454545 median(sedona_skewed) ## [1] 4 In this relatively unskewed example, the tails are approximately even. This shape is also referred to as a normal or Gaussian distribution. Here, we superimposed the bellshaped Normal or Gaussian distribution. In this example of skewed data, the tail tapers to the right, indicated that the data is skewed to the right. In order to explain outliers, we need to look at quantiles! Quantiles are proportions of your data, in other words a way to break your data into chunks to understand spread. You can break your data into as many quantiles as you would like, but it is most common to break your data into 4 parts, also called quartiles. (If you break data into 5 parts, the components are called quintiles, 10 parts = deciles, 100 parts = percentiles). When you break data into quartiles, roughly 25 percent of the data occurs within each data chunk. The first chunk of the dataset contains 25% of the data (25th percentile; 25% of the data fall at or below this cut-off) is called the first quartile, the 50th percentile is called the sample median or the second quartile, the 75th percentile is called the third quartile. Box and whisker plots are commonly used to quickly examine quartiles. Let’s check out our plant height data again, using a box and whisker plot. In the plot shown here, the box encapsulates the Interquartile Range (IQR); the center of the data ranging from the 25th percentile to the 75th. The black line in the middle of the box is the median (also called the 50th percentile, because it bisects the dataset; half of the data occur above the median and half below). The lines emerging from the box (whiskers) indicate the extent of the first and third quartiles, and usually corresponding with the minimum and maximum values of the dataset, unless there are outliers. An outlier is a datapoint that occurs outside of the 1st or 3rd quantile. Let’s add one to our Sedona dataset, and see how it is represented on the box and whisker plot. #Let&#39;s add a plant height of 20. sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2, 20) boxplot(sedona_skewed, main=&quot;Skewed&quot;, ylab=&quot;Plant height (cm)&quot;) The outlier appears as a dot on the box and whisker plot, and is the maximum value of the dataset. One other thing to note: Standard deviation also breaks data into meaningful segments, but is only used when data conform to a normal distribution; the mean +/- 1 SD accounts for 68% of the data, +/-2 SDs contains 95% of data, and +/- 3SD includes 99% of data. That said, I’ve never presented standard deviation in a manuscript; it is much more common to include standard error or confidence intervals (discussed later). We’ve played around a lot with data, but what do you actually need to take away from this?: Data types (Categorical, Numerical discrete, Numerical continuous, Ordinal) Why? We will select analyses based on data type. The two basic questions that most statistical analyses answer. Why? This will help you define what statistics can and can’t do and bound our learning space! Ways to describe numerical continuous data (Location, Spread, Shape, Outliers). Why? You will describe your results using these concepts in write-up AND these concepts will be important for certain analyses. Know how to calculate mean, median, and standard error. Why? These are typical ways to describe data in results sections. Start to familiarize yourself with mathematical annotation. Why? You may need to include equations in your methods section. Start to familiarize yourself with R code. Why? Most researchers now use R to analyze, describe, and visualize their data. *Be able to interpret a histogram and box-whisker plot. Why? These are commonly used ways to visualize data. "],["ecological-sampling.html", "Chapter 6 Ecological sampling 6.1 Background 6.2 What kind of study are you designing? 6.3 Sampling approaches 6.4 Systematic Sampling 6.5 Adaptive Sampling (Sampling Rare or Patchy Species) 6.6 Sampling Along Gradients 6.7 Imperfect Detection in Ecological Sampling 6.8 Temporal Sampling and Study Designs Through Time 6.9 Plot shapes, sizes, and transects 6.10 Distance Sampling and Point Counts 6.11 Reducing sampling error 6.12 Sample Size Determination in Ecology: Effect Sizes and Precision 6.13 Variables of interest 6.14 Test your knowledge 6.15 Assignment", " Chapter 6 Ecological sampling 6.1 Background Ecology is the study of organisms and their relationship to the environment. With infinite time and capacity, we could measure every organism, every characteristic of the environment, every physiological function that affects the way an organism responds to the environment, and every gene that underlies those physiological functions in order to understand ecological systems. In practice, such detailed measurements are time-consuming and impractical. For that reason, we use statistics to account for the fact we are always missing information when we conduct ecological studies. In statistics, a population refers to all units of the thing that you are interested in (i.e., all Suriname frogs, all species in a marshland, all grains of sand, all aspen leaves from a genotype found in southern Arizona). Note that the term â€˜populationâ€™ in statistics differs from the term population in population ecology, where a population refers to a group of individuals in a particular area that interbreed. Statistics accounts for the fact that we never perfectly measure the â€˜true populationâ€™ or the all units of interest. Luckily, by properly applying statistics, we can learn practically anything about almost any population using samples! A sample is a subset of the population that we measure to infer something about the true population. In order to avoid erroneous conclusions about the population, our sample must be representative of the population of interest and unbiased. As an example, imagine that you were interested in whether coat color in cats differed between house cats and feral cats. To select the house cat sample, you randomly select house numbers, visit the house and record coat color, thus collecting a random sample. However, to survey feral cats, you go to several cat colonies at night and record the first cat that you see, which are always white or tan. The sampling strategy for feral cats introduces bias, because darker cats are harder to see at night. This causes you to overestimate the number of light-coated feral cats, and underestimate dark-coated feral cats, resulting in the erroneous conclusion that a greater proportion of feral cats are light-colored compared to house cats. Experiments must be carefully planned to reduce bias. We can conduct statistical analysis until the cats come home (ha!), but if your sample is biased, our results will always be meaningless. In the cat example, it was pretty obvious that the researcher was introducing bias, BUT it is REALLY easy to introduce bias in ecological and social research on accident! Imagine that you looking at fire effects on vegetative communities in the Sonoran. In high severity burn areas, there are thickets of cat’s claw (a pokey plant). Without proper field sampling protocols, it is very tempting to avoid establishing plots in the cat claw thickets, thus not capturing true differences in vegetation along burn severity gradients. 6.2 What kind of study are you designing? Before choosing a sampling method, you need to ask a more fundamental question: What kind of study are you running? The answer shapes every sampling decision that follows—where you put plots, how many you need, and what you can conclude from the data. Ecological studies generally fall into two broad categories: Manipulative experiments are studies in which the researcher controls and assigns the treatment. You decide which plots get burned, which seedlings get watered, which enclosures exclude herbivores. Sampling in manipulative experiments focuses on ensuring that treatment groups are comparable and that replication is adequate for the treatments being tested. The sampling methods in this chapter (random, stratified, blocked) are used to place experimental units and assign treatments within them. Observational studies are studies in which the researcher does not control the treatment. Instead, you observe variation that already exists—comparing burned and unburned sites after a wildfire, measuring tree growth across a natural elevation gradient, or comparing species composition in grazed and ungrazed pastures where grazing was determined by the rancher, not by you. Sampling in observational studies focuses on capturing the natural range of variation in the system and ensuring representative spatial coverage. Methods like GRTS, stratified random sampling, and gradient-based designs are particularly important here. This distinction matters for two reasons. First, it determines which sampling methods are most appropriate. In a manipulative experiment, you might use a completely randomized or blocked design to assign treatments to plots (covered in the next chapter, Experimental Design). In an observational study, you are more likely to use GRTS, stratified random sampling, or systematic sampling along a gradient to capture existing variation. Second, it determines what you can conclude. Manipulative experiments support causal language (“fire reduced canopy cover”); observational studies support associative language (“sites that burned had lower canopy cover”). The sampling design cannot fix this distinction—it is baked into the study type. Many ecological studies fall somewhere in between. Natural experiments exploit unplanned events—a wildfire that burns half a watershed, a policy change that protects one river but not another, a beaver that colonizes one stream reach. The “treatment” was not assigned by the researcher, but nature applied it in a way that approximates an experiment. Quasi-experiments involve deliberate human actions without researcher control—a restoration project implemented by a land management agency, a logging operation that creates treated and untreated stands. In both cases, careful sampling of treatment and reference areas is critical for drawing defensible conclusions. One of the most common observational approaches in ecology is space-for-time substitution: instead of waiting decades to observe succession after disturbance, you sample sites of different ages right now and treat the spatial gradient as a proxy for temporal change. Instead of experimentally manipulating climate, you compare populations across a temperature gradient. This approach assumes that the sites differ primarily in the variable of interest (time since disturbance, temperature, elevation) and are otherwise comparable. That assumption is often violated—a site that burned 5 years ago and a site that burned 50 years ago may also differ in soil type, aspect, land-use history, and the species pool available for recolonization. Space-for-time substitution is not inherently wrong, but it requires careful thought about what might be confounded with the gradient, and the conclusions should acknowledge this limitation. The table below summarizes how study type connects to sampling priorities: Table 6.1: Different study types call for different sampling priorities and methods. Knowing your study type before choosing a sampling method prevents mismatches between design and inference. Study type Sampling priority Common methods Manipulative experiment Balance and replication across treatment groups Randomized, blocked, or stratified within treatments Natural experiment Representative coverage of impact and reference areas Stratified random or GRTS across impact/control areas Observational (gradient) Even coverage along the gradient; avoid spatial confounds Systematic or stratified along the gradient Space-for-time substitution Sites comparable except for the variable of interest Stratified by confounds (soil, aspect); systematic along gradient Long-term monitoring Spatial balance and temporal consistency (panels) GRTS with rotating or permanent panels With this framing in mind, let’s look at the specific sampling methods available. The Experimental Design chapter that follows covers the complementary question: once you know where to sample, how do you structure treatments, controls, and replication to support valid inference? 6.3 Sampling approaches Sampling approaches differ in how they balance randomness, spatial coverage, logistical constraints, and inference goals. Here is a brief overview, before we take a look at the most common sampling methods used in ecology. Sampling design What it does When youâ€™d use it Simple random Completely random points Small, homogeneous areas Systematic Regular grid or transects Mapping gradients, efficiency Stratified random Random within strata Heterogeneous landscapes Cluster Groups of nearby points Reduce travel cost GRTS Spatially balanced random Large-scale monitoring Adaptive Adds points where signal is high Rare or patchy species Model-based Guided by covariates Targeting ecological processes Gradient-based Points along environmental gradient Elevation, moisture, disturbance gradients 6.3.1 Random sampling In order to reduce bias, researchers randomize sampling. Random sampling is when every item within the focal population has an equal chance of being selected. In research, random sampling can be applied to selecting experimental subjects, assigning individuals to treatments, or identifying plot locations. It is REALLY easy to introduce bias in ecological and social research on accident if you do not use a random sampling technique! Imagine that you are looking at fire effects on vegetative communities in the Sonoran. In high severity burn areas, there are thickets of cat’s claw (a pokey plant). Without proper field sampling protocols, it is very tempting to avoid establishing plots in the cat claw thickets, thus not capturing true differences in vegetation along burn severity gradients. In practice, researchers use number generators, like those on your phone, or within computer programs, like ArcGIS, to randomly place sampling points. Here, we’ve included a random number sheet to use to randomly array plots. A random number sheet contains random numbers that someone generated in advance to assist in the field. Important note: Random is not the same as wandering around and picking what looks good. Random sampling = using a rule or tool (random number generator, coordinates, random bearings and distances) so every location has a known chance of being selected. Haphazard sampling = picking what feels convenient or typical - this almost always introduces bias. We can quickly and easily generate such a sample in R, using the sample function. sample(1:100, 10, replace=FALSE) ## [1] 100 84 31 77 3 40 24 93 10 97 #1:10000 = numbers to chose among #number of random numbers you wish to generate #to replace or not (in other words do you wish for the same number to be selected multiple times) 6.3.2 Stratified random sampling To make a sample representative of the population, you will want to capture the typical state of the population of interest. This is challenging, since prior to collecting data, you do not know the typical state of the population. With an understanding of ecology, however, and precisely describing your research question, you can improve the representation of your sample without a lot of specific a priori (beforehand) knowledge of the target population. One typical approach is referred to as stratified random sampling, in which you ensure that you are proportionately sampling from major habitat types or features. In the example in Fig. 1, a random sample of the study area overrepresents the forested habitat relative to the grassland habitat. To account for this, the researchers adjust the sampling technique, such that plot locations occur in both of the major habitats proportionally. Since grasslands make up 55% of the study area, 55% of the points would be randomly located in the grassland area. Since there are twenty plots, 11 are placed within grasslands (0.55*20). The remaining 9 plots are then randomly allotted to the forested habitat. Figure 1. Random versus stratified sampling. 6.3.3 Gridded random sampling In complex, multi-species systems, another approach to improve coverage of random sampling is to randomly place plots within a grid (Fig. 2). This is to ensure that you capture species, which may have an array of distributions. Distribution in plant ecology refers to the spatial arrangement of a species or organisms across the landscape. Depending on system dynamics, species may be dispersed, randomly arrayed, or clumped, thus a gridded approach can help capture species, no matter their spatial orientation (Fig. 2). Figure 2. Randomly placing plots within a gridded region helps maximize the likelihood to capture species dynamics in complex, multi-species systems, composed of species with a variety of spatial distributions. 6.3.4 Random cluster sampling Random cluster sampling randomly select groups (aka clusters) within a population. This sampling design is used commonly in ecology, when we select random locations for plots, then measure all individuals within those plots. If for instance, we are interested in Ponderosa Pine growth rates on the Coconino National Forest, we would randomly assign points across Pondo habitat on the Coconino. At each point, we would set up a plot in which we measure Ponderosa Pines within an 11.71m radius plot. Why wouldn’t we just go out to a point and measure 1 tree to create a totally random sample? The plots are randomly assigned (yay!), but the trees within the plots are not independent. In other words, we might expect measures of trees within plot A to be more similar to each other than they are to trees within plot B, due to differences in microsite characteristics, genetic similarity among co-occurring trees, or site history (logging, fire). Luckily, we can account for this non-independence, as long as the plots are random! 6.3.4.1 Pseudoreplication When we treat non-independent measurements as if they were independent replicates, we call this pseudoreplication. For example, if we measure 20 trees inside 1 plot and then pretend we have 20 independent samples - we are ignoring the fact that those trees share the same microsite, history, and environment. In most ecological studies, the plot is the true replicate, and the trees within the plot are subsamples that help us better estimate conditions at that plot. 6.3.5 GRTS Sampling (Generalized Random-Tessellation Stratified Sampling) As ecological questions increasingly span large, heterogeneous landscapes, researchers need sampling approaches that are both statistically rigorous and spatially balanced. One method that has become foundational in long-term ecological monitoringâ€”used by the U.S. EPA, USGS, USFS (e.g., FIA intensification), and many watershed and biodiversity programsâ€”is GRTS, which stands for Generalized Random-Tessellation Stratified sampling. 6.3.5.1 What problem does GRTS solve? Imagine trying to monitor a species or habitat across a large region using simple random sampling. Although random - this approach can still place many points close together and leave other parts of the landscape unrepresented (spatial clumping). Stratified random sampling improves representation across broad habitat types, but still may not ensure even spatial coverage within each stratum. GRTS was developed to solve two key issues: Ensuring spatial balance: Sample points are spread evenly across the landscape (or within strata), minimizing large gaps and clusters. Maintaining true probability-based sampling: Every location has a known probability of being selected, preserving the ability to make unbiased, design-based statistical inferences. This makes GRTS ideal for monitoring programs where the goal is to detect long-term changes in ecological condition, species distributions, or habitat quality. 6.3.5.2 How GRTS Works GRTS uses a special type of spatial ordering, similar to a space-filling curve, to assign every location on the landscape a unique hierarchical address. This lets us draw a sample that: spreads points out as evenly as possible, remains fully random and unbiased, allows consistent sampling over time (e.g., rotating panels), and accommodates stratification, unequal selection probabilities, or oversampling in rare habitats. While the algorithm is mathematically complex, researchers rarely need to understand the internalsâ€”the spsurvey package in R implements GRTS with a single function. 6.3.5.3 When to Use GRTS in Ecological Sampling Researchers choose GRTS when: The study area is large and spatially complex Habitat types are patchy or unevenly distributed Long-term monitoring requires consistency through time Detecting spatial trends or hotspots is important A mixture of old (legacy) and new plots must be integrated without bias GRTS is used in applications such as: Riparian and stream monitoring (EPA EMAP, NRSA) Forest health surveys (USFS FIA intensification) Sage-grouse habitat monitoring Wetland condition assessment Vegetation change detection after disturbance Species occupancy surveys over large regions Restoration monitoring (e.g., fuel treatments, floodplain restoration) In other words, GRTS is the tool of choice when spatial representativeness matters. 6.3.5.4 Example: Sampling Emory oak habitat in across drought and non-drought areas. Overview In this tutorial, you will learn how to implement a GRTS (Generalized Random-Tessellation Stratified) sampling design in R. GRTS produces spatially balanced sample points, meaning sites are evenly spread across the landscape while still being selected randomly. This makes GRTS widely used in ecological monitoring programs (EPA EMAP, NRSA, USFS FIA intensification, watershed monitoring, etc.). Other types of sampling can be implemented in R using similar mapping and spatial workflows. Common designs include simple random sampling, systematic sampling (e.g., regularly spaced grids or transects), stratified random sampling (where samples are allocated within predefined habitat types, management units, or elevation bands), and cluster sampling (where groups of nearby points are sampled together). R also supports adaptive sampling, where additional samples are placed based on initial observations (e.g., high-density patches), unequal probability sampling (e.g., probability proportional to area or habitat suitability), and model-based sampling designs that use covariates such as NDVI, elevation, or climate to guide site selection. GRTS is particularly valuable when spatial balance is critical, but other designs may be more appropriate depending on study objectives, scale, and field constraints. Since GRTS is widely used ecology-based projects, we will start there! We will: 1. Import a study area boundary from Google Drive 2. Generate a spatially balanced GRTS sample 3. Visualize the sample 4. Export the output for field use 6.3.5.4.1 Load Required Packages 6.3.5.4.2 Step 1: Load Spatial Data Our study area includes oak woodlands in southern Arizona. We’ll download three spatial datasets from Google Drive: the sampling frame (study area boundary), strata (drought vs. non-drought areas), and existing monitoring plots. # Temporary directory for downloads temp_dir &lt;- tempdir() # Google Drive file IDs file_ids &lt;- list( sampling_area = &quot;1TOr1BKJpqKYWsGOAPaGrhkql5ovNglqa&quot;, strata = &quot;1ms4ErDYOFkkB4UFFeGGXmWITa3WE97KS&quot;, existing_plots = &quot;1EfI6AorSrgOS1xmr4LioJeSCp6F1yFfZ&quot; ) # Download function (handles Google Drive&#39;s virus scan page) download_from_gdrive &lt;- function(file_id, dest, name) { zip_path &lt;- file.path(dest, paste0(name, &quot;.zip&quot;)) url &lt;- paste0( &quot;https://drive.usercontent.google.com/download?id=&quot;, file_id, &quot;&amp;export=download&amp;confirm=t&quot; ) GET(url, write_disk(zip_path, overwrite = TRUE), progress()) out_dir &lt;- file.path(dest, name) unzip(zip_path, exdir = out_dir) # Removed quiet = TRUE out_dir } # Download all datasets sampling_dir &lt;- download_from_gdrive(file_ids$sampling_area, temp_dir, &quot;SamplingArea&quot;) strata_dir &lt;- download_from_gdrive(file_ids$strata, temp_dir, &quot;Strata&quot;) existing_dir &lt;- download_from_gdrive(file_ids$existing_plots, temp_dir, &quot;ExistingPlots&quot;) # Helper function to read shapefiles read_shp &lt;- function(dir) { shp &lt;- list.files(dir, pattern = &quot;\\\\.shp$&quot;, recursive = TRUE, full.names = TRUE) st_read(shp[1], quiet = TRUE) } # Read the spatial data sampling_frame &lt;- read_shp(sampling_dir) strata &lt;- read_shp(strata_dir) legacy_points &lt;- read_shp(existing_dir) Let’s examine what we loaded: # Check the sampling frame cat(&quot;Sampling Frame contains&quot;, nrow(sampling_frame), &quot;features\\n&quot;) ## Sampling Frame contains 3 features cat(&quot;Available habitat types:&quot;, unique(sampling_frame$R3ERU), &quot;\\n\\n&quot;) ## Available habitat types: Madrean Encinal Woodland Madrean Pinyon-Oak Woodland Ponderosa Pine - Evergreen Oak # Check existing plots cat(&quot;Number of existing monitoring plots:&quot;, nrow(legacy_points), &quot;\\n&quot;) ## Number of existing monitoring plots: 82 6.3.5.4.3 Step 2: Define Study Area We’ll focus on the Madrean Encinal Woodland ecological unit and transform to Albers Equal Area projection for accurate area calculations. encinal &lt;- sampling_frame %&gt;% filter(R3ERU == &quot;Madrean Encinal Woodland&quot;) %&gt;% st_transform(5070) # NAD83 / Conus Albers # Calculate study area study_area_km2 &lt;- round(as.numeric(st_area(encinal)) / 1e6, 2) cat(&quot;Study area:&quot;, study_area_km2, &quot;km²\\n&quot;) ## Study area: 1195.44 km² 6.3.5.4.4 Step 3: Generate GRTS Sample GRTS (Generalized Random-Tessellation Stratified) sampling creates spatially balanced samples. We’ll select 40 base sites plus 10 oversample sites (used if base sites become inaccessible). set.seed(123) # For reproducibility grts_sites &lt;- grts( sframe = encinal, n_base = 40, n_over = 10 ) # Extract base and oversample sites base_sites &lt;- grts_sites$sites_base over_sites &lt;- grts_sites$sites_over cat(&quot;Generated&quot;, nrow(base_sites), &quot;base sites\\n&quot;) ## Generated 40 base sites cat(&quot;Generated&quot;, nrow(over_sites), &quot;oversample sites\\n&quot;) ## Generated 10 oversample sites 6.3.5.4.5 Step 4: Visualize the Sampling Design This step often takes a while, since ggplot is loading spatial data! ggplot() + geom_sf(data = encinal, fill = &quot;forestgreen&quot;, alpha = 0.3, color = &quot;darkgreen&quot;, linewidth = 0.5) + geom_sf(data = base_sites, aes(color = &quot;Base Sites&quot;), size = 3, shape = 19) + geom_sf(data = over_sites, aes(color = &quot;Oversample&quot;), size = 2.5, shape = 1, stroke = 1) + geom_sf(data = legacy_points, aes(color = &quot;Legacy Plots&quot;), size = 2.5, shape = 4, stroke = 1.5) + scale_color_manual( values = c(&quot;Base Sites&quot; = &quot;gold&quot;, &quot;Oversample&quot; = &quot;orange&quot;, &quot;Legacy Plots&quot; = &quot;dodgerblue&quot;), name = &quot;Site Type&quot; ) + theme_minimal(base_size = 14) + theme(legend.position = &quot;bottom&quot;) + labs( title = &quot;GRTS Sampling Design: Madrean Encinal Woodland&quot;, subtitle = paste0(&quot;Study area: &quot;, study_area_km2, &quot; kmÂ²&quot;) ) Figure 6.1: GRTS probability-based sampling design showing 40 base sites (gold circles), 10 oversample sites (orange circles), and existing monitoring plots (blue crosses) in the Madrean Encinal Woodland. Notice how GRTS sites are spatially balanced across the study area. Key observations: - Base sites (gold) are spread evenly across the landscape - Oversample sites (orange) fill spatial gaps and serve as replacements - Legacy plots (blue) show existing monitoring locations - This spatial balance ensures representative coverage 6.3.5.4.6 Step 5: Export Data for Field Work #------------------------------------------------------------ # Step 5: Export Data for Field Work #------------------------------------------------------------ # Create output directory dir.create(&quot;grts_outputs&quot;, showWarnings = FALSE) # Combine all new sample sites all_sites &lt;- rbind( base_sites %&gt;% mutate(site_type = &quot;Base&quot;), over_sites %&gt;% mutate(site_type = &quot;Oversample&quot;) ) #------------------------------------------------------------ # 1. FOR GPS DEVICES - Simplified GPX (just coordinates &amp; names) #------------------------------------------------------------ # GPX format is VERY strict - only name and geometry allowed gpx_sites &lt;- all_sites %&gt;% mutate(name = paste0(siteID, &quot; (&quot;, site_type, &quot;)&quot;)) %&gt;% dplyr::select(name, geometry) st_write(gpx_sites, &quot;grts_outputs/grts_sampling_points.gpx&quot;, driver = &quot;GPX&quot;, delete_dsn = TRUE) #------------------------------------------------------------ # 2. FOR GIS - Full data in Shapefile &amp; GeoJSON #------------------------------------------------------------ # Shapefile (most universal for GIS) st_write(all_sites, &quot;grts_outputs/grts_sampling_points.shp&quot;, delete_dsn = TRUE) # GeoJSON (modern, includes all fields) st_write(all_sites, &quot;grts_outputs/grts_sampling_points.geojson&quot;, delete_dsn = TRUE) # KML (alternative to GPX - works in Google Earth &amp; many GPS apps) kml_sites &lt;- all_sites %&gt;% mutate(Name = paste0(siteID, &quot; (&quot;, site_type, &quot;)&quot;)) st_write(kml_sites %&gt;% dplyr::select(Name, geometry), &quot;grts_outputs/grts_sampling_points.kml&quot;, driver = &quot;KML&quot;, delete_dsn = TRUE) #------------------------------------------------------------ # 3. FOR ANALYSIS - Full data in CSV #------------------------------------------------------------ # Get coordinates coords_albers &lt;- st_coordinates(all_sites) # Create comprehensive CSV with all information sites_csv &lt;- all_sites %&gt;% st_drop_geometry() %&gt;% mutate( X_albers = coords_albers[,1], Y_albers = coords_albers[,2] ) %&gt;% dplyr::select(siteID, site_type, lon_WGS84, lat_WGS84, X_albers, Y_albers, wgt, ip, R3ERU) write.csv(sites_csv, &quot;grts_outputs/grts_sampling_points.csv&quot;, row.names = FALSE) #------------------------------------------------------------ # 4. FIELD DATA SHEET - Blank template for data collection #------------------------------------------------------------ field_sheet &lt;- sites_csv %&gt;% dplyr::select(siteID, site_type, lon_WGS84, lat_WGS84) %&gt;% mutate( date_visited = &quot;&quot;, observers = &quot;&quot;, canopy_cover_pct = &quot;&quot;, tree_density = &quot;&quot;, notes = &quot;&quot; ) write.csv(field_sheet, &quot;grts_outputs/field_data_sheet.csv&quot;, row.names = FALSE) #------------------------------------------------------------ # 5. SAMPLING SUMMARY #------------------------------------------------------------ summary_table &lt;- data.frame( Category = c(&quot;Total Sites&quot;, &quot;Base Sites&quot;, &quot;Oversample Sites&quot;, &quot;Study Area (kmÂ²)&quot;, &quot;Average Site Weight (kmÂ²)&quot;), Value = c( nrow(all_sites), nrow(base_sites), nrow(over_sites), round(as.numeric(st_area(encinal)) / 1e6, 2), round(mean(as.numeric(all_sites$wgt)) / 1e6, 2) ) ) write.csv(summary_table, &quot;grts_outputs/sampling_summary.csv&quot;, row.names = FALSE) 6.3.6 Understanding Design Weights Important: Each GRTS site has a design weight (wgt) representing the area it represents. When analyzing data collected at these sites, you must use these weights to get unbiased population estimates. # Example: First 5 sites and their weights sites_csv %&gt;% dplyr::select(siteID, site_type, wgt) %&gt;% head(5) %&gt;% knitr::kable(caption = &quot;Sample sites with design weights&quot;) Table 6.2: Sample sites with design weights siteID site_type wgt Site-01 Base 29886054 [m^2] Site-02 Base 29886054 [m^2] Site-03 Base 29886054 [m^2] Site-04 Base 29886054 [m^2] Site-05 Base 29886054 [m^2] Example calculation: If you measure canopy cover at each site, calculate the population mean as: # Example field data (for demonstration) field_data &lt;- data.frame( canopy_cover = c(45, 62, 38, 71, 55), wgt = sites_csv$wgt[1:5] ) # Weighted mean (correct for GRTS) weighted.mean(field_data$canopy_cover, w = field_data$wgt) # Simple mean (WRONG - ignores spatial design) mean(field_data$canopy_cover) 6.4 Systematic Sampling Another approach commonly used in ecological studies is systematic sampling, in which sample points or transects are placed at regular intervals across the landscape (e.g., every 50 m along a grid or trail). Unlike random sampling, where points can be clustered, systematic sampling ensures even spatial coverage of a study area. Systematic sampling is useful when: The landscape is large and relatively uniform The goal is to detect broad-scale patterns Field logistics require simple, repeatable placement of plots However, systematic sampling carries one risk: If the sampling interval accidentally aligns with a natural pattern (e.g., spacing of vegetation bands, fence-line effects, or management history), the sample may over- or under-represent certain features. Despite this, systematic sampling performs extremely well in many ecological systems and often provides more spatially uniform coverage than simple random sampling. 6.5 Adaptive Sampling (Sampling Rare or Patchy Species) Some species of interestâ€”threatened plants, cryptic mammals, rare insectsâ€”occur in patchy, clustered distributions. When organisms are rare, simple random sampling may completely miss them. Adaptive sampling increases sampling intensity only where the organism is found. For example: Select initial sample locations randomly. When a target species is detected at a site, sample additional plots in neighboring locations. Continue expanding sampling outward until no new detections occur. This approach is efficient for: Rare plants Disease outbreaks (e.g., white-nose syndrome, oak wilt) Invasive species early detection Patchy coral or seagrass distributions Adaptive sampling improves our ability to detect and map rare organisms, but it also introduces statistical challenges, since sampling intensity is no longer uniform. These can be addressed using specialized estimators or model-based inference. 6.6 Sampling Along Gradients Many ecological questions involve continuous environmental variation rather than discrete treatments. How does species composition change with elevation? How does tree growth respond to a moisture gradient? How does vegetation recover as you move away from a disturbance boundary? These are gradient studies, and they require a different sampling logic than randomized experiments. 6.6.1 What is a gradient study? In a gradient study, the researcher samples across a continuous range of an environmental variable—elevation, distance from a river, time since fire, soil moisture, latitude—and asks how ecological responses change along that gradient. There is no treatment assignment; the gradient already exists in the landscape, and the goal is to characterize the relationship between the environmental variable and the ecological response. Gradient studies are observational by nature, which means they reveal associations rather than causal effects. A pattern of decreasing species richness with elevation does not prove that elevation causes lower richness—temperature, precipitation, growing season length, and soil depth all change with elevation, and any of them could be responsible. This is where thoughtful sampling design helps: by measuring potential confounds at each sampling point, you provide the data needed to disentangle these effects during analysis. 6.6.2 Designing a gradient study Sampling along a gradient requires decisions about three things: 1. How to distribute points along the gradient. Two common strategies are: Even spacing: Place sample points at regular intervals along the gradient (e.g., every 100 m of elevation). This ensures equal representation of the full gradient range and works well when you expect the response to change gradually. Systematic or stratified approaches work well here. Stratified or targeted placement: Concentrate sampling in transition zones where ecological change is expected to be fastest (e.g., ecotones, treeline, the boundary of a burn). This is more efficient for detecting thresholds or nonlinear responses but risks under-sampling the stable portions of the gradient. In practice, a combination often works best: even spacing across the full gradient with additional sampling at ecologically important transitions. 2. How to handle lateral variation. Gradients are rarely one-dimensional. An elevation transect crosses different aspects, soil types, and land-use histories. If you place a single transect straight up a mountain, you cannot separate the effect of elevation from the effect of whatever else changes along that particular path. The solution is replication across the gradient: multiple transects on different slopes, or stratified random sampling that captures the gradient while varying other site characteristics. For example, if studying elevation effects on tree growth, you might sample at 3–5 locations per elevation band, spread across different aspects and drainages. 3. How far apart to sample. The appropriate spacing depends on the spatial scale of variation in both the gradient variable and the ecological response. If tree species composition changes dramatically over 200 m of elevation, sampling every 500 m will miss important transitions. Pilot data or prior ecological knowledge can inform spacing decisions. 6.6.3 Gradient sampling in R A gradient study can be implemented using many of the sampling methods already described in this chapter. Here is an example using stratified random sampling along an elevation gradient: # Stratified random sampling along an elevation gradient # Goal: 5 plots per 200 m elevation band from 1500 to 2500 m library(sf) library(tidyverse) # Assume you have a DEM (digital elevation model) and a study area boundary # Classify the study area into elevation bands elevation_bands &lt;- study_area %&gt;% mutate(elev_band = cut(elevation, breaks = seq(1500, 2500, by = 200), labels = paste0(seq(1500, 2300, by = 200), &quot;-&quot;, seq(1700, 2500, by = 200), &quot; m&quot;))) # Generate random points within each band set.seed(42) gradient_points &lt;- elevation_bands %&gt;% group_by(elev_band) %&gt;% slice_sample(n = 5) # 5 random locations per band # Check distribution across the gradient table(gradient_points$elev_band) GRTS can also be applied within each stratum (elevation band) to ensure spatial balance within each portion of the gradient, combining the advantages of gradient coverage and spatial balance. 6.6.4 Common pitfalls in gradient studies Confounding the gradient with geography. A single transect confounds the gradient variable with everything else that varies along that specific path. Replicate across the gradient, not just along it. Assuming linearity. Many ecological responses to gradients are nonlinear—species richness may peak at mid-elevations, growth may plateau above a moisture threshold. Sample densely enough to detect curvature, especially near expected transitions. Ignoring spatial autocorrelation. Points close together along a gradient are likely to have similar ecological conditions regardless of the gradient variable. If your points are too close, they provide less independent information than widely spaced points. We will address spatial autocorrelation in a later chapter. Space-for-time traps. When a gradient represents time (e.g., distance from a disturbance boundary as a proxy for time since disturbance), remember that the sites may differ in ways beyond the variable of interest. Measure and report potential confounds. 6.7 Imperfect Detection in Ecological Sampling Ecologists rarely observe organisms perfectly. Whether estimating abundance, occupancy, or survival, detection probability can influence sampling accuracy. Common sources of imperfect detection include: Vegetation density (harder to see animals) Observer skill Weather, time of day, or season Species behavior (cryptic, nocturnal, burrowing) Habitat structure Even when sampling is random and unbiased, ignoring detection probability can lead to biased estimates. For example, frogs in dense vegetation may appear â€œabsentâ€ when they are simply undetected. This is especially important when comparing habitats, because detection typically differs among environments. Common study designs that account for detection include: Repeated surveys (occupancy modeling) Point counts with distance sampling Removal sampling Mark-recapture N-mixture models A simple conceptual model: Observed count = True abundance Ã— Detection probability Accounting for detection sets the foundation for later modeling approaches in wildlife ecology and plant demography. 6.8 Temporal Sampling and Study Designs Through Time Sampling is not only about where you measure, but also when. Many ecological processesâ€”recovery after disturbance, climate-driven changes, successional dynamics require data collected over time. 6.8.1 Sampling Panels Long-term monitoring programs often use panels, which describe when sites are revisited: Permanent panel: Same sites revisited every year (high power to detect change). Rotating panels: Different subsets of sites visited in different years (greater spatial coverage). Split panels: Mixture of permanent and rotating sites (e.g., GRTS with a fixed core). GRTS integrates panel design naturally, making temporal inference more robust. 6.8.1.1 Sampling Frequency Sampling too infrequently risks missing important dynamics; too frequently wastes effort. Key considerations: Generation time of focal species Expected speed of recovery Variability of climate or disturbance regime Practical logistics Temporal sampling decisions strongly influence the ability to detect ecological change. 6.8.2 BACI and Other Experimental Designs When evaluating the effect of a treatment—like a fire, restoration project, or invasive removal—ecologists often use a Before-After-Control-Impact (BACI) design, which combines temporal and spatial comparisons to isolate treatment effects from natural variation. BACI designs, along with other experimental design concepts such as blocking, factorial designs, and split-plot designs, are covered in detail in the Experimental Design chapter. 6.9 Plot shapes, sizes, and transects Deciding on the shape and size of your sampling unit depends on the species or feature that you are trying to measure. Plots can be ANY shape, but usually the shape of the plot is either a square or circle for simplicity â€“ why would you sample using a hexagon? Often in forestry, plots are circular, marked with a central post, which foresters attach logging tape and rapidly measure trees that fall within a certain radius from the central post (Fig. 3). Since trees are large, this helps foresters quickly collect data on the species composition and structure of forests. For smaller organisms, like understory species, quadrats (small plots, often square and 1 m2 in size) are often used, since many smaller organisms occur in this area â€“ if plots were too large, then data collection would be too time-consuming. In some cases, researchers are interested in how certain ecological variables differ as a function of distance from a feature. In these cases, researchers will often use a transect â€“ a linear feature â€“ and collect variables of interest along it. Any of these sampling shapes and sizes can be combined or adapted to measure ecological features to answer the question of interest. Figure 3. A) The standard plot configuration for the Forest Inventory and Analysis dataset, which includes data on all of our forested lands in the US. Forestry plots are often circular (A), allowing foresters to attach loggers tape to a central plot marker (B) and quickly measure trees within these fairly large plots (C). Plots must be large in order to include enough trees to describe stand characteristics. 6.10 Distance Sampling and Point Counts Distance sampling is widely used in wildlife ecology, especially for birds, mammals, and sometimes plants or shrubs. The key idea: the probability of detecting an organism decreases with distance from the observer. Two common designs: Line-Transect Distance Sampling Observers walk a transect and record the perpendicular distance to each detected organism. Detection probability is modeled as a function of distance. Point Count Distance Sampling Observers stand at a fixed point and record distances to detected individuals during a timed count. Distance sampling allows estimation of true density without needing to census every individual, making it fundamental for large-area monitoring. 6.11 Reducing sampling error What is sampling error? Sampling error is the difference between the true estimate of a population and the measurements that researchers collect on a sample. Error happens by chance and is unavoidable â€“ it can be thought of as noise within the data. Error is different from bias, because it is non-systematic. For instance, imagine two people are measuring cactus heights for a demographic study. Error in height measurement is introduced by many things - the shakiness of each person’s hands, the amount of degradation and stretch in various measuring tapes. Bias, on the other hand, would be introduced if person 1 only measures the small cacti, or always mis-reading the measuring tape and measuring heights 5 cm less than their actual height. Bias should always be avoided, and error reduced as much as possible. Larger samples are less affected by chance and so will have lower sampling error. In ecology, we refer to the number of independent units being measured as replicates. The more replicates, the less sampling error! Figure 4. As the number of replicate plots increases so does the accuracy at which we can estimate parameters for this forest stand. 6.12 Sample Size Determination in Ecology: Effect Sizes and Precision Ecological studies often face constraints in time, funding, or accessibility. Although there is no universal sample size, several principles guide decisions: Effect Size Matters Small effects (e.g., a 2% change in cover) require more replication than large effects (e.g., a 50% mortality event). Variability Determines Needed Sampling Systems with high natural variability (e.g., deserts, wetlands) require more replicates to estimate population parameters precisely. Plot Size vs. Plot Number Trade-off â€¢ Larger plots reduce variance but are more time-consuming â€¢ More small plots increase representation and reduce sampling error Pilot Studies Often, researchers conduct a small pilot sampling effort to estimate variance and inform final sample size. Although formal power analyses in ecology can be complex, the principles above provide practical guidance for designing effective sampling. 6.13 Variables of interest Finally, depending on the research question, there are a number of different variables that you might want to measure. In ecology, you may want to measure the number of different species in an area to look at diversity patterns, or collect data on size or growth to look at performance, or monitor individuals after a disturbance to look at mortality. We will collect different forms of data throughout the semester, but the following principles will always apply: Samples should be random and representative Sampling methodology â€“ plot shape and size â€“ should reflect the organism or ecological feature that you are measuring More replication is better, since it reduces sampling error In the rest of this course, weâ€™ll use these samples (collected with careful designs like the ones above) to estimate population parameters such as mean height, survival probability, or species richness. Good sampling design is what makes our later statistical inferences valid and trustworthy. 6.14 Test your knowledge Below are several examples of study designs. Select the best sampling method and indicate why you selected it! 6.15 Assignment Write out your sampling design. Be sure to clearly describe your sampling area, sampling unit, number of replicates, and sampling method (e.g., simple random, stratified random, systematic, GRTS, cluster). Specify whether your design includes stratification, spatial balance, or unequal sampling effort, and explain how sample locations will be selected. In addition, justify each component of your design in light of your study objectives, the ecological system, and any practical constraints (e.g., access, time, cost, safety, detectability). Your justification should explain why this design is appropriate for addressing your research question and what tradeoffs you are making (for example, between spatial coverage and replication, or statistical rigor and field feasibility). 6.15.1 Example Methods: Sampling Design Study Area This study was conducted across oak woodland habitat across Arizona and New Mexico, encompassing the current distribution of Quercus emoryi woodlands. The study area defined using oak habitat derived from vegetation classification maps and land cover data. Areas that were inaccessible due to land ownership restrictions, unsafe terrain, or logistical constraints were excluded prior to sample selection to ensure that all selected sites were feasible to sample and that the resulting dataset would be representative of accessible oak habitat. Sampling Design Monitoring locations were selected using a Generalized Random-Tessellation Stratified (GRTS) sampling design. GRTS generates a spatially balanced random sample, ensuring that sites are well distributed across the landscape while retaining the probabilistic properties required for unbiased inference. This approach is particularly appropriate for large, heterogeneous landscapes such as oak woodlands, where environmental conditions vary across elevation, aspect, and disturbance history, and where simple random sampling may result in clustered or uneven spatial coverage. Each sampling unit consisting of a circular, 16 m radius vegetation plot. A total of 100 plots were selected across the study area. To ensure adequate representation of ecologically meaningful gradients, the sampling frame was stratified by elevation zone and management status (e.g., burned vs. unburned areas). Stratification allowed us to explicitly capture variation associated with these factors while maintaining random, spatially balanced site selection within each stratum through the GRTS algorithm. "],["experimental-design-from-question-to-study-structure.html", "Chapter 7 Experimental Design: From Question to Study Structure 7.1 Observational vs. manipulative studies 7.2 The logic of controls and comparison 7.3 Randomization: why and how 7.4 Common experimental designs 7.5 Before-After-Control-Impact (BACI) designs 7.6 Identifying your unit of replication 7.7 Connecting design to analysis 7.8 Summary 7.9 Assignment", " Chapter 7 Experimental Design: From Question to Study Structure In the previous chapter, we focused on where and how to select sampling units—choosing plot locations, balancing spatial coverage, and ensuring that our sample represents the population we want to study. Sampling design answers the question: Where do I collect data? This chapter addresses a different question: How do I structure my study to answer a causal question? Specifically, how do I assign treatments, arrange controls, handle sources of unwanted variation, and ensure that my design supports the statistical analysis I plan to run? The distinction matters. You can have a beautifully balanced GRTS sampling design and still draw incorrect conclusions if your experimental structure is flawed—if treatments are confounded with sites, if you mistake subsamples for true replicates, or if you ignore known sources of variation that could be controlled through blocking. Conversely, a well-designed experiment at poorly selected sites may not generalize beyond the study area. Sampling design and experimental design work together. Sampling tells you where to look; experimental design tells you what to do once you get there. This chapter covers the second half of that partnership. 7.1 Observational vs. manipulative studies Before choosing a specific design, you need to be honest about what kind of study you are running. The answer determines what you can and cannot conclude. 7.1.1 Manipulative experiments In a manipulative experiment, the researcher controls and assigns the treatment. You decide which plots get burned, which seedlings get watered, which enclosures exclude herbivores. Because you assigned the treatment randomly, you can (in principle) attribute differences in the response to the treatment itself rather than to some other factor that happened to differ between groups. Manipulative experiments are the gold standard for causal inference, but they are not always possible in ecology. You cannot randomly assign drought to a watershed or fire to a national forest. You cannot retroactively assign land-use history to a landscape. 7.1.2 Observational studies In an observational study, the researcher does not control the treatment. Instead, you observe variation that already exists—comparing burned and unburned sites after a wildfire, measuring tree growth across a natural elevation gradient, or comparing species composition in grazed and ungrazed pastures where grazing was determined by the rancher, not by you. Observational studies can reveal patterns and associations, but attributing those patterns to a specific cause is harder because confounding variables may differ between groups. A site that burned in a wildfire may also differ from an unburned site in elevation, slope, soil type, or pre-fire vegetation. Without randomization, you cannot be certain which of these factors is responsible for the observed difference. This does not make observational studies useless—far from it. Most landscape-scale ecology is observational. But it does mean that the language you use matters: observational studies support statements like “sites that burned had lower canopy cover” rather than “fire reduced canopy cover.” The difference is subtle but important, and reviewers will notice. 7.1.3 Natural experiments and quasi-experiments Sometimes nature provides something close to a manipulative experiment. A wildfire burns half of a watershed but not the other. A policy change protects one river but not an adjacent one. A beaver colonizes one stream reach but not the next. These are natural experiments: the “treatment” was not assigned by the researcher, but it was applied in a way that approximates random assignment. Quasi-experiments are similar but involve deliberate human actions without researcher control—a restoration project implemented by a land management agency, a logging operation that creates treated and untreated stands, or a grazing exclosure built by a rancher. The researcher takes advantage of an existing intervention rather than creating one. Natural and quasi-experiments are powerful because they operate at realistic scales and involve real ecological processes. Their weakness is the same as any observational study: without randomization, confounding factors may explain the results. 7.1.4 Space-for-time substitution One of the most common approaches in ecology—and one of the most commonly misunderstood—is space-for-time substitution. Instead of waiting decades to observe succession after disturbance, you sample sites of different ages right now and treat the spatial gradient as a proxy for temporal change. Instead of experimentally manipulating climate, you compare populations across a temperature gradient. This approach assumes that the sites differ only in the variable of interest (time since disturbance, temperature, elevation) and are otherwise comparable. That assumption is often violated: a site that burned 5 years ago and a site that burned 50 years ago may also differ in soil type, aspect, land-use history, and the species pool available for recolonization. These differences are confounded with time. Space-for-time substitution is not inherently wrong—it is often the only practical option. But it requires careful thought about what might be confounded with the gradient, and the conclusions should acknowledge this limitation. Table 7.1: Study types differ in who controls the treatment and how strongly you can infer causation. Study Type Who assigns treatment? Causal inference? Ecological example Manipulative experiment Researcher (randomly) Strong Randomly assign fire treatments to plots Natural experiment Nature (approximately random) Moderate (depends on context) Wildfire burns half a watershed Quasi-experiment Manager/agency (not random) Moderate (check for confounds) Agency thins some stands but not others Observational (gradient) No one (pre-existing variation) Weak (association only) Measure species along a natural elevation gradient Space-for-time substitution No one (spatial variation as proxy) Weak (confounds likely) Sample sites burned 5, 20, 50 years ago Why this matters for your statistics: The type of study you are running should influence both the language of your results and the statistical model you choose. Manipulative experiments support strong causal language; observational studies call for more cautious interpretation. Many of the design principles in the rest of this chapter—randomization, blocking, controls—are strategies for strengthening causal inference, whether your study is manipulative or observational. 7.2 The logic of controls and comparison Every study involves comparison. You compare treated plots to untreated plots, burned sites to unburned sites, or populations across an environmental gradient. The purpose of a control is to provide a baseline: what would have happened in the absence of the treatment or the factor of interest? 7.2.1 What makes a good control? A good control differs from the treatment group in one thing only: the treatment. Everything else—soil type, elevation, canopy cover, sampling effort, timing of measurement—should be as similar as possible. When this condition is met, any difference in the response can be attributed to the treatment rather than to some other factor. In practice, perfect controls are rare. But the closer you get, the stronger your inference. Common control failures in ecology: Spatial confounding: All treatment plots are on one slope and all controls are on another. Differences might reflect aspect, not treatment. Temporal confounding: Treatment plots are measured in June and controls in August. Differences might reflect phenology, not treatment. Effort confounding: More time is spent sampling treatment plots because they are “more interesting.” Detection probability differs between groups. No control at all: Measuring a site before and after treatment without a reference site. Any change might reflect weather, succession, or other factors unrelated to treatment. 7.2.2 Procedural controls In some experiments, the act of applying a treatment introduces effects unrelated to the treatment itself. Walking to a plot and setting up equipment creates disturbance. Clipping vegetation to simulate herbivory involves cutting. In these cases, a procedural control mimics the disturbance of treatment application without applying the treatment itself. For example, if your treatment involves spraying herbicide, a procedural control might involve spraying water. 7.3 Randomization: why and how Randomization is the single most powerful tool for causal inference. When you randomly assign treatments to experimental units, you eliminate systematic bias—any factor that might confound the treatment effect is equally likely to occur in both groups. Note the difference from the previous chapter: in sampling design, randomization ensures that your sample is representative of the population. In experimental design, randomization ensures that your treatment groups are comparable to each other. Same tool, different purpose. 7.3.1 What randomization does Imagine you have 20 plots and want to assign 10 to a burning treatment and 10 to a control. If you let the land manager choose which plots to burn, they might avoid steep slopes, rocky areas, or plots near roads. The burned plots would then differ from unburned plots in ways that have nothing to do with fire. Random assignment eliminates this problem. With randomization, steep slopes and gentle slopes, rocky and sandy soils, near-road and remote plots are all equally likely to end up in either group. On average, the two groups will be balanced on every variable—including variables you did not measure or did not think to control. set.seed(42) # Imagine 20 plots with varying elevation (a potential confound) n_plots &lt;- 20 elevations &lt;- round(runif(n_plots, min = 1500, max = 2500)) # Randomly assign treatments treatment &lt;- sample(rep(c(&quot;Burn&quot;, &quot;Control&quot;), each = n_plots / 2)) plot_data &lt;- data.frame( plot = 1:n_plots, elevation = elevations, treatment = treatment ) # Compare group means --- randomization approximately balances elevation tapply(plot_data$elevation, plot_data$treatment, mean) ## Burn Control ## 2025.2 2201.0 tapply(plot_data$elevation, plot_data$treatment, sd) ## Burn Control ## 261.4119 267.1899 The group means for elevation will not be exactly equal, but they will be close. With enough replicates, randomization balances all potential confounds—even ones you did not measure. 7.3.2 How to randomize In R, randomization is straightforward: # Completely randomized assignment of 3 treatments to 30 plots set.seed(123) n &lt;- 30 treatments &lt;- rep(c(&quot;Control&quot;, &quot;Low fertilizer&quot;, &quot;High fertilizer&quot;), each = n / 3) assignment &lt;- sample(treatments) # shuffle randomly table(assignment) ## assignment ## Control High fertilizer Low fertilizer ## 10 10 10 In the field, randomization should happen before you visit the sites. Generate your random assignments in R, print a field sheet with plot-treatment pairings, and follow the sheet regardless of what the plots look like when you arrive. Changing assignments in the field because a plot “doesn’t look right” defeats the purpose of randomization. 7.4 Common experimental designs The following designs represent the most common ways ecologists structure manipulative experiments and observational studies. Each design addresses a specific problem—controlling for known variation, accommodating logistical constraints, or isolating treatment effects in complex systems. Understanding these designs matters because your design determines your statistical model. A completely randomized design leads to a simple ANOVA or regression. A blocked design requires a term for blocks. A split-plot design requires a mixed model with nested error terms. If you do not understand your design, you cannot write the correct model—and the wrong model gives wrong answers. 7.4.1 Completely Randomized Design (CRD) The simplest experimental design: treatments are assigned entirely at random to experimental units with no additional structure. When it works: Experimental units are reasonably homogeneous. There are no strong spatial, temporal, or other gradients that might confound treatment effects. When it fails: If there is a major source of variation across experimental units (such as a moisture gradient across a greenhouse bench, or elevation differences among field plots), a CRD wastes statistical power by treating that variation as unexplained noise. set.seed(226) # 4 treatments, 5 replicates each = 20 plots treatments &lt;- rep(c(&quot;Control&quot;, &quot;Low N&quot;, &quot;High N&quot;, &quot;N + P&quot;), each = 5) plots &lt;- data.frame( plot_id = 1:20, treatment = sample(treatments), # randomize row = rep(1:4, each = 5), col = rep(1:5, times = 4) ) # Visualize the layout plot(plots$col, plots$row, pch = 19, cex = 3, col = as.numeric(as.factor(plots$treatment)), xlab = &quot;Column&quot;, ylab = &quot;Row&quot;, main = &quot;Completely Randomized Design&quot;, xlim = c(0.5, 5.5), ylim = c(0.5, 4.5)) legend(&quot;topright&quot;, legend = levels(as.factor(plots$treatment)), col = 1:4, pch = 19, cex = 0.8) Figure 7.1: A completely randomized design assigns treatments without regard to spatial or environmental structure. This works well when experimental units are homogeneous. Statistical model: One-way ANOVA or linear model with treatment as the sole explanatory variable. # Analysis for a CRD model &lt;- lm(response ~ treatment, data = my_data) anova(model) 7.4.2 Randomized Complete Block Design (RCBD) Blocking is one of the most important concepts in experimental design, and one of the most underused by beginning researchers. A block is a group of experimental units that are similar to each other in some important way. Within each block, every treatment appears exactly once. This ensures that treatment comparisons are made within relatively homogeneous groups, removing the block-to-block variation from the comparison. The key insight: Blocking controls for a known source of variation by removing it from the error term. This increases statistical power—the ability to detect a real treatment effect—without requiring more replicates. When to block: Greenhouse benches differ in light or temperature → block by bench Field plots span an elevation gradient → block by elevation zone Experimental runs happen on different days → block by day Sites have different soil types → block by soil type Individual animals or plants vary in size → block by initial size class The rule of thumb: If you can identify a source of variation that is not your treatment but might affect the response, block on it. set.seed(42) # 3 treatments, 4 blocks n_blocks &lt;- 4 treatments &lt;- c(&quot;Control&quot;, &quot;Thinned&quot;, &quot;Burned&quot;) n_treats &lt;- length(treatments) # Within each block, randomize treatment order rcbd &lt;- data.frame( block = rep(paste(&quot;Block&quot;, 1:n_blocks), each = n_treats), treatment = unlist(lapply(1:n_blocks, function(b) sample(treatments))) ) rcbd$plot_num &lt;- 1:nrow(rcbd) rcbd$x &lt;- rep(1:n_treats, times = n_blocks) rcbd$y &lt;- rep(n_blocks:1, each = n_treats) # Visualize cols &lt;- c(&quot;Control&quot; = &quot;gray70&quot;, &quot;Thinned&quot; = &quot;goldenrod&quot;, &quot;Burned&quot; = &quot;firebrick&quot;) plot(rcbd$x, rcbd$y, pch = 22, cex = 5, bg = cols[rcbd$treatment], xlab = &quot;&quot;, ylab = &quot;&quot;, axes = FALSE, main = &quot;Randomized Complete Block Design&quot;, xlim = c(0.5, n_treats + 0.5), ylim = c(0.3, n_blocks + 0.7)) text(rcbd$x, rcbd$y, rcbd$treatment, cex = 0.6) axis(2, at = n_blocks:1, labels = paste(&quot;Block&quot;, 1:n_blocks), las = 1, tick = FALSE) Figure 7.2: In a Randomized Complete Block Design, each block contains all treatments. Treatments are randomized within each block. This removes block-to-block variation from the treatment comparison. Statistical model: The block is included as an additive term but is not the focus of inference. We are not interested in whether blocks differ; we know they do. We include blocks to remove that variation from the error term. # RCBD analysis: treatment is the focus, block removes known variation model &lt;- lm(response ~ treatment + block, data = my_data) anova(model) Ecological example: You want to test whether prescribed fire increases native grass cover. Your study area spans a 500 m elevation gradient. Without blocking, elevation differences add noise to the treatment comparison. With blocking by elevation zone, each treatment is compared to its control at the same elevation, and the analysis is more powerful. A common mistake: Some researchers put “block” as a random effect in a mixed model. This is appropriate when you have many blocks sampled from a larger population of possible blocks (e.g., sites randomly selected from a region). When blocks are few and fixed (e.g., 3 greenhouse benches), treating block as a fixed additive term is simpler and often more appropriate. We will revisit this distinction in the Mixed Effects Models chapter. 7.4.3 Factorial designs A factorial design includes two or more treatment factors, with every combination of factor levels represented. This is extremely common in ecology, where organisms respond to multiple interacting environmental drivers simultaneously. Example: You want to test the effects of fire and grazing on plant community composition. You have two factors: Fire: burned vs. unburned (2 levels) Grazing: grazed vs. ungrazed (2 levels) A full factorial design includes all 4 combinations: burned + grazed, burned + ungrazed, unburned + grazed, unburned + ungrazed. Why factorial designs are powerful: They allow you to test for interactions—situations where the effect of one factor depends on the level of another. Fire might reduce shrub cover in ungrazed areas but have no effect in grazed areas (because grazing already reduced shrubs). Without the factorial design, you would miss this interaction entirely. # 2 x 2 factorial: fire and grazing fire &lt;- rep(c(&quot;Burned&quot;, &quot;Unburned&quot;), each = 2) grazing &lt;- rep(c(&quot;Grazed&quot;, &quot;Ungrazed&quot;), times = 2) combinations &lt;- data.frame(fire, grazing) combinations$treatment &lt;- paste(fire, grazing, sep = &quot; + &quot;) knitr::kable(combinations, caption = &quot;All treatment combinations in a 2 x 2 factorial design&quot;) Table 7.2: All treatment combinations in a 2 x 2 factorial design fire grazing treatment Burned Grazed Burned + Grazed Burned Ungrazed Burned + Ungrazed Unburned Grazed Unburned + Grazed Unburned Ungrazed Unburned + Ungrazed Statistical model: A factorial design is analyzed with main effects and their interaction. # Factorial ANOVA model &lt;- lm(response ~ fire * grazing, data = my_data) # Equivalent to: response ~ fire + grazing + fire:grazing anova(model) The interaction term (fire:grazing) tests whether the effect of fire depends on grazing status. If the interaction is significant, interpret the interaction rather than the main effects alone—because the main effects are misleading when the factors interact. Design consideration: Factorial designs grow quickly. A 2 × 2 design has 4 combinations; a 3 × 3 has 9; a 2 × 3 × 4 has 24. Each combination needs replication, so the total number of experimental units can become large. If resources are limited, consider dropping factor levels or using a fractional factorial design. 7.4.4 Nested designs In a nested design, the levels of one factor are unique to each level of another factor. This is different from a factorial design, where every level of each factor appears with every level of every other factor. The classic ecological example: You study plant growth across 3 sites. Within each site, you establish 4 plots. Within each plot, you measure 5 individual plants. The structure is: Plants are nested within plots Plots are nested within sites The 4 plots at Site A are different physical locations from the 4 plots at Site B. Plot 1 at Site A is not the same as Plot 1 at Site B—they just share a label. This is nesting, not crossing. ## Nested structure: ## 3 Sites ## └── 4 Plots per site (12 plots total) ## └── 5 Plants per plot (60 plants total) ## ## True replicates for site-level effects: 3 sites ## NOT 60 plants. Why nesting matters: The 60 plants are not independent observations for testing site effects. Plants within the same plot share microsite conditions; plots within the same site share climate and soils. If you analyze this as lm(growth ~ site) with 60 observations, you are pretending that you have 60 independent replicates when you actually have 3 (the sites). This is pseudoreplication (see Chapter 6), and it dramatically inflates your Type I error rate. Statistical model: Nested designs are analyzed with mixed effects models, which we will cover in detail later. The key is recognizing the nesting in your design before you analyze the data. # Nested design analyzed with mixed model library(lme4) model &lt;- lmer(growth ~ site + (1 | site:plot), data = my_data) 7.4.5 Split-plot designs A split-plot design arises when one treatment factor is applied to large experimental units (whole plots) and a second treatment factor is applied to smaller units within them (subplots). This often occurs when one treatment is logistically difficult to apply at a small scale. Ecological example: You are testing the effects of prescribed fire (hard to apply to small areas) and nitrogen addition (easy to apply to small areas). Each large plot (1 hectare) is randomly assigned to either burned or unburned. Within each large plot, small subplots (5 × 5 m) are randomly assigned to nitrogen addition or control. ## Split-plot structure: ## Whole plot factor: Fire (burned vs. unburned) ## Applied to: 1-hectare plots ## Subplot factor: Nitrogen (added vs. control) ## Applied to: 5 x 5 m subplots within each whole plot ## Key consequence: the error term for testing the whole-plot factor (fire) ## is different from the error term for testing the subplot factor (nitrogen). ## This requires a mixed model or split-plot ANOVA. Why it matters: In a split-plot design, the whole-plot treatment (fire) has fewer true replicates than the subplot treatment (nitrogen), because fire was only applied to whole plots. A standard factorial ANOVA would incorrectly pool the error terms, leading to inflated significance for the whole-plot factor. A mixed model with whole-plot as a random effect handles this correctly. # Split-plot analysis with mixed model library(lme4) model &lt;- lmer(response ~ fire * nitrogen + (1 | whole_plot), data = my_data) How to recognize a split-plot: Ask yourself: “Is one treatment applied at a larger scale than the other?” If yes, you likely have a split-plot design, even if you did not plan it that way. 7.4.6 Repeated measures and longitudinal designs When you measure the same experimental units over time, observations within each unit are not independent. A plant measured in June and again in August is likely to have correlated growth measurements—a large plant in June is probably still relatively large in August. Repeated measures designs are the temporal equivalent of nesting: observations are nested within time points within subjects. Ignoring this non-independence (analyzing each time point as an independent observation) is a form of pseudoreplication. Common ecological examples: Measuring tree diameter annually for 10 years Sampling species composition at permanent plots across seasons Tracking individual survival through monthly surveys Monitoring water quality at fixed stations over time Statistical approaches: # Option 1: Mixed model with random intercept for subject library(lme4) model &lt;- lmer(response ~ treatment * time + (1 | subject), data = my_data) # Option 2: If trajectories differ, allow random slopes model &lt;- lmer(response ~ treatment * time + (1 + time | subject), data = my_data) We will cover these models in detail in the Mixed Effects Models chapter. For now, the design principle is: if you measure the same unit more than once, you need a model that accounts for that. 7.5 Before-After-Control-Impact (BACI) designs BACI designs deserve special attention because they are among the most common designs in applied ecology—restoration monitoring, impact assessment, and adaptive management all rely on some form of BACI logic. 7.5.1 The problem BACI solves Suppose a mining company plans to discharge treated wastewater into a stream, and you are asked to assess the impact on aquatic invertebrate communities. You have two options: Before-After only: Sample the stream before and after the discharge begins. Problem: any change you observe might be caused by the discharge, or by a drought, a flood, natural seasonal variation, or anything else that changed between your two sampling periods. Control-Impact only: Sample the affected stream and an unaffected reference stream at the same time, after the discharge begins. Problem: any difference between streams might be caused by the discharge, or by pre-existing differences between the two streams. BACI combines both comparisons. By measuring both sites at both times, you can test whether the change over time differs between sites. This is the interaction term in your statistical model, and it is the key test in a BACI design. 7.5.2 The four standard BACI designs BACI designs vary in complexity depending on replication in space and time: Table 7.3: BACI designs vary in replication. The full ‘Beyond BACI’ design with multiple control sites and multiple time periods before and after provides the strongest inference. Design Impact sites Control sites Before periods After periods Strength Basic BACI 1 1 1 1 Weak: no replication in space or time BACI with multiple controls 1+ Multiple 1 1 Moderate: spatial replication of controls BACI with multiple time periods 1 1 Multiple Multiple Moderate: temporal replication Full BACI (Beyond BACI) 1+ Multiple Multiple Multiple Strong: replication in both space and time 7.5.3 The BACI interaction The core of a BACI analysis is a two-way interaction between period (before vs. after) and site type (impact vs. control). If the discharge has no effect, both sites should change by roughly the same amount over time. If the discharge has an effect, the change at the impact site will differ from the change at the control site. par(mfrow = c(1, 2), mar = c(4, 4, 3, 1)) # No impact scenario plot(c(1, 2), c(50, 45), type = &quot;b&quot;, pch = 19, col = &quot;steelblue&quot;, xlim = c(0.5, 2.5), ylim = c(30, 60), xlab = &quot;&quot;, ylab = &quot;Invertebrate abundance&quot;, main = &quot;No impact (parallel change)&quot;, xaxt = &quot;n&quot;) lines(c(1, 2), c(40, 35), type = &quot;b&quot;, pch = 17, col = &quot;firebrick&quot;) axis(1, at = 1:2, labels = c(&quot;Before&quot;, &quot;After&quot;)) legend(&quot;topright&quot;, legend = c(&quot;Control&quot;, &quot;Impact&quot;), col = c(&quot;steelblue&quot;, &quot;firebrick&quot;), pch = c(19, 17), cex = 0.8) # Impact scenario plot(c(1, 2), c(50, 45), type = &quot;b&quot;, pch = 19, col = &quot;steelblue&quot;, xlim = c(0.5, 2.5), ylim = c(30, 60), xlab = &quot;&quot;, ylab = &quot;Invertebrate abundance&quot;, main = &quot;Impact detected (divergence)&quot;, xaxt = &quot;n&quot;) lines(c(1, 2), c(40, 25), type = &quot;b&quot;, pch = 17, col = &quot;firebrick&quot;) axis(1, at = 1:2, labels = c(&quot;Before&quot;, &quot;After&quot;)) legend(&quot;topright&quot;, legend = c(&quot;Control&quot;, &quot;Impact&quot;), col = c(&quot;steelblue&quot;, &quot;firebrick&quot;), pch = c(19, 17), cex = 0.8) Figure 7.3: The BACI design tests whether the change from before to after differs between impact and control sites. If both sites change in parallel (left), there is no impact. If the impact site diverges (right), the discharge likely had an effect. 7.5.4 Statistical model for BACI # Basic BACI: the interaction is the test of impact model &lt;- lm(response ~ period * site_type, data = my_data) # With multiple time periods and sites: use mixed model library(lme4) model &lt;- lmer(response ~ period * site_type + (1 | site) + (1 | year), data = my_data) The coefficient for period:site_type is the BACI interaction—it estimates the difference in the before-to-after change between impact and control sites. This is the quantity of interest. 7.5.5 BACI pitfalls Too few control sites: A single control site might be unusual for reasons unrelated to the impact. Multiple control sites strengthen inference. Too few time periods: A single before and single after measurement cannot distinguish an impact from natural year-to-year variation. Multiple before and after periods are strongly preferred. Spatial confounding: If the impact and control sites were already different before the impact, the BACI interaction might reflect pre-existing divergence. Delayed or gradual effects: If the impact takes years to manifest, a simple before/after comparison might miss it. Consider staggered after-periods. We will work through a complete BACI analysis with real data in a later chapter when we cover mixed effects models and time series approaches. 7.6 Identifying your unit of replication This is arguably the most important practical skill in experimental design. Getting it wrong—treating subsamples as independent replicates—is pseudoreplication, which was introduced in Chapter 6 but deserves deeper treatment here because it is the single most common statistical error in ecology (Hurlbert, 1984). 7.6.1 The rule The unit of replication is the smallest unit to which a treatment is independently applied. Everything measured within that unit is a subsample, not a replicate. Table 7.4: Identifying the unit of replication. The treatment is applied at the level of the replicate, not the subsample. Scenario Unit of replication Subsamples Problem? 3 fire treatments applied to 3 watersheds; 10 plots per watershed Watershed (n = 1 per treatment!) Plots within watersheds Yes: n = 1 per treatment, no replication Herbicide sprayed on 6 garden beds (3 treated, 3 control); 20 plants per bed Garden bed (n = 3 per treatment) Plants within beds No: adequate replication 4 grazing exclosures and 4 grazed areas; species counted in 5 quadrats per area Exclosure/area (n = 4 per treatment) Quadrats within areas No: adequate replication Fertilizer applied to individual pots; 1 plant per pot; 15 pots per treatment Pot (n = 15 per treatment) None (1 plant per pot) No: adequate replication 2 greenhouses set to different temperatures; 50 plants per greenhouse Greenhouse (n = 1 per treatment!) Plants within greenhouses Yes: n = 1 per treatment, no replication Notice the first and last examples: even with many individual measurements (10 plots, 50 plants), you have no replication of the treatment if the treatment was applied to only one unit per level. Two greenhouses set to different temperatures gives you n = 1 for each temperature, regardless of how many plants are inside. This is a design problem that no statistical model can fix. 7.6.2 What to do with subsamples Subsamples are not useless—they help you better estimate the condition at each replicate. But they must be handled correctly in analysis: # Option 1: Average subsamples to the replicate level first plot_means &lt;- my_data %&gt;% group_by(plot, treatment) %&gt;% summarize(mean_response = mean(response), .groups = &quot;drop&quot;) model &lt;- lm(mean_response ~ treatment, data = plot_means) # Option 2: Use a mixed model that accounts for nesting library(lme4) model &lt;- lmer(response ~ treatment + (1 | plot), data = my_data) Both approaches are valid. Option 1 (averaging) is simpler and makes the sample size transparent. Option 2 (mixed model) preserves all the data and can estimate within-plot variation, but requires correctly specifying the random effects. 7.7 Connecting design to analysis Every design decision you make has a direct consequence for your statistical model. The table below summarizes the connections we have built in this chapter: Table 7.5: Each experimental design maps to a specific statistical model. Understanding your design is a prerequisite for writing the correct model. Design Statistical model Key feature Completely Randomized (CRD) One-way ANOVA / lm(y ~ treatment) Treatment as only predictor Randomized Complete Block (RCBD) lm(y ~ treatment + block) Block removes known variation (not tested) Factorial lm(y ~ A * B) [two-way ANOVA] Interaction tests whether effects depend on each other Nested lmer(y ~ treatment + (1 | group)) Random effect accounts for non-independence Split-plot lmer(y ~ whole_plot_trt * subplot_trt + (1 | whole_plot)) Different error terms for whole-plot and subplot Repeated measures lmer(y ~ treatment * time + (1 | subject)) Random effect for repeated observations on same unit BACI lmer(y ~ period * site_type + (1 | site)) Interaction is the test of impact If you cannot write down the correct statistical model for your design before you collect data, that is a signal that the design needs more thought. 7.8 Summary Experimental design is about structuring your study to support the conclusions you want to draw. The core principles are: Identify your study type. Are you running a manipulative experiment, observing natural variation, or exploiting a natural experiment? This determines how strongly you can infer causation. Use controls. Every comparison needs a baseline. Good controls differ from the treatment group in one thing only: the treatment. Randomize. Random assignment of treatments eliminates systematic bias and balances confounding variables across groups. Block when you can. If you know of a source of variation (elevation, bench, day, site), block on it. Blocking removes that variation from your error term and increases power. Identify your unit of replication. The treatment is applied at the replicate level. Everything measured within a replicate is a subsample. Getting this wrong is pseudoreplication. Know your design before you analyze. Your design dictates your statistical model. A blocked design needs a block term. A nested design needs a random effect. A factorial design needs an interaction term. Plan the analysis at the design stage, not after data collection. 7.9 Assignment Goal: Develop and justify the experimental or observational design for your research project. 7.9.1 Part 1: Study type Is your study manipulative, observational, a natural experiment, or a quasi-experiment? Explain why. What are the implications for causal inference? What can and cannot you conclude from your design? 7.9.2 Part 2: Design structure Draw or describe your design structure. Include: Treatment factors and their levels (if applicable) How treatments are assigned (randomly? by nature? by a manager?) Whether you are using blocking, and if so, what the blocks are Whether your design has nesting, and if so, what is nested within what Identify your unit of replication and your subsamples (if any). How many true replicates do you have per treatment level? 7.9.3 Part 3: Controls and confounds What serves as your control or baseline for comparison? Identify at least two potential confounding variables in your study. For each, explain whether your design controls for it (and how) or whether it remains a limitation. 7.9.4 Part 4: Design-to-model connection Based on your design, write the R formula for the statistical model you expect to use. If you have a blocked design, include the block term. If you have nesting, indicate which effects are random. Example: If your design is a randomized complete block with 2 treatments and 4 blocks, your model might be: lm(biomass ~ treatment + block, data = my_data) "],["power-analysis.html", "Chapter 8 Power analysis 8.1 Prework 8.2 Statistical power", " Chapter 8 Power analysis 8.1 Prework Install packages ‘pwr’, ‘faraway’, ‘simr’, ‘simglm’, and ‘Superpower’. 8.2 Statistical power As we learned in lesson 3, Basic Statistical Test, statistical power is a measure of making a Type II error - saying that there is no treatment effect when, in fact, there is one. A power analysis is a way of estimating statistical power to either speak to the ability of your experiment to detect treatment effects or estimate sample size needed to answer the question that you are interested in with your experimental design. library(pwr) library(tidyverse) library(simr) library(simglm) library(Superpower) #load data data(&#39;oatvar&#39;, package=&#39;faraway&#39;) #Using power analysis to estimate needed sample size. To conduct a power analysis, you will need to know: The number of groups in your study Significance level. It is standard to use a significance level of 0.05. The power required for your experiment, which is typically set at 0.8. Effect size, which can be calculated from data from a pilot study or estimated. Effect size is a relativized estimate of difference between groups being compared. Generally, effect size is calculated by taking the difference between the two groups (e.g., the mean of treatment group minus the mean of the control group) and dividing it by the standard deviation of one of the groups. Because effect size is converted to standard deviations units, it tells you how many standard deviations lie between the two means, and can be compared across datasets regardless of the original units of the study (which is why effect sizes are calculated for meta-analyses). A classic effect size calculation is Cohen’s D calculated as \\(\\frac{\\overline{x}_1 - \\overline{x}_2}{s_{pooled}}\\), where \\({\\overline{x}_1}\\) is the mean of one group, \\({\\overline{x}_2}\\) is the mean of the second group, and \\(s_{pooled}\\) is standard deviation (typically pooled; sometimes of the control or pretest data) calculated as \\(s_{pooled} = \\sqrt{\\frac{sd_{a}^{2}+ sd_{b}^{2}}{2}}\\). Note that Cohen’s D is one of many ways of calculating effect size. Two other metrics are used by the ‘pwr package’: \\(f\\), calculated as expected standard deviation of the group means divided by the pooled within-group standard deviation, is used in our example below. Another option is eta-squared (η2). The eta-squared is the proportion of the total variance explained by the means variance. It is harder to detect a smaller effect of the treatment, and easier to detect larger effects. Cohen in his 1988 book (citation below) classified effect sizes into 3 general categories for Cohen’s D (CONFIRM): a small effect is typically set at 0.1 - 0.3, a medium effect at 0.3 - 0.5, and a large effect at &gt; 0.5. Note that the range for small, medium, and large effects differ by effect size calculation Using these classifications, you can estimate the sample size for a proposed study even if you have no data. Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum. Below, we will run a power analysis with actual data, but let’s start by running a power analysis to guide experimental planning for a study when no opportunity to conduct a pilot. Imagine you are planning an experiment in which you are trialing the effect of a new fertilizer on oat growth. You plan to include three levels, a control (no fertilizer added), a moderate fertilization treatment, and a high fertilization treatment and measure height as a dependent variable. In the code below, k indicates the number of groups (here: control, moderate, high), f indicates an effect size (we selected a medium effect size), sig.level indicates the significance level (0.05), and power (standard to use 0.8). To calculate the number of groups, if you have two factors, simply multiply the number of groups in each factor to get the value k. For instance, say you are looking at the effect of 2 levels of pesticide and 3 temperature levels on bee longevity, you would multiply 2 * 3, yielding 6 groups. Why do we use 0.8? It is by convention, much like we set a significance level (\\(\\alpha\\)) of 0.05. At some point scientists agreed that a power level of 0.8, which means that the probability of rejecting a false null hypothesis is 0.8 (or 80%), is an acceptable risk of committing a Type II error. pwr.anova.test(k=3, f=0.3, sig.level=0.05, power=0.8) ## ## Balanced one-way analysis of variance power calculation ## ## k = 3 ## n = 36.70126 ## f = 0.3 ## sig.level = 0.05 ## power = 0.8 ## ## NOTE: n is number in each group In this case, we’d should include at least 37 individuals (plus a few extra) to accommodate loss of individuals during the experiment. When possible, it is preferable to run a pilot experiment in order to improve experimental design. The ‘pwr’ package in R allows you to run a power analysis on various forms of data. Let’s run through several quick analyses using the ‘pwr’ package. The effect size calculations will depend on your statistical test (for a full description of tests, go to the package). Since Cohen’s description of effect sizes as small, medium and large depend on each statistical test, there is an easy way to generate this information in the ‘pwr’ dataset. For example, if you are interested in determining the value associated with a small effect size for a regression, you would run the following code: cohen.ES(test = &#39;r&#39;, size = &#39;small&#39;) ## ## Conventional effect size from Cohen (1982) ## ## test = r ## size = small ## effect.size = 0.1 Note that you have several test options here: r = regression r; alternative = ‘two.sided’ = correlation (can specify direction ‘greater’) - not 100 percent sure I’m right here… p = t = for t-test (type = ‘paired’; you can select between two population to a repeated measure test) anov = anova chisq = chi sq tests *f2 = glms The ‘pwr’ package is nice for quick looks at power for simple analyses with no previous data. Note: that you can calculate effect sizes from data by hand and plug them into ‘pwr’ to generate sample sizes or power assessments. Let’s check this out with the ‘oatvar dataset’. ggplot(oatvar, aes(y=yield, x=block, color=variety)) + geom_point() + geom_line(aes(x=as.integer(block))) The cbpp is a dataset on contagious bovine pleuropneumonia. Data description is here: https://rdrr.io/cran/lme4/man/cbpp.html library(simr) head(cbpp) ## herd incidence size period ## 1 1 2 14 1 ## 2 1 3 12 2 ## 3 1 4 9 3 ## 4 1 0 5 4 ## 5 2 3 22 1 ## 6 2 1 18 2 cbpp$obs &lt;- 1:nrow(cbpp) "],["selecting-statistical-tests.html", "Chapter 9 Selecting statistical tests 9.1 A foray into statistics 9.2 Pick the explanatory and response variable 9.3 Variable types refresher 9.4 More examples 9.5 The decision matrix 9.6 A note on assumptions 9.7 Learning goals 9.8 Downloads for this class 9.9 In-class practice 9.10 Assignment: Choosing and Running the Right Test 9.11 Statistical analyses for your species interaction lab", " Chapter 9 Selecting statistical tests 9.1 A foray into statistics We’ve talked about data types, describing data, and basic hypothesis testing. This week we are applying these concepts to run a statistical analysis. When conducting an analysis, a dataset will contain one or more response variables (aka y-variables, dependent variables) and one or more explanatory variables (aka x-variables, independent variables). Explanatory variables are used to explain variation in response variables. The data type of both the explanatory and response variables determines which statistical test we use. Selecting the right test is important because it ensures that we’re asking a question our data can actually answer. 9.2 Pick the explanatory and response variable Imagine that we want to identify areas that support high numbers of plants from the genus Mitella. We hypothesize that Mitella occurrence is positively related to water supply (i.e., the number of Mitella plants goes up as water availability increases). In this example the: Response Variable (Y) is the number of Mitella plants in a specific area (continuous count data). Explanatory Variable (X) is the Water availability (continuous). In this case, both the explanatory and response variables are continuous, so we might test their relationship using regression. 9.3 Variable types refresher Variable Type Examples Notes Categorical (nominal) Species identity, treatment group (control vs. watered) Categories with no natural order Categorical (ordinal) Low/medium/high shade Ordered categories Continuous Height, biomass, rainfall (measured on a scale) Quantitative, can take on many values Count Number of seedlings, number of visits by a pollinator Discrete values (0, 1, 2, …), often treated separately in statistics 9.4 More examples Example 1: Categorical explanatory → continuous response - Question: Do soil nitrogen levels differ between burned vs. unburned plots? - Test: ANOVA (a one way ANOVA is basically equivalent to a two-sample t-test, which we discussed in the chapter on basic statistical testing) Example 2: Categorical explanatory → categorical response - Question: Is survival (alive vs. dead) related to treatment (control vs. watered)? - Test: G-test (a type of Chi-square test) Example 3: Continuous explanatory → continuous response - Question: Does plant biomass increase with light availability? - Test: Regression. Example 4: Continuous explanatory → categorical response - Question: Does plant biomass increase survivorship of duckweed? - Test: Logistic regression. 9.5 The decision matrix Below is a simple decision matrix for selecting statistical analyses. How to use it: Identify your explanatory and response variables. Decide whether each is categorical, continuous, or count. Follow the matrix to the test. Example: Students conducted an experiment by manipulating three levels of competition: low, medium, and high, and evaluated the growth of a species of native pea. Since the explanatory variable is categorical and the response variable is continuous, you would perform an ANOVA. 9.6 A note on assumptions Choosing a test is only step one. Most tests also have assumptions (e.g., data are normally distributed, groups have equal variance, observations are independent). If assumptions are not met, we either transform the data or use a non-parametric alternative. We won’t perform transformations here, but it is important to understand that this is important when conducting statistics for peer-reviewed research. 9.7 Learning goals By the end of this module, you should be able to: Correctly identify explanatory and response variables. Match data types to the appropriate statistical test. Run a statistical test 9.8 Downloads for this class Download the R file Completing your species interactions final project and need more help? Watch the YouTube tutorial here 9.9 In-class practice Let’s practice these statistical tests in R (these examples are preloaded in your R file)! G-test (Categorical Response and Categorical Explanatory Variable) Scenario: You are studying bird nest preferences in a forest. You want to know if birds prefer nesting in different tree species (oak, pine, or maple). Response variable: Nest presence (Yes/No) Explanatory variable: Tree species (oak, pine, maple) Run the code in R. t-test and ANOVA (Continuous Response and Categorical Explanatory Variable) t-test Scenario: You want to compare the weight of two species of frogs (Species A and Species B) to see if there’s a significant difference in weight between them. Response variable: Frog weight (grams) Explanatory variable: Species (A or B) ANOVA (Continuous Response and Categorical Explanatory Variable with More Than Two Categories) Scenario: You are studying the growth of plants in three different habitats: Desert, Forest, and Wetland. You want to compare plant height across these habitats. Response variable: Plant height (cm) Explanatory variable: Habitat (Desert, Forest, Wetland) Linear Regression (Continuous Response and Continuous Explanatory Variable) Scenario: You are studying how the number of fish in a river changes with water temperature. You want to model the relationship between water temperature (°C) and fish count. Response variable: Fish count Explanatory variable: Water temperature (°C) Logistic Regression (Categorical Response and Continuous Explanatory Variable) Scenario: You want to study the probability of a specific bird species’ presence in different areas based on elevation. The response is whether the bird is present or absent. Response variable: Bird presence (Yes/No) Explanatory variable: Elevation (meters) Skip this section if you are using this chapter to run your analyses for your species interaction project. 9.10 Assignment: Choosing and Running the Right Test Next, let’s practice on your own. For each scenario: Read the description carefully. Decide which statistical test is most appropriate. Modify the code from the examples we’ve covered in class to run the test in R. Interpret the output using proper results statements. Scenario 1: Comparing Two Groups A biologist measures the leaf nitrogen content (%) in plants from two different habitats: Sunny vs. Shady. Question: What test should you use to compare nitrogen between habitats? Scenario 2: More Than Two Groups An ecologist measures the average number of pollinator visits to flowers of three species: Aster, Goldenrod, and Sunflower. Question: What test should you use to compare mean visits among these three species? Scenario 3: Relationship Between Two Variables A forester records tree diameter (cm) and age (years) for a sample of trees. Question: What test should you use to test whether tree diameter predicts age? Scenario 4: Categorical Data A conservationist records whether birds are Present or Absent at two sites: Restored and Unrestored. Question: What test should you use to see if bird presence differs between restored and unrestored sites? 9.10.1 Deliverables For each of the 4 scenarios above, run the appropriate statistical test, and provide: Results statements including: The correct test statistics Associated figures with correct figure legends. Start here again if using this chapter to analyze data for your species interaction lab 9.11 Statistical analyses for your species interaction lab Using the statistical tests provided here, select your statistical test based on the data type for your response and explanatory variable, run a statistical test, record your results, and create a figure! "],["basic-statistical-testing.html", "Chapter 10 Basic statistical testing 10.1 A short statistical review 10.2 Hypothesis testing review 10.3 Downloads for this module 10.4 Objectives 10.5 Tailed tests 10.6 Drawing conclusions from statistics 10.7 Reporting results 10.8 Assignment", " Chapter 10 Basic statistical testing 10.1 A short statistical review 10.1.1 What can statistics tell us? Welcome to our statistical exploration of the natural world! Almost all statistical analysis boils down to answering 1 of 2 questions: Do these groups differ? Is there a relationship between these variables? These seem like relatively simple questions to answer, perhaps just by looking at our data, so Why do we need statistics? The short answer is: error and sampling! Whenever we collect data, we introduce error; our instruments are imprecise and do not capture an exact measure of whatever you are measuring (e.g., height, weight), and humans make mistakes during measurement collection. Secondly, we are always measuring a sub-sample of the true population (true population meaning all representatives of whatever you are trying to measure; this can be grass, marbles, or the tibia of humans). Not only is it intractable in most cases to measure all individuals of whatever you are interested in, even when it is possible to attempt to measure all individuals (like in the case of rare plant work), statistics acknowledges that it is still unlikely that we are able to do so, since individuals may be dormant or challenging to locate. If we could measure all individuals of our focal population with perfect accurately, we could calculate population parameters, or quantities describing populations like averages and variation, rather than estimating these metrics, and just compare them. In this way, statistics is inherently practical, and asks: What can we say about whatever we are looking at, given our numerous flaws? 10.1.2 Sampling populations After a few classes, we will explore sampling methodology in greater depth in order to design appropriate experiments that test a statistical hypothesis. Let’s quickly talk about sampling now so that we have a shared understanding and vocabulary to build on - after all, statistics really centers around estimating characteristics of a true population from a sample. The really, truly amazing thing is that by properly applying statistics, we can learn practically anything about almost any population using samples! In statistics, a population refers to the all units of the thing that you are interested (i.e., all suriname frogs, all grains of sand, all aspen leaves from a genotype found in southern Arizona). Note: Population in statistics differs from the term population in population ecology, where a population refers to a group of individuals in a particular area that interbreed. A sample is a subset of the population that we measure to infer something about the population. Statistical analysis is only one part of presenting your research results. Generally, a results section in a manuscript includes: statistical results, data description (e.g., describing means, ranges, maxima, minima of groups of interest), and data visualization (i.e., creating beautiful figures). 10.2 Hypothesis testing review Ahhhh the scientific process: A researcher makes observations about the natural world, generates a hypothesis to test, tests the hypothesis, rejects or fails to reject the hypothesis, and reports these findings. A simple, yet glorious process that has led to incredible discoveries! Statistical hypothesis testing answers very simple questions, while scientists work in very complex knowledge environments. For beginning researchers, it is important to understand what statistics can tell us, and how this builds information to address amazing and very interesting research questions. Hypotheses allow us to articulate exactly what we are testing in statistics and to organize thoughts and analyses. 10.3 Downloads for this module Download this file to the folder you created for this lab: Download the R file. As you read the tutorial, follow along in the R code. Then, use the code to finish your assignment. 10.4 Objectives We will highlight the basic components of a statistical test with a very simple statistical ‘tailed’ test. Today, we will: State a hypothesis Calculate a test statistic Determine the p-value Interpret results The null hypothesis (\\(H_0\\)) is a statement about a population parameter that would be interesting to reject. The null hypothesis typically asserts that there is no effect or relationship or that results will not deviate from established knowledge. For instance: The mean height of giraffes in captivity and in the wild do NOT differ. The incidence of toenail fungus is the SAME in the control group and the group given anti-fungal medicine. There is NO relationship between sea grass height and the number of sea snails. The mean human body temperature is 98.6 degrees Fahrenheit. Null hypotheses are paired with alternative hypotheses (\\(H_A\\)) that represent ALL other possibilities other than that stated in the null hypothesis. For instance: The mean height of giraffes in captivity and in the wild differs. The incidence of toenail fungus is different in the control group and the group given anti-fungal medicine. There is a relationship between sea grass height and the number of sea snails. The mean human body temperature is not 98.6 degrees Fahrenheit. Note that the null hypothesis is very specific, while the alternative hypothesis is general. Statistical tests are designed to either reject or fail to reject the null hypothesis. 10.5 Tailed tests Tailed tests are very simple tests for comparing means or proportions, and are great for illustrating the basic components of a frequentist statistical analysis. Let’s walk through an example! Handedness is common in humans. Around 90% of humans preferentially use their right hand. You’ve been watching your cat, Geraldo, play with his toy mouse, and you notice that he preferentially uses his right paw to bat the mouse around. You start to wonder if cats display handedness like humans! You run around visiting cats and observing their paw usage and determine that 14 cats of the 18 you observe appear to be right-pawed, while only 4 preferentially use their left paw. Is this enough evidence to suggest that cats display ‘handedness’ or did this pattern just emerge by chance? 10.5.1 Generate hypotheses What is the null hypothesis in this case? Remember it must be specific so that we can either reject or fail to reject the null! \\(H_0\\): Left and right-pawed cats are equally frequent in the population (i.e., Cats are not right or left-pawed). Note that this null hypothesis is very specific. If we would describe this mathematically, we would say that we expect half the cats (9 / 18) to use their right paws and half to use their left paws. If we express this as a proportion, (\\(p\\)), we are testing whether \\(p\\) = 0.5. Very specific. What is the alternative hypothesis? \\(H_A\\): Left and right-pawed cats are not equally frequent in the population. Note that the alternative hypothesis is very broad and encompasses all other possibilities. Because, in theory, we could observe proportions below 0.5 (1/18 cats are right-handed) or above 0.5 (16/19 cats are right-handed), we refer to this as two-tailed. In a two-tailed test, the alternative hypothesis includes parameters on both sides of the value specified by the null hypothesis. Before we move on, can you think of an example of a 1-tailed test? Don’t look before guessing! Here are some examples: Did you score better than the class average? Is the time to getting to the student union less than 10 minutes when you avoid driving through campus? Note the difference with the 2-tailed test: we are only interested in values in one direction. In the first example, we are interested in whether your score is &gt;80% (class average). In the second, we are interested in whether your drive time is &lt;10 minutes (time to the student union driving through campus from your house). How could you phrase the first example to be a 2-sided test? Don’t look before guessing! It could be something like this: Was my score different than the class average? In this case, your score could be higher or lower. 10.5.2 Calculate a test statistic We generated our hypotheses. Let’s calculate a test statistic. What is a test statistic? A test statistic is a quantity calculated from that data used in statistical analysis to evaluate the null hypothesis. For this simple test, our test statistic will be 14, since this is the number of right-handed cats we observed. We want to ask whether observing 14 out of 18 cats using their right paw is truly different from the null (9 out of 18 cats using their right paw), or did this pattern occur by chance in our sample? 10.5.3 Determine the p-value Frequentists statistics is based on the concept of statistical distributions. If we run many trials, we can determine the likelihood of certain events occurring by chance. We refer to the patterns of occurrence of trials as frequency distributions. Let’s illustrate using the data above. A cat can either be right-handed or left-handed (in this case there are no ambidextrous cats). To determine the likelihood that our pattern arose by chance, we conduct numerous trials like a coin toss. We would randomly flip a coin 18 times and record the outcome of each trial; heads being right-pawed, and tails being left-pawed. In class: Each student took a coin. Flipped the coin 18 times and recorded number of heads. Divided by total number of trials (in this case students) to derive relative frequency for each event. If we would flip the coins many times, we probably generated something that looks like the figure generated by running the code below (run in your R code to generate the figure). This is referred to as a probability distribution and expresses the relative frequency of particular events occurring. Frequentist statistics derives its name from this probability distribution. ## quartz_off_screen ## 2 Figure 10.1: Binomial probability distribution Here is a table of those probabilities: probability &lt;- dbinom(paws, 18, 0.5) N &lt;- 0:18 pawtable &lt;- cbind(N, probability) pawtableF &lt;- as.data.frame(pawtable); pawtableF ## N probability ## 1 0 3.814697e-06 ## 2 1 6.866455e-05 ## 3 2 5.836487e-04 ## 4 3 3.112793e-03 ## 5 4 1.167297e-02 ## 6 5 3.268433e-02 ## 7 6 7.081604e-02 ## 8 7 1.213989e-01 ## 9 8 1.669235e-01 ## 10 9 1.854706e-01 ## 11 10 1.669235e-01 ## 12 11 1.213989e-01 ## 13 12 7.081604e-02 ## 14 13 3.268433e-02 ## 15 14 1.167297e-02 ## 16 15 3.112793e-03 ## 17 16 5.836487e-04 ## 18 17 6.866455e-05 ## 19 18 3.814697e-06 Take a look at the chart. What is the probability of observing right pawedness in 14 out of 18 cats? Is this difference from the null (9 cats are right-handed, no better than random) big enough to reject the null? To determine this we calculate a p-value. A p-value is the probability of obtaining the data that we observe if the null hypothesis were true. In this case, we will generate a p-value for a two-tailed test. To do this, we will add the probabilities of observing 14 right pawed cats or more by chance AND for the possibility of observing 4 or fewer right paws, which would indicate left pawedness. P-value = Pr[14] + Pr[15] + Pr[16] + Pr[17] + Pr[18] + Pr[4] + Pr[3] + Pr[2] + Pr[1] + Pr[0] Recall that we can add these probabilities up, since, in our example, we say that being right or left pawed are mutually exclusive events. pvalue &lt;- (0.0117 + 0.0031 + 0.0006 + 0.00007 + 0.000004)*2; pvalue ## [1] 0.030948 We generate a P-value of 0.031. In most sciences, we have agreed on a threshold of 0.05 for establishing statistical significance. If p-values are less than or equal to 0.05, we reject the null hypothesis. If larger, we fail to reject. The significance level, \\(\\alpha\\), is a probability used as a criterion for rejecting the null hypothesis. This significance level is important. In the sciences, we would rather err on the side of not identifying a pattern, rather than saying there is a pattern, when there it doesn’t actually exist. This concept is included in the in the discussion of *statistical errors**. A Type I error is when you reject a true null hypothesis. You are saying there is a difference, when actually, if could perfectly measure your focal population, there is no difference. By establishing a significance level (\\(\\alpha\\)) of 0.05, we are saying that we are willing to accept that 5% of the time, we will say there is an effect when there isn’t one. A Type II error is failing to find a pattern or a difference when there actually is one. If you reduce your \\(\\alpha\\) to reduce your likelihood of making a Type I, you increase the likelihood of committing a Type II error. The probability of committing a Type II error is more challenging to quantify and is related to the concept of statistical power. A study with high power has a low likelihood of committing a Type II error. Statistical power depends on several things, including sample size, the magnitude of the effect of the treatment, and variation within the sample. A study with a LARGE sample size, a BIG treatment effect, and SMALL variation within samples will have high statistical power. We will talk about calculating statistical power later. 10.6 Drawing conclusions from statistics In this case, we reject the null hypothesis, and state that our results support the alternative hypothesis that there is handedness in cats. Note that we ‘support’ the alternative hypothesis, rather than saying that there is pawedness in cats or accepting the alternative hypothesis. Statements about statistics are phrased to reflect that we are dealing in probabilities, and there is always a chance that our findings are incorrect. Additionally, statistical tests specifically test the null hypothesis, not the alternative (for which there are often many possibilities). What would we say if we didn’t reject the null? We would state that we failed to reject the null hypothesis. Failing to reject the null indicates that our sample did not provide sufficient evidence to conclude that the effect exists, but lack of evidence doesn’t prove that the effect does not exist. For this reason, we never accept the null. 10.7 Reporting results When we report findings, we will provide: A statement of findings The test statistic The P-value A description of differences, if differences exist A visualization of differences, if differences exist Here is how we might report the written results of our previous test: Cats displayed higher levels of handedness than expected by chance (t = 14, p = 0.03). Around 78% of cats preferentially use their right paw (Fig. 1). Note that it is common to include up to 2 decimal places in the results statements.If p-values are less than 0.01, it is common to report the p-value as p &lt; 0.01. 10.8 Assignment We will now apply the tailed-test to a new question! You think that your dog, Rupert, prefers blue to red. You want to know: Do dogs prefer the color blue? Provide the following information in a document and turn into your TA: What is your null hypothesis? What is your alternative hypothesis? You invite all your friends with dogs, place both red and blue balls on the ground, and see if how many times the dogs select the blue ball out of a series of 10 trials. Ten of friends with dogs participate and you record the number of times that the dogs select the blue ball. Run the t-test in R! Provide a corrected crafted results statement describing the outcome of the test. Please correctly structure your results statements, and make sure that you have included the 5 components mentioned above. For your figure, please include a properly formatted figure legend. Recall from last lesson, the key parts of the figure legend: A description of what the figure is showing you. For complex figures with multiple panels, an orientation to the structure of the figure Explanation of any symbols, colors, and/or lines Description of how variance is quantified Definitions of axes or units, if unclear Acknowledgment of data source, if data source requires attribution Implications of the figure (optional) "],["generalized-linear-models-glms.html", "Chapter 11 Generalized Linear Models (GLMs) 11.1 Linear models", " Chapter 11 Generalized Linear Models (GLMs) 11.1 Linear models What is a linear model? A linear model is a model where the data and parameters of interest interact only via addition and multiplication. Most commonly, the term ‘linear model’ refers to statistical models that involve linear regression. Clearly, linear models include linear regression in all its beautiful forms, like ANCOVA, and logistic regression. However, ANOVA is actually considered a linear model as well, since it meets our basic definition. Though it may not seem so from the outset, ANOVA and regression, statistically are related. Here’s an example: Let’s pretend we are looking at SLA (Specific Leaf Area) measurements of 3 different populations of plants, one population from Flagstaff, one from Sedona, and one from Camp Verde. library(tidyverse) data &lt;- tribble(~Population, ~SLA, &quot;Flagstaff&quot;, 2, &quot;Flagstaff&quot;, 1, &quot;Flagstaff&quot;, 2, &quot;Sedona&quot;, 5, &quot;Sedona&quot;, 6, &quot;Sedona&quot;, 7, &quot;CampV&quot;, 10, &quot;CampV&quot;, 11, &quot;CampV&quot;, 10) pop &lt;- group_by(data, Population) SLAtable &lt;- summarise(pop, meanSLA = mean(SLA)); SLAtable ## # A tibble: 3 × 2 ## Population meanSLA ## &lt;chr&gt; &lt;dbl&gt; ## 1 CampV 10.3 ## 2 Flagstaff 1.67 ## 3 Sedona 6 #ANOVA model1 &lt;- aov(SLA ~ Population, data=data) summary(model1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Population 2 112.67 56.33 101.4 2.37e-05 *** ## Residuals 6 3.33 0.56 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #ANOVA run as a linear model model2 &lt;- lm(SLA ~ Population, data=data) summary(model2) ## ## Call: ## lm(formula = SLA ~ Population, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0000 -0.3333 0.0000 0.3333 1.0000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.3333 0.4303 24.01 3.43e-07 *** ## PopulationFlagstaff -8.6667 0.6086 -14.24 7.50e-06 *** ## PopulationSedona -4.3333 0.6086 -7.12 0.000386 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7454 on 6 degrees of freedom ## Multiple R-squared: 0.9713, Adjusted R-squared: 0.9617 ## F-statistic: 101.4 on 2 and 6 DF, p-value: 2.373e-05 #in this simple model, #notice that the Intercept is the mean SLA of the #reference group #then population Flagstaff Coefficient #is 10.333 - 8.667 = 1.67 (mean of the Flagstaff pop) #Sedona population = 10.3333 - 4.3333 #6 = mean SLA of the Sedona population In other words, ANOVA compares means and provides a p-value that tells us that at least two groups are different, while the linear model form reports 1 mean for the reference group (intercept), and p-values indicate whether each group is different from the reference group. Well, hopefully that was an interesting aside and served to connect a variety of different statistical techniques. Now, let’s have a b***ing session about old-school linear models, like ANOVA. They have SO many assumptions that need to be met - in particular, linear models assume a normal distribution of residuals. Then, if that assumption isn’t met, you have to transform your dependent variable, and back transform your error bars, and on and on until you achieve normality, which - let’s be honest - may never happen. If only there was an easy way to deal with the assumption of normality of residuals! Enter a new(ish) generation of models - Generalized Linear Models (GLMS)! "],["generalized-linear-models.html", "Chapter 12 Generalized Linear Models 12.1 Link functions 12.2 GLMs in R", " Chapter 12 Generalized Linear Models A Generalized Linear Model (GLM) is an flexible statistical framework that allows us to model relationships between variables when the assumptions of ordinary linear regression are not met. Generalized Linear Models makes linear regression generalizable by using a link function to relate the linear model (i.e., relationship between x and y; systematic component) to the error (random component), allowing the magnitude of the variance for each measurement to be a function of the mean value and allowing us to specify different types of error distributions. Practically, GLMs allow you to analyze a variety of regression models, including linear regression, ANOVA, models for examining count data, models for predicting likelihood of events, under one statistical umbrella. Model assumptions What are the assumptions of GLMs? The data are independent. No problem - this is always important! The residuals do NOT need to be normally distributed, but you do need to specify a distribution from an exponential family that best fits your data (i.e., normal/Gaussian, binomial, Poisson, etc.) The homogeneity of variance does NOT need to be satisfied. Wow! This is great - let’s go over the components of GLMs - like what is this “link” function that everyone is talking about? A little aside Don’t confused Generalized linear models with General linear models. The term “general” linear model (GLM) usually refers to a linear regression models that assumes a Gaussian (normal) distribution, while generalized linear models allow you to specify other distribution from the exponential family (a set of distributions which include normal, Poisson, gamma and other commonly used distributions) for residuals. Parameter estimation uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS). Remember from our previous discussion of linear regression, that we determine the line of best fit for our data points by using ordinary least squares. Maximum likelihood estimation is Components of the GLM The linear predictor: This is the function that describes the relationship between the independent variable/s and the dependent variable. This essentially has the same structure as a linear model: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + … \\(\\beta_{p}X_{ip}\\) Where \\(\\eta_{i}\\) is the equivalent of y; the linear predictor - the predicted point on the y-axis according to the coefficients of predictors in combination with . \\(\\beta\\) values indicate coefficients of the predictors and x values indicate values of the predictors. The error or random component. The link function which brings together the linear predictor and the error distribution. How do link functions work? Let’s start with the formula for a line. \\(y =\\beta_{0} + \\beta_{1}*x\\) where y is the y-value (point along the y-axis); x is the value along the x-axis; \\(\\beta_{1}\\) (aka m) is the slope, or how much the line rises for 1 unit increase in x; \\(\\beta_{0}\\) is the intercept, or the value of y, when x = 0. In GLMs, the y term is \\(\\eta_{i}\\), so: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + … \\(\\beta_{p}X_{ip}\\) You can keep adding predictor variables (i.e., explanatory variables, independent variables) to the model as \\(\\beta_{2}\\) and so on! You can also specify non-linear relationships, like polynomial relationships, by including the second order term \\(\\beta_{2}X_{i2}^2\\) like so: \\(\\eta_{i}\\) = \\(\\beta_{0}\\) + \\(\\beta_{1}X_{i1}\\) + \\(\\beta_{2}X_{i2}^2\\) For our classic regression models, you obtain an equation for the line of best fit presented in the syntax above. These classic linear regression models make several important assumptions: Additive relationships: Model variables have an additive relationship with each other, rather than multiplicative. Homoskedastic data: Constant variance, in order words, variance does not increase or decrease as a function of the mean. Normally distributed errors (residuals): Residuals are normally distributed, with mean 0 Non-correlated variables: Variables are independent. In standard linear model analysis, we use transformations to meet these assumptions, but GLMs are really cool, because we can avoid using transformation, by applying the link function. Through the beauty of link functions and conditional probabilities, we do not need to worry about homoskedasticity, normal distribution of residuals, or additive relations. 12.1 Link functions Let’s talk link functions, as this is what modifies our regression models, depending on the error distribution of our response variable. You specify the link function based on error distribution of your response variables, let’s go over the most common functions. Keep in mind that statisticians have developed many, many distributions! Some interesting ones include Pareto distribution, often applied to model Gross Domestic Product, and the von Mises distribution, for circular data, applied to days of the year! We will go over the most common link functions and their formulas used in the ecological sciences. Error distribution = Gaussian or Normal Link name = Identity This is the generalized linear model corresponding to a Gaussian distribution, in other words, regression/ANOVA. We do not need to transform the data in anyway, so the link is called identity. Link function = Revisiting the standard equation for a line, \\(y =\\beta_{0} + \\beta_{1}*x\\), we are saying that the mean y value will be what is calculated by the predicted model; we are not transforming anything. This is sometimes indicated with the following equation: \\(g(\\pi)=\\pi\\) where g indicates the link function, and \\(\\pi\\) indicates the mean y. Error distribution = Binomial Link name = Logit Link function = \\(g(\\pi_i)=ln(\\frac{\\pi_i}{1-\\pi_i})\\) This function can be rewritten to solve for y, as: \\(\\pi_i=ln(\\frac{e^{\\pi_i\\beta}}{1+e^{\\pi_i\\beta}})\\) Why would you want to do this? Back in the day, I used this function to create the line of best fit for logistic regressions! See excel example from my very first publication ever! Error distribution = Poisson Count data cannot be less than 0, so we use the Poisson distribution, so we transform the y variable by taking the natural log. Link name = Log Link function = \\(g(\\pi_i)=ln(\\pi_i)\\) This function can be rewritten to solve for y, as: \\(\\pi_i=e^{\\pi_i\\beta}\\) Error distribution = Gamma Used for data that are continuous and positive but may have skewed distributions. Often uses for lengths, durations or amounts (i.e., time to death). Link name = Reciprocal Link function = \\(g(\\pi_i)=1/pi_i)\\) This function can be rewritten to solve for y, as: 12.2 GLMs in R Let’s generate some code for statistical analysis, and create some figures! First, we will start by examining data with a Gaussian/normal distribution. data(iris) #Is petal width related to petal length? #model &lt;- glm(y-value ~ x-values, family = specifylinkingfunctions, data = dataset) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 &lt;2e-16 *** ## Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.2286808) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 33.845 on 148 degrees of freedom ## AIC: 208.35 ## ## Number of Fisher Scoring iterations: 2 #for comparison run a linear regression for comparison iris_modelR &lt;- lm(Petal.Length ~ Petal.Width, data = iris) #y data is continuous, use gaussian summary(iris_modelR) ## ## Call: ## lm(formula = Petal.Length ~ Petal.Width, data = iris) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.33542 -0.30347 -0.02955 0.25776 1.39453 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 &lt;2e-16 *** ## Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4782 on 148 degrees of freedom ## Multiple R-squared: 0.9271, Adjusted R-squared: 0.9266 ## F-statistic: 1882 on 1 and 148 DF, p-value: &lt; 2.2e-16 When we call the summary, you can see several interesting things. First, the first species alphabetically is represented by the intercept - essentially each species is compared against this first species. Then, you see the dispersion parameter (smaller the better), and AIC for model comparison (smaller the better). The dispersion parameter is a measure of variance - how the actual data points scatter around a mean, similar to the sum of squares in a linear regression. The AIC or the Akaike Information Criterion is usually calculated for model comparison. Here, it is presented as a general assessment of goodness of fit. AIC = 2K – 2ln(L) where: K: The number of model parameters. ln(L): The log-likelihood of the model. This tells us how likely the model is, given the data. Let’s take a direct look at the results of a statistical test using the Anova function in the ‘car’ package. library(car) #glm #iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) #y data is continuous, use gaussian Anova(iris_model) ## Analysis of Deviance Table (Type II tests) ## ## Response: Petal.Length ## LR Chisq Df Pr(&gt;Chisq) ## Petal.Width 1882.5 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #for comparison run a linear regression for comparison #iris_modelR &lt;- lm(Petal.Length ~ Petal.Width, data = iris) #y data is continuous, use gaussian Anova(iris_modelR) ## Anova Table (Type II tests) ## ## Response: Petal.Length ## Sum Sq Df F value Pr(&gt;F) ## Petal.Width 430.48 1 1882.5 &lt; 2.2e-16 *** ## Residuals 33.84 148 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #Look at residuals res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) The residuals should have a random pattern, yet here we see a distinctive shape in which they increase at mid-size values and decrease, particularly at the largest values. We could try a different error distribution. iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = Gamma (), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = Gamma(), data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.532340 0.017386 30.62 &lt;2e-16 *** ## Petal.Width -0.172682 0.008915 -19.37 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Gamma family taken to be 0.08000084) ## ## Null deviance: 44.655 on 149 degrees of freedom ## Residual deviance: 12.444 on 148 degrees of freedom ## AIC: 412.86 ## ## Number of Fisher Scoring iterations: 5 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian (link=&quot;log&quot;), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(link = &quot;log&quot;), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.59485 0.04195 14.18 &lt;2e-16 *** ## Petal.Width 0.54740 0.02283 23.98 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.4808902) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 71.172 on 148 degrees of freedom ## AIC: 319.85 ## ## Number of Fisher Scoring iterations: 7 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian (link=power(0.25)), data = iris) #y data is continuous, use gaussian summary(iris_model) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian(link = power(0.25)), ## data = iris) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.133377 0.012699 89.25 &lt;2e-16 *** ## Petal.Width 0.198171 0.007213 27.47 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.4035011) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 59.718 on 148 degrees of freedom ## AIC: 293.53 ## ## Number of Fisher Scoring iterations: 6 res_irismodel &lt;- rstandard(iris_model) plot(iris_model$fitted.values, res_irismodel, pch=20, ylab = &quot;Standarized residuals&quot;, xlab = &quot;fitted values&quot;) All of this to point out that you can in essence perform transformations within the link and you can use the AIC values to compare different models and select the best one for your data (lowest AIC value). In the end, our first model was the best fit to our data, though it wasn’t perfect. Over Dispersion is measured by comparing variance of the response variable to the variance of the linear predictors, when the variance of the response variable is larger than that of the linear predictor, we have overdispersion, meaning those data are more weidley spread than the explanatory variables, and indicates that additional covariates need to be identified. At this time, let’s assume that we don’t have additional variables to add to our GLM model. Let’s run this and generate a nice plot! iris_model &lt;- glm(Petal.Length ~ Petal.Width, family = gaussian(), data = iris) If you want to make predictions: add this info if you want to helpful summary page 507. "],["mixed-effects-models.html", "Chapter 13 Mixed Effects Models 13.1 Examples in R", " Chapter 13 Mixed Effects Models Observations of data aren’t always independent, violating an assumption of our GLMs. Never fear, there are statistical models that deal with that; namely, our aforementioned mixed effects models. Let’s first cite some examples of non-independent observations: Time-series data, in which we are resampling the same points multiple times. Blocked data. For example, plants within a plot. We might expect individuals within 1 plot to respond similarly given higher likelihood of relatedness or greater similarity in microsite conditions, relative to plants in other plots. *Nested data. For example, multiple blood samples taken from an individual. We’d want to indicate that these data are non-independent and likely to be more similar to each other than to samples taken from another individual. Why call these models ‘mixed effects’? Because these models contain both fixed and random effects. Fixed effects = Variables of interest. We are interested in how these factors affect our response variable. Factors and levels of factors have been specifically chosen, and are replicable in future experiments. Random effects = Variables that may explain variation, but that we are not interested in and that we are not interested in replicating in future experiments. For instance, we don’t care if we have the same exact block or we sample blood from the same exact person or we collect data in the same year. 13.1 Examples in R Let’s take a look at running mixed effects models in R. Since agricultural researchers are the royals of blocking, we will take a look at the oat dataset. Be sure to load the lmerTest package, since this package will actually generate p-values. Want to read some snarky statistics back and forth? Check out commentary on developers of the lmer package on why they don’t include p-values… sigh… #load libraries and datasets suppressWarnings(library(&#39;faraway&#39;)) suppressWarnings(library(&#39;lmerTest&#39;)) suppressWarnings(library(&#39;lme4&#39;)) suppressWarnings(library(&#39;tidyverse&#39;)) suppressWarnings(library(&#39;emmeans&#39;)) suppressWarnings(library(&#39;multcomp&#39;)) data(&#39;oatvar&#39;, package=&#39;faraway&#39;) First, let’s talk about oats. The oats dataset ‘Data from an experiment to compare 8 varieties of oats. The growing area was heterogeneous and so was grouped into 5 blocks. Each variety was sown once within each block and the yield in grams per 16ft row was recorded.’ - Official description see ?faraway::oats When we are blocking, I find it really helpful to draw out the statistical design (Draw out what is happening). For now, let’s just take a look at the data. ggplot(oatvar, aes(y=yield, x=block, color=variety)) + geom_point() + geom_line(aes(x=as.integer(block))) Let’s just ask how does variety affect yield. The oat-folks have planted the varieties in 5 replicate blocks. This is a smart thing to do, since variation in microsite conditions will cause differences in yield, and they want their yield estimates to reflect this. While microsite effects are interesting, keep in mind, this is not the variable of interest and they would not try to precisely place the same plots. In other words, the blocks are a random variable. We would expect individuals within blocks to respond more similarly to each other than to those plants outside and individuals block, so let’s account for that variation! The syntax is simple. model &lt;- lmer(responsevariable ~ predictorvariable + (1|block), data=dataset). oatmodel.1 &lt;- lmer( yield ~ variety + (1|block), data=oatvar) anova(oatmodel.1) ## Type III Analysis of Variance Table with Satterthwaite&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## variety 77524 11075 7 28 8.2839 1.804e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This equation basically says let yield means vary by block. There is a statistically significant effect of variety. So let’s do a post-hoc test to see which varieties are different from the other. oatmodel.1 &lt;- lmerTest::lmer( yield ~ variety + (1|block), data=oatvar) dispairwise1 &lt;- emmeans::emmeans(oatmodel.1, ~variety, type = &quot;response&quot;); dispairwise1 ## variety emmean SE df lower.CL upper.CL ## 1 334 21 15.2 290 379 ## 2 377 21 15.2 332 421 ## 3 363 21 15.2 318 407 ## 4 287 21 15.2 242 332 ## 5 439 21 15.2 395 484 ## 6 331 21 15.2 286 375 ## 7 318 21 15.2 274 363 ## 8 384 21 15.2 339 429 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 dis_glht &lt;- glht(oatmodel.1, mcp(variety = &quot;Tukey&quot;)) #need to fix the below line #LetterResults &lt;- multcomp::cld(dis_glht, alpha=0.05, Letters = LETTERS) Add content on nested designs - need to find a decent dataset #why can&#39;t i use the oat dataset from MASS? #model &lt;- lmer(yield ~ variety + Fertilizer + (1|plot/subplot), data=oats) Add content crossed design Add content random slope and intercept "],["describing-ecological-patterns.html", "Chapter 14 Describing ecological patterns 14.1 When to use model selection? 14.2 Step 1: Identifying predictor variables or co-variates of importance 14.3 Step 2: Removing colinear variables 14.4 Example: Reducing colinear climate variables 14.5 Step 3: Select the best model", " Chapter 14 Describing ecological patterns When working at landscape-scales, we often need to employ model selection techniques to identify important predictor variables or co-variates to explain response patterns. There are several discrete steps and important considerations when completing such analyses, but before that, let’s talk a little about the goals of model selection. 14.1 When to use model selection? Put simply, model selection is used when you have multiple competing hypotheses or models and want to: Identify the best-supported model give the data Quantify the relative support for each model Avoid overfitting by penalizing overly complex models Now, competing hypotheses can mean many things. Typically, I have strong hypothesis related to a research question, but less understanding of what covariates could mediate, enhance, or otherwise alter the effect of the predictor variables on the response variable. However, you can be more strategic in your tests, exploring whether data conform better to particular hypotheses or others. In this tutorial, we will examine a dataset related to understanding resilience to drought in the Southwest. From 2020-2021, the Southwestern US experienced an extreme drought event that resulted in widespread die-offs several woody species. To derive models that predict resilience or recovery in Emory oak woodlands, we collected demographic and community data for overstory and understory communities at 100 plots across Emory oak’s range. We measured resilience or recovery in two ways. First, we calculated a metric of community divergence between over- and understory communities, and second, we retrieved remotely sensed data that estimates productivity on the landscape. Building on resilience theory, we hypothesized that stands that were better connected and more diverse would exhibit higher resilience or recovery. Additionally, those sites experiencing lower climatic stress, before, during and after the drought would perform better (i.e., seedling communities exhibit less divergence from the adult plant community, and productivity returns to or exceeds pre-drought levels). However, there are many, many ways to describe climate, and many climatic variables are correlated, and in complex systems, one pillar of resilience (connectivity, diversity) may drive recovery. For this reason, we applied standard model selection techniques to appropriately model resilience/recovery in this system. The results of these models were used to identify stands for restoration treatment likely to be resilient to perturbations like drought. 14.2 Step 1: Identifying predictor variables or co-variates of importance In this example, we identified several predictor variables based on resilience theory. However, climatic covariates could also reveal patterns of stress experienced by oaks. Given the numerous ways that climatic data can be summarized, we first identified variables that could be important for our system. Semi-arid regions of the Southwest are water limited, so we wanted to include a variety of precipitation metrics. Since precipitation patterns are bimodal (we receive roughly half our precipitation in the winter, often as snow, and the other half during the summer monsoons), we wanted to include both annual summaries of climate as well as monsoon specific summaries (including winter precipitation would be a strategic idea as well). Additionally, temperatures influence drought stress as well as respiration rates, affecting tree performance. Maximum and minimum temperatures may affect distinct physiological processes. For instance, minimum temperatures occur primarily at night, and affect the energy balance of trees, since higher temperatures increase respiration rates during a time when trees are photosynthesizing. This can lead to a loss of energetic stores to allocate to growth, reproduction and tissue maintenance and repair. Maximum temperatures, mostly occurring during the day, affect the ability to photosynthesize and maintain water balance. To reduce complexity, we decided to summarize only mean temperatures, rather than mean minimum or maximum temperatures, since we felt temperature would be less important that precipitation in this system. When identifying covariates for your system, think through likely drivers of performance, which in addition to climate could include information on soils or disturbances, like grazing, fires, and human activity. 14.3 Step 2: Removing colinear variables When two or more predictor variables are highly collinear (i.e., strongly correlated with each other), they essentially carry the same information. This can confuse your model in several ways: Unstable estimates: The model struggles to decide how much each variable contributes, which can lead to inflated or inconsistent coefficient estimates. Reduced interpretability: It’s harder to understand the effect of each variable because their influence overlaps — they “share the credit.” Misleading significance tests: Collinearity can make some variables appear non-significant, even if they’re actually important, because their shared information is spread across multiple predictors. Poor model generalization: Models with collinear variables are more likely to overfit to your data and perform worse when applied to new situations. By removing or combining collinear variables, you help the model focus on independent sources of information, making it more stable, interpretable, and accurate. So let’s do that! First, we will want to select a method to remove correlated variables. We have two major options - We can either automate variable removal or use expertise to select variables. 14.3.1 Automated Variable Removal Using statistical metrics like correlation thresholds or Variance Inflation Factor (VIF) to reduce multicollinearity. 14.3.1.1 Merits: • Objective &amp; reproducible: Provides consistent results across datasets. • Handles high-dimensional data: Especially useful when there are many predictor variables. • Improves model stability: Reduces inflated standard errors and overfitting risk in regression models. • Compatible with model selection workflows: Can be integrated with stepwise selection, LASSO, or random forest importance. Note: I only completely automate variable selection when I’m batch processing loads of data and the objective of the analysis is to look broadly across numerous comparisons. As an example, I automate variable removal when I’m generating a large number of Species Distribution Models to explore richness landscape-level patterns. 14.3.1.2 Limitations: • Ignores ecological meaning: May discard biologically relevant or interpretable variables. • Over-reliance can lead to information loss: For example, two drought metrics may both be predictive, even if correlated, because they represent different climate processes (input vs. deficit). • Thresholds are somewhat arbitrary: Why r &gt; 0.7 or VIF &gt; 10? Different fields use different cutoffs. 14.3.2 Expert Knowledge-Driven Selection Manually selecting variables based on ecological theory, prior studies, or local knowledge. 14.3.2.1 Merits: • Maintains interpretability: You keep variables with clear ecological meaning. • Aligns with study goals: You can prioritize variables that are hypothesized drivers of your response. • Supports story-driven science: Especially useful when communicating with land managers, policymakers, or interdisciplinary teams. 14.3.2.2 Limitations: • May retain collinearity: Which can destabilize models if unaddressed. • Subjectivity: Different experts may choose different variables. • Less scalable: Can be slow or inconsistent across many datasets or repeated analyses. 14.3.3 Blended Strategy (Recommended) Use expert knowledge to define the pool of candidate predictors, then apply statistical tools to reduce redundancy within that pool. Workflow: 1. Start with expert-justified variables. 2. Check for high correlations or high VIFs. 3. If two variables are strongly collinear, decide which is more interpretable or central to your ecological question. 4. Optionally test models with and without each to evaluate performance/stability. 14.4 Example: Reducing colinear climate variables Let’s remove colinear climate variables! First, we can use a fully automated method, then we will transition to the blended strategy. We can contrast these approaches with each other, and with a dataset we would have put together with no statistical information on covariance! We divided the climatic environment into three categories: 1) Pre-drought baseline conditions, 2) Climatic change rates, and 3) Post-drought recovery conditions. Sectioning different categories of variables that you suspect a priori influence the response variable is a strategy that allows you to capture different ecological processes, while reducing colinearity of predictors. library(car) library(dplyr) library(purrr) library(tibble) # # Load directly from Google Drive (readr-style) # library(readr) # # data &lt;- read_csv(&quot;https://drive.google.com/uc?export=download&amp;id=1Yap0vVnrf-5nJemsFQ8sSIH3RNLxU5WF&quot;) # # # Select only numeric predictors and drop rows with missing values # numeric_predictors &lt;- data %&gt;% # dplyr::select(where(is.numeric)) # # # Visualize # library(corrplot) # cor_matrix &lt;- cor(numeric_predictors, use = &quot;complete.obs&quot;) # corrplot(cor_matrix, method = &quot;color&quot;, type = &quot;lower&quot;, tl.cex = 0.7) # # climatechange_df &lt;- read_csv(&quot;climate_change_allvariables.csv&quot;) # # # Select only numeric predictors and drop rows with missing values # numeric_predictors &lt;- climatechange_df %&gt;% # dplyr::select(where(is.numeric)) # # # Remove identifier column # predictor_data &lt;- resilience_clean %&gt;% dplyr::select(-Plot_ID) # # # Loop over each variable and calculate max VIF # vif_results &lt;- map_dfr(names(predictor_data), function(var) { # # Build formula: var ~ all other variables # formula &lt;- as.formula(paste(var, &quot;~ .&quot;)) # # Create modeling dataset: use current var as response, others as predictors # model_data &lt;- predictor_data %&gt;% # dplyr::select(-all_of(var)) %&gt;% # mutate(response = predictor_data[[var]]) # # Fit the model # model &lt;- lm(response ~ ., data = model_data) # # Get VIFs # vif_vals &lt;- vif(model) # tibble(response_var = var, max_vif = max(vif_vals, na.rm = TRUE)) # }) # # print(vif_results) What happened here? Let’s repeat the process. Repeat for the other suites of climatic variables: climate change and post-drought conditions. Then, merge all datasets, and calculate VIFs again. That’s it! We have our final set of climatic predictors! I repeated this process again for other types of variables, including diversity estimates and connectivity. As you can see, generating a biologically-grounded, statistically sound predictor dataset is an iterative process, but worth the effort! 14.5 Step 3: Select the best model Now that we have assembled a dataset of climate predictors, we will want to select the model that best explains variation in our response variable, in this case a measure of community dissimilarity (labeled ‘bray_curtis’ in the dataset). Model selection is the process of identifying the best model(s) from a set of candidates that explain or predict a response variable based on a set of predictors. Below are the major approaches, their definitions, benefits, drawbacks, and primary applications in ecology and related disciplines. Model selection is a hotly debated topic in statistics, with disagreements about when and how it should be used. Some argue it’s essential for identifying the best-supported models, while others caution that it can be misused, leading to overfitting or misinterpretation if not grounded in strong theory and careful reasoning. As an ecologist working in complex systems, I typically choose to use some sort of model selection tool. Here’s why: Complex systems often need simplification: In ecology (and many other fields), there are often many plausible predictors. Model selection helps identify which ones meaningfully contribute to explaining patterns, rather than relying solely on intuition or arbitrary choices. It guards against overfitting: By comparing models using criteria like AIC, BIC, or cross-validation error, model selection balances fit with complexity, helping you avoid models that explain your current data perfectly but perform poorly on new data. It enables hypothesis comparison: You can formally compare models that reflect different ecological hypotheses — e.g., does drought or disturbance better explain recovery? — rather than testing each variable in isolation. Let’s explore several popular methods of model selection. 14.5.1 Major Types of Model Selection: Overview, Benefits, Drawbacks, and Applications 14.5.1.1 Information-Theoretic Approaches (e.g., AIC, BIC) What it is: • Compares multiple models based on goodness of fit penalized by model complexity. • AIC (Akaike Information Criterion) focuses on minimizing information loss. • BIC (Bayesian Information Criterion) penalizes complexity more harshly and favors simpler models as sample size increases. Benefits: • Allows comparison of non-nested models. • Emphasizes parsimony (balancing fit with simplicity). • Useful in exploratory studies with many competing hypotheses. Drawbacks: • Can favor overly complex models if predictors are correlated or sample size is small (AIC). • Results depend on the candidate model set — unconsidered models are ignored. Applications: • Ecology, epidemiology, evolutionary biology. • Useful when comparing alternative ecological hypotheses or predictor sets. 14.5.1.2 Stepwise Regression (Forward, Backward, Bidirectional) What it is: • Automatically adds or removes predictors based on p-values or information criteria (e.g., AIC). • Forward: starts with no predictors; adds variables one at a time. • Backward: starts with all variables; removes one at a time. Benefits: • Easy to implement. • Reduces large variable sets quickly. Drawbacks: • Ignores model uncertainty. • Inflated Type I error rates. • Final model can be unstable (small changes in data can lead to different models). Applications: • Often used in exploratory analyses. • Sometimes used in automated workflows, though not recommended for inference. 14.5.1.3 All-Subsets Regression (aka Best Subsets Selection) What it is: • Evaluates all possible combinations of predictors and ranks models based on a selection criterion (AIC, BIC, R-squared, etc.). Benefits: • Thorough exploration of model space. • Helps identify the best model given a criterion. Drawbacks: • Computationally intensive, especially with many predictors. • High risk of overfitting without careful constraints. Applications: • Model exploration when the number of predictors is moderate (&lt;20). • Common in applied ecological modeling where model space is small and well-defined. 14.5.1.4 Cross-Validation (CV) What it is: • Divides the dataset into training and testing subsets repeatedly. • Evaluates model performance based on predictive accuracy (e.g., RMSE, classification error). • K-fold CV is common (e.g., 5- or 10-fold). Benefits: • Focuses on model predictive performance. • Helps avoid overfitting. Drawbacks: • Does not provide information about explanatory power. • More computationally demanding. Applications: • Machine learning, predictive modeling. • Useful in ecological forecasting, SDMs, or models aimed at out-of-sample prediction. 14.5.1.5 Bayesian Model Selection What it is: • Uses Bayes factors or posterior probabilities to compare models. • Accounts for model uncertainty explicitly. Benefits: • Incorporates prior knowledge. • Quantifies model uncertainty. • Can average over multiple models (Bayesian model averaging). Drawbacks: • Requires strong computational resources. • Sensitive to choice of priors. Applications: • Hierarchical models, small-sample inference, decision analysis. • Growing use in ecological and conservation decision-making. 14.5.1.6 Regularization Methods (e.g., Lasso, Ridge, Elastic Net) What it is: • Shrinks coefficients by adding a penalty term to the loss function. • Lasso (L1) can set some coefficients to zero (variable selection). • Ridge (L2) shrinks coefficients but keeps all predictors. Benefits: • Handles multicollinearity well. • Useful in high-dimensional datasets. Drawbacks: • Less interpretable coefficients. • Choice of tuning parameter (lambda) requires validation. Applications: • Genomics, remote sensing, high-dimensional ecological models. • When predictor &gt; sample size. 14.5.1.7 Summary of model selection techniques For most applications, I use AIC-based approaches. They offer a nice balance between model fit and complexity, and you can average across top models to incorporate model uncertainty (explained more below). Here are a couple of exceptions: • If I had very high-dimensional data (e.g., genomics, remote sensing), I’d switch to LASSO (Least Absolute Shrinkage and Selection Operator). Regularization technique that performs variable selection and regularization simultaneously, so it is computationally efficient. • If the goal was out-of-sample prediction, I’d rely on cross-validation or machine learning methods with holdout sets. I use these techniques often when creating species distribution models and I’m trying to extrapolate suitable habitat across the landscape. • If I needed to quantify uncertainty explicitly (e.g., in decision analysis), I’d consider Bayesian model selection or Bayesian model averaging. 14.5.2 Stepwise regression based on AIC (Akaike Information Criterion). library(MASS) #full_model &lt;- glm(response ~ ., data = data_reduced, family = binomial) #stepwise_model &lt;- stepAIC(full_model, direction = &quot;both&quot;) #summary(stepwise_model) LASSO (Least Absolute Shrinkage and Selection Operator) Regularization technique that performs variable selection and regularization simultaneously. Benefits: Automatic Variable Selection: LASSO can automatically shrink some coefficients to zero, effectively performing variable selection and reducing model complexity. Handles High Dimensionality: Particularly useful when the number of predictors is much larger than the number of observations. Regularization: Helps prevent overfitting by adding a penalty to the magnitude of coefficients. Interpretability: The resulting model is often simpler and easier to interpret, as it includes only a subset of the predictors. Computational Efficiency: Computationally efficient and can be solved using convex optimization methods. Drawbacks: Bias: The shrinkage can introduce bias into the estimates of the coefficients. Model Assumptions: Assumes linear relationships between predictors and the response variable. Choice of Penalty Parameter: The performance depends on the choice of the penalty parameter (lambda), which requires cross-validation to tune. Cannot Handle Multicollinearity Well: While LASSO can select variables, it might not perform well in the presence of high multicollinearity compared to other techniques like ridge regression. library(glmnet) #x &lt;- model.matrix(response ~ ., data_reduced)[, -1] #y &lt;- data_reduced$response #lasso_model &lt;- cv.glmnet(x, y, alpha = 1, family = &quot;binomial&quot;) #best_lambda &lt;- lasso_model$lambda.min #best_model &lt;- glmnet(x, y, alpha = 1, family = &quot;binomial&quot;, lambda = best_lambda) #coef(best_model) Best Subset Selection; Evaluate all possible subsets of predictors and select the best model based on a criterion like AIC, BIC, or adjusted R-squared. Benefits: Exhaustive Search: Considers all possible combinations of predictors, ensuring the best possible model according to a specified criterion (e.g., AIC, BIC). Model Performance: Often provides the best fit in terms of the criterion used for selection. Flexibility: Can be used with any type of regression model and can include interactions and polynomial terms. Drawbacks: Computationally Intensive: Becomes impractical with a large number of predictors due to the exponential increase in the number of models to be evaluated. Overfitting: Risk of overfitting, especially when the number of predictors is large relative to the number of observations. Multicollinearity: Does not address multicollinearity among predictors, which can lead to unstable coefficient estimates. library(leaps) #best_subset &lt;- regsubsets(response ~ ., data = data_reduced, nbest = 1, really.big = TRUE) #summary(best_subset) Model Averaging; Perform model averaging to account for model uncertainty. Benefits: Accounts for Model Uncertainty: By averaging over multiple models, it incorporates model uncertainty into the final predictions. Improved Predictive Performance: Often leads to better predictive performance by averaging out the errors of individual models. Flexibility: Can be applied to various types of models and selection criteria. Stability: Provides more stable estimates by considering multiple models rather than relying on a single best model. Drawbacks: Complexity: Results in a more complex model that can be harder to interpret compared to selecting a single best model. Computationally Intensive: Requires fitting and averaging a large number of models, which can be computationally demanding. Weight Selection: The choice of weights for averaging (e.g., based on AIC, BIC, or cross-validation errors) can influence the final model and may not always be straightforward. Potential for Overfitting: If not carefully managed, averaging over too many models can still lead to overfitting, particularly if the individual models are not regularized. # library(MuMIn) # options(na.action = &quot;na.fail&quot;) #global_model &lt;- glm(response ~ ., data = data_reduced, family = binomial) #dredged_models &lt;- dredge(global_model) #averaged_model &lt;- model.avg(dredged_models, subset = delta &lt; 2) #summary(averaged_model) "],["plot-establishment.html", "Chapter 15 Plot establishment", " Chapter 15 Plot establishment One other thing to consider, is the placement of plots across the landscape. Though this is step one of the process, since many folks will have previously established plots, we will discuss here! Spatially balanced random sampling offers several benefits, particularly in ecological and environmental studies. Here are some of the key advantages: Improved Representativeness Coverage: Ensures that the sample points are spread out evenly across the study area, which helps in capturing the spatial heterogeneity of the environment. Reduction of Bias: Minimizes the chances of over-sampling or under-sampling specific areas, leading to more accurate and generalizable results. Enhanced Statistical Efficiency Reduced Variance: By evenly distributing sample points, spatially balanced sampling often reduces the variance of the estimates compared to simple random sampling. Better Inference: Provides better estimates of population parameters and improves the precision of spatially explicit models. Flexibility and Adaptability Multiple Scales: Can be applied at various spatial scales, making it suitable for different types of studies ranging from local to regional levels. Integration with GIS: Easily integrated with Geographic Information Systems (GIS) to facilitate sample design and data collection. Cost-Effectiveness Efficient Use of Resources: Reduces travel time and costs associated with fieldwork by ensuring that sample locations are optimally distributed. Focused Sampling Effort: Enables targeted sampling in areas of interest while still maintaining a representative coverage. Robustness to Spatial Autocorrelation Handling Spatial Dependencies: Helps in accounting for spatial autocorrelation by ensuring that samples are not clustered, which can lead to more reliable statistical analyses. Examples of Applications Ecological Monitoring: Used to monitor biodiversity, habitat quality, and species distributions across large landscapes. Environmental Assessment: Applied in studies assessing soil contamination, water quality, and air pollution to ensure comprehensive spatial coverage. Resource Management: Useful in forestry, agriculture, and fisheries to assess the distribution and abundance of resources. Key Methods and Tools Spatially Balanced Sampling Algorithms: Such as the Generalized Random-Tessellation Stratified (GRTS) design. R Packages: spsurvey package in R provides tools for implementing spatially balanced sampling designs. library(spsurvey) # Define the study area and number of sample points #study_area &lt;- as.spatialPolygons(my_shapefile) #n_samples &lt;- 100 # Generate spatially balanced sample points #sample_points &lt;- grts(study_area, n = n_samples) # Plot the sample points #plot(study_area) #points(sample_points, col = &quot;red&quot;) "],["before-after-control-impact.html", "Chapter 16 Before-After-Control-Impact 16.1 Which design 16.2 BACI Design 2", " Chapter 16 Before-After-Control-Impact 16.1 Which design Four standard BACI DesignsFour standard BACI designs: 1. Single impact site; single control site; one year before; oneyear after 2. Single/multiple impact site; multiple control sites; one yearbefore; one year after 3. Single impact site; single control site; multiple yearsbefore; multiple years after. 4. Single impact site; multiple control sites; multiple yearsbefore; multiple years after See this tutorial 16.2 BACI Design 2 #test1 &lt;- lmer(responsevariable ~ GrazingTreatment+Time+GrazingTreatment:Time, random~1|Plot/Time, data=yourdata) "],["time-is-a-flat-circle.html", "Chapter 17 Time is a flat circle", " Chapter 17 Time is a flat circle "],["bootstrapping-and-resampling.html", "Chapter 18 Bootstrapping and resampling", " Chapter 18 Bootstrapping and resampling "],["permuting-your-brains-out.html", "Chapter 19 Permuting your brains out", " Chapter 19 Permuting your brains out "],["spatial-data.html", "Chapter 20 Spatial data", " Chapter 20 Spatial data Working with Spatial Data Introduction: Why Spatial Data Matters in Ecology Almost all ecological data has a spatial component “Everything is related to everything else, but near things are more related than distant things” (Tobler’s First Law) Spatial context influences sampling, analysis, and interpretation Ignoring spatial structure can lead to pseudoreplication and biased inference Types of Spatial Data Vector data Points — sample locations, species occurrences, sensor stations Lines — transects, streams, roads, animal movement paths Polygons — study area boundaries, habitat patches, management units Raster data Grid cells with continuous values Examples: elevation (DEMs), temperature, precipitation, NDVI, land cover Resolution matters: cell size determines detail and file size When to use which Vector for discrete features and sample locations Raster for continuous environmental surfaces Many analyses require both Visual comparison: Same landscape represented as vector vs. raster Common Spatial File Formats Vector formats FormatExtensionProsConsShapefile.shp (+ .dbf, .shx, .prj)Universal compatibilityMultiple files, 2GB limit, field name limitsGeoPackage.gpkgSingle file, no size limit, modernLess universal (but growing)GeoJSON.geojsonHuman-readable, web-friendlyLarge file sizes, less preciseKML/KMZ.kml/.kmzGoogle Earth compatibleLimited attribute supportGPS Exchange.gpxGPS device standardLimited to points/tracks Raster formats FormatExtensionProsConsGeoTIFF.tifUniversal, supports metadataCan be largeASCII Grid.ascHuman-readableVery large, slowNetCDF.ncGreat for time series, climate dataComplex structureERDAS Imagine.imgCommon in remote sensingProprietary Recommendation: GeoPackage for vector, GeoTIFF for raster when possible Coordinate Reference Systems (CRS) Why CRS matters The Earth is round; maps are flat Different systems optimize for different purposes Mismatched CRS = misaligned data = errors Geographic vs. Projected CRS Geographic (unprojected) Units: degrees (latitude/longitude) Common system: WGS84 (EPSG:4326) Good for: storing raw coordinates, GPS data, global datasets Limitation: distances and areas distorted Projected Units: meters or feet Examples: UTM zones, State Plane, Albers Equal Area Good for: measuring distances, calculating areas, local/regional analysis Limitation: distortion increases away from projection center EPSG codes Standardized numeric codes for CRS Common codes to know: 4326 = WGS84 (GPS coordinates) 4269 = NAD83 (North America) 32612 = UTM Zone 12N (Arizona/Utah region) How to check CRS in R st_crs(my_shapefile) crs(my_raster) Transforming between CRS st_transform(my_data, crs = 32612) project(my_raster, “EPSG:32612”) Common CRS problems and solutions Data won’t overlay → check and match CRS Distance calculations wrong → project to appropriate local CRS Area calculations wrong → use equal-area projection “NA” or missing CRS → assign with st_set_crs() (only if you know the correct CRS!) Reading and Writing Spatial Data in R The sf package (vector data) Modern standard, tidy-friendly st_read() and st_write() Works with dplyr verbs library(sf) "],["read.html", "Chapter 21 Read", " Chapter 21 Read plots &lt;- st_read(“sampling_plots.shp”) study_area &lt;- st_read(“boundary.gpkg”) "],["check-structure.html", "Chapter 22 Check structure", " Chapter 22 Check structure class(plots) st_geometry_type(plots) st_crs(plots) "],["write.html", "Chapter 23 Write", " Chapter 23 Write st_write(plots, “output.gpkg”) The terra package (raster data) Successor to raster package rast() to read, writeRaster() to write library(terra) "],["read-1.html", "Chapter 24 Read", " Chapter 24 Read elevation &lt;- rast(“dem.tif”) "],["check-properties.html", "Chapter 25 Check properties", " Chapter 25 Check properties res(elevation) ext(elevation) crs(elevation) "],["write-1.html", "Chapter 26 Write", " Chapter 26 Write writeRaster(elevation, “output.tif”) Worked example: Load study area boundary, sampling points, and elevation raster; verify all share the same CRS Basic Spatial Operations Vector operations Buffering — st_buffer() Clipping/intersection — st_intersection() Spatial joins — st_join() Calculating area — st_area() Calculating distances — st_distance() Raster operations Cropping — crop() Masking — mask() Extracting values at points — extract() Resampling — resample() Reclassifying — classify() Vector-raster interactions Extract raster values at point locations Zonal statistics within polygons Converting between formats Worked example: Extract elevation, slope, and aspect values for vegetation sampling plots Visualizing Spatial Data Quick plots for exploration plot(st_geometry(study_area)) plot(elevation) Publication-quality maps with ggplot2 + sf ggplot() + geom_sf(data = study_area, fill = “lightgray”) + geom_sf(data = plots, aes(color = treatment)) + theme_minimal() Adding basemaps ggmap for Google/Stamen tiles maptiles for OpenStreetMap Interactive maps with leaflet or mapview Great for data exploration and sharing mapview(plots) Spatial Autocorrelation What is spatial autocorrelation? Nearby locations tend to have similar values Positive autocorrelation: similar values cluster (most common in ecology) Negative autocorrelation: dissimilar values cluster (rare) Zero autocorrelation: spatial randomness Why it matters for statistics Violates independence assumption Inflates effective sample size Increases Type I error (false positives) Standard errors are too small Ecological examples Soil nutrients clustered by parent material Species abundance clustered by dispersal limitation Disease prevalence clustered by transmission Detecting spatial autocorrelation Visual methods Map residuals from your model Look for spatial clustering of positive/negative residuals Moran’s I Most common test Ranges from -1 (dispersed) to +1 (clustered), 0 = random Requires defining spatial neighbors/weights library(spdep) "],["create-neighbor-list.html", "Chapter 27 Create neighbor list", " Chapter 27 Create neighbor list coords &lt;- st_coordinates(plots) nb &lt;- dnearneigh(coords, d1 = 0, d2 = 1000) # neighbors within 1km weights &lt;- nb2listw(nb, style = “W”) "],["test-residuals.html", "Chapter 28 Test residuals", " Chapter 28 Test residuals moran.test(residuals(my_model), weights) Variograms Shows how variance changes with distance Useful for determining range of autocorrelation Key parameters: nugget, sill, range library(gstat) vario &lt;- variogram(response ~ 1, data = plots) plot(vario) Correlograms Moran’s I calculated at multiple distance classes Shows at what scales autocorrelation occurs Dealing with Spatial Autocorrelation Design-based solutions (prevention) Increase spacing between samples Stratified or systematic sampling GRTS sampling (balances spatial spread) Model-based solutions (accommodation) Include spatial covariates Add coordinates as predictors (crude but sometimes sufficient) Add spatially-structured environmental variables Spatial regression models Spatial lag models — autocorrelation in response Spatial error models — autocorrelation in residuals spatialreg package Geostatistical models Model the correlation structure explicitly Kriging for prediction gstat package Mixed models with spatial correlation Add spatial correlation structure to residuals nlme::lme() with correlation = corSpatial() glmmTMB with spatial random effects Generalized Least Squares gls() with spatial correlation structures Decision framework: When to worry about spatial autocorrelation Always check residuals spatially If significant autocorrelation exists, consider: Scale of autocorrelation vs. scale of inference Purpose of model (prediction vs. hypothesis testing) Available sample size for more complex models Special Considerations for Ecological Field Data GPS accuracy and precision Consumer GPS: ± 3-5 meters typical Differential GPS: sub-meter Canopy cover reduces accuracy Always record metadata about GPS equipment Datum shifts NAD27 vs NAD83 can differ by tens of meters Always document and verify datum Scale and extent Grain: finest spatial resolution Extent: total area covered Ecological patterns are scale-dependent Match analysis scale to question scale Edge effects Sampling near boundaries can bias results Buffer study areas when possible Modifiable Areal Unit Problem (MAUP) Results can change depending on how you aggregate spatial data Be consistent and justify choices Key Takeaways Always check and document your CRS Match CRS before combining datasets Use projected CRS for distance and area calculations Spatial autocorrelation violates independence — check your residuals Prevention (good sampling design) is easier than cure (complex models) The sf and terra packages are your friends Test Your Knowledge Conceptual questions What is the difference between geographic and projected coordinate systems? Why does spatial autocorrelation inflate Type I error rates? When would you use vector vs. raster data? Applied exercises Given two datasets that won’t overlay, diagnose the CRS problem Calculate Moran’s I on model residuals and interpret results Create a variogram and identify the range of spatial autocorrelation Assignment For your project data: Document the CRS of all spatial datasets Create a map showing sampling locations and study area If applicable, extract environmental covariates from rasters at your sample points After fitting a preliminary model, map residuals and test for spatial autocorrelation Discuss implications for your analysis "],["species-distribution-modeling.html", "Chapter 29 Species Distribution Modeling 29.1 Introduction 29.2 A brief review of niche theory 29.3 Downloads for this lab 29.4 Objectives 29.5 Methods", " Chapter 29 Species Distribution Modeling 29.1 Introduction Species distribution models (a.k.a.; ecological niche models, habitat models) relate environmental predictors like climate, elevation, or soil characteristics to species presence or abundance. These relationships are used to project likelihood of occurrence across space, by calculating the likelihood of occurrence across the study area using values associated with raster maps of the environmental variables in the model (Fig. 1). Most SDMs are correlative models that mathematically describe observed patterns of occurrence, and that do not incorporate underlying mechanisms in model projections. Understanding the limitations of correlative models (discussed below) is important for deciding when to use these models and interpreting your results. Figure 1. Raster layers are stacked to predict likely habitat. 29.2 A brief review of niche theory In spatial and population ecology, we define a species’ niche as all the conditions under which populations of a species maintain growth rates that are at or exceed replacement rates. The niche is often defined in n dimensional space, since so many factors contribute to the performance of a species (Fig. 2). In ecology, there tends to be a lot of confusion about spatial niche concepts, since ecology students often first learn about species niches from an evolutionary standpoint. In evolutionary ecology, a species’ niche is defined by a suite of traits possessed by an organism related to how this species ‘makes its living’ (attains food, nutrients, water). However, niche concepts and definitions are inherently related, and broadly describe the role of species within ecosystems. Figure 2. Species niches are complex. In theory, we could describe the niche of a species by adding N number of axes and create a cloud representing all the habitats where a species could persist. Ecologists break a species niche into two components: the fundamental niche and the realized niche. The fundamental niche is similar to the Grinnellian niche concept (Introduced by Joseph Grinnell in is 1917 paper, The niche relationships of the California Thrasher) niche concept. The fundamental niche of the species describes all the abiotic conditions that a species can physiologically tolerate and maintain population growth at or above replacement rates (we don’t count areas where species persist, but are not maintaining themselves; these area are known as demographic sinks). The realized niche refers to all of the areas that we actually observe a species on the landscape. The concept emerged out of the work of Elton, who highlighted the importance of species interactions in defining species distributions. The realized niche, therefore, reflects the combined effects of the abiotic and biotic environment on persistence across the landscape. Typically, the fundamental niche is larger than the realized niche. In other words, a species can be found in a lot of places, but processes such as competition for resources or predation, reduce the total area occupied by a species. In some cases, the realized niche can be larger than the fundamental niche. This occurs when positive species interactions, like mutualisms or facilitation, allow a species to overcome some sort of environmental resistance and occupy sites that would be inhospitable for the species without ‘help from a friend’. Finally, stochastic events, like disturbances, or landscape features, such as barriers to dispersal, can influence where as a species is found on the landscape. The distinction between fundamental and realized niches is important in order to understand the limitation of correlative SDMs, since these models cannot distinguish between the fundamental and realized niche of a species. Recall that species distribution models relate environmental factors to current occupation of a species. In most cases, habitat suitability is predicted using abiotic factors, including climate, soils, topographic information; all of which essentially describe the fundamental niche of a species (i.e., physiological tolerance to abiotic characteristics). However, the data used to build these models quantifies the current occupation of a species on the landscape, or the realized niche. This presents several issues: While we can learn generally about the abiotic factors that affect a species range, it is not a perfect picture of these tolerances, since distribution is affected by a variety of factors not included in the model. When a species fundamental niche and realized niche are really different due to factors not included in the model, current habitat projects can be inaccurate. This is a common problem when modeling habitat suitability for wild-harvested species, since they are underrepresented in suitable habitat, because those habitats are targeted for harvest. Using these models to predict future suitability should be interpreted skeptically. Future habitat suitability predictions are strong working hypotheses for ecological investigations or management actions. We don’t actually expect many species to track their bioclimatic niches, since many of the factors that influence a species range aren’t directly measured when building SDMs. SDMs are particularly unreliable when factors that shape a species niche change as a function of climate change. For instance, species interactions shape species distributions, and since species respond idiosyncratically to climate change, represent a major source of uncertainty in model predictions. These caveats and limitations, particularly related to your data, should be included in the discussion of your results. All of that said, SDMs can provide us with a lot of information with relatively little effort, and are often the best hypothesis on which to base decisions. 29.3 Downloads for this lab Create a file on your desktop called ‘speciesdistributionmodels’ and place the following files within it: R script for creating the SDM Occurrence data Worksheet to turn-in 29.4 Objectives Project the effects of climate change on Pinus ponderosa in Arizona. 29.5 Methods 29.5.1 Let’s get modeling Now, let’s walk through an example to discuss the various considerations and options for creating SDMs. For this exercise, we will use bioclimatic variables as environmental predictors. Bioclimatic variables are derived from downscaled climate models and created to be more more ecologically relevant compared to simple temperature and precipitation means. Bioclimatic variables are a great first step in model building, but depending on your study species and area, you may need to download finer scale layers or include other factors, like soil data. Resolution Raster layers are spatially mapped grids comprised of hundreds, thousands, or millions of cells (aka pixels) with values related to a variable assigned to each pixel. The smaller the pixel, the higher the resolution, but this greatly affects processing speed and may exceed computer storage. Map projections Different methods are used to project the 3D earth into a 2D map. We have to specify the projection of the layers used in our models or our data layers will not align properly. In the example below, we will specify a coordinate reference system (CRS), which defines, with the help of coordinates, how the projected map relates to locations on the earth. A CRS contains the following information: Coordinate system: The X, Y grid that defines where a point is located in space. Horizontal and vertical units: The units used to define the grid along the x, y (and z) axis. Datum: A modeled version of the shape of the Earth which defines the origin used to place the coordinate system in space. You will learn this further below. Projection Information: The mathematical equation used to flatten objects that are on a round surface (e.g. the Earth) so you can view them on a flat surface (e.g. your computer screens or a paper map). Luckily, we can pull all of this information from a spatial object, use the CRS function and reproject our data so that we are working with all data using the same CRS. Let’s start by installing and loading the libraries that we will need for our analysis, and by importing both current climate and future climate projections. For this exercise, we will download bioclimatic variables to characterize current climate. Bioclimatic variables are variables derived from mean, maximum and minimum temperature and precipitation data summarized from weather station data from across the globe, then interpolated based on various landscape features, most importantly elevation, in order to assign climatic values to locations with no climate stations. These bioclimatic variables have been created in order to represent climate data in a way that is biologically-relevant. Specifically, these bioclimatic include: Annual Mean Temperature (bio1) Mean Diurnal Range (Mean of monthly (max temp - min temp); bio2) Isothermality (bio3), Temperature Seasonality (standard deviation ×100; bio4) Max Temperature of Warmest Month (bio5) Min Temperature of Coldest Month (bio6) Temperature Annual Range (bio7) Mean Temperature of Wettest Quarter (bio8) Mean Temperature of Driest Quarter (bio9) Mean Temperature of Warmest Quarter (bio10) Mean Temperature of Coldest Quarter (bio11) Annual Precipitation (bio12) Precipitation of Wettest Month (bio13) Precipitation of Driest Month (bio14) Precipitation Seasonality (Coefficient of Variation; bio13) Precipitation of Wettest Quarter (bio16) Precipitation of Driest Quarter (bio17) Precipitation of Warmest Quarter (bio18) Precipitation of Coldest Quarter (bio19). Additionally, we will download climate projections. Climate projections are generated by Global Climate Models, which predict future climatic conditions based on complex algorithms describing the atmosphere. In order to project future species distributions, we need to select a particular climate model and a time period for which we are making predictions. Here, we are projecting suitable habitat for the time period 2061-2080. Since several facilities equipped with climate models generate climatic projections, we also have selected the CNRM-CM6-1 modeling group. Finally, we select the ‘socio-economic pathway’ utilized by our climate model. The degree of warming that occurs depends primarily on decisions that humans make around fossil fuel use and other climate mitigation strategies. The Intergovermental Panel on Climate Change (IPCC) works with social scientists, legislators and other to generate possible carbon use futures, which are then used to generate climate predictions. Here, we will use the Shared Socio-economic Pathway (SSP) ‘585’. Take a minute to search SSP 585. Record the answers to these questions on your worksheet: Provide a description of SSP 585. How do countries respond to climate change in this scenario? What climate-related technologies are assumed to be used in this future? Is a low, middle-of-the-road, or high degree of warming predicted in this scenario? If you were to repeat this exercise, which SSP would you choose and why? 29.5.2 Run the R code Load your R file run and walk through the exercise. Now that we’ve loaded our current and future climate models, let’s input our occurrence data. For our data on species occurrence, we will use data from the Global Biodiversity Information Facility (GBIF), a repository for species observations and locations derived from multiple sources, including citizen science, herbarium and museum collections. The GBIF data are biased by observer behavior, since many observations are derived from citizen science projects. Humans tend to collect data from easily accessed areas around roads, popular hiking trails or congregating areas. One way to reduce bias in presence only data is to use spatial thinning to reduce weighting observations from heavily trafficked areas more than observations made in other areas. There is no standard thinning distance, but it is typical to require a minimum of 5 km between observations. If you are working at smaller or larger scales, you could reduce or increase this distance! Also, if you are using presence and absence data or have employed an unbiased sampling strategy to collect data, you can skip this next step. While there are various quality control measures used by GBIF to ensure high data quality, we will run a few other data cleaning codes to remove anomalous points. This step is not necessary if using nonGBIF data! However, when producing your own spatial datasets, some form of data quality control is necessary. For this exercise, we will investigate whether models predict that Ponderosa pine forests that surround Flagstaff are predicted to persist as climate changes. Let’s download occurrence data for Ponderosa pine (Pinus ponderosa). Great! Now we have data! Let’s build an SDM. Our first decision point on model construction is based on the response variable. In this case, we have presence-only data; in other words, no one went out to the field to confirm locations where a species is absent across the landscape. Since location information often suffers from absence of absence data (ha), researchers have found statistical workarounds, which produce amazingly similar results to models fitted with presence or absence data. The method most commonly used to model habitat suitability with presence-only data involves generated numerous background points across your study area to compare with areas where your species is present. Note that your focal species could occur at any one of these background points, but that doesn’t matter. Essentially your model is characterizing habitat available to the species and the habitat of known occurrence to identify the environmental factors that best distinguish occupied habitat. Let’s breakdown the major model types used for SDMs: Profile techniques Profile techniques are simple algorithms that use environmental distance to known sites of occurrence to ‘profile’ habitat characteristics. These techniques are rarely used any more, so I won’t discuss further! Profile techniques include: Mahalanobis distance Ecological niche factor analysis (ENFA) Isodar analysis Bioclim Regression-based approaches You are familiar with regression based approaches from other statistical analyses! All regression approaches build upon standard regression models (Fig. 3), but differ in subtle ways to address common challenges to data modeling, like issues of nonnormality or heterogeneity of variance. Figure 3. Regression basics. Term y is related to term x. If the slope of the line differs significantly from 0, then there is a relationship between the variables. Error terms are derived from the residuals of the model; how much each individual point deviates from the line of best fit. The best fit is determined by repeatedly mapping lines across the data to identify that which most reduces error. Regression-based techniques include: Generalized Linear Modeling (GLM) (parametric) Flexible Discriminant Analysis (FDA) (parametric) Multivariate Adaptive Regression Splines (MARS) (nonparametric) Generalized Additive Modeling (GAM) (nonparametric) Generalized Linear Models are a flexible form of regression models. GLMs are ‘generalized’ by using a link function to relate the linear model to the response variable (which can be binomial, continuous, count data or other) and by relativizing the variance of each model term to its predicted value. Generalized Additive Models incorporate ‘smoothing functions’ to allow nonparametric estimates to be generated using a Bayesian approach. Multivariate Adaptive Regression Splines automatically models data nonlinearities and interactions between variables. Flexible Discriminant Analysis uses optimal scoring to transform the response variable so that the data are in a better form for linear separation. Machine learning approaches: Machine learning techniques use training data to ‘learn’ about the dataset in order to make predictions. Machine learning approaches include: Random Forest (RF) Boosted Regression Trees (BRT) Maximum Entropy (MaxEnt) There are other machine learning techniques, like Artificial Neural Networks (ANN), but the list above is most commonly used for distribution modeling! Random forest and boosted regression trees are similar, in that they create different ‘trees’ by iteratively bifurcating the dataset using predictor factors and identifying the tree that best predicts species occurrence. Figure 4. An illustration of random forest tree construction. MaxEnt models are a little different. According to the principle of maximum entropy, high entropy is when the probability distribution best represents the current state of knowledge about a system, in the context of precisely stated prior data. These models evaluate the set of all trial probability distributions that would encode the prior data and select the distribution with maximal information entropy. 29.5.2.1 Model selection The world of species distribution modeling is a contentious one! Many leaders in the field have their own ‘pet’ models that invariably they helped to develop software or methodology for! The general consensus is that each of the different modeling techniques has various strengths and weaknesses, and they should be combined into ensemble models for habitat predictions. However, other approaches exist. One line of thinking in distribution modeling is to use solely GLMs, spending great care to identify critical predictor variables in a way that is tied to current ecological understanding and that reduces nonlinearities among these variables. By taking these steps, models are created, which in theory, should provide better inferential power for both current and future habitats. For presence only data, maximum entropy models are generally considered an excellent model choice. In my experience, there is no perfect model, rather model accuracy varies from species to species. For this reason, I typically build ensemble models to integrate the strengths of different model types. 29.5.2.2 Build an SDM Deal with environmental predictor colinearity In general, it is recommended to avoid having correlated features (variables that have different numbers, but are following the same pattern) in your dataset. Indeed, a group of highly correlated features will not bring additional information to our analyses, but will increase the complexity of the algorithm, thus increasing the risk of errors. Including highly correlated variables in models also, in essence, weights the correlated variables more than independent variables, again leading to less accurate model outputs. In other words, we need to remove highly correlated variables. We will do this by generating Variable Inflation Factor (VIF) values, a measure of collinearity, for all predictor variables. Then, we will remove one of the two correlated variables. Build the dataframe for the SDM Building the SDM, requires two additional steps. In the first, we assemble the final dataset to be used in the model. Using the sdmData function, we indicate the following: The column that contains presence data. The environmental predictors. Absence data or how to create background data. Specify model evaluation parameters When we build the final model using the SDM function, we specify replication. Replication is the method used to partition the dataset into training and test data. Ideally, we would have collected completely independent training and test datasets; however, I’ve never actually seen this done, except for researchers who are investigating SDM methods. Ninety nine point nine percent of the time, datasets are split into test and training datasets. As the names imply, training data are used to build the model, and then test data are used to measure how good our predictions are by quantifying how often our model correctly predicts presence or absence. Splitting or partitioning data into test and training datasets is often conducted several times, since outcomes may depend on the test or training data used to build and evaluate models. There are several methods to create training and test datasets. The three available in the package that we will use are subsampling (sub), crossvalidation (cv), bootstrapping (boot). For sub and boot, you must indicate what proportion of test and training data. A 30% test data, 70% training data split is common (test.percent=30). Finally, you will also the models how many times to repeat evaluations using the n equals code. This can eat up a lot of memory, so I typically use an n of 5. Choosing the evaluation model Crossvalidation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, in most methods, multiple rounds of crossvalidation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to give an estimate of the model’s predictive performance. Crossvalidation does not rely on random sampling, but rather splits the dataset into k unique subsets. This is the preferred method for spatial model evaluation and estimating generalization capability. Note that you have to select the number of ‘folds’ or data partitions, which is typically set at 5. Bootstrapping iteratively creates separate datasets from randomly sampling with replacement. Bootstrapping it is not as strong as crossvalidation when it is used for model validation, since it contains repeated elements in every subset. Bootstrapping is typically repeated 30 times in SDM model evaluation! Subsampling randomly splits the dataset into training and test datasets, but doesn’t maintain the independence of the datasets. In other words, due to random sampling, you might wind up with similar training and test datasets in each trial. For this reason, the more structured crossvalidation method is typically preferred. Build the SDM Once the data is appropriately compiled, we use the sdm function to build the actual model. Within this function, we specify: The column that contains presence or presence or absence The dataframe that we are using (d1) The types of models that we are using Replication type (cv), number of folds (5), how many times to repeat partitioning (1) THIS STEP WILL TAKE SOME TIME - JUST LET THE PROGRAM RUN! The model object (m1) tells you several things. First, it gives a brief summary of the model you ran. You can double check this to be sure that the model did what you told it to do. Here, everything seems fine: We ran a model for one species, we used two modeling methods, glm and maxent, we used cross_validation with 5 partitions. The model runs were successful (100% each). Finally, we are provided with 4 measures of model performance: AUC, COR, TSS, and Deviance. What types of models are we using to predict habitat suitability for Ponderosa pines (i.e., machine learning, regression, profile techniques)? 29.5.2.3 Model evaluation explained AUC stands for Area Under the Curve. AUC refers to a ROC plot, which plots sensitivity over 1 minus specificity. An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. AUC is desirable for SDM model evaluation for two main reasons: AUC is scale invariant. AUC is classification threshold invariant. It measures the quality of the model’s predictions irrespective of what classification threshold is chosen. This curve plots two parameters: True Positive Rate (Sensitivity): the proportion of presences correctly predicted as presence, False Positive Rate (1 minus Specificity): The specificity denotes the proportion of absences that are correctly predicted as absence, so the false positive rate indicates how many times the model predicted an occurrence when there was none. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. As a rule, an AUC &gt; 0.75 indicates a high performing model. SDMs predict a probability of occurrence across the landscape. Different thresholds can be used to create a cutoff to predict presences or absences. For instance, we could say that if there is a 90% chance or more that a pixel is suitable habitat, then we consider those areas as occupied. We want to identify a cutoff that maximizes true presences, while minimizes false positives (i.e., areas that you incorrectly say contain a population, but don’t). You can see that as you decrease the cutoff, from say 90% to 70%, then your likelihood of correctly predicting presences goes up, BUT so does your likelihood of false positives. So, let’s check out the ROC plot below. Looking at AUC, a common form of model performance assessment, which is the best performing model? Generally, there is strong agreement between the test and the training data. As you increase the cutoff threshold, the likelihood that you correctly assign presence goes up, but so does the false positive rate (Fig. 5). Note that on the far right hand side of each ROC plot, if the cutoff is high enough, you will have a 100% true positive rate, and a 100% false positive rate (the cutoff is so low, that all habitats are predicted to support the focal species). Alternatively, with a low enough cutoff (left hand side of the ROC plot), you won’t have any positives or any false positives! This AUC cutoff will be important for building ensemble models; explained below! Figure 5 This figure (lifted from an ARCGIS website) shows the relationship between omission rates and ROC plots. So if we want an Omission Rate that is slightly less than 10%, we can use 0.29 as the Cutoff instead, and in this case, we will pick up 20.48% background points as potential presence locations, which is also a good rate. Like AUC, True Skill Statistic (TSS) values are calculated across the range of possible thresholds for classifying model scores.The TSS similarly incorporates sensitivity and specificity comparing models against random, yielding values that range from negative 1 to positive 1, where positive 1 indicates perfect prediction and greater than or equal to 0 indicates a model that performs no better than random. TSS is typically considered a better indicator of model performance for presence only models. A TSS of 0.5 or higher indicates high model performance. Pearson correlation (COR) between the predicted likelihood of presence and the presence or absence testing data. Deviance Lastly, if a model is interpreted as estimating species’ probability of presence, rather than just giving an index of habitat suitability, then the model predictions can be evaluated using deviance, defined as 2 times the log probability of the test data. 29.5.2.4 Ensemble model assembly Finally, we will merge models into an ensemble model. You may want to exclude models that didn’t have high predictive performance. We will give higher weights to the models with higher accuracy, in this cause using the TSS score. 29.5.2.5 Investigating model components We can run code to look at the model components that best predict presence. According this figure, which climatic variable best predicts habitat suitability for Ponderosa pine? 29.5.2.6 Convert to presence or absense predictions We use the test statistics to identify a threshold that maximized true positives and reduced false negatives. In order to do this, we will create a new raster and populate it with predictions of presence, using that threshold. 29.5.2.7 Plotting and predictions Let’s take a quick look at the predictions we have created for the current time period. To predict response of your focal species to future climate, just plug the novel climate conditions into the model! Let’s run this model. Now, let’s plot this prediction against our original! First, we’ll take a zoomed out look, then we will focus into our region! Let’s convert to predicted occurrence and plot! According to these maps, how will the amount of suitable habitat for Pinus ponderosa in Flagstaff change if climate change continues along the SSP 585 projection? How certain are you of these projections? Why might these models NOT be accurate? What type of vegetation do you think might be more common around Flagstaff as climate changes? Submit your answers to the questions presented throughout this tutorial and the figures that you generated (Occurrence of Pinus ponderosa currently and in the future) to your TA. "],["diversity-statistics.html", "Chapter 30 Diversity statistics 30.1 iNext 30.2 Coverage‐based R/E sampling curves 30.3 Data manipulation", " Chapter 30 Diversity statistics How do we describe the variety of species, traits or phylogenies in a particular area? With diversity statistics! Simple species counts, or species richness, is a time-old method for describing diversity. Since the olden days of creating ‘species lists’ for every habitat under the sun, new methods have emerged to describe the variety of life within ecological communities. These statistics attempt to deal with a problem inherent to diversity assessments: It is really hard to find all the species within an ecosystem and the more you look, the more species you find! There are a variety of different diversity statistics, which vary in terms of how much they weight relative abundances of species. These metrics are: Species richness: Simple counts of species in an area. Common species and rare species are given the same weight, since each species no matter how abundant it is, increases species richness by 1 unit! Includes no measure of evenness. Evenness is a measure of relative abundance of species at a site. The more equal species are in proportion to each other the greater the evenness of the site. The Shannon diversity index is a diversity index based on both richness (species counts) and evenness (relative abundance). The Simpson diversity index, like the Shannon diversity index, combines richness and evenness, but more strongly weights evenness relative to richness. These three metrics, richness, Shannon diversity and Simpson diversity index can be expressed as Hill numbers, or the effective number of species. The advantage of using Hill numbers, rather than generating diversity metrics using other indices, is that they are more easily interpreted, since they follow the doubling rule, and more easily compared to better understand diversity in a system. Hill numbers are parameterized by a diversity order q, which determines the measures’ sensitivity to species relative abundances. Hill numbers include the three most widely used species diversity measures as special cases: species richness (q = 0), Shannon diversity (q = 1) and Simpson diversity (q = 2). Specifically: \\[^qD = \\left(\\sum_{i=1}^{S} p_i^q\\right)^{1/(1-q)}\\] When q = 0, \\(^0D\\) is simply species richness, which counts species equally without regard to their relative abundances. For q = 1, the equation above is undefined, since 1/0, but the limit as q tends to 1 is the exponential of the familiar Shannon index, referred to as Shannon diversity. The measure for q = 1 counts individuals equally and thus counts species in proportion to their abundances; the measure \\(^1D\\) can be interpreted as the effective number of common species in the assemblage. The measure for q = 2 (\\(^2D\\)), referred to as Simpson diversity, discounts all but the dominant species and can be interpreted as the effective number of dominant species in the assemblage. The doubling rule refers to the fact that as a species assemblage goes from 8 species to 16 the calculated Hill numbers double. This seems like, of course, that would be the case, BUT diversity indices like the Shannon entropy (“Shannon-Wiener index”) and the Gini-Simpson index do not follow the doubling rule! By calling all of these indices “diversities” and treating them as if they were interchangeable in formulas or analyses requiring diversities, we will often generate misleading results.So, Hill numbers are true diversities (also referred to as the effective number of species), rather than just indices of diversity, unanchored to the actual diversity at a site. In other words, a community with eight equally-common species has a diversity of eight species, or a community with S equally-common species has a diversity of S species. This definition behaves as we expect of a diversity; the diversity of a community of sixteen equally-common species is double that of a community with eight equally-common species. One reason to calculate the effective number of species rather than diversity indices is that it allows straightforward and intuitive comparisons among communities. The goal in many diversity analyses is to make fair comparison of diversities across multiple assemblages that may vary in the size of their species pools or in the way in which they are sampled. Diversity metrics are strongly affected by both search time and search area. Even when researchers standardize search effort, both in terms of time spent surveying a plot and by plot area, diversity metrics are extremely sensitive to the diversity of the community itself. A more diverse community with high unevenness (i.e., lots of rare species) would require more search effort to estimate true diversity relative to a low diversity community with high evenness. For that reason, even when we’ve established appropriate sampling stategies, we have to standardize communities in order to compare them. For this reason, community ecologists use statistical techniques like extrapolation and rarefaction to estimate the ‘true’ number of species within an area based on your sample. Rarefaction deals with unequal sampling by down-sampling the larger samples until they contain the same number of observed individuals or sampling units as the smallest sample. In the past, rarefaction was the principal means to compare assemblages. When using rarefaction, you lose data, since you cull your other assemblages to be equivalently comparable with your “worst” sample. For this reason, many community ecologists now choose to generate asymptotic estimates of diversity, which involves combining rarefaction with extrapolation. To calculate asymptotic diversity estimates, you first generate a rarefaction/extrapolation sampling curve (R/E curve) that estimates diversity over a series of sampling units. Diversity estimates below your sample’s observed diversity estimate is derived from rarefaction (referred to as the sample-size-based approach to standardize data based on sample effort), and estimates above the observed diversity are derived from extrapolation. There are several ways of extrapolating diversity data beyond your actual sample. Parametric methods extend the species accumulation curve by fitting parametric functions. Most commonly, however, a non-parametric method that uses the frequency of rare species in a sample is used for extrapolating samples (a method developed by Alan Turing when designing the enigma machine). This approach standardizes data based on sample completeness, an estimated assemblage characteristic. Sampling completeness is the ratio between the detected and estimated diversity and indicates the proportion of detected species. The comparison between detected and estimated diversity is made by calculating and comparing sample coverage (thus these methods for extrapolating data are referred to as coverage-based approaches), or the total relative abundances of the observed species. The sample completeness curve provides a bridge between the size- and coverage-based R/E sampling curves. In other words, since sample completeness can be calculated for rarefied samples (i.e., use your actual data to compare detected to estimated diversity), sample completeness can be used to anchor and unite the rarefaction and extrapolation curves. By combining R/E curves to estimate of diversity and expressing diversity estimates as Hill numbers, iNEXT is a great all around package to compare diversity among assemblages of ecological data. This framework allows ecologists to compare of the species diversity of different assemblages in time or space, with reliable statistical inferences about these comparisons. 30.1 iNext What type of data do you have? The first decision to make is to determine what type of data you will analyze. For calculating diversity statistics, there are two principle forms of diversity data: Abundance data are data that include a measure of abundance - This could be data with counts of species or that includes cover data. When R/E curves are generated, the sampling unit is an individual. For example, to generate rarefaction curves, rarefied assemblages are created by randomly removing individuals within an assemblage. Note that many ecological studies collect abundance data within a plot or quadrat. In these cases, species are not independently sampled, and many ecologist recommend converting these datasets to incidence data (discussed below) to calculate diversity estimates, while others simply treat it as abundance data. Currently, statisticians are deriving methods to deal with sample-based abundance data (see Chui 2023) again using Turing’s methods of estimate completeness - hopefully, these new equations are integrated into the iNEXT package soon! Sample-based incidence data are data that note whether a give species is present or absent, and does not include information on how abundant that species is within an assemblage. In these cases the sampling unit is a trap, net, quadrat, plot, or timed survey. For sample-based incidence data, the sampling units (i.e., plots, quadrats, etc.), rather than individuals, are removed to generate rarefied diversity estimates. Note that for both abundance data and incidence data, the rarefaction process is repeated numerous times, allowing us to calculate confidence intervals (described in more detail below). There are two kinds of incidence input data for iNEXT: (1) incidence-raw data: for each assemblage, input data consist of a species-by-sampling-unit matrix; when there are N assemblages, input data consist of N matrices via a list object, with each matrix being a species-by-sampling-unit matrix. In iNEXT, this type of data is specified by datatype=“incidence_raw”. (2) Incidence-frequency data: input data for each assemblage consist of the number of sampling units (T) followed by the observed incidence frequencies (Y1, Y2, …, YS). Let’s check out a few of these examples. First, we will begin with the abundance dataset, spider. The spider dataset was collected at Harvard Experimental Forest. Researchers killed hemlock trees using two different methods (girdling or logging), in order to observe the effect of hemlock loss on the remnant community. Here, Sackett et al. (2011) provides abundance data for spiders collected on trees killed by girdling the trunk or by logging. library(iNEXT) library(tidyverse) #or #library(devtools) #install_github(&#39;AnneChao/iNEXT&#39;) #First let&#39;s check out two abundance datasets #Individual‐based abundance data (datatype=&quot;abundance&quot;): Input data for each assemblage/site include species abundances in an empirical sample of n individuals (“reference sample”). When there are N assemblages, input data consist of an S by N abundance matrix, or N lists of species abundances. #Check out spider data(&quot;spider&quot;); spider ## $Girdled ## [1] 46 22 17 15 15 9 8 6 6 4 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 ## ## $Logged ## [1] 88 22 16 15 13 10 8 8 7 7 7 5 4 4 4 3 3 3 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #The spider dataset consists of abundance data from two canopy manipulation treatments (“Girdled” and “Logged”) of hemlock. Counts of individuals for species are provided for girdled and logged trees. #Go ahead and estimate diversity out &lt;- iNEXT(spider, q=c(0, 1, 2), datatype=&quot;abundance&quot;, endpoint=500) ggiNEXT(out, type=1, facet.var=&quot;Assemblage&quot;) The iNEXT functions calculates our R/E curve. There are several components of this function (taken from the package information): 1. The first term in the iNEXT function specifies the dataset. 2. Argument q allows you to select the type of diversity estimate that you are interested in. Here, we have chosen to calculate Hill numbers q = 0 (richness), 1 (Shannons), and 2 (Simpsons). 3. The argument datatype allows you to specify which type of data you are inputting (“abundance”, “incidence_raw” or “incidence_freq”). 4. The argument size to specify sample sizes for which diversity estimates are computed. If NULL, then diversity estimates will be calculated for those sample sizes determined by the specified/default endpoint and knots. 5. Argument endpoint is an integer specifying the sample size that is the endpoint for R/E calculation; If NULL, then endpoint=double the sample size of your assemblage (total sample size for abundance data; total sampling units for incidence data). As a general rule of thumb, for species richness, the size in the R/E curve can be extrapolated to at most double or triple the minimum observed sample size, guided by an estimated asymptote. For Shannon diversity and Simpson diversity, if the data are not too sparse, the extrapolation can be reliably extended to infinity to attain the estimated asymptote. 6. Knots an integer specifying the number of equally‐spaced knots between size 1 and the endpoint; default is 40. se a logical variable to calculate the bootstrap standard error and conf confidence interval. nboot an integer specifying the number of bootstrap replications; default is 50. Let’s take a look at another abundance dataset and use this next analysis to discuss the components of the output from the iNEXT function. The bird dataset consists of abundance tallies for birds at two sites: North site and South site. #Check out the other abundance dataset, called &#39;bird&#39; data(&quot;bird&quot;); bird ## North.site South.site ## Acanthiza_lineata 0 3 ## Acanthiza_nana 0 18 ## Acanthiza_pusilla 41 31 ## Acanthorhynchus_tenuirostris 0 2 ## Alisterus_scapularis 3 1 ## Cacatua_galerita 1 2 ## Cacomantis_flabelliformis 5 5 ## Calyptorhynchus_funereus 4 1 ## Colluricincla_harmonica 4 6 ## Cormobates_leucophaea 11 32 ## Corvus_coronoides 1 0 ## Dacelo_novaeguineae 2 0 ## Eopsaltria_australis 5 5 ## Gerygone_mouki 12 10 ## Leucosarcia_melanoleuca 1 1 ## Lichenostomus_chrysops 0 4 ## Malurus_cyaneus 0 6 ## Malurus_lamberti 0 6 ## Manorina_melanophrys 0 9 ## Meliphaga_lewinii 11 18 ## Menura_novaehollandiae 9 5 ## Monarcha_melanopsis 1 10 ## Neochmia_temporalis 0 9 ## Oriolus_sagittatus 1 0 ## Pachycephala_olivacea 0 2 ## Pachycephala_pectoralis 16 15 ## Pachycephala_rufiventris 0 3 ## Pardalotus_punctatus 15 17 ## Petroica_rosea 1 1 ## Phylidonyris_niger 0 2 ## Platycercus_elegans 2 7 ## Psophodes_olivaceus 7 7 ## Ptilonorhynchus_violaceus 2 2 ## Ptiloris_paradiseus 0 3 ## Rhipidura_albicollis 18 20 ## Rhipidura_rufifrons 8 14 ## Sericornis_citreogularis 0 2 ## Sericornis_frontalis 2 6 ## Strepera_graculina 3 4 ## Zoothera_lunulata 0 1 ## Zosterops_lateralis 16 17 #calculate diversity metrics for the bird dataset birdtest &lt;- iNEXT(bird, q=c(0,1,2), datatype=&quot;abundance&quot;, size=NULL, endpoint=NULL, knots=40, se=TRUE, conf=0.95, nboot=50) birdtest$AsyEst ## Assemblage Diversity Observed Estimator s.e. LCL UCL ## 1 North.site Species richness 27.00000 31.47772 9.776980 27.00000 50.64025 ## 2 North.site Shannon diversity 16.53585 17.96568 1.257434 15.50115 20.43020 ## 3 North.site Simpson diversity 11.84785 12.52375 1.298586 9.97857 15.06893 ## 4 South.site Species richness 38.00000 40.07655 8.043144 38.00000 55.84082 ## 5 South.site Shannon diversity 25.44707 27.25065 1.387661 24.53088 29.97041 ## 6 South.site Simpson diversity 19.63930 20.91318 1.488592 17.99559 23.83077 #plot your bird data ggiNEXT(birdtest, type=1, se=TRUE, facet.var=&quot;None&quot;, color.var=&quot;Assemblage&quot;, grey=FALSE) The iNEXT() function returns the “iNEXT” object, which includes three output lists (taken from the iNEXT package documentation): 1. $DataInfo for summarizing data information; 2. $iNextEst for showing size- and coverage-based diversity estimates along with related statistics for a series of rarefied and extrapolated samples; 3. $AsyEst for showing asymptotic diversity estimates along with related statistics. 4. $DataInfo, as shown below, returns basic data information including the reference sample size (n), observed species richness (S.obs), sample coverage estimate for the reference sample (SC), and the first ten frequency counts (f1‐f10). This part of output can also be computed by the function DataInfo() You can take a look at the entire output by calling ‘birdtest’ or you can grab the data that you will use in your analyses (like we did above), by calling ‘birdtest$AsyEst’. For each estimate, 95% confidence intervals are calculated by bootstrapping samples. In the size-based standardization (i.e., rarefaction), the sample size is fixed in each regenerated bootstrap sample. In the coverage-based standardization (i.e., extrapolated), for a given standardized coverage value, bootstrapping is again used, but using random draws based on simulated data. The result is that the sampling uncertainty is greater in the coverage-based standardization and the resulting confidence interval is wider than that in the corresponding size-based standardization. The bootstrapping default is 50, and since it is a random process expect CI to differ each time you calculate them. Now let’s look at incidence data. First let’s look at the tropical ant data (in the dataset ant included in the package) at five elevations (50m, 500m, 1070m, 1500m, and 2000m) collected by Longino &amp; Colwell (2011) from Costa Rica. The 5 lists of incidence frequencies are shown below. The first entry of each list must be the total number of sampling units, followed by the species incidence frequencies. #incidence dataset data(ant) str(ant) ## List of 5 ## $ h50m : num [1:228] 599 330 263 236 222 195 186 183 182 129 ... ## $ h500m : num [1:242] 230 133 131 123 78 73 65 60 60 56 ... ## $ h1070m: num [1:123] 150 99 96 80 74 68 60 54 46 45 ... ## $ h1500m: num [1:57] 200 144 113 79 76 74 73 53 50 43 ... ## $ h2000m: num [1:15] 200 80 59 34 23 19 15 13 8 8 ... Look at the second incidence dataset. The ciliates data were collected from three coastal dune habitats to demonstrate the use of the input datatype=“incidence_raw”. The data set (ciliates) included in the package is a list of three species-by-plot matrices. data(ciliates) str(ciliates) ## List of 3 ## $ EtoshaPan : int [1:365, 1:19] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:19] &quot;x53&quot; &quot;x54&quot; &quot;x55&quot; &quot;x56&quot; ... ## $ CentralNamibDesert : int [1:365, 1:17] 0 0 0 0 0 1 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:17] &quot;x31&quot; &quot;x32&quot; &quot;x34&quot; &quot;x35&quot; ... ## $ SouthernNamibDesert: int [1:365, 1:15] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:365] &quot;Acaryophrya.collaris&quot; &quot;Actinobolina.multinucleata.n..sp.&quot; &quot;Afroamphisiella.multinucleata.n..sp.&quot; &quot;Afrothrix.multinucleata.n..sp.&quot; ... ## .. ..$ : chr [1:15] &quot;x9&quot; &quot;x17&quot; &quot;x19&quot; &quot;x20&quot; ... #Run the following commands to get the output as shown below. out.raw &lt;- iNEXT(ciliates, q = 0, datatype=&quot;incidence_raw&quot;, endpoint=150) 30.2 Coverage‐based R/E sampling curves You can derive a single measure of diversity for the same coverage/sample to compare among communities using estimateD. #The following command returns the species diversity with a specified level of sample coverage of 98.5% for the ant data. For some assemblages, this coverage value corresponds to rarefaction (i.e., less than the coverage of the reference sample), while for the others it corresponds to extrapolation (i.e., greater than the coverage of the reference sample), as indicated under the method column of the output. estimateD(ant, datatype=&quot;incidence_freq&quot;, base=&quot;coverage&quot;, level=0.985, conf=0.95) ## Assemblage t Method Order.q SC qD qD.LCL qD.UCL ## 1 h50m 327.1646 Rarefaction 0 0.985 197.487977 185.909446 209.066507 ## 2 h50m 327.1646 Rarefaction 1 0.985 78.052670 76.033801 80.071538 ## 3 h50m 327.1646 Rarefaction 2 0.985 50.461029 49.039152 51.882906 ## 4 h500m 342.8592 Extrapolation 0 0.985 268.725933 243.783218 293.668647 ## 5 h500m 342.8592 Extrapolation 1 0.985 103.847150 99.512280 108.182020 ## 6 h500m 342.8592 Extrapolation 2 0.985 64.758264 62.125480 67.391048 ## 7 h1070m 158.9508 Extrapolation 0 0.985 123.608792 105.992796 141.224787 ## 8 h1070m 158.9508 Extrapolation 1 0.985 59.591818 57.112494 62.071142 ## 9 h1070m 158.9508 Extrapolation 2 0.985 41.775173 39.786274 43.764073 ## 10 h1500m 125.9590 Rarefaction 0 0.985 50.478877 42.105978 58.851776 ## 11 h1500m 125.9590 Rarefaction 1 0.985 26.248998 24.672980 27.825016 ## 12 h1500m 125.9590 Rarefaction 2 0.985 18.648902 17.411470 19.886334 ## 13 h2000m 104.6306 Rarefaction 0 0.985 12.909623 11.063489 14.755757 ## 14 h2000m 104.6306 Rarefaction 1 0.985 7.710717 6.927205 8.494229 ## 15 h2000m 104.6306 Rarefaction 2 0.985 5.794580 5.137574 6.451585 30.3 Data manipulation Scripts from the iNEXT package are fairly straightforward and easy to run. The challenge with these datasets is wrangling the data into the correct format for analysis. Since diversity statistics are often paired with NMDS data, let’s start with an example in which we wrangle data formatted for the Vegan package. library(readr) # Download and read the first dataset url1 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1c1guQTQwGNfA5Kx-xNPKRDsSJrBR-HxW&quot; env_matrix &lt;- read_csv(url1) # Download and read the second dataset url2 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1jCqfJPEuEWo4uNZfxW43VkSvEDDtayF5&quot; species_matrix &lt;- read_csv(url2) This data is incidence data collected at 3 replicate control plots and 6 treatment plots before and after disturbance. # Load necessary libraries library(tidyverse) print(colnames(species_matrix)) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; ## [4] &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; &quot;Aristida.purpurea&quot; ## [10] &quot;Aristida.schiedeana.var.orcuttiana&quot; &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; &quot;Asclepias.nyctaginifolia&quot; ## [16] &quot;Astragalus.sp&quot; &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; &quot;Bothriochloa.ischaemum&quot; ## [22] &quot;Bouteloua.curtipendula&quot; &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; &quot;Brickellia.betonicifolia&quot; ## [28] &quot;Brickellia.californica&quot; &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; &quot;Calliandra.humilis&quot; ## [34] &quot;Calliandra.humilis.var.reticulata&quot; &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; &quot;Coleogyne.ramosissima&quot; ## [40] &quot;Collinsia.parviflora&quot; &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; &quot;Cyperus.fendlerianus&quot; ## [46] &quot;Cyperus.sp&quot; &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; &quot;Desmanthus.cooleyi&quot; ## [52] &quot;Desmodium.batocaulon&quot; &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; &quot;Eragrostis.curvula&quot; ## [58] &quot;Eragrostis.intermedia&quot; &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; &quot;Eriogonum.wrightii&quot; ## [64] &quot;Escobaria.sp&quot; &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; &quot;Euphorbia.serpyllifolia&quot; ## [70] &quot;Evolvulus.sericeus&quot; &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; &quot;Glandularia.bipinnatifida&quot; ## [76] &quot;Glandularia.gooddingii&quot; &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; &quot;Heterosperma.pinnatum&quot; ## [82] &quot;Houstonia.wrightii&quot; &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; &quot;Lepidium.lasiocarpum&quot; ## [88] &quot;Lonicera.arizonica&quot; &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; &quot;Mimosa.aculeaticarpa&quot; ## [94] &quot;Mimosa.biuncifera&quot; &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; &quot;Muhlenbergia.longiligula&quot; ## [100] &quot;Muhlenbergia.sp&quot; &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; &quot;Packera.neomexicana&quot; ## [106] &quot;Pediomelum.tenuiflorum&quot; &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; &quot;Phemeranthus.parviflorus&quot; ## [112] &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; &quot;Polygonum.douglasii&quot; ## [118] &quot;Portulaca.umbraticola&quot; &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; &quot;Rhus.trilobata&quot; ## [124] &quot;richness_aggregated&quot; &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; &quot;Symphyotrichum.falcatum&quot; ## [130] &quot;Tradescantia.sp&quot; &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; &quot;Vulpia.octoflora&quot; ## [136] &quot;Xanthisma.gracile&quot; print(colnames(env_matrix)) ## [1] &quot;...1&quot; &quot;Year&quot; &quot;PlotN&quot; &quot;Treatment&quot; &quot;Treatment_status&quot; # combine the datasets, by hand or with code! combined_data &lt;- inner_join(species_matrix, env_matrix, by = c(&quot;...1&quot; = &quot;...1&quot;)) # Split the data into different groups control_pre &lt;- combined_data %&gt;% filter(Treatment == &quot;Control&quot; &amp; Treatment_status == &quot;PreTreatment&quot;) #remove unnecessary columns colnames(control_pre) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; ## [4] &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; &quot;Aristida.purpurea&quot; ## [10] &quot;Aristida.schiedeana.var.orcuttiana&quot; &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; &quot;Asclepias.nyctaginifolia&quot; ## [16] &quot;Astragalus.sp&quot; &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; &quot;Bothriochloa.ischaemum&quot; ## [22] &quot;Bouteloua.curtipendula&quot; &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; &quot;Brickellia.betonicifolia&quot; ## [28] &quot;Brickellia.californica&quot; &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; &quot;Calliandra.humilis&quot; ## [34] &quot;Calliandra.humilis.var.reticulata&quot; &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; &quot;Coleogyne.ramosissima&quot; ## [40] &quot;Collinsia.parviflora&quot; &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; &quot;Cyperus.fendlerianus&quot; ## [46] &quot;Cyperus.sp&quot; &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; &quot;Desmanthus.cooleyi&quot; ## [52] &quot;Desmodium.batocaulon&quot; &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; &quot;Eragrostis.curvula&quot; ## [58] &quot;Eragrostis.intermedia&quot; &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; &quot;Eriogonum.wrightii&quot; ## [64] &quot;Escobaria.sp&quot; &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; &quot;Euphorbia.serpyllifolia&quot; ## [70] &quot;Evolvulus.sericeus&quot; &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; &quot;Glandularia.bipinnatifida&quot; ## [76] &quot;Glandularia.gooddingii&quot; &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; &quot;Heterosperma.pinnatum&quot; ## [82] &quot;Houstonia.wrightii&quot; &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; &quot;Lepidium.lasiocarpum&quot; ## [88] &quot;Lonicera.arizonica&quot; &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; &quot;Mimosa.aculeaticarpa&quot; ## [94] &quot;Mimosa.biuncifera&quot; &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; &quot;Muhlenbergia.longiligula&quot; ## [100] &quot;Muhlenbergia.sp&quot; &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; &quot;Packera.neomexicana&quot; ## [106] &quot;Pediomelum.tenuiflorum&quot; &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; &quot;Phemeranthus.parviflorus&quot; ## [112] &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; &quot;Polygonum.douglasii&quot; ## [118] &quot;Portulaca.umbraticola&quot; &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; &quot;Rhus.trilobata&quot; ## [124] &quot;richness_aggregated&quot; &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; &quot;Symphyotrichum.falcatum&quot; ## [130] &quot;Tradescantia.sp&quot; &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; &quot;Vulpia.octoflora&quot; ## [136] &quot;Xanthisma.gracile&quot; &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; control_pre &lt;- dplyr::select(control_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1)) control_pret &lt;- t(control_pre) control_post &lt;- combined_data %&gt;% filter(Treatment == &quot;Control&quot; &amp; Treatment_status == &quot;PostTreatment&quot;) colnames(control_post) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; ## [4] &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; &quot;Aristida.purpurea&quot; ## [10] &quot;Aristida.schiedeana.var.orcuttiana&quot; &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; &quot;Asclepias.nyctaginifolia&quot; ## [16] &quot;Astragalus.sp&quot; &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; &quot;Bothriochloa.ischaemum&quot; ## [22] &quot;Bouteloua.curtipendula&quot; &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; &quot;Brickellia.betonicifolia&quot; ## [28] &quot;Brickellia.californica&quot; &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; &quot;Calliandra.humilis&quot; ## [34] &quot;Calliandra.humilis.var.reticulata&quot; &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; &quot;Coleogyne.ramosissima&quot; ## [40] &quot;Collinsia.parviflora&quot; &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; &quot;Cyperus.fendlerianus&quot; ## [46] &quot;Cyperus.sp&quot; &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; &quot;Desmanthus.cooleyi&quot; ## [52] &quot;Desmodium.batocaulon&quot; &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; &quot;Eragrostis.curvula&quot; ## [58] &quot;Eragrostis.intermedia&quot; &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; &quot;Eriogonum.wrightii&quot; ## [64] &quot;Escobaria.sp&quot; &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; &quot;Euphorbia.serpyllifolia&quot; ## [70] &quot;Evolvulus.sericeus&quot; &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; &quot;Glandularia.bipinnatifida&quot; ## [76] &quot;Glandularia.gooddingii&quot; &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; &quot;Heterosperma.pinnatum&quot; ## [82] &quot;Houstonia.wrightii&quot; &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; &quot;Lepidium.lasiocarpum&quot; ## [88] &quot;Lonicera.arizonica&quot; &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; &quot;Mimosa.aculeaticarpa&quot; ## [94] &quot;Mimosa.biuncifera&quot; &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; &quot;Muhlenbergia.longiligula&quot; ## [100] &quot;Muhlenbergia.sp&quot; &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; &quot;Packera.neomexicana&quot; ## [106] &quot;Pediomelum.tenuiflorum&quot; &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; &quot;Phemeranthus.parviflorus&quot; ## [112] &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; &quot;Polygonum.douglasii&quot; ## [118] &quot;Portulaca.umbraticola&quot; &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; &quot;Rhus.trilobata&quot; ## [124] &quot;richness_aggregated&quot; &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; &quot;Symphyotrichum.falcatum&quot; ## [130] &quot;Tradescantia.sp&quot; &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; &quot;Vulpia.octoflora&quot; ## [136] &quot;Xanthisma.gracile&quot; &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; control_post &lt;- dplyr::select(control_post, -c(Year, PlotN, Treatment, Treatment_status, ...1)) control_postt &lt;- t(control_post) treatment_pre &lt;- combined_data %&gt;% filter(Treatment == &quot;Treatment&quot; &amp; Treatment_status == &quot;PreTreatment&quot;) colnames(treatment_pre) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; ## [4] &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; &quot;Aristida.purpurea&quot; ## [10] &quot;Aristida.schiedeana.var.orcuttiana&quot; &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; &quot;Asclepias.nyctaginifolia&quot; ## [16] &quot;Astragalus.sp&quot; &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; &quot;Bothriochloa.ischaemum&quot; ## [22] &quot;Bouteloua.curtipendula&quot; &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; &quot;Brickellia.betonicifolia&quot; ## [28] &quot;Brickellia.californica&quot; &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; &quot;Calliandra.humilis&quot; ## [34] &quot;Calliandra.humilis.var.reticulata&quot; &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; &quot;Coleogyne.ramosissima&quot; ## [40] &quot;Collinsia.parviflora&quot; &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; &quot;Cyperus.fendlerianus&quot; ## [46] &quot;Cyperus.sp&quot; &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; &quot;Desmanthus.cooleyi&quot; ## [52] &quot;Desmodium.batocaulon&quot; &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; &quot;Eragrostis.curvula&quot; ## [58] &quot;Eragrostis.intermedia&quot; &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; &quot;Eriogonum.wrightii&quot; ## [64] &quot;Escobaria.sp&quot; &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; &quot;Euphorbia.serpyllifolia&quot; ## [70] &quot;Evolvulus.sericeus&quot; &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; &quot;Glandularia.bipinnatifida&quot; ## [76] &quot;Glandularia.gooddingii&quot; &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; &quot;Heterosperma.pinnatum&quot; ## [82] &quot;Houstonia.wrightii&quot; &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; &quot;Lepidium.lasiocarpum&quot; ## [88] &quot;Lonicera.arizonica&quot; &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; &quot;Mimosa.aculeaticarpa&quot; ## [94] &quot;Mimosa.biuncifera&quot; &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; &quot;Muhlenbergia.longiligula&quot; ## [100] &quot;Muhlenbergia.sp&quot; &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; &quot;Packera.neomexicana&quot; ## [106] &quot;Pediomelum.tenuiflorum&quot; &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; &quot;Phemeranthus.parviflorus&quot; ## [112] &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; &quot;Polygonum.douglasii&quot; ## [118] &quot;Portulaca.umbraticola&quot; &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; &quot;Rhus.trilobata&quot; ## [124] &quot;richness_aggregated&quot; &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; &quot;Symphyotrichum.falcatum&quot; ## [130] &quot;Tradescantia.sp&quot; &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; &quot;Vulpia.octoflora&quot; ## [136] &quot;Xanthisma.gracile&quot; &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; treatment_pre &lt;- dplyr::select(treatment_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1)) treatment_pret &lt;- t(treatment_pre) treatment_post &lt;- combined_data %&gt;% filter(Treatment == &quot;Treatment&quot; &amp; Treatment_status == &quot;PostTreatment&quot;) colnames(treatment_post) ## [1] &quot;...1&quot; &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; ## [4] &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; &quot;Arctostaphylos.pringlei&quot; ## [7] &quot;Arctostaphylos.pungens&quot; &quot;Arenaria.lanuginosa.var.saxosa&quot; &quot;Aristida.purpurea&quot; ## [10] &quot;Aristida.schiedeana.var.orcuttiana&quot; &quot;Aristida.sp&quot; &quot;Aristida.ternipes&quot; ## [13] &quot;Artemisia.ludoviciana&quot; &quot;Artemisia.sp&quot; &quot;Asclepias.nyctaginifolia&quot; ## [16] &quot;Astragalus.sp&quot; &quot;Baccharis.pteronioides&quot; &quot;Bahia.biternata&quot; ## [19] &quot;Bidens.sp&quot; &quot;Boechera.perennans&quot; &quot;Bothriochloa.ischaemum&quot; ## [22] &quot;Bouteloua.curtipendula&quot; &quot;Bouteloua.eriopoda&quot; &quot;Bouteloua.gracilis&quot; ## [25] &quot;Bouteloua.hirsuta&quot; &quot;Bouteloua.sp&quot; &quot;Brickellia.betonicifolia&quot; ## [28] &quot;Brickellia.californica&quot; &quot;Brickellia.sp&quot; &quot;Bromus.ciliatus&quot; ## [31] &quot;Bromus.tectorum&quot; &quot;Bryophyta.sp&quot; &quot;Calliandra.humilis&quot; ## [34] &quot;Calliandra.humilis.var.reticulata&quot; &quot;Calochortus.sp&quot; &quot;Carex.sp&quot; ## [37] &quot;Ceanothus.fendleri&quot; &quot;Chenopodium.fremontii&quot; &quot;Coleogyne.ramosissima&quot; ## [40] &quot;Collinsia.parviflora&quot; &quot;Comandra.umbellata&quot; &quot;Conyza.canadensis&quot; ## [43] &quot;Cylindropuntia.sp&quot; &quot;Cynoglossum.officinale&quot; &quot;Cyperus.fendlerianus&quot; ## [46] &quot;Cyperus.sp&quot; &quot;Dalea.albiflora&quot; &quot;Datura.sp&quot; ## [49] &quot;Descurainia.obtusa&quot; &quot;Descurainia.sophia&quot; &quot;Desmanthus.cooleyi&quot; ## [52] &quot;Desmodium.batocaulon&quot; &quot;Dysphania.graveolens&quot; &quot;Dysphania.pumilio&quot; ## [55] &quot;Echinocereus.sp&quot; &quot;Elymus.elymoides&quot; &quot;Eragrostis.curvula&quot; ## [58] &quot;Eragrostis.intermedia&quot; &quot;Erigeron.divergens&quot; &quot;Erigeron.flagellaris&quot; ## [61] &quot;Erigeron.oreophilus&quot; &quot;Eriogonum.jamesii&quot; &quot;Eriogonum.wrightii&quot; ## [64] &quot;Escobaria.sp&quot; &quot;Escobaria.vivipara&quot; &quot;Euphorbia.albomarginata&quot; ## [67] &quot;Euphorbia.revoluta&quot; &quot;Euphorbia.schizoloba&quot; &quot;Euphorbia.serpyllifolia&quot; ## [70] &quot;Evolvulus.sericeus&quot; &quot;Festuca.arizonica&quot; &quot;Galactia.wrightii&quot; ## [73] &quot;Galium.microphyllum&quot; &quot;Garrya.wrightii&quot; &quot;Glandularia.bipinnatifida&quot; ## [76] &quot;Glandularia.gooddingii&quot; &quot;Gutierrezia.sarothrae&quot; &quot;Heliomeris.longifolia.var.annua&quot; ## [79] &quot;Heliomeris.multiflora&quot; &quot;Hesperidanthus.linearifolius&quot; &quot;Heterosperma.pinnatum&quot; ## [82] &quot;Houstonia.wrightii&quot; &quot;Hybanthus.verticillatus&quot; &quot;Hymenopappus.filifolius&quot; ## [85] &quot;Juncus.saximontanus&quot; &quot;Koeleria.macrantha&quot; &quot;Lepidium.lasiocarpum&quot; ## [88] &quot;Lonicera.arizonica&quot; &quot;Lotus.wrightii&quot; &quot;Lycurus.setosus&quot; ## [91] &quot;Machaeranthera.gracilis&quot; &quot;Mammillaria.sp&quot; &quot;Mimosa.aculeaticarpa&quot; ## [94] &quot;Mimosa.biuncifera&quot; &quot;Mirabilis.sp&quot; &quot;Mollugo.verticillata&quot; ## [97] &quot;Monarda.sp&quot; &quot;Muhlenbergia.emersleyi&quot; &quot;Muhlenbergia.longiligula&quot; ## [100] &quot;Muhlenbergia.sp&quot; &quot;Nolina.microcarpa&quot; &quot;Ophioglossum.engelmannii&quot; ## [103] &quot;Opuntia.chlorotica&quot; &quot;Opuntia.sp&quot; &quot;Packera.neomexicana&quot; ## [106] &quot;Pediomelum.tenuiflorum&quot; &quot;Penstemon.barbatus&quot; &quot;Penstemon.eatonii&quot; ## [109] &quot;Penstemon.linarioides&quot; &quot;Penstemon.sp&quot; &quot;Phemeranthus.parviflorus&quot; ## [112] &quot;Phoradendron.leucarpum.ssp.tomentosum&quot; &quot;Physalis.hederifolia&quot; &quot;Poa.fendleriana&quot; ## [115] &quot;Polygala.alba&quot; &quot;Polygala.obscura&quot; &quot;Polygonum.douglasii&quot; ## [118] &quot;Portulaca.umbraticola&quot; &quot;Pseudognaphalium.canescens&quot; &quot;Psoralidium.tenuiflorum&quot; ## [121] &quot;Quercus.turbinella&quot; &quot;Rhamnus.ilicifolia&quot; &quot;Rhus.trilobata&quot; ## [124] &quot;richness_aggregated&quot; &quot;Solanum.elaeagnifolium&quot; &quot;Sporobolus.contractus&quot; ## [127] &quot;Sporobolus.cryptandrus&quot; &quot;Sporobolus.interruptus&quot; &quot;Symphyotrichum.falcatum&quot; ## [130] &quot;Tradescantia.sp&quot; &quot;Verbascum.densiflorum&quot; &quot;Verbascum.thapsus&quot; ## [133] &quot;Verbena.bracteata&quot; &quot;Vulpia.microstachys&quot; &quot;Vulpia.octoflora&quot; ## [136] &quot;Xanthisma.gracile&quot; &quot;Year&quot; &quot;PlotN&quot; ## [139] &quot;Treatment&quot; &quot;Treatment_status&quot; treatment_post &lt;- dplyr::select(treatment_post, -c(Year, PlotN, Treatment, Treatment_status, ...1)) treatment_postt &lt;- t(treatment_post) #combine matrices, control_pre, control_post, treatment_pre, treatment_post, in a matrix of N lists combined_list &lt;- list(control_pre = control_pre, control_post = control_post, treatment_pre = treatment_pre, treatment_post = treatment_post) lapply(combined_list, head) ## $control_pre ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans Arctostaphylos.pringlei Arctostaphylos.pungens Arenaria.lanuginosa.var.…¹ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 0 1 0 ## 2 0 0 0 0 0 1 0 ## 3 0 0 0 0 0 1 0 ## 4 0 1 0 0 0 1 0 ## 5 0 0 0 0 0 1 0 ## 6 0 0 0 1 0 1 0 ## # ℹ abbreviated name: ¹​Arenaria.lanuginosa.var.saxosa ## # ℹ 128 more variables: Aristida.purpurea &lt;dbl&gt;, Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, ## # Bahia.biternata &lt;dbl&gt;, Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, Bouteloua.curtipendula &lt;dbl&gt;, ## # Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, Bouteloua.hirsuta &lt;dbl&gt;, Bouteloua.sp &lt;dbl&gt;, Brickellia.betonicifolia &lt;dbl&gt;, ## # Brickellia.californica &lt;dbl&gt;, Brickellia.sp &lt;dbl&gt;, Bromus.ciliatus &lt;dbl&gt;, Bromus.tectorum &lt;dbl&gt;, Bryophyta.sp &lt;dbl&gt;, ## # Calliandra.humilis &lt;dbl&gt;, Calliandra.humilis.var.reticulata &lt;dbl&gt;, Calochortus.sp &lt;dbl&gt;, Carex.sp &lt;dbl&gt;, Ceanothus.fendleri &lt;dbl&gt;, … ## ## $control_post ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans Arctostaphylos.pringlei Arctostaphylos.pungens Arenaria.lanuginosa.var.…¹ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 1 0 ## 3 0 0 0 0 0 1 0 ## 4 0 0 0 0 0 1 0 ## 5 0 0 0 0 0 1 0 ## 6 0 0 0 0 0 1 0 ## # ℹ abbreviated name: ¹​Arenaria.lanuginosa.var.saxosa ## # ℹ 128 more variables: Aristida.purpurea &lt;dbl&gt;, Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, ## # Bahia.biternata &lt;dbl&gt;, Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, Bouteloua.curtipendula &lt;dbl&gt;, ## # Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, Bouteloua.hirsuta &lt;dbl&gt;, Bouteloua.sp &lt;dbl&gt;, Brickellia.betonicifolia &lt;dbl&gt;, ## # Brickellia.californica &lt;dbl&gt;, Brickellia.sp &lt;dbl&gt;, Bromus.ciliatus &lt;dbl&gt;, Bromus.tectorum &lt;dbl&gt;, Bryophyta.sp &lt;dbl&gt;, ## # Calliandra.humilis &lt;dbl&gt;, Calliandra.humilis.var.reticulata &lt;dbl&gt;, Calochortus.sp &lt;dbl&gt;, Carex.sp &lt;dbl&gt;, Ceanothus.fendleri &lt;dbl&gt;, … ## ## $treatment_pre ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans Arctostaphylos.pringlei Arctostaphylos.pungens Arenaria.lanuginosa.var.…¹ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 0 1 0 ## 2 0 0 0 0 0 1 0 ## 3 0 0 0 0 0 1 0 ## 4 0 0 0 0 0 1 0 ## 5 0 0 0 0 0 1 0 ## 6 0 0 0 0 0 1 0 ## # ℹ abbreviated name: ¹​Arenaria.lanuginosa.var.saxosa ## # ℹ 128 more variables: Aristida.purpurea &lt;dbl&gt;, Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, ## # Bahia.biternata &lt;dbl&gt;, Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, Bouteloua.curtipendula &lt;dbl&gt;, ## # Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, Bouteloua.hirsuta &lt;dbl&gt;, Bouteloua.sp &lt;dbl&gt;, Brickellia.betonicifolia &lt;dbl&gt;, ## # Brickellia.californica &lt;dbl&gt;, Brickellia.sp &lt;dbl&gt;, Bromus.ciliatus &lt;dbl&gt;, Bromus.tectorum &lt;dbl&gt;, Bryophyta.sp &lt;dbl&gt;, ## # Calliandra.humilis &lt;dbl&gt;, Calliandra.humilis.var.reticulata &lt;dbl&gt;, Calochortus.sp &lt;dbl&gt;, Carex.sp &lt;dbl&gt;, Ceanothus.fendleri &lt;dbl&gt;, … ## ## $treatment_post ## # A tibble: 6 × 135 ## Acalypha.neomexicana Allium.sp Ambrosia.psilostachya Arabis.perennans Arctostaphylos.pringlei Arctostaphylos.pungens Arenaria.lanuginosa.var.…¹ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 0 0 1 0 ## 2 0 0 0 0 0 1 0 ## 3 0 0 0 0 0 1 0 ## 4 0 0 0 0 0 1 0 ## 5 0 0 0 0 0 1 0 ## 6 0 0 0 0 0 1 0 ## # ℹ abbreviated name: ¹​Arenaria.lanuginosa.var.saxosa ## # ℹ 128 more variables: Aristida.purpurea &lt;dbl&gt;, Aristida.schiedeana.var.orcuttiana &lt;dbl&gt;, Aristida.sp &lt;dbl&gt;, Aristida.ternipes &lt;dbl&gt;, ## # Artemisia.ludoviciana &lt;dbl&gt;, Artemisia.sp &lt;dbl&gt;, Asclepias.nyctaginifolia &lt;dbl&gt;, Astragalus.sp &lt;dbl&gt;, Baccharis.pteronioides &lt;dbl&gt;, ## # Bahia.biternata &lt;dbl&gt;, Bidens.sp &lt;dbl&gt;, Boechera.perennans &lt;dbl&gt;, Bothriochloa.ischaemum &lt;dbl&gt;, Bouteloua.curtipendula &lt;dbl&gt;, ## # Bouteloua.eriopoda &lt;dbl&gt;, Bouteloua.gracilis &lt;dbl&gt;, Bouteloua.hirsuta &lt;dbl&gt;, Bouteloua.sp &lt;dbl&gt;, Brickellia.betonicifolia &lt;dbl&gt;, ## # Brickellia.californica &lt;dbl&gt;, Brickellia.sp &lt;dbl&gt;, Bromus.ciliatus &lt;dbl&gt;, Bromus.tectorum &lt;dbl&gt;, Bryophyta.sp &lt;dbl&gt;, ## # Calliandra.humilis &lt;dbl&gt;, Calliandra.humilis.var.reticulata &lt;dbl&gt;, Calochortus.sp &lt;dbl&gt;, Carex.sp &lt;dbl&gt;, Ceanothus.fendleri &lt;dbl&gt;, … combined_list &lt;- lapply(combined_list, function(x) { if(is.data.frame(x)) as.matrix(x) else x }) str(combined_list) ## List of 4 ## $ control_pre : num [1:6, 1:135] 0 0 0 0 0 0 0 0 0 1 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ control_post : num [1:6, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ treatment_pre : num [1:16, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... ## $ treatment_post: num [1:16, 1:135] 0 0 0 0 0 0 0 0 0 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:135] &quot;Acalypha.neomexicana&quot; &quot;Allium.sp&quot; &quot;Ambrosia.psilostachya&quot; &quot;Arabis.perennans&quot; ... Now that we have the data in the correct format, let’s analyze! library(iNEXT) # Example of running iNEXT on incidence_raw data results &lt;- suppressWarnings({iNEXT(combined_list, q=0, datatype=&quot;incidence_raw&quot;)}) # Plot the results plot(results) Let’s transform an abundance dataset! This dataset consists of observations of pollinators within an ecoregion for two time periods. Far more observations were collected after the development of cell phones and app-based species identification software like iNaturalist. In order to compare the two assemblages, you must calculate asymptotic diversity estimates using R/E curves. The dataset has been cleaned and spatially-thinned, so that we assume that each observation indicates a distinct individual and thus we have an estimate of abundance within this ecoregion. First, check out the dataset. Here, each row corresponds to an observation. In order to run analyses on this data, we must transform the data into either an S by N abundance matrix (bird data), or N lists of species abundances (spider data). Let’s transform our data into the list structure. #you have to adjust the code to port in this datasets! library(readr) url3 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1bpLmtDDEPAdSaTPFPNg33hyj6y0viqxk&quot; arcticlocs &lt;- read_csv(url3) #time periods arcticlocsTP1 &lt;- filter(arcticlocs, year &gt;= 1939 &amp; year &lt; 1979) arcticlocsTP2 &lt;- filter(arcticlocs, year &gt;= 1980 &amp; year &lt; 2021) obsTP1 &lt;- length(arcticlocsTP1$genus) obsTP2 &lt;- length(arcticlocsTP2$genus) lengthsofobs &lt;- c(obsTP1, obsTP2) #Time period 1 arcticlocsTP1sum &lt;- plyr::count(arcticlocsTP1, &#39;genus&#39;) arcticlocsTP1unitnum &lt;- length(arcticlocsTP1$genus) arcticlocsTP1V &lt;- c(arcticlocsTP1unitnum, arcticlocsTP1sum$freq) arcticlocsTP1Vn &lt;- as.numeric(arcticlocsTP1V) #Time period 2 arcticlocsTP2sum &lt;- plyr::count(arcticlocsTP2, &#39;genus&#39;) arcticlocsTP2unitnum &lt;- length(arcticlocsTP2$genus) arcticlocsTP2V &lt;- c(arcticlocsTP2unitnum, arcticlocsTP2sum$freq) arcticlocsTP2Vn &lt;- as.numeric(arcticlocsTP2V) arctic &lt;- list(&quot;TimePeriod1&quot; = arcticlocsTP1Vn, &quot;TimePeriod2&quot; = arcticlocsTP2Vn) str(arctic) ## List of 2 ## $ TimePeriod1: num [1:11] 13 1 2 1 1 1 3 1 1 1 ... ## $ TimePeriod2: num [1:163] 365 3 4 1 1 1 2 2 3 3 ... Now, our data consists of two lists - one for time period one and one describing time period two. Let’s run our analyses. Note that ggiNEXT is a wrapper for the standard ggplot function, and can be manipulated just like ggplot. #establish the max extrapolation number (two times the largest sample) and the knots manually maxrun &lt;- (max(obsTP1, obsTP2)*2) t &lt;- seq(1, maxrun, by=1) out.inc &lt;- iNEXT(arctic, q=c(0,1,2), datatype=&quot;incidence_freq&quot;, size=t, nboot=200) arcticfigure &lt;- ggiNEXT(out.inc, facet.var=&quot;Order.q&quot;, se =TRUE, grey = TRUE) + ylab(&quot;Generic diversity&quot;) + ggtitle(&quot;Arctic cordillera&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)); arcticfigure Wonderful! You’ve transformed your data into the iNEXT format according to your data type. Now, work through an example with your own data! Put your data into the correct format based on your data, and analyze away. "],["ordination-station.html", "Chapter 31 Ordination station", " Chapter 31 Ordination station "],["population-sensation.html", "Chapter 32 Population sensation 32.1 Population characteristics 32.2 Planning a census 32.3 Life cycle diagrams 32.4 Population demographic models 32.5 Integral projection models 32.6 Population dynamics 32.7 Chapter summary 32.8 Test your knowledge 32.9 Assignment", " Chapter 32 Population sensation Populations contain multitudes - numerous interacting individuals of the same species with slightly different genetic backgrounds, sharing genes, colonizing new areas, responding to environmental stimuli. Populations are hot-pots of evolution and essential for understanding species viability, especially when species are rare. Population-level studies have contributed fundamental ecological knowledge in evolution, range dynamics, and species conservation. Now that we are all jazzed about populations, let’s learn about how to describe them and their dynamics quantitative! May your knowledge acquisition be exponential! 32.1 Population characteristics In population ecology, we commonly describe populations in terms of size and structure. Size is simply the number of individuals in a population and structure refers to the proportion of individuals across age or size classes. For rare species or species with low population sizes, population size can be directly estimated through a census. Just as it seems, a census is when each individual is counted. We often collect information pertinent to understanding demographic vital rates of individuals that are censused - just like we do in the U.S. census. For plants, rather than collect information on religious background or age as we would for populations of humans, we typically record the size of the plant and other salient characteristics derived from an understanding of the species’ breeding system, dispersal mechanism, life history, and ecology. When species are abundant, we use other methods to estimate population size, such as density (i.e., how many individuals occur within a particular area) or sub-sampling (i.e., collecting census data within a plot). If a species if cryptic, meaning hard to observe (as is the case for most animals), we use mark-recapture or occupancy modeling to estimate population size and structure. 32.2 Planning a census Censuses are the ideal method for collecting demographic data, since it allows in-depth and comprehensive examination of the population (and it’s dynamics!). Let’s discuss some considerations for establishing a census protocol. When conducting a census, you want to plan on capturing critical life events and ensure that you are able to capture those life events through time (for multiple years). Let’s look at an example and establish a plan to census individuals within a population of this hypothetical species. The figure above shows a typical phenological pattern for an understory plant species in the eastern deciduous forest. These plants are dormant throughout the winter when temperatures are cold enough to freeze plant tissue. All plants, adults and new seedlings, emerge in the spring, and grow to their full size for the summer over a few week period in early spring. Then, they begin flowering and seed development in late summer, then disperse seeds into the fall. The first census indicated in this figure takes place after emergence in the spring once plants have reached their final size for the growing season. The census is planned to occur as early as possible post-growth in order to assess recruitment (new seedlings that enter the population), since seedlings tend to start to die-off through time. Seeds of this species require an 18-month stratification period prior to germination. In order to census across all members of the population, including seeds, we need to include the second census to quantify the number of seeds present at census 1, since counting seeds post-dispersal is almost impossible. Note that we could capture individuals across all important classes, adult plants, seedlings and seeds, if we conducted a single census at time point 2. Why not conduct a single census? In this case, the researchers were interested in causes of mortality of plants, particularly new germinants, across the growing season. By conducting the census in the spring, they were able to identify all plants that emerged that year and note if those plants were lost during the growing season and in many cases ascribe a reason for the mortality of the plant. 32.3 Life cycle diagrams In the above example, the census was timed to measure the performance and fate of important classes within the population. A useful tool for developing census protocols and demographic models is called a life cycle diagram. A life cycle diagram indicates important life stages and possible transitions among those stages. Continuing with our example above, we develop the following life history diagram. Here, you will note several important demographic characteristics of this species. First, on the right hand side of the diagram, you can see that the researchers have classified plants into several groups: new seedlings, &gt;1 year old seedlings, juveniles, small adults and large adults. These categories were selected because individuals within the categories share similar rates of reproduction and survival (vital rates). On the left hand side of the diagram, you will see that this species forms a seedbank and that seeds within this seed back persist around 45 months. 32.4 Population demographic models Population demographic models allow us to predict population trajectories, evaluate management strategies, understand extinction risk, and identify key life stages for conservation. Population demographic models come in several forms. We will take a deep dive into Integral Projection Models (IPMs), but understanding the various forms of population models will help you understand IPMs better! 32.4.1 Unstructured Models Unstructured models refer to population growth models that do not distinguish among individuals within a population. In these models, all individuals are treated as equivalent, meaning they are assumed to have the same probabilities of survival and reproduction, regardless of differences in age, size, or life stage. Because unstructured models treat all individuals as identical, they are best suited for simple or theoretical questions and often serve as a foundation for more complex, structured population models that account for age, size, or stage. The most basic population model describes a population experiencing exponential growth. Exponential growth—the idea that populations increase multiplicatively rather than additively — is foundational to Darwin’s development of the Theory of Evolution by Natural Selection. Darwin recognized that organisms have the capacity to produce far more offspring than are needed to replace themselves, and yet the world is not overrun by offspring (for example, ladybugs). From this insight, he reasoned that not all individuals can survive and reproduce, and that selection must therefore operate strongly and continuously. This differential survival and reproduction provides the mechanism by which natural selection can drive evolutionary change over time. Since the concept of multiplicative growth is central to the equation for exponential growth rate, let’s compare additive versus exponential growth. Additive growth means a population increases by a fixed number of individuals each time step, regardless of how large the population already is. You can think of it as: “The population gains the same number each year.” Example: Start with 100 individuals Add 10 individuals each year Population over time: Year 0: 100; Year 1: 110; Year 2: 120; Year 3: 130 Mathematically, this looks like: \\[ N_{t+1} = N_t + b \\] where b is a constant number added each time step. Multiplicative growth means the population increases by a proportion of its current size each time step. You can think of it as: “The population grows by a percentage.” Example: Start with 100 individuals Grow by 10% per year Population over time: Year 0: 100; Year 1: 110; Year 2: 121; Year 3: 133 Additive growth increases a population by a fixed number, while multiplicative growth increases a population by a proportion of its current size—making growth faster as populations get larger. Mathematically, this looks like: \\[ N_{t+1} = \\lambda N_t \\] or in continuous time: \\[ \\frac{dN}{dt} = rN \\] This form of growth is biologically realistic over short time scales and is the foundation of population ecology and evolutionary theory. 32.4.1.1 Exponential Growth: Unlimited resources, constant per capita growth When to use: Short-term projections, invasive species establishment Key assumption: No limits to growth Equations: The continuous-time exponential growth model describes how a population grows when resources are unlimited and the per-capita growth rate remains constant. \\[ N(t) = N_0 e^{rt} \\] where: \\(N(t)\\) is the population size at time \\(t\\) \\(N_0\\) is the initial population size (at \\(t = 0\\)) \\(r\\) is the intrinsic rate of increase \\(e\\) is the base of the natural logarithm \\(t\\) is time or more simply: \\[ N_{t+1} = \\lambda N_t \\] Given that it is exceedingly rare that there are no limits to population growth, population ecologist rarely use exponential growth models (I’ve never used this model for research). 32.4.1.2 Logistic Growth: Density-dependent regulation In real ecosystems, resources are finite, so populations cannot grow exponentially forever. The logistic growth model captures this reality by slowing population growth as population size approaches carrying capacity—the maximum number of individuals an environment can support over time. When to use: Populations approaching carrying capacity Key assumption: Negative density dependence, as populations get larger, per capita (per individual) growth decreases. The logistic growth model is written as: \\[ \\frac{dN}{dt} = rN\\left(1 - \\frac{N}{K}\\right) \\] where: \\(N\\) is population size \\(r\\) is the intrinsic rate of increase \\(K\\) is the carrying capacity When population size (\\(N\\)) is small relative to carrying capacity (\\(K\\)), the term \\(\\left(1 - \\frac{N}{K}\\right)\\) is close to 1 and population growth is approximately exponential. As \\(N\\) approaches \\(K\\), this term approaches 0, slowing growth until the population stabilizes. Note that the logistic growth equation is essentially the continuous exponential growth equation with a penalty for large populations! 32.4.2 Structured Models For most macroecological applications—such as modeling population growth in plants, tigers, or mice—unstructured models are inappropriate because individuals differ substantially in their probabilities of survival and reproduction depending on their age, size, or life stage. To address this, age-structured population models were developed in the mid-20th century. In 1945, Patrick Leslie introduced the Leslie matrix, a discrete-time, age-structured model designed to track populations divided into age classes. Leslie’s work was motivated largely by human demography and vertebrate populations, where age is relatively easy to determine and closely tied to survival and reproduction. The Leslie matrix provided a powerful framework for predicting population growth rates, stable age distributions, and sensitivity to changes in survival or fecundity. However, for many organisms—particularly plants and invertebrates—age is difficult or impossible to measure, and demographic rates are often more strongly associated with developmental stage or size than chronological age. In response, Lefkovitch (1965) extended Leslie’s framework to create the stage-structured matrix model, which allows individuals to transition among life stages rather than progress strictly by age. This innovation made structured population modeling broadly applicable across ecological systems, especially for organisms with complex life cycles or variable growth rates. Hal Caswell formalized, unified, and generalized structured population models into a coherent mathematical and ecological framework. His book is the cornerstone reference for population modeling, especially for ecology: Caswell, H. (2001; updated 2019). Matrix Population Models: Construction, Analysis, and Interpretation. William F. Morris and Daniel F. Doak further tuned population analysis for conservation, focusing on viability analyses, in their seminal book: Morris, W. F., &amp; Doak, D. F. (2002). Quantitative Conservation Biology. These are great references and citations to use in your research! 32.4.2.1 Age-structured models (Leslie matrix) Structure: Discrete age classes When to use: Species with clearly defined age classes Long-lived organisms where age strongly predicts survival and reproduction Examples: Mammals Because demographic rates in many ecological systems depend more on size or stage than on age, we will walk through a matrix model example below using a stage-structured (Lefkovitch) matrix. The mathematics underlying this approach is essentially identical to that of age-structured models. 32.4.2.2 Stage-structured models (Lefkovitch matrix) Structure: Discrete life stages (e.g., juvenile, subadult, adult) When to use: Age is difficult or impossible to determine Demographic rates depend more on stage or size than age Examples: Plants (seedling, sapling, adult) Insects with metamorphosis Amphibians Using matrices to model population dynamics allows us to track the fate of individuals in a population within a single, unified framework. To build a demographic model, population ecologists first describe the species’ life cycle, identifying groups of individuals that share similar vital rates, such as survival, growth, and reproduction. These groups—often called stages—form the structure of the matrix. Each column represents individuals currently in a given stage, and each row represents the stage they may transition into during the next time step. The values in the matrix describe the probabilities of survival, transitions among stages, and reproduction. 32.4.2.2.1 Example: A stage-structured (Lefkovitch) matrix Let’s look at a matrix for a hypothetical plant population. We’ve broken the population into three stages Juveniles, Subadults, and Adults. The adults are the only stage able to reproduce. We start with a population consisting of 100 juveniles, 50 subadults, 20 adults. Let’s transform this life cycle diagram into a matrix! To do this, you would have marked the plants in this population and conducted a census. You would then be able to quantify all the possible transitions, marked by arrows connecting stages in the life cycle diagram. Load programs: Create a life cycle diagram: # Create life cycle diagram for the plant example grViz(&quot; digraph plant_lifecycle { # Graph attributes graph [rankdir = LR, fontsize = 12] # Node definitions with labels node [shape = circle, style = filled, fillcolor = lightblue, fontname = Helvetica, fontsize = 14] Seeds [label = &#39;Seeds\\n(S)&#39;] Juveniles [label = &#39;Juveniles\\n(J)&#39;] Adults [label = &#39;Adults\\n(A)&#39;] # Edge definitions with labels showing transition probabilities Seeds -&gt; Seeds [label = &#39;0.05\\n(stay seed)&#39;, fontsize = 10] Seeds -&gt; Juveniles [label = &#39;0.10\\n(germinate)&#39;, fontsize = 10] Juveniles -&gt; Juveniles [label = &#39;0.30\\n(stay juv)&#39;, fontsize = 10] Juveniles -&gt; Adults [label = &#39;0.50\\n(mature)&#39;, fontsize = 10] Adults -&gt; Adults [label = &#39;0.90\\n(survive)&#39;, fontsize = 10] Adults -&gt; Seeds [label = &#39;15.0\\n(fecundity)&#39;, fontsize = 10, color = red, penwidth = 2] } &quot;) Let’s transform this into a matrix! A &lt;- matrix(c(0.1, 0.3, 0, # Juveniles column 0, 0.5, 0.2, # Subadults column 0, 0, 0.8), # Adults column (with fecundity) nrow = 3, ncol = 3, byrow = FALSE) # Let&#39;s look at the matrix library(tibble) library(knitr) # Name stages stages &lt;- c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;) # Convert matrix to a tidy table A_df &lt;- as.data.frame(A) colnames(A_df) &lt;- stages rownames(A_df) &lt;- stages # Display nicely kable(A_df, digits = 2, caption = &quot;Stage-structured (Lefkovitch) projection matrix&quot;) Table 32.1: Stage-structured (Lefkovitch) projection matrix Juvenile Subadult Adult Juvenile 0.1 0.0 0.0 Subadult 0.3 0.5 0.0 Adult 0.0 0.2 0.8 # Starting population vector n0 &lt;- c(100, 50, 20) # 100 juveniles, 50 subadults, 20 adults # Project one time step n1 &lt;- A %*% n0 Here, the population vector lists the number of individuals in each stage at time \\(t\\), and matrix multiplication projects the population forward one time step to \\(t + 1\\). To see what is happening biologically, we can write out the matrix multiplication explicitly for one time step: The number of juveniles at the next time step is calculated as: \\[ n(J, t+1) = 0.1(100) = 10 \\] This means that 10% of the 100 juveniles present at time \\(t\\) survive and remain in the juvenile stage. The number of subadults at the next time step is calculated as: \\[ n(S, t+1) = 0.3(100) + 0.5(50) = 55 \\] This includes contributions from two processes: 30% of juveniles grow into subadults 50% of subadults survive and remain subadults The number of adults at the next time step is calculated as: \\[ n(A, t+1) = 0.2(50) + 0.8(20) = 26 \\] This reflects: Maturation of subadults into adults Survival of existing adults 32.4.2.2.1.1 Total population size and growth The total population size at time \\(t\\) is the sum of individuals across all stages: \\[ N_t = 100 + 50 + 20 = 170 \\] The total population size at time \\(t+1\\) is: \\[ N_{t+1} = 10 + 55 + 26 = 91 \\] The absolute change in population size is: \\[ \\Delta N = N_{t+1} - N_t = 91 - 170 = -79 \\] This indicates that the population declined by 79 individuals over one time step. The proportional population growth rate over one time step is: \\[ \\lambda = \\frac{N_{t+1}}{N_t} = \\frac{91}{170} \\approx 0.54 \\] A value of \\(\\lambda &lt; 1\\) indicates that, under these demographic rates, the population is declining. Et viola! That is basic matrix math! Want to learn how to multiply matrices? Leslie matrix population projection example (YouTube) These short-term, time-dependent dynamics are summarized using a suite of metrics collectively referred to as transient dynamics. These measures capture how populations behave before reaching long-term equilibrium, and we will explore them in more detail shortly. 32.4.2.2.1.2 Population growth rate (λ): the dominant eigenvalue After many time steps (repeat the process above), a structured population tends to settle into a stable pattern in which the relative proportions of individuals in each stage remain constant, even though the total population size may be changing. The rate at which the population grows or declines at this stable structure is denoted by \\(\\lambda\\) (lambda). Transient dynamics capture how populations behave over short time scales and can be strongly influenced by the initial mix of life stages. While these short-term responses are often ecologically important, they can be difficult to compare across populations because they depend on where the population starts. By contrast, describes the long-term growth or decline of a population once it has settled into a stable stage distribution. Because is determined by the underlying life cycle rather than initial conditions, it provides a consistent and interpretable measure of population viability and long-term persistence. Conceptual definition: λ is the long-term, proportional population growth rate implied by the matrix. • $\\lambda &gt; 1$: population grows • $\\lambda = 1$: population is stable • $\\lambda &lt; 1$: population declines Mathematically, \\(\\lambda\\) is the dominant eigenvalue of the projection matrix: \\[ \\mathbf{A}\\mathbf{n} = \\lambda \\mathbf{n} \\] In practice, \\(\\lambda\\) can be interpreted as the ratio of population size between successive time steps once the population has reached its stable stage distribution: \\[ \\lambda = \\frac{N_{t+1}}{N_t} \\] Mathematically, is the dominant eigenvalue of the projection matrix. When the matrix is repeatedly multiplied by a population vector, the population eventually grows or declines at a constant proportional rate, and that rate is given by . What is an eigenvalue? Think of a matrix as a machine that reshuffles individuals among life stages. Most starting populations change shape as they pass through this machine. Eventually, the population settles into a stable mix of juveniles, subadults, and adults. After that point, the matrix redistributes individuals in the same proportions each time step, so the population simply grows or shrinks without changing its stage structure. The number that tells us how much larger or smaller the population gets each step is called the dominant eigenvalue, . Let me show you in terms of matrix structure: 32.4.2.2.1.2.1 The projection matrix (structure) The A or transition matrix (as we call the matrix the summarizes transitions / dynamics), consists of these parts: Rows = stage at t+1 Columns = stage at t Entries = survival, growth, reproduction 32.4.2.2.1.2.2 Eigenvectors = stage structure An eigenvector describes a pattern of stage abundances: Dominant eigenvector → stable stage distribution Subdominant eigenvectors → transient dynamics (oscillations, overshoot, lag) 32.4.2.2.1.2.3 Eigenvalues = scaling rates Eigenvalues tell us how fast those patterns grow or decay. Dominant eigenvalue (_1) → long-term growth rate Subdominant eigenvalues (_2, _3) → how fast transients fade 32.4.2.2.1.2.4 Why “dominant” matters The dominant eigenvalue is called “dominant” because it eventually overwhelms all other dynamics. No matter how a population starts, its long-term behavior is governed by this single value. This matrix-based framework provides the foundation for sensitivity analyses, elasticities, and more advanced models such as Integral Projection Models (IPMs), which extend the same logic to continuous size variables. 32.5 Integral projection models When building standard matrix population models, stages are defined based on our understanding of which groups within a population exhibit similar vital rates. In reality, however, vital rates often vary continuously among individuals rather than falling into discrete categories. As a result, stage boundaries are frequently imposed by binning individuals into classes that may be somewhat arbitrary. In some cases this binning is practical or biologically justified—for example, when land managers conduct rapid censuses by counting only large, reproductively mature individuals. In many systems, however, discrete stages are approximations rather than natural divisions of demographic variation. Instead of binning individuals into discrete stages, Integral Projection Models (IPMs) describe population dynamics using a continuous state variable, most commonly a measure of individual size (such as height, diameter, or biomass in plants). In IPMs, vital rates—such as survival, growth, and reproduction—are modeled as functions of this state variable using statistical models fit to data. Conceptually, IPMs extend stage-structured matrix models by replacing discrete stage classes with a continuous size axis. This allows IPMs to capture fine-scale demographic variation without requiring arbitrary size bins. One useful way to think about an IPM is as an extremely fine-grained matrix model. Instead of a small matrix with a handful of discrete stages, an IPM can be viewed as a very large matrix in which individuals are divided into many tiny size classes, each with correspondingly small transition probabilities. In practice, this “infinite matrix” is represented mathematically by a kernel that combines survival, growth, and reproduction processes. This kernel plays the same conceptual role as a projection matrix in a matrix population model: it maps the population’s size distribution at time t to the distribution at time t+1. As in matrix models, repeated application of the kernel leads to a stable size distribution and a long-term population growth rate, . Mathematically, IPMs are built from a kernel that combines survival, growth, and reproduction processes. This kernel plays the same role as a projection matrix in a matrix population model: it maps the population’s size distribution at time \\(t\\) to the distribution at time \\(t+1\\). As in matrix models, repeated application of the kernel leads to a stable size distribution and a long-term population growth rate, \\(\\lambda\\). Because IPMs preserve the biological logic of matrix models while allowing demographic rates to vary smoothly with size, they are particularly well suited for plant populations and other organisms in which size, rather than age or stage, best predicts survival and reproduction. Since my lab uses IPMs for most demographic analyses, we will explore these models in detail in the next chapter! 32.6 Population dynamics Once a demographic model has been constructed—whether as a stage-structured matrix or an Integral Projection Model—it can be used to quantify a wide range of population-level properties. These quantities describe not only whether a population is growing or declining, but also why it behaves the way it does and which demographic processes matter most. Together, these quantities are referred to as population dynamics, and they provide insight into long-term growth, short-term responses to disturbance, and the sensitivity of populations to changes in survival, growth, or reproduction. 32.6.1 Population growth rate The most fundamental quantity derived from a projection matrix is the long-term population growth rate, \\(\\lambda\\). As discussed above, \\(\\lambda\\) is the dominant eigenvalue of the matrix and describes whether a population is expected to grow (\\(\\lambda &gt; 1\\)), decline (\\(\\lambda &lt; 1\\)), or remain stable (\\(\\lambda = 1\\)) once it reaches a stable structure. We calculated this above! 32.6.2 Stable stage distribution Associated with \\(\\lambda\\) is the stable stage distribution, given by the dominant right eigenvector of the projection matrix. This distribution describes the long-term proportion of individuals in each stage, independent of initial population structure. 32.6.3 Reproductive value The reproductive value of each stage, given by the dominant left eigenvector, describes the relative contribution of individuals in different stages to future population growth. Stages with high reproductive value have a disproportionate influence on population dynamics. 32.6.4 Sensitivities: absolute effects Sensitivity analysis quantifies how much \\(\\lambda\\) would change in response to a small absolute change in a given matrix element. Sensitivities answer the question: If this vital rate increased slightly, how much would population growth change? Let \\(\\mathbf{A}\\) be a population projection matrix with dominant eigenvalue \\(\\lambda\\), right eigenvector \\(\\mathbf{w}\\) (stable stage distribution), and left eigenvector \\(\\mathbf{v}\\) (reproductive value), scaled such that: \\[ \\mathbf{v}^\\top \\mathbf{w} = 1 \\] The sensitivity of population growth rate \\(\\lambda\\) to a matrix element \\(a_{ij}\\) is defined as: \\[ s_{ij} = \\frac{\\partial \\lambda}{\\partial a_{ij}} \\] For matrix population models, sensitivities can be calculated as: \\[ s_{ij} = v_i w_j \\] Sensitivity measures how much \\(\\lambda\\) changes in response to a small absolute change in a vital rate. 32.6.5 Elasticities: proportional effects Because vital rates are measured on different scales, sensitivities can be difficult to compare directly. Elasticity analysis rescales sensitivities to measure the proportional change in \\(\\lambda\\) resulting from a proportional change in a matrix element. Elasticities answer the question: Which life-history processes does population growth depend on most, relative to their current values? Since elasticities allow us to compare across species, reveal life-history strategies, and can be useful for management prioritization, we use and report elasticities more frequently than sensitivities. Because matrix elements are measured on different scales, sensitivities are often rescaled to obtain elasticities, which measure proportional effects. The elasticity of \\(\\lambda\\) with respect to matrix element \\(a_{ij}\\) is: \\[ e_{ij} = \\frac{a_{ij}}{\\lambda} \\frac{\\partial \\lambda}{\\partial a_{ij}} \\] Substituting the sensitivity expression gives: \\[ e_{ij} = \\frac{a_{ij}}{\\lambda} v_i w_j \\] The sum of all elasticities equals 1: \\[ \\sum_{i,j} e_{ij} = 1 \\] Together, sensitivities and elasticities reveal how population growth is partitioned among survival, growth, and reproduction. For example, long-lived species often show high elasticity to adult survival, whereas short-lived or fast-growing species tend to show higher elasticity to reproduction. 32.6.6 Beyond asymptotic dynamics: transient behavior While \\(\\lambda\\), stable stage distributions, and elasticities describe long-term behavior, populations often experience important short-term dynamics before equilibrium is reached. These transient dynamics capture temporary amplification, decline, or oscillations driven by initial population structure or disturbance. Let’s go over some common metrics to describe transient dynamics! Let: \\(\\mathbf{n}_0\\) be an initial population vector \\(\\mathbf{A}\\) be the projection matrix \\(\\lambda\\) be the dominant eigenvalue 32.6.6.1 Reactivity (short-term amplification) Reactivity measures the maximum possible proportional population growth over one time step, relative to long-term growth: \\[ \\rho_1 = \\max_{\\mathbf{n}_0} \\frac{\\|\\mathbf{A}\\mathbf{n}_0\\|}{\\|\\mathbf{n}_0\\|} \\] Interpretation: \\(\\rho_1 &gt; \\lambda\\) indicates transient amplification \\(\\rho_1 &lt; \\lambda\\) indicates immediate decline 32.6.6.2 Maximum amplification over time The maximum amplification over all time steps is: \\[ \\rho_{\\max} = \\max_{t \\ge 1} \\frac{\\|\\mathbf{A}^t \\mathbf{n}_0\\|}{\\|\\mathbf{n}_0\\|} \\] This quantity captures the largest possible transient increase in population size that can occur before long-term (asymptotic) behavior dominates. Interpretation: Maximum amplification describes the strongest short-term population response that can arise purely from population structure, even when long-term growth is stable or declining. A population with \\(\\lambda \\le 1\\) may still experience substantial temporary growth if its initial stage structure aligns with highly productive or resilient stages. In applied contexts, high values of \\(\\rho_{\\max}\\) indicate the potential for short-term booms following disturbance, management action, or unusual recruitment events, even if long-term persistence is not guaranteed. 32.6.6.3 Inertia Inertia describes how long the influence of initial population structure persists before convergence to stable growth: \\[ \\text{Inertia} = \\frac{\\|\\mathbf{A}^t \\mathbf{n}_0\\|}{\\lambda^t \\|\\mathbf{n}_0\\|} \\quad \\text{as } t \\to \\infty \\] Interpretation: Values greater than 1 indicate persistent amplification Values less than 1 indicate persistent suppression 32.6.6.4 Damping ratio (rate of convergence) The damping ratio quantifies how quickly transient dynamics decay and is defined as: \\[ \\text{Damping ratio} = \\frac{|\\lambda_1|}{|\\lambda_2|} \\] where: \\(\\lambda_1\\) is the dominant eigenvalue \\(\\lambda_2\\) is the subdominant eigenvalue (second largest magnitude) Interpretation: Larger values indicate faster convergence to the stable stage distribution Values close to 1 indicate long-lasting transient dynamics 32.7 Chapter summary In this chapter, we explored a progression of demographic models used to describe and analyze population dynamics. We began with simple, unstructured models of exponential and logistic growth, which capture fundamental principles of population increase and resource limitation. While these models provide important conceptual foundations, they assume that all individuals in a population are demographically identical. We then introduced structured population models, which explicitly account for differences among individuals based on age, stage, or size. Age-structured (Leslie) and stage-structured (Lefkovitch) matrix models describe how individuals transition among life stages and how these transitions determine population growth. From these models, we can calculate key quantities such as the population growth rate (\\(\\lambda\\)), stable stage distribution, and reproductive value. Building on this framework, we examined how sensitivities and elasticities identify which vital rates have the greatest influence on population growth, and how transient dynamics describe short-term population responses before long-term equilibrium is reached. Metrics such as reactivity, maximum amplification, inertia, and the damping ratio reveal how populations can temporarily grow, decline, or overshoot even when long-term growth is stable or negative. Finally, we introduced Integral Projection Models (IPMs), which extend matrix models by treating size as a continuous variable rather than dividing individuals into discrete stages. IPMs preserve the logic of matrix models while avoiding arbitrary stage boundaries, making them particularly well suited for plant populations and other systems where vital rates vary smoothly with size. Together, these approaches provide a powerful toolkit for understanding how individual-level processes scale up to population-level dynamics, and for identifying the demographic mechanisms that drive population growth, decline, and resilience. 32.8 Test your knowledge What is the key difference between unstructured population models and structured population models? Why is exponential growth considered a multiplicative process rather than an additive one? In a stage-structured matrix model, what biological processes are represented by: diagonal matrix elements? off-diagonal matrix elements? What does the dominant eigenvalue (\\(\\lambda\\)) represent in a population projection matrix, and why is it useful for comparing populations? What is the stable stage distribution, and how does it differ from the population’s initial stage structure? Explain why sensitivities and elasticities can lead to different conclusions about which life stages matter most for population growth. A population has \\(\\lambda &lt; 1\\) but exhibits high maximum amplification. What does this tell you about its short-term versus long-term dynamics? Why might transient dynamics be especially important for populations experiencing disturbance, management interventions, or rapid environmental change? Give one ecological situation where a stage-structured matrix model is appropriate and one where an Integral Projection Model would be preferable. Explain why sensitivities and elasticities can lead to different conclusions about which life stages matter most for population growth. A population has \\(\\lambda &lt; 1\\) but exhibits high maximum amplification. What does this tell you about its short-term versus long-term dynamics? Why might transient dynamics be especially important for populations experiencing disturbance, management interventions, or rapid environmental change? Give one ecological situation where a stage-structured matrix model is appropriate and one where an Integral Projection Model would be preferable. Suppose a population has: high elasticity to adult survival low elasticity to reproduction What type of life-history strategy does this suggest, and how might this influence management priorities? Two populations have the same \\(\\lambda\\), but one has a much lower damping ratio than the other. What does this imply about their transient dynamics? Why might focusing only on long-term population growth (\\(\\lambda\\)) be misleading in some ecological or conservation contexts? How do matrix models and IPMs help bridge individual-level processes (survival, growth, reproduction) with population-level outcomes? 32.9 Assignment Create a life cycle diagram for a species that you would like to examine. This species may be a plant or animal, but you should choose a system for which life stages or size classes are biologically meaningful. Life cycle diagrams are simplified representations of population structure and demographic processes. For Integral Projection Models (IPMs) in particular, these diagrams are often highly reduced, because size is treated as a continuous variable rather than divided into discrete stages. For example, a perennial plant life cycle diagram might include: A single size-based individual stage (rather than multiple discrete stages) Survival and growth within that size continuum Reproduction producing new individuals (e.g., seedlings) 32.9.1 Your task Choose a focal species and briefly describe its life history (1–2 sentences). Identify the key life stages or size classes relevant to its survival, growth, and reproduction. Draw a life cycle diagram that includes: All stages or size classes Arrows showing possible transitions among stages Arrows representing survival, growth, and reproduction Clearly label all stages and arrows. 32.9.2 Guidelines Your diagram does not need to include numerical values. Focus on biological realism rather than mathematical detail. You may draw your diagram by hand, digitally, or using software (e.g., PowerPoint, Illustrator, R). 32.9.3 What to submit A clear image or PDF of your life cycle diagram A figure legend (3–5 sentences) for your figure, describing how it reflects the species’ biology This figure can be included in a manuscript and will set you up to complete the next activity. "],["integral-population-models.html", "Chapter 33 Integral Population Models 33.1 Case Study: Modeling an Endangered Hawaiian Plant 33.2 Designing a Demographic Census: Timing and Measurements 33.3 Packages and approaches to creating IPMs 33.4 Building an IPM: Structuring linear models, variable transformations, and dealing with outliers 33.5 Constructing a transition matrix 33.6 Building an IPM: Boundary points, mesh points, and step size 33.7 Model Evaluation: Eviction 33.8 Estimating population dynamics parameters 33.9 Calculating confidence intervals 33.10 Putting this all together in code form! 33.11 Test your knowledge 33.12 Assignment", " Chapter 33 Integral Population Models 33.1 Case Study: Modeling an Endangered Hawaiian Plant For our applied example, we’ll build a population model for Silene lanceolata (lanceolate catchfly), a small woody shrub endemic to the Hawaiian Islands. This species is federally listed as threatened/endangered and faces multiple conservation challenges that make it an ideal candidate for demographic modeling. 33.1.1 Why model S. lanceolata populations? Hawaiian plant species like S. lanceolata occur in small, isolated populations that are particularly vulnerable to extinction. At Pōhakuloa Training Area (PTA) on Hawaii Island, these native plants face a perfect storm of threats: Invasive plant competition: Fountain grass (Cenchrus setaceus) and fireweed (Senecio madagascariensis) outcompete native species for water, light, and space Altered fire regimes: Invasive grasses produce fine fuels that dramatically increase fire frequency—a disturbance to which Hawaiian plants have no evolutionary adaptations Climate change: Increasing drought frequency threatens plants already stressed by competition and fire Small population sizes: Limited numbers mean that small changes in vital rates (survival, growth, reproduction) can have large consequences for extinction risk 33.1.2 The management question: Conservation managers need to decide how to allocate limited resources. Should they prioritize invasive plant control? Focus on fire suppression? Protect certain life stages? Population models allow us to project population trajectories under different management scenarios and identify which vital rates have the greatest influence on population growth. In this example, we’ll use demographic data collected from field studies at PTA to build an Integral Projection Model (IPM) that links individual plant size to survival, growth, and reproduction. This will allow us to evaluate how management actions might influence S. lanceolata persistence. 33.2 Designing a Demographic Census: Timing and Measurements Before we dive into building the population model, let’s review how demographic data are collected. The design of a census protocol involves several critical decisions that directly impact the quality and interpretability of your population projections. 33.2.1 Principle 1: Census Timing Must Align with the Organism’s Life Cycle For demographic models to be meaningful, censuses must occur at regular intervals that correspond to biologically relevant time steps. Ideally, you want to census: At the same time each year to capture consistent population states Before or after major demographic events (reproduction, mortality pulses, germination) When individuals are most visible/measurable for accurate data collection For S. lanceolata at Pōhakuloa Training Area, we faced practical constraints. While Hawaii lacks dramatic seasonal variation in temperature, the species does show phenological patterns. We conducted censuses in summer for several pragmatic reasons: Field accessibility: Summer weather allowed consistent access to remote field sites Plant visibility: Woody shrubs maintain their structure year-round, but summer timing captured both vegetative and reproductive activity Logistical feasibility: Research team availability and funding cycles The key is that we censused at the same time each year, allowing us to track year-to-year changes in a standardized way. Our annual time step (summer to summer) captures one full cycle of growth, reproduction, and survival. 33.2.2 Principle 2: Measurements Must Link to Vital Rates Demographic models require data on survival, growth, and reproduction. The measurements we collect must allow us to estimate these vital rates. For S. lanceolata, we structured our census to capture: Size Measurements (for survival and growth): We measured multiple aspects of plant size because size often predicts both survival probability and reproductive output: Foliated length of longest branch (cm): Captures vegetative vigor and photosynthetic capacity Plant height (cm): Structural size metric, indicates establishment and competitive ability Plant height with reproductive stalk (cm): Total height including reproductive structures Stem diameter (cm): Proxy for plant age and woody biomass accumulation Number of branches (n): Architectural complexity, related to resource acquisition For our Integral Projection Model (IPM), we’ll select one primary size variable that best predicts survival, growth, and fecundity. Often this is stem diameter or height, but we measured multiple metrics to explore which is most predictive. Reproductive Measurements (for fecundity): To estimate how many offspring each individual produces, we counted: Number of inflorescences (n): Reproductive effort (number of flowering stalks) Number of flowers and seed heads per stalk: Potential and realized seed production Seeds per fruit: Obtained from literature since counting tiny seeds in the field is impractical These measurements allow us to build a size-fecundity function: larger plants typically produce more inflorescences, more flowers, and ultimately more seeds. 33.2.3 Principle 3: Track Individual Fates Through Time The power of demographic models comes from tracking individuals across census intervals: Did this individual survive from year t to year t+1? If it survived, how much did it grow (change in size)? How many offspring did it produce? This requires marking individual plants (tags, GPS coordinates, maps) so we can relocate them in subsequent years. For S. lanceolata, each plant received a unique identifier allowing us to build a longitudinal dataset of individual life histories. 33.2.4 Principle 4: Document Context and Threats Beyond demographic measurements, we recorded factors that might explain variation in vital rates: Browse damage: Evidence of herbivory (ungulates, insects) Fire history: Burned vs. unburned individuals Disease/stress: Chlorosis, wilting, pathogen damage Proximity to invasive plants: Competition effects These covariates allow us to ask: Does fire reduce survival? Do plants near fountain grass grow more slowly? Does herbivory reduce reproduction? Let’s check out data from our initial collection trip: library(tidyverse) library(httr) # Create data directory if it doesn&#39;t exist if (!dir.exists(&quot;data&quot;)) dir.create(&quot;data&quot;) # Google Drive file ID file_id &lt;- &quot;1WCToCDAuSR_Wd2ScRy9yhwiDGijL47OX&quot; GET( url = paste0( &quot;https://drive.usercontent.google.com/download?id=&quot;, file_id, &quot;&amp;export=download&amp;confirm=t&quot; ), write_disk(&quot;data/silene_census.csv&quot;, overwrite = TRUE) ) ## Response [https://drive.usercontent.google.com/download?id=1WCToCDAuSR_Wd2ScRy9yhwiDGijL47OX&amp;export=download&amp;confirm=t] ## Date: 2026-02-12 23:40 ## Status: 200 ## Content-Type: application/octet-stream ## Size: 5.03 kB ## &lt;ON DISK&gt; /Users/sks379/Desktop/GitHubProjects/DataAnalysis/data/silene_census.csv # Load the data silene &lt;- read_csv(&quot;data/silene_census.csv&quot;, show_col_types = FALSE) |&gt; dplyr::select(-...1) # Remove row number column # Quick summary cat(&quot;Dataset dimensions:&quot;, nrow(silene), &quot;rows x&quot;, ncol(silene), &quot;columns\\n&quot;) ## Dataset dimensions: 100 rows x 11 columns cat(&quot;Number of unique individuals:&quot;, n_distinct(silene$UniqueID), &quot;\\n&quot;) ## Number of unique individuals: 100 cat(&quot;Weed control treatments:&quot;, paste(unique(silene$WeedControl), collapse = &quot;, &quot;), &quot;\\n&quot;) ## Weed control treatments: C, W cat(&quot;Map units:&quot;, paste(sort(unique(silene$MapUnit)), collapse = &quot;, &quot;), &quot;\\n&quot;) ## Map units: 1, 2, 3 cat(&quot;Proportion reproduced:&quot;, mean(silene$Reproduced), &quot;\\n&quot;) ## Proportion reproduced: 0.44 glimpse(silene) ## Rows: 100 ## Columns: 11 ## $ UniqueID &lt;chr&gt; &quot;Bobcat03_1&quot;, &quot;Bobcat03_2&quot;, &quot;Bobcat03_3&quot;, &quot;Bobcat03_4&quot;, &quot;Bobcat03_5&quot;, &quot;Bobcat03_6&quot;, &quot;Bobcat03_7&quot;, &quot;Bobcat03… ## $ WeedControl &lt;chr&gt; &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C… ## $ MapUnit &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,… ## $ VegHeight &lt;dbl&gt; 5.4, 42.6, 8.3, 2.5, 31.0, 26.8, 39.1, 18.5, 14.4, 6.8, 18.5, 11.0, 13.8, 19.9, 13.2, 11.0, 12.5, 9.0, 32.3… ## $ VegReproHeight &lt;dbl&gt; 5.4, 56.4, 8.3, 2.5, 31.0, 44.2, 53.6, 18.5, 14.4, 6.8, 18.5, 11.0, 13.8, 19.9, 13.2, 11.0, 12.5, 9.0, 32.3… ## $ StemDiameter &lt;dbl&gt; 0.18, 0.30, 0.12, 0.06, 0.22, 0.19, 0.29, 0.17, 0.24, 0.15, 0.18, 0.12, 0.15, 0.19, 0.17, 0.19, 0.15, 0.13,… ## $ StemNum &lt;dbl&gt; 0, 6, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 0, 4, 0, 0, 0, 0, 6, 4, 2, 2, 2, 0,… ## $ LengthLongestBranchwFoliage &lt;dbl&gt; 3.7, 1.0, 5.8, 1.5, 22.4, 18.0, 24.0, 16.4, 8.8, 4.3, 12.8, 5.1, 8.1, 12.4, 17.7, 14.6, 5.1, 5.2, 18.2, 12.… ## $ InflorNum &lt;dbl&gt; 0, 6, 0, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 26, 0, 21, 0, 0, 0, 0, 16, 18, 13, 4, … ## $ Reproduced &lt;dbl&gt; 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,… ## $ TotalReproOutput &lt;dbl&gt; 0, 21, 0, 0, 0, 26, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 58, 0, 49, 0, 0, 0, 0, 33, 40, 40,… 33.2.5 Understanding State Variables in IPMs In an Integral Projection Model (IPM), we need to choose a state variable that describes the “state” of each individual in the population. This variable must: Predict vital rates: Larger/older individuals typically have different survival, growth, and reproduction than smaller/younger ones Be continuously measured: IPMs work with continuous size distributions (unlike matrix models with discrete stages) Be measurable across time: We need to track how individuals change in this variable from year to year Capture biological meaningful variation: The variable should reflect real differences in demographic performance Common state variables in plant IPMs: Stem diameter Plant height Basal area Number of stems/ramets Leaf area Let’s explore our data to identify the best state variable for S. lanceolata. 33.2.6 Explore Potential State Variables # Summary of candidate state variables state_summary &lt;- silene |&gt; summarise( n_plants = n(), # Continuous size measurements mean_stem_diam = mean(StemDiameter, na.rm = TRUE), sd_stem_diam = sd(StemDiameter, na.rm = TRUE), mean_height_veg = mean(VegHeight, na.rm = TRUE), sd_height_veg = sd(VegHeight, na.rm = TRUE), mean_height_repro = mean(VegReproHeight, na.rm = TRUE), sd_height_repro = sd(VegReproHeight, na.rm = TRUE), mean_branch_length = mean(LengthLongestBranchwFoliage, na.rm = TRUE), sd_branch_length = sd(LengthLongestBranchwFoliage, na.rm = TRUE), # Count variables mean_stems = mean(StemNum, na.rm = TRUE), sd_stems = sd(StemNum, na.rm = TRUE), # Reproduction mean_inflor = mean(InflorNum, na.rm = TRUE), sd_inflor = sd(InflorNum, na.rm = TRUE), mean_repro = mean(TotalReproOutput, na.rm = TRUE), sd_repro = sd(TotalReproOutput, na.rm = TRUE), prop_reproduced = mean(Reproduced, na.rm = TRUE) ) knitr::kable(t(state_summary), col.names = &quot;Value&quot;, digits = 2, caption = &quot;Summary statistics for potential state variables&quot;) Table 33.1: Summary statistics for potential state variables Value n_plants 100.00 mean_stem_diam 0.54 sd_stem_diam 0.68 mean_height_veg 49.33 sd_height_veg 43.32 mean_height_repro 56.00 sd_height_repro 49.77 mean_branch_length 12.03 sd_branch_length 7.14 mean_stems 1.29 sd_stems 1.80 mean_inflor 3.98 sd_inflor 6.67 mean_repro 17.86 sd_repro 24.89 prop_reproduced 0.44 # Check for missing data missing_data &lt;- silene |&gt; summarise(across(everything(), ~sum(is.na(.)))) |&gt; pivot_longer(everything(), names_to = &quot;Variable&quot;, values_to = &quot;Missing&quot;) |&gt; filter(Missing &gt; 0) if (nrow(missing_data) &gt; 0) { cat(&quot;\\nMissing data detected:\\n&quot;) print(knitr::kable(missing_data)) } else { cat(&quot;\\n✓ No missing data in size measurements!\\n&quot;) } ## ## ✓ No missing data in size measurements! 33.2.7 Visualize Distribution of Candidate State Variables # Reshape data for plotting state_vars_long &lt;- silene |&gt; dplyr::select( UniqueID, StemDiameter, VegHeight, VegReproHeight, LengthLongestBranchwFoliage, StemNum ) |&gt; tidyr::pivot_longer( cols = -UniqueID, names_to = &quot;variable&quot;, values_to = &quot;value&quot; ) |&gt; dplyr::mutate( variable = dplyr::recode( variable, StemDiameter = &quot;Stem Diameter (cm)&quot;, VegHeight = &quot;Vegetative Height (cm)&quot;, VegReproHeight = &quot;Height with Repro (cm)&quot;, LengthLongestBranchwFoliage = &quot;Longest Branch w/ Foliage (cm)&quot;, StemNum = &quot;Number of Stems&quot; ) ) # Plot distributions ggplot(state_vars_long, aes(x = value)) + geom_histogram(bins = 15, fill = &quot;steelblue&quot;, alpha = 0.7, color = &quot;white&quot;) + facet_wrap(~variable, scales = &quot;free&quot;, ncol = 2) + theme_minimal(base_size = 12) + labs(title = &quot;Distribution of Potential State Variables&quot;, subtitle = &quot;Which variable best captures individual variation in S. lanceolata?&quot;, x = &quot;Measurement value&quot;, y = &quot;Number of individuals&quot;) ### Assess Correlations Between Measurements State variables should ideally be correlated with other size metrics (indicating they capture overall plant size) but also provide unique information. library(corrplot) # Calculate correlation matrix cor_data &lt;- silene |&gt; dplyr::select(StemDiameter, VegHeight, VegReproHeight, LengthLongestBranchwFoliage, StemNum, InflorNum, TotalReproOutput) |&gt; rename( `Stem Diam` = StemDiameter, `Height Veg` = VegHeight, `Height Repro` = VegReproHeight, `Branch Length` = LengthLongestBranchwFoliage, `N Stems` = StemNum, `N Inflor` = InflorNum, `Repro Output` = TotalReproOutput ) cor_matrix &lt;- cor(cor_data, use = &quot;complete.obs&quot;) # Visualize correlations corrplot(cor_matrix, method = &quot;color&quot;, type = &quot;upper&quot;, addCoef.col = &quot;black&quot;, number.cex = 0.7, tl.col = &quot;black&quot;, tl.srt = 45, tl.cex = 0.8, title = &quot;Correlations Between Size and Reproductive Metrics&quot;, mar = c(0, 0, 2, 0)) In many demographic studies, time constraints limit how long we have to identify appropriate state variables, establish a census protocol, and collect sufficient data to parameterize transition matrices. Because survival and growth require observations across multiple years, early stages of a study often rely on variables that can be measured and linked to demographic processes within a single field season. For this reason, I often prioritize selecting state variables that best explain variation in reproductive rates, since reproduction can typically be measured alongside size or trait data in the same year. Below, we use model selection to identify the state variable that best predicts reproductive output. In my experience, the state variable that most strongly explains reproduction often also performs well as a predictor of other vital rates, such as survival and growth, once enough data have been collected to evaluate these relationships. This approach provides a practical and biologically informed starting point for demographic modeling when data are initially limited. 33.2.8 Selecting Our State Variable Recall that we are trying to identify state variables with the following characteristics: Continuously distributed: Not discrete categories, works well with IPM framework Strong biological meaning: Represents accumulated woody growth and age Practical: Easy to measure consistently across years Predictive: Likely correlates with survival (established plants) and reproduction (larger plants) Low measurement error: Less affected by seasonal variation So far, the majority of our variables meet these criteria, but let’s test predictability of vital rates! The ultimate decider! 33.2.8.1 Quantitative Model Comparison with AIC # Fit Poisson GLMs for each candidate state variable # (Poisson is appropriate for count data like reproductive output) model_diameter &lt;- glm(TotalReproOutput ~ StemDiameter, family = poisson, data = silene) model_height &lt;- glm(TotalReproOutput ~ VegHeight, family = poisson, data = silene) model_height_repro &lt;- glm(TotalReproOutput ~ VegReproHeight, family = poisson, data = silene) model_branch &lt;- glm(TotalReproOutput ~ LengthLongestBranchwFoliage, family = poisson, data = silene) model_stems &lt;- glm(TotalReproOutput ~ StemNum, family = poisson, data = silene) # Create comprehensive comparison table aic_comparison &lt;- tibble( State_Variable = c(&quot;Stem Diameter&quot;, &quot;Vegetative Height&quot;, &quot;Height with Repro&quot;, &quot;Branch Length&quot;, &quot;Number of Stems&quot;), AIC = c(AIC(model_diameter), AIC(model_height), AIC(model_height_repro), AIC(model_branch), AIC(model_stems)), df = c(2, 2, 2, 2, 2) # All have 2 parameters (intercept + slope) ) |&gt; arrange(AIC) |&gt; mutate( Delta_AIC = AIC - min(AIC), Relative_Likelihood = exp(-0.5 * Delta_AIC), AIC_Weight = Relative_Likelihood / sum(Relative_Likelihood), Interpretation = case_when( Delta_AIC == 0 ~ &quot;Best model&quot;, Delta_AIC &lt; 2 ~ &quot;Substantial support&quot;, Delta_AIC &lt; 7 ~ &quot;Considerably less support&quot;, TRUE ~ &quot;Essentially no support&quot; ) ) knitr::kable(aic_comparison, digits = 3, caption = &quot;AIC comparison: Which size metric best predicts fecundity?&quot;) Table 33.2: AIC comparison: Which size metric best predicts fecundity? State_Variable AIC df Delta_AIC Relative_Likelihood AIC_Weight Interpretation Height with Repro 1588.305 2 0.000 1 1 Best model Vegetative Height 1876.079 2 287.774 0 0 Essentially no support Number of Stems 2193.372 2 605.067 0 0 Essentially no support Stem Diameter 3057.851 2 1469.546 0 0 Essentially no support Branch Length 3401.991 2 1813.686 0 0 Essentially no support Now, let’s visualize the top relationship! library(patchwork) # Get predictions from the best model for smooth curve pred_data &lt;- tibble( VegReproHeight = seq(min(silene$VegReproHeight, na.rm = TRUE), max(silene$VegReproHeight, na.rm = TRUE), length.out = 100) ) pred_data$predicted &lt;- predict(model_height_repro, newdata = pred_data, type = &quot;response&quot;) # Main scatter plot with model fit p1 &lt;- ggplot(silene, aes(x = VegReproHeight, y = TotalReproOutput)) + geom_point(aes(color = factor(Reproduced)), alpha = 0.6, size = 3) + geom_line(data = pred_data, aes(x = VegReproHeight, y = predicted), color = &quot;coral&quot;, linewidth = 1.5) + scale_color_manual(values = c(&quot;0&quot; = &quot;gray60&quot;, &quot;1&quot; = &quot;steelblue&quot;), labels = c(&quot;No reproduction&quot;, &quot;Reproduced&quot;), name = &quot;&quot;) + theme_minimal(base_size = 12) + labs(title = &quot;Best Predictor: Height with Reproductive Structures&quot;, subtitle = paste0(&quot;AIC = &quot;, round(AIC(model_height_repro), 2), &quot; | AIC Weight = &quot;, round(aic_comparison$AIC_Weight[aic_comparison$State_Variable == &quot;Height with Repro&quot;], 3)), x = &quot;Height with reproductive structures (cm)&quot;, y = &quot;Total reproductive output (flowers + seeds)&quot;) + theme(legend.position = &quot;top&quot;) # Residual plot to check model fit silene_resid &lt;- silene |&gt; mutate( fitted = predict(model_height_repro, type = &quot;response&quot;), residuals = TotalReproOutput - fitted ) p2 &lt;- ggplot(silene_resid, aes(x = fitted, y = residuals)) + geom_point(alpha = 0.6, color = &quot;steelblue&quot;) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;coral&quot;) + geom_smooth(se = FALSE, color = &quot;gray30&quot;) + theme_minimal(base_size = 12) + labs(title = &quot;Model Diagnostics: Residual Plot&quot;, x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;) p1 / p2 + plot_layout(heights = c(2, 1)) Top Panel: The Size-Fecundity Relationship Let’s check out the figure and think about the implications: The Zero-Inflation Problem: Notice the large cluster of gray points at reproductive output = 0. These are plants that didn’t reproduce at all (56% of individuals!). This creates a challenge for Poisson models, which don’t naturally handle “excess zeros.” Clear Size Threshold: Among reproducing plants (blue), there’s a strong positive relationship - taller plants with larger reproductive structures produce more seeds. But notice that ALL small plants (&lt;~40 cm) failed to reproduce. This suggests a reproductive size threshold. Increasing Variance: As height increases, the spread of blue points gets wider. Small reproductive plants show relatively consistent output (~10-30 seeds), while large plants vary dramatically (20-100 seeds). This heteroscedasticity (unequal variance) can be an issue for simple linear models. The Perfect Fit “Problem”: The coral line fits the reproducing plants beautifully, BUT this creates a conceptual issue for IPMs: VegReproHeight includes the reproductive stalks themselves! This is somewhat circular - we’re using reproductive structures to predict reproduction. Bottom Panel: Model Diagnostics (Critical!) Let’s check out the figure and think about the implications: Non-Random Residual Pattern: The residuals should be randomly scattered around zero (the dashed orange line). Instead, notice: Left side (fitted values 0-25): Residuals are tightly clustered near zero (all those non-reproductive plants) Middle (fitted values 25-50): Residuals are nicely random ✓ Right side (fitted values &gt;75): The smooth line curves downward, indicating the model underpredicts reproductive output for the largest plants The Outlier: See that point at the far right with residual ≈ -75? That’s a very large plant that produced MUCH less than expected. What happened? (Disease? Herbivory? Late-season measurement?) What This Means for Model Selection: Let’s think this through: Statistically: VegReproHeight has the best AIC, BUT the residual pattern suggests the Poisson model isn’t perfect. Biologically: This relationship makes sense - plants invest in tall reproductive stalks to display flowers and disperse seeds. A classic (and very common) way to handle “zero inflation” in plant fecundity when building IPMs is to use a two‐part (hurdle) model. In this approach, we first model whether an individual reproduces at all (i.e., produces any flowers/fruits/seeds) using a binomial model. Then, conditional on reproduction occurring, we model the amount of reproductive output (e.g., number of fruits or seeds) using a count model such as a Poisson (or often a negative binomial if counts are overdispersed). This is often more biologically realistic because it separates two distinct processes: (1) the decision/ability to reproduce and (2) how much is produced once reproduction happens. A zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) also addresses excess zeros, but it assumes the zeros come from two sources: 1. Structural zeros: individuals in a “certain zero” state (they cannot reproduce / are not eligible) 2. Sampling zeros: individuals who are “eligible,” but still produce zero by chance under the count distribution Thus, in the hurdle model, all zeros are handled by the binomial part; the count model is fit to positive counts only. In the zero-inflated model, zeros can come from either the inflation process or the count process. The hurdle (binomial + conditional count) approach aligns well with plant reproductive biology because: Reproduction often reflects a threshold-like process (size/condition must be sufficient to flower/fruit). Once reproducing, output typically scales with size and resources. It yields two interpretable functions for the IPM: probability of reproduction as a function of size expected fecundity given reproduction as a function of size and, bonus, it’s also often simpler to implement and communicate in an IPM context Let’s check this out: # Fit logistic regression for each candidate state variable # Response: Reproduced (0 = no, 1 = yes) logit_diameter &lt;- glm(Reproduced ~ VegReproHeight, family = binomial, data = silene) logit_height &lt;- glm(Reproduced ~ VegHeight, family = binomial, data = silene) logit_height_repro &lt;- glm(Reproduced ~ VegReproHeight, family = binomial, data = silene) logit_branch &lt;- glm(Reproduced ~ LengthLongestBranchwFoliage, family = binomial, data = silene) logit_stems &lt;- glm(Reproduced ~ StemNum, family = binomial, data = silene) # Compare models with AIC aic_reproduction &lt;- tibble( State_Variable = c(&quot;Stem Diameter&quot;, &quot;Vegetative Height&quot;, &quot;Height with Repro&quot;, &quot;Branch Length&quot;, &quot;Number of Stems&quot;), AIC = c(AIC(logit_diameter), AIC(logit_height), AIC(logit_height_repro), AIC(logit_branch), AIC(logit_stems)) ) |&gt; arrange(AIC) |&gt; mutate( Delta_AIC = AIC - min(AIC), AIC_Weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC)) ) knitr::kable(aic_reproduction, digits = 3, caption = &quot;Step 1: Which size metric best predicts probability of reproduction?&quot;) Table 33.3: Step 1: Which size metric best predicts probability of reproduction? State_Variable AIC Delta_AIC AIC_Weight Stem Diameter 38.661 0.000 0.497 Height with Repro 38.661 0.000 0.497 Number of Stems 48.159 9.498 0.004 Vegetative Height 50.583 11.923 0.001 Branch Length 129.301 90.640 0.000 # Filter to plants that reproduced silene_reproductive &lt;- silene |&gt; filter(Reproduced == 1) cat(&quot;Reproductive plants:&quot;, nrow(silene_reproductive), &quot;out of&quot;, nrow(silene), paste0(&quot;(&quot;, round(100 * nrow(silene_reproductive)/nrow(silene), 1), &quot;%)\\n&quot;)) ## Reproductive plants: 44 out of 100 (44%) # Fit Poisson regression for seed production (reproductive plants only) pois_diameter &lt;- glm(TotalReproOutput ~ VegReproHeight, family = poisson, data = silene_reproductive) pois_height &lt;- glm(TotalReproOutput ~ VegHeight, family = poisson, data = silene_reproductive) pois_height_repro &lt;- glm(TotalReproOutput ~ VegReproHeight, family = poisson, data = silene_reproductive) pois_branch &lt;- glm(TotalReproOutput ~ LengthLongestBranchwFoliage, family = poisson, data = silene_reproductive) pois_stems &lt;- glm(TotalReproOutput ~ StemNum, family = poisson, data = silene_reproductive) # Compare models aic_seed_production &lt;- tibble( State_Variable = c(&quot;Stem Diameter&quot;, &quot;Vegetative Height&quot;, &quot;Height with Repro&quot;, &quot;Branch Length&quot;, &quot;Number of Stems&quot;), AIC = c(AIC(pois_diameter), AIC(pois_height), AIC(pois_height_repro), AIC(pois_branch), AIC(pois_stems)) ) |&gt; arrange(AIC) |&gt; mutate( Delta_AIC = AIC - min(AIC), AIC_Weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC)) ) knitr::kable(aic_seed_production, digits = 3, caption = &quot;Step 2: Which size metric best predicts seed count among reproducers?&quot;) Table 33.3: Step 2: Which size metric best predicts seed count among reproducers? State_Variable AIC Delta_AIC AIC_Weight Number of Stems 726.427 0.000 0.813 Stem Diameter 730.757 4.331 0.093 Height with Repro 730.757 4.331 0.093 Vegetative Height 747.756 21.329 0.000 Branch Length 798.683 72.256 0.000 # Combine the two tables combined_aic &lt;- aic_reproduction |&gt; dplyr::rename( AIC_Reproduction = AIC, Weight_Reproduction = AIC_Weight ) |&gt; dplyr::select( State_Variable, AIC_Reproduction, Weight_Reproduction ) |&gt; dplyr::left_join( aic_seed_production |&gt; dplyr::rename( AIC_SeedCount = AIC, Weight_SeedCount = AIC_Weight ) |&gt; dplyr::select( State_Variable, AIC_SeedCount, Weight_SeedCount ), by = &quot;State_Variable&quot; ) |&gt; dplyr::mutate( Combined_Weight = Weight_Reproduction * Weight_SeedCount, Rank_Reproduction = rank(AIC_Reproduction), Rank_SeedCount = rank(AIC_SeedCount), Average_Rank = (Rank_Reproduction + Rank_SeedCount) / 2 ) |&gt; dplyr::arrange(Average_Rank) knitr::kable(combined_aic, digits = 3, caption = &quot;Combined performance: Which variable is best at BOTH tasks?&quot;) Table 33.3: Combined performance: Which variable is best at BOTH tasks? State_Variable AIC_Reproduction Weight_Reproduction AIC_SeedCount Weight_SeedCount Combined_Weight Rank_Reproduction Rank_SeedCount Average_Rank Stem Diameter 38.661 0.497 730.757 0.093 0.046 1.5 2.5 2 Height with Repro 38.661 0.497 730.757 0.093 0.046 1.5 2.5 2 Number of Stems 48.159 0.004 726.427 0.813 0.004 3.0 1.0 2 Vegetative Height 50.583 0.001 747.756 0.000 0.000 4.0 4.0 4 Branch Length 129.301 0.000 798.683 0.000 0.000 5.0 5.0 5 library(patchwork) # Use the best model (let&#39;s assume it&#39;s stem diameter for example) # Create prediction data pred_data &lt;- tibble( VegReproHeight = seq(min(silene$VegReproHeight, na.rm = TRUE), max(silene$VegReproHeight, na.rm = TRUE), length.out = 100) ) # Predict probability of reproduction pred_data$prob_reproduce &lt;- predict(logit_diameter, newdata = pred_data, type = &quot;response&quot;) # Predict seed count (on log scale, then back-transform) pred_data$expected_seeds &lt;- predict(pois_diameter, newdata = pred_data, type = &quot;response&quot;) # Combined expected output pred_data$expected_total &lt;- pred_data$prob_reproduce * pred_data$expected_seeds # Panel 1: Probability of Reproduction p1 &lt;- ggplot(silene, aes(x = VegReproHeight, y = Reproduced)) + geom_point(alpha = 0.4, size = 2, position = position_jitter(height = 0.02, width = 0)) + geom_line(data = pred_data, aes(x = VegReproHeight, y = prob_reproduce), color = &quot;coral&quot;, linewidth = 1.5) + theme_minimal(base_size = 12) + labs(title = &quot;Step 1: Probability of Reproducing&quot;, subtitle = &quot;Logistic regression on all plants&quot;, x = &quot;Stem diameter (cm)&quot;, y = &quot;P(Reproduction)&quot;) + ylim(-0.05, 1.05) # Panel 2: Seeds IF reproducing p2 &lt;- ggplot(silene_reproductive, aes(x = VegReproHeight, y = TotalReproOutput)) + geom_point(alpha = 0.6, size = 2, color = &quot;steelblue&quot;) + geom_line(data = pred_data, aes(x = VegReproHeight, y = expected_seeds), color = &quot;coral&quot;, linewidth = 1.5) + theme_minimal(base_size = 12) + labs(title = &quot;Step 2: Seeds IF Reproducing&quot;, subtitle = &quot;Poisson regression on reproductive plants only&quot;, x = &quot;Stem diameter (cm)&quot;, y = &quot;Seed count (given reproduction)&quot;) # Panel 3: Combined expected reproduction p3 &lt;- ggplot(silene, aes(x = VegReproHeight, y = TotalReproOutput)) + geom_point(aes(color = factor(Reproduced)), alpha = 0.6, size = 2) + geom_line(data = pred_data, aes(x = VegReproHeight, y = expected_total), color = &quot;coral&quot;, linewidth = 1.5) + scale_color_manual(values = c(&quot;0&quot; = &quot;gray60&quot;, &quot;1&quot; = &quot;steelblue&quot;), labels = c(&quot;Did not reproduce&quot;, &quot;Reproduced&quot;), name = &quot;&quot;) + theme_minimal(base_size = 12) + labs(title = &quot;Combined: Expected Reproduction&quot;, subtitle = &quot;E[seeds] = P(reproduce) × E[seeds | reproduce]&quot;, x = &quot;Stem diameter (cm)&quot;, y = &quot;Expected reproductive output&quot;) + theme(legend.position = &quot;top&quot;) p1 + p2 + p3 33.2.8.2 Why Use Only One State Variable? The Multi-Dimensional Trade-off State variables are rarely perfect predictors of vital rates. As a result, it is tempting to assume that including additional state variables will always improve demographic models. In practice, however, adding multiple state variables introduces substantial challenges. First, it increases the amount of field data required, often extending monitoring timelines and complicating census protocols. Multi-variable models can also be less intuitive for land managers, making it harder to interpret key drivers of population dynamics or implement streamlined monitoring programs. Second—and more importantly—adding state variables dramatically increases model complexity through what is known as the dimensionality problem, which we describe in the following section. 33.2.9 The dimensionality problem An Integral Projection Model (IPM) works by tracking how individuals move through a continuous distribution of sizes over time. Mathematically, this involves solving an integral equation: \\[ n(z&#39;, t+1) = \\int \\left[ s(z)\\, g(z&#39;, z) + f(z&#39;, z) \\right] n(z, t)\\, dz \\] where: \\(z\\) is the state variable (e.g., size) at time \\(t\\) \\(z&#39;\\) is the state variable at time \\(t+1\\) \\(n(z, t)\\) is the population density of individuals of size \\(z\\) at time \\(t\\) \\(s(z)\\) is the probability of survival for individuals of size \\(z\\) \\(g(z&#39;, z)\\) describes growth from size \\(z\\) to size \\(z&#39;\\) \\(f(z&#39;, z)\\) describes reproductive contributions from individuals of size \\(z\\) to size \\(z&#39;\\) The integral is evaluated over all possible values of \\(z\\), meaning that contributions from individuals of every size at time \\(t\\) are summed to determine the population distribution at time \\(t+1\\). With ONE state variable (e.g., stem diameter): We discretize the size range into ~100-200 cells (bins) This creates a 100×100 projection matrix (manageable!) Computational time: seconds With TWO state variables (e.g., diameter AND height): We need a 2-dimensional grid: diameter × height With 100 bins each → 100×100 = 10,000 cells Projection matrix becomes 10,000×10,000 Computational time: minutes to hours Data requirements: Need MANY more individuals to fill that grid With THREE state variables (diameter, height, number of stems): 100×100×100 = 1,000,000 cells Matrix size: 1,000,000×1,000,000 Computational time: potentially days Data requirements: Tens of thousands of observations Most cells would be EMPTY This is called the “curse of dimensionality” - complexity grows exponentially with each added dimension. Especially since IPMs are often used to model rare plants characterized by low population sizes, the data requirements imposed by the inclusion of even a second state variable, renders this approach intractable. On rare occasions, it might be worth it to include to an additional state variable, if the two variables two variables capture different aspects of performance and they are uncorrelated and if you have HUGE datasets. Onward! With total height selected as our state variable, we’re ready to build the IPM vital rate functions! 33.3 Packages and approaches to creating IPMs There are multiple ways to build and analyze Integral Projection Models (IPMs) in R. All approaches are based on the same underlying demographic theory, but they differ in how much structure is imposed, how much code must be written by the user, and how transparent the resulting model is. Here, we briefly introduce three commonly used approaches: fully automated IPM frameworks, semi-structured IPM tools, and hand-coded IPMs. In the sections that follow, we use these approaches to illustrate model fitting and selection using the same biological questions. 33.3.1 ipmr: a modern, flexible IPM framework The ipmr package provides a modern, modular framework for building IPMs in R. Rather than fitting the IPM as a single object, ipmr encourages users to specify each vital-rate submodel (survival, growth, reproduction) explicitly and then combine them into an IPM kernel. This approach emphasizes transparency and flexibility. Model components can be easily modified, compared, and extended, making ipmr particularly well suited for model selection, uncertainty analysis, and advanced demographic metrics such as sensitivities, elasticities, and transient dynamics. Because ipmr requires users to think carefully about each model component, it has a steeper learning curve than more automated approaches, but it provides the most control and clarity for research-grade analyses. 33.3.2 IPMpack: a more automated IPM workflow The IPMpack package offers a more automated approach to building IPMs, handling many steps of kernel construction and numerical integration internally. Users specify vital-rate models and size bounds, and the package generates the IPM and associated outputs. This approach can be efficient and relatively easy to implement for standard one-dimensional IPMs. However, the abstraction can make it harder to see how individual model components contribute to population dynamics, and flexibility is more limited when extending models or exploring alternative formulations. 33.3.3 Hand-coded IPMs: maximum transparency A third approach is to build IPMs entirely by hand using base R code. In this workflow, vital-rate models are fit using standard statistical tools (e.g., glm, lm, gam), and the IPM kernel is constructed explicitly using numerical integration and matrix operations. Hand-coded IPMs provide complete transparency and conceptual clarity, making them valuable for understanding how IPMs work at a fundamental level. However, they require substantially more code, are more prone to implementation errors, and can be difficult to maintain or extend. Now let’s create the linear models that make up the IPM kernel! Through, we can work through the process using each approach! 33.4 Building an IPM: Structuring linear models, variable transformations, and dealing with outliers In this section, we build the statistical models that form the core of an Integral Projection Model (IPM). Regardless of whether an IPM is implemented using a package such as ipmr, IPMpack, or coded by hand, the underlying structure is the same: IPMs are constructed from a set of regression models that describe how individual state variables influence survival, growth, and reproduction. Before assembling an IPM kernel, it is therefore essential to think carefully about (1) which vital rates will be modeled, (2) how state variables enter those models, and (3) how issues such as zero inflation, outliers, and missing values are handled. First, let’s go ahead and pull in our transition dataset. A transition dataset consists of two years of matched data, in which the fate of each individual from one year to the next is documented. Notice the structure of the dataset! This dataframe tracks the fate of all individuals in the population from time 1 to time 2. The ‘id’ column corresponds with the tag number for each plant. The ‘size’ column contains sizes (in this case heights) of individuals in time 1, while ‘sizeNext’ indicates the size at time 2. In the ‘surv’ column, the fate of the individual at time 2 is indicated by either a 0 (died) or 1 (survived). For individuals that died, we place an ‘NA’ in the sizeNext column, since that individual didn’t exist that year! Reproduction is always the most complex part of demographic modeling for plant species. Often, a reproductive cycle includes cryptic stages (seeds!) that are hard to track, may include vegetative and sexual reproductive components, and may involve several processes (like flower production and seed production) that may be important to examine to understand why population growth rates vary! For Silene lanceolata, we don’t know enough about the seed bank to include this in our models. Seed dynamics are difficult to track across multiple sites and years. For this reason, we have built the models such that seeds produced in year 1 has the potential to germinate in year 2 or perish. Luckily, ignoring the seed bank for species with high rates of seed production has negligible affects on population growth. A new seedling won’t have a size, survival or reproductive values in year 1 (NAs are added to this column), but will have a measurement in the ‘sizeNext’ column - using this pattern in the data is how we tell R to pull data on seedlings, so it is important to have this information correctly entered in the dataframe. We’ve broken reproduction into two components, fec1 and fec2. If an individual reproduced, we mark a ‘1’ in fec1, if the individual didn’t reproduce, then we add a ‘0’ to the fec1 column. For those individuals that did reproduce, the fec2 column contains the number of seeds produced. Again notice that if an individual didn’t reproduce, we place an ‘NA’ in the fec2 column. Finally, we’ve documented other observations for each individual that we think might explain population growth rates, like whether a plant has been browsed by deer or is in competition with other vegetation. IPMs are only as good as the linear models that comprise them! As a critical first step in analyses, we have to take a look at the relationship between our state variable and growth, reproduction and survival. We want to be sure to address any issues with normality and unequal variance. First, examine variance; if variation depends on the state variable, include this in the model (we’ll do this in a minute). It is fairly common in plants to see, for instance, that growth rates are more variable in larger individuals. For the ipmr and handcoding, column names could essentially be anything, though it is good practice to name columns in a way that is intuitive for your analyses. The IPMpack syntax is stricter, so we will default to using those naming conventions. Let’s pull in our data and look at its structure. library(tidyverse) library(httr) # Download transition data file_id &lt;- &quot;1V0qWq0SlA9rWzyraZaOFdWDVDKQyiu53&quot; GET( url = paste0(&quot;https://drive.usercontent.google.com/download?id=&quot;, file_id, &quot;&amp;export=download&amp;confirm=t&quot;), write_disk(&quot;data/silene_transitions.csv&quot;, overwrite = TRUE) ) ## Response [https://drive.usercontent.google.com/download?id=1V0qWq0SlA9rWzyraZaOFdWDVDKQyiu53&amp;export=download&amp;confirm=t] ## Date: 2026-02-12 23:40 ## Status: 200 ## Content-Type: application/octet-stream ## Size: 18.2 kB ## &lt;ON DISK&gt; /Users/sks379/Desktop/GitHubProjects/DataAnalysis/data/silene_transitions.csv # Load the data transitions &lt;- read_csv(&quot;data/silene_transitions.csv&quot;, show_col_types = FALSE) # Initial exploration cat(&quot;Dataset dimensions:&quot;, nrow(transitions), &quot;rows x&quot;, ncol(transitions), &quot;columns\\n\\n&quot;) ## Dataset dimensions: 392 rows x 14 columns glimpse(transitions) ## Rows: 392 ## Columns: 14 ## $ id &lt;dbl&gt; 7, 34, 2, 46, 31, 23, 36, 32, 1, 41, 6, 23, 35, 22, 32, 26, 4, 1, 40, 11, 42, 21, 41, 24, 42, 49, 48, 45,… ## $ size &lt;dbl&gt; 110.5, 121.6, 56.4, 97.5, 90.0, 144.5, 103.4, 90.2, 76.2, 106.8, 94.8, 109.7, 150.4, 136.1, 131.5, 138.9,… ## $ surv &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ sizeNext &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 26.7, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 12.2, 1… ## $ fec1 &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ fec2 &lt;dbl&gt; 3600, 10080, 11340, 12150, 13500, 15120, 15750, 18000, 29700, 31500, 72900, 93150, 98010, 133650, 233280,… ## $ Exclude &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ Site &lt;chr&gt; &quot;KalawamounaE&quot;, &quot;Bobcat03&quot;, &quot;Bobcat03&quot;, &quot;KalawamounaE&quot;, &quot;KalawamounaE&quot;, &quot;KalawamounaE&quot;, &quot;KalawamounaE&quot;, &quot;… ## $ `Herbivory (Y/N)_2024` &lt;chr&gt; NA, NA, NA, &quot;N&quot;, NA, NA, NA, NA, &quot;N&quot;, &quot;N&quot;, NA, NA, NA, NA, NA, NA, &quot;N&quot;, NA, NA, NA, NA, NA, NA, NA, &quot;N&quot;, … ## $ `Herbivory Agent_2024` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ `Disease (Y/N)_2024` &lt;chr&gt; &quot;N&quot;, &quot;N&quot;, NA, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, NA, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, NA, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, NA,… ## $ `Description of Disease_2024` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ NotesYear1 &lt;chr&gt; NA, NA, NA, &quot;most leaves are gone&quot;, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ NotesYear2 &lt;chr&gt; &quot;NO&quot;, &quot;NO&quot;, NA, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, NA, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, &quot;NO&quot;, NA, &quot;NO… cat(&quot;\\n=== Column names ===\\n&quot;) ## ## === Column names === print(names(transitions)) ## [1] &quot;id&quot; &quot;size&quot; &quot;surv&quot; &quot;sizeNext&quot; ## [5] &quot;fec1&quot; &quot;fec2&quot; &quot;Exclude&quot; &quot;Site&quot; ## [9] &quot;Herbivory (Y/N)_2024&quot; &quot;Herbivory Agent_2024&quot; &quot;Disease (Y/N)_2024&quot; &quot;Description of Disease_2024&quot; ## [13] &quot;NotesYear1&quot; &quot;NotesYear2&quot; cat(&quot;\\n=== Summary statistics ===\\n&quot;) ## ## === Summary statistics === print(summary(transitions)) ## id size surv sizeNext fec1 fec2 Exclude Site ## Min. : 1.00 Min. : 2.50 Min. :0.000 Min. : 0.700 Min. :0.0000 Min. : 90 Min. :0.00000 Length:392 ## 1st Qu.: 39.75 1st Qu.: 11.00 1st Qu.:0.000 1st Qu.: 3.000 1st Qu.:0.0000 1st Qu.: 10800 1st Qu.:0.00000 Class :character ## Median :111.50 Median : 32.30 Median :1.000 Median : 4.300 Median :0.0000 Median : 30240 Median :0.00000 Mode :character ## Mean :125.44 Mean : 55.29 Mean :0.596 Mean : 6.167 Mean :0.4343 Mean : 130305 Mean :0.04337 ## 3rd Qu.:190.25 3rd Qu.:103.30 3rd Qu.:1.000 3rd Qu.: 6.525 3rd Qu.:1.0000 3rd Qu.: 127665 3rd Qu.:0.00000 ## Max. :479.00 Max. :160.20 Max. :1.000 Max. :44.000 Max. :1.0000 Max. :1086120 Max. :1.00000 ## NA&#39;s :293 NA&#39;s :293 NA&#39;s :40 NA&#39;s :293 NA&#39;s :349 ## Herbivory (Y/N)_2024 Herbivory Agent_2024 Disease (Y/N)_2024 Description of Disease_2024 NotesYear1 NotesYear2 ## Length:392 Length:392 Length:392 Mode:logical Length:392 Length:392 ## Class :character Class :character Class :character NA&#39;s:392 Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character Mode :character ## ## ## ## cat(&quot;\\n=== First few rows ===\\n&quot;) ## ## === First few rows === print(head(transitions, 10)) ## # A tibble: 10 × 14 ## id size surv sizeNext fec1 fec2 Exclude Site `Herbivory (Y/N)_2024` `Herbivory Agent_2024` `Disease (Y/N)_2024` Description of Disea…¹ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 7 110. 0 NA 1 3600 0 Kala… &lt;NA&gt; &lt;NA&gt; N NA ## 2 34 122. 0 NA 1 10080 0 Bobc… &lt;NA&gt; &lt;NA&gt; N NA ## 3 2 56.4 0 NA 1 11340 0 Bobc… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 4 46 97.5 0 NA 1 12150 0 Kala… N &lt;NA&gt; N NA ## 5 31 90 0 NA 1 13500 0 Kala… &lt;NA&gt; &lt;NA&gt; N NA ## 6 23 144. 0 NA 1 15120 0 Kala… &lt;NA&gt; &lt;NA&gt; N NA ## 7 36 103. 0 NA 1 15750 0 Kala… &lt;NA&gt; &lt;NA&gt; N NA ## 8 32 90.2 0 NA 1 18000 0 Kala… &lt;NA&gt; &lt;NA&gt; N NA ## 9 1 76.2 1 26.7 1 29700 0 Kala… N &lt;NA&gt; N NA ## 10 41 107. 0 NA 1 31500 0 Kala… N &lt;NA&gt; N NA ## # ℹ abbreviated name: ¹​`Description of Disease_2024` ## # ℹ 2 more variables: NotesYear1 &lt;chr&gt;, NotesYear2 &lt;chr&gt; # I always include an Exclude column to allow folks entering or collecting data to identify a priori really weird stuff to exclude! final_data &lt;- transitions |&gt; dplyr::filter(Exclude == 0) Key features: survival (surv) coded as a binary, 0 = dead, 1 = alive size in year one size, continuous variable sizeNext, year two size, continuous variable fec1 = reproduced, yes or no, coded as 0 for no, and 1 for yes fec2 two number of seeds produced, estimated from floral counts, rounded to the nearest whole number includes any important information that could explain what happened to the plants (where they eaten by deer? where were they located?) includes an ID number new seedlings indicated by not having a size year 1 (coded as NA), survival information (NA), reproduction (NA), and a sizeNext entry NA indicate missing data, and 0s are true zero A column labeled ‘Exclude’ used to mark observations with unusual circumstances (e.g., severe damage, measurement error, or other anomalies) that would otherwise distort model fitting. Rather than deleting these observations permanently, retaining them in the dataset and filtering them explicitly allows decisions about inclusion to remain transparent and reproducible. Using this dataset, we will build four core components of the IPM: Survival model Probability of surviving from time \\(t\\) to \\(t+1\\) as a function of size. Growth model Expected size at time \\(t+1\\) given size at time \\(t\\), conditional on survival. Probability of reproduction Probability that an individual reproduces as a function of size. Reproductive output Number of offspring produced, conditional on reproduction occurring. 33.4.1 Variable transformations and scale Demographic rates often exhibit nonlinear relationships with size and strong right-skew, particularly for growth and fecundity. As a result, transformations are commonly applied to improve model fit and biological realism. In this example, we will explore transformations such as: log or square-root transformations of size log transformations of reproductive output centering and scaling of predictors for numerical stability Rather than assuming a single transformation a priori, we will use model selection to evaluate competing formulations and identify those that best explain variation in each vital rate. 33.4.2 Dealing with zeros, missing values, and outliers This dataset illustrates several common challenges in demographic data: Survival and reproduction include many zeros Growth is undefined for individuals that did not survive Reproductive output spans several orders of magnitude Some individuals are flagged for exclusion We address these issues explicitly by: Modeling survival and reproduction as binomial processes Conditioning growth models on survival Using two-stage (hurdle) models for fecundity Excluding flagged individuals prior to model fitting These steps ensure that each statistical model aligns with the biological process it represents. 33.4.3 Parallel IPM workflows Importantly, the statistical models described above are identical across IPM implementations. What differs among approaches is how these models are incorporated into a population projection framework. In the sections that follow, we use the same fitted vital-rate models to construct IPMs using three approaches: ipmr — a modular, transparent framework that explicitly links each model component to the IPM kernel. IPMpack — a more automated approach that streamlines kernel construction. Hand-coded IPMs — a fully explicit implementation that reveals the underlying mechanics of numerical integration and matrix approximation. By working through each approach in parallel, we emphasize that differences among packages reflect differences in software design, not differences in demographic theory. We begin by fitting and comparing candidate models for each vital rate, starting with growth. At each step, we evaluate model fit, interpret parameter estimates, and discuss how these choices influence the resulting IPM. 33.4.4 Growth transitions I typically start by modeling growth. Why? Growth is typically modeled as a continuous relationship between size at time \\(t\\) and size at time \\(t+1\\). Extreme deviations from this relationship—such as implausibly large shrinks or jumps—can strongly influence parameter estimates and propagate unrealistic behavior throughout the IPM kernel. In contrast, extreme reproductive values often reflect genuine biological processes and should be treated with caution rather than automatically excluded. Demographic data often contain extreme values, but not all extremes should be treated as outliers. In particular, reproductive output can exhibit large variation that is biologically real (e.g., mast events, episodic flowering), whereas extreme values in growth are more likely to reflect measurement error or data recording issues. For this reason, we focus first on identifying and handling outliers in the growth model, rather than applying blanket outlier removal across all vital-rate models. We begin by fitting a preliminary growth model using all available, non-excluded data. Remember, that we will only work with individuals that survived (otherwise there is no growth!) growth_data &lt;- final_data |&gt; dplyr::filter(surv == 1, !is.na(sizeNext)) m_growth_lin &lt;- lm(sizeNext ~ size, data = growth_data) m_growth_log &lt;- lm(log(sizeNext) ~ log(size), data = growth_data) AIC(m_growth_lin, m_growth_log) ## df AIC ## m_growth_lin 3 430.8275 ## m_growth_log 3 122.3578 Great! The lower AIC value wins and we see that we need to log transform the data. Now lets look at model fit (linear vs polynomial). m_growth_log_lin &lt;- lm(log(sizeNext) ~ log(size), data = growth_data) m_growth_log_poly &lt;- lm(log(sizeNext) ~ poly(log(size), 2, raw = TRUE), data = growth_data) AIC(m_growth_log_lin, m_growth_log_poly) ## df AIC ## m_growth_log_lin 3 122.3578 ## m_growth_log_poly 4 120.1388 The polynomial model is best! But wait, before we proceed - let’s check out the fit. This is critical for two reasons. First, we want to identify and remove any outliers. Remember, these outliers are more likely to be ‘true’ outliers (mis-ided individuals, measurement error). Secondly, sometimes higher order models produce biological unrealistic fits, especially when sample size is low (i.e., odd peaks and valleys for survival). When this occurs, it is typically better to revert to the simpler model! Let’s take a look at both fits. newdat &lt;- data.frame( size = seq(min(growth_data$size), max(growth_data$size), length.out = 200) ) newdat$lin &lt;- exp(predict(m_growth_log_lin, newdat)) newdat$poly &lt;- exp(predict(m_growth_log_poly, newdat)) library(ggplot2) ggplot(growth_data, aes(size, sizeNext)) + geom_point(alpha = 0.4) + geom_line(data = newdat, aes(size, lin, color = &quot;Linear&quot;), linewidth = 1) + geom_line(data = newdat, aes(size, poly, color = &quot;Quadratic&quot;), linewidth = 1) + scale_x_log10() + scale_y_log10() + labs( x = &quot;Size at time t&quot;, y = &quot;Size at time t+1&quot;, color = &quot;Model&quot; ) + theme_minimal() Interesting! The polynomial fit indicates that growth decreases at larger sizes, and indication of aging or some biophysical limit on growth at larger sizes. This seems biologically defensible and from a modeling standpoint (lower AIC) defensible. Let’s keep the polynomial fit! 33.4.4.1 Outlier removal We identify growth outliers using standardized residuals from the fitted growth model, flagging extreme deviations for biological inspection rather than automatic removal. Only observations that are clearly inconsistent with plausible growth are excluded, and the model is refit to ensure stable kernel behavior. m_growth_quad &lt;- lm( log(sizeNext) ~ poly(log(size), 2, raw = TRUE), data = growth_data ) # Extract residuals growth_data &lt;- growth_data |&gt; dplyr::mutate( fitted = fitted(m_growth_quad), resid = residuals(m_growth_quad), std_res = rstandard(m_growth_quad) ) # Visual residuals library(ggplot2) ggplot(growth_data, aes(log(size), std_res)) + geom_point(alpha = 0.6) + geom_hline(yintercept = c(-3, 3), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs( x = &quot;log(size at time t)&quot;, y = &quot;Standardized residual&quot; ) + theme_minimal() # Apply ±3 is a flagging threshold, not an automatic deletion rule growth_data &lt;- growth_data |&gt; dplyr::mutate( flag_outlier = abs(std_res) &gt; 3 ) Here, we don’t see any significant outliers! Awesome! Let take a different look: # Evaluating data for IPM construction using log(size) growth_log &lt;- lm(log(sizeNext) ~ log(size), na.action = na.omit, data = final_data) resid_log &lt;- residuals(growth_log) # Normality test shapiro.test(resid_log) ## ## Shapiro-Wilk normality test ## ## data: resid_log ## W = 0.97379, p-value = 0.2316 # Residuals vs fitted plot(fitted(growth_log), resid_log, xlab = &quot;Fitted values (log sizeNext)&quot;, ylab = &quot;Residuals&quot;, main = &quot;Residuals vs Fitted (log–log model)&quot;) abline(h = 0, col = &quot;red&quot;) id.n &lt;- nrow(final_data) qqPlot(growth_log, distribution = &quot;norm&quot;, id.method = &quot;y&quot;, id.cex = 0.6, id.n = id.n, id.col = &quot;blue&quot;, id.location = &quot;ab&quot;) ## [1] 72 81 This figure is showing a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis. We use these scatterplots to detect non-linearity, unequal error variances, and outliers. The residuals should “bounce randomly” around the 0 line, indicating that the assumption that the relationship is linear is reasonable. You also show see that the residuals roughly form a “horizontal band” around the 0 line, indicating that the variances of the error terms are equal. Finally, we looking for a dataset in which no one residual “stands out” from the basic random pattern of residuals. Let’s look at these residuals another way and use label the outliers so that we can remove them if necessary! A quantile-quantile plot, often abbreviated as Q-Q plot, is a graphical tool used to assess whether a dataset follows a particular theoretical distribution, such as the normal distribution. It compares the quantiles of the observed data against the quantiles of the expected theoretical distribution. Here’s how to interpret a Q-Q plot: The x-axis of the Q-Q plot represents the theoretical quantiles from a specified distribution (e.g., the normal distribution). The y-axis represents the quantiles of the observed data. If the points on the Q-Q plot fall approximately along a straight line, it suggests that the data follows the theoretical distribution. Deviations from the straight line indicate departures from the assumed distribution. If points are above the line, it suggests that the observed values are higher than expected for that quantile. If points are below the line, it suggests that the observed values are lower than expected for that quantile. The ends of the Q-Q plot are often of particular interest. Deviations in the tails can indicate differences in tail behavior. These data look fine! In cases where this is deviation from normality, it is good practice to try to determine whether it is legitimate to remove outliers from any statistical analysis. In demographic studies, there are so many plants and many reasonable possibilities for why we may observe a strange transition from one year to the next. For example: In the first year, someone measured the plant, but it had already been browsed by a deer and so was extra short, and then appears to grow like wild in the following year Someone took data on the wrong space on the datasheet Someone couldn’t find a mama plant, who actually died, so accidentally measured a baby that had germinated in a nearby spot Given this, unlike with standard statistical analyses, we tend to be less stringent about when we remove outliers. Let’s take a look at residuals. # row_index &lt;- 59 # value &lt;- final_data[row_index,] # print(value) # # #or you can generate the id and use that to subset (just looking at the id number from above) # target_id &lt;- 17 # row_data_index &lt;- final_data[final_data$ID == target_id, ] # print(row_data_index) # # #check out the other outlier # row_index &lt;- 74 # value &lt;- final_data[row_index,] # print(value) We could decide to remove outliers! Example below: # # Remove identified outliers # final_data &lt;- final_data[-c(44, 74), ] # # # Fit growth model on the log scale # growth_log &lt;- lm(log(sizeNext) ~ log(size), # na.action = na.omit, # data = final_data) # # # Extract residuals # resid_log &lt;- residuals(growth_log) # # # Test normality of residuals (on log scale) # shapiro.test(resid_log) # # # Set up plotting window # par(mfrow = c(1, 2), mar = c(4, 4, 2, 1)) # # # Scatter plot of log(size) vs log(sizeNext) # plot(log(sizeNext) ~ log(size), # data = final_data, # xlab = &quot;log(Size at time t)&quot;, # ylab = &quot;log(Size at time t+1)&quot;, # main = &quot;Growth relationship (log–log)&quot;) # abline(growth_log, col = &quot;red&quot;, lwd = 2) # # # Q-Q plot of residuals # id.n &lt;- nrow(final_data) # qqPlot(growth_log, # distribution = &quot;norm&quot;, # id.method = &quot;y&quot;, # id.cex = 0.6, # id.n = id.n, # id.col = &quot;blue&quot;, # id.location = &quot;ab&quot;) Remember, if you do remove outliers, you must refit the model! growth_clean &lt;- growth_data |&gt; dplyr::filter(!flag_outlier) # Refit model without outliers m_growth_quad_clean &lt;- lm( log(sizeNext) ~ poly(log(size), 2, raw = TRUE), data = growth_clean ) # Compare models in order to determine whether the removal of the outlier changed fit. summary(m_growth_quad) ## ## Call: ## lm(formula = log(sizeNext) ~ poly(log(size), 2, raw = TRUE), ## data = growth_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.25728 -0.44403 -0.01676 0.38419 1.38985 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.95684 1.09712 -1.784 0.07990 . ## poly(log(size), 2, raw = TRUE)1 1.96402 0.67401 2.914 0.00512 ** ## poly(log(size), 2, raw = TRUE)2 -0.19582 0.09611 -2.037 0.04634 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6424 on 56 degrees of freedom ## Multiple R-squared: 0.5209, Adjusted R-squared: 0.5038 ## F-statistic: 30.44 on 2 and 56 DF, p-value: 1.128e-09 summary(m_growth_quad_clean) ## ## Call: ## lm(formula = log(sizeNext) ~ poly(log(size), 2, raw = TRUE), ## data = growth_clean) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.25728 -0.44403 -0.01676 0.38419 1.38985 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.95684 1.09712 -1.784 0.07990 . ## poly(log(size), 2, raw = TRUE)1 1.96402 0.67401 2.914 0.00512 ** ## poly(log(size), 2, raw = TRUE)2 -0.19582 0.09611 -2.037 0.04634 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6424 on 56 degrees of freedom ## Multiple R-squared: 0.5209, Adjusted R-squared: 0.5038 ## F-statistic: 30.44 on 2 and 56 DF, p-value: 1.128e-09 Note that if you do remove outliers you must repeat the model fitting process and update the final model that can be included in the kernel! 33.4.4.2 Probability of reproduction Next, we repeat this process for all individuals. I generally do not perform outlier removal for the rest of the analyses, since we want to capture true variation in vital rates. Thus, the oddballs can be important for understanding the system, but only if they are real outliers, rather than created by human error. We model whether an individual reproduced (fec1) as a function of size: \\[ \\text{logit}(p_{\\text{repr}}) = \\beta_0 + \\beta_1 z \\] where \\(z\\) is the state variable (size at time \\(t\\)). First, let’s determine whether we should use a log transformation. We will apply this consistently across all models. Reproduction is often log transformed, since reproduction is expected to increase multiplicatively with size. # Binomial model for probability of reproduction m_repr &lt;- glm(fec1 ~ size, data = final_data, family = binomial, subset = Exclude == 0) m_repr_log &lt;- glm(fec1 ~ log(size), data = final_data, family = binomial, subset = Exclude == 0) AIC(m_repr, m_repr_log) ## df AIC ## m_repr 2 35.03888 ## m_repr_log 2 30.57976 And yes, the log scale has the lower AIC value, so we choose log tranformed data! Now let’s compare model fits (i.e., linear vs polynomial models). m_repr_log_lin &lt;- glm( fec1 ~ log(size), data = final_data, family = binomial ) m_repr_log_poly &lt;- glm( fec1 ~ poly(log(size), 2, raw = TRUE), data = final_data, family = binomial ) AIC(m_repr_log_lin, m_repr_log_poly) ## df AIC ## m_repr_log_lin 2 30.57976 ## m_repr_log_poly 3 31.11613 Wonderful - the linear model wins! Next, we need to visualize the state variable-vital rate relationship. library(ggplot2) library(tidyr) library(dplyr) newdat &lt;- data.frame( size = seq(min(final_data$size, na.rm = TRUE), max(final_data$size, na.rm = TRUE), length.out = 200) ) pred_df &lt;- newdat |&gt; mutate( `Linear (log size)` = predict(m_repr_log_lin, newdat, type = &quot;response&quot;), `Quadratic (log size)` = predict(m_repr_log_poly, newdat, type = &quot;response&quot;) ) |&gt; pivot_longer( cols = -size, names_to = &quot;Model&quot;, values_to = &quot;Prediction&quot; ) ggplot(final_data, aes(size, fec1)) + geom_jitter(height = 0.05, width = 0, alpha = 0.4) + geom_line( data = pred_df, aes(size, Prediction, color = Model), linewidth = 1 ) + labs( y = &quot;Probability of reproduction&quot;, color = &quot;Model fit&quot; ) + theme_minimal() 33.4.4.3 Seed production Seed production (fec2) is only observed for individuals that reproduced. We therefore model fecundity conditional on reproduction (fec1 == 1). Because seed counts are highly right-skewed and often overdispersed, we use a negative binomial model. As above, we first evaluate whether a log transformation of size is appropriate, then compare linear versus polynomial functional forms. fec_data &lt;- final_data |&gt; dplyr::filter(fec1 == 1, !is.na(fec2)) library(MASS) m_fec_lin &lt;- glm.nb( fec2 ~ size, data = fec_data ) m_fec_log &lt;- glm.nb( fec2 ~ log(size), data = fec_data ) AIC(m_fec_lin, m_fec_log) ## df AIC ## m_fec_lin 3 972.3240 ## m_fec_log 3 967.9926 Log transformation wins again! As with reproduction probability, fecundity is often expected to increase multiplicatively with size. # Compare function form m_fec_log_lin &lt;- glm.nb( fec2 ~ log(size), data = fec_data ) m_fec_log_poly &lt;- glm.nb( fec2 ~ poly(log(size), 2, raw = TRUE), data = fec_data ) AIC(m_fec_log_lin, m_fec_log_poly) ## df AIC ## m_fec_log_lin 3 967.9926 ## m_fec_log_poly 4 963.6462 Polynomial model wins! But note, we have a warning that the model didn’t converge! This is annoying, but not uncommon for rare plants. This typically means that we should choose the simpler model, despite AIC findings. Let’s see whether the simpler model converges. summary(m_fec_log_lin) ## ## Call: ## glm.nb(formula = fec2 ~ log(size), data = fec_data, init.theta = 0.4985063643, ## link = log) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -4.8531 2.9095 -1.668 0.0953 . ## log(size) 3.5580 0.6291 5.656 1.55e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Negative Binomial(0.4985) family taken to be 1) ## ## Null deviance: 60.115 on 38 degrees of freedom ## Residual deviance: 49.562 on 37 degrees of freedom ## AIC: 967.99 ## ## Number of Fisher Scoring iterations: 1 ## ## ## Theta: 0.4985 ## Std. Err.: 0.0932 ## ## 2 x log-likelihood: -961.9930 O.K. The simple model converged! We will likely go with that model. Let’s still consider whether the preferred model is biologically feasible. Since convergence errors often occur due to low sample size, it is usually safer to go with the simpler model! Let’s visualize both models. newdat &lt;- data.frame( size = seq(min(fec_data$size, na.rm = TRUE), max(fec_data$size, na.rm = TRUE), length.out = 200) ) pred_df &lt;- newdat |&gt; mutate( `Linear (log size)` = predict(m_fec_log_lin, newdat, type = &quot;response&quot;), `Quadratic (log size)` = predict(m_fec_log_poly, newdat, type = &quot;response&quot;) ) |&gt; pivot_longer( cols = -size, names_to = &quot;Model&quot;, values_to = &quot;Prediction&quot; ) ggplot(fec_data, aes(size, fec2)) + geom_point(alpha = 0.5) + geom_line( data = pred_df, aes(size, Prediction, color = Model), linewidth = 1 ) + scale_y_log10() + labs( y = &quot;Seed production&quot;, color = &quot;Model fit&quot; ) + theme_minimal() # SEED PRODUCTION MODEL (Poisson GLM) ---- # Check for OVERDISPERSION # check_overdispersion &lt;- function(model) { # resid_dev &lt;- sum(residuals(model, type = &quot;deviance&quot;)^2) # ratio &lt;- resid_dev / model$df.residual # # cat(&quot;\\n=== Overdispersion Check (Poisson Model) ===\\n&quot;) # cat(&quot;Residual deviance:&quot;, round(resid_dev, 2), &quot;\\n&quot;) # cat(&quot;Degrees of freedom:&quot;, model$df.residual, &quot;\\n&quot;) # cat(&quot;Dispersion ratio:&quot;, round(ratio, 3), &quot;\\n&quot;) # # if(ratio &gt; 2) { # cat(&quot;⚠️ OVERDISPERSED - consider using negative binomial or quasipoisson\\n&quot;) # } else if(ratio &lt; 0.5) { # cat(&quot;⚠️ UNDERDISPERSED - check for zero-inflation or model structure\\n&quot;) # } else { # cat(&quot;✓ Dispersion looks reasonable for Poisson\\n&quot;) # } # # return(ratio) # } # # dispersion_ratio &lt;- check_overdispersion(seed_mod) # # # If overdispersed, consider refitting: # if(dispersion_ratio &gt; 2) { # cat(&quot;\\n📝 Consider refitting as:\\n&quot;) # cat(&quot; library(MASS)\\n&quot;) # cat(&quot; seed_mod_nb &lt;- glm.nb(fec2 ~ size_log + I(size_log^2), data = final_data)\\n&quot;) # } O.K. we have a judgement call, we’ve seen ‘aging’ in other metrics, so this could be reasonable, but the apparent downturn looks like it is driven by a small number of large individuals, and with the lack of model convergence, any estimate of “aging effects” would be highly uncertain. This could go either way and we could compare the difference in outcomes! 33.4.4.4 Survival Survival is modeled as a binary response and is therefore fit using a binomial model. We do not perform outlier removal for survival, as extreme values (alive vs. dead) are intrinsic to the process. m_surv_lin &lt;- glm( surv ~ size, data = final_data, family = binomial ) m_surv_log &lt;- glm( surv ~ log(size), data = final_data, family = binomial ) AIC(m_surv_lin, m_surv_log) ## df AIC ## m_surv_lin 2 93.24766 ## m_surv_log 2 93.78090 These are so close! Given the other relationships, I’m just going to go with the log scale. Notably, you can include both scales for different variables in an IPM. In an Integral Projection Model (IPM), all vital rates are linked to the same underlying state variable (e.g., size), but they do not need to share the same functional form. This means that it is perfectly acceptable for one vital rate to be modeled with a linear relationship, while another uses a polynomial or nonlinear form. Each vital rate reflects a different biological process, and these processes often scale with size in different ways. For example, growth may decelerate at large sizes, while survival changes more gradually, and reproduction increases multiplicatively with size. Allowing each vital rate to adopt the functional form that best reflects its biology improves realism and model performance. Importantly, all vital-rate models must be well supported by the data and behave sensibly when extrapolated across the full range of sizes included in the IPM. More complex models (e.g., polynomial fits) are retained only when they converge reliably and do not introduce implausible behavior at the boundaries of the size distribution. In practice, this means that a single IPM may include: a quadratic growth model, a linear (log-scale) reproduction model, and a linear survival model, all operating together within the same projection kernel. The consistency of the IPM comes from the shared state variable, not from enforcing identical mathematical forms across vital rates. All that said, I tend to find that the same transformation works across all equations and I find it more parsimonous to include the same transformation, especially when data are sparse. m_surv_log_lin &lt;- glm( surv ~ log(size), data = final_data, family = binomial ) m_surv_log_poly &lt;- glm( surv ~ poly(log(size), 2, raw = TRUE), data = final_data, family = binomial ) AIC(m_surv_log_lin, m_surv_log_poly) ## df AIC ## m_surv_log_lin 2 93.78090 ## m_surv_log_poly 3 94.31272 Let’s visualize! newdat &lt;- data.frame( size = seq(min(final_data$size, na.rm = TRUE), max(final_data$size, na.rm = TRUE), length.out = 200) ) pred_df &lt;- newdat |&gt; mutate( `Linear (log size)` = predict(m_surv_log_lin, newdat, type = &quot;response&quot;), `Quadratic (log size)` = predict(m_surv_log_poly, newdat, type = &quot;response&quot;) ) |&gt; pivot_longer( cols = -size, names_to = &quot;Model&quot;, values_to = &quot;Prediction&quot; ) ggplot(final_data, aes(size, surv)) + geom_jitter(height = 0.05, width = 0, alpha = 0.4) + geom_line( data = pred_df, aes(size, Prediction, color = Model), linewidth = 1 ) + labs( y = &quot;Survival probability&quot;, color = &quot;Model fit&quot; ) + theme_minimal() Oh yeah. Confirmed. That polynomial looks bonkers! One thing to note in terms of packages. The IPMpack package has fairly slick built in equations for these initial model comparisons. For this reason, I sometimes mix-and-match packages, using the IPM pack for initial visualization and other packages or hand-coding for the actual modeling! The approach is up to you, though sometimes coding just gives you more flexibility! At this point, we have assembled all of the vital-rate models needed to build a population projection model: (1) growth, (2) survival, (3) probability of reproduction, and (4) reproductive output. Together, these components describe how individuals move through the population from one time step to the next. In principle, additional demographic processes could be modeled if sufficient data were available. For example, reproduction could be decomposed into multiple steps, such as (1) the probability of flowering, (2) the probability that a flower sets seed, and (3) reproductive output conditional on successful flowering and seed set. Each of these processes may respond differently to environmental conditions or individual state. In practice, however, demographic data are extremely time- and labor-intensive to collect, and most studies are limited to the transitions described above. As a result, population models typically combine multiple biological processes into a smaller set of composite vital rates. That said, additional model complexity can be justified when driven by specific hypotheses. For example, if a study focuses on pollination limitation or herbivore effects on flowering, explicitly modeling intermediate reproductive steps may be necessary and informative. The key is to match model complexity to both the available data and the biological questions being asked. 33.5 Constructing a transition matrix To build a population projection model, we must translate our fitted vital-rate models into a structure that projects the population forward in time. In matrix population models, this structure is a transition matrix, where each element describes the contribution of individuals in one state to another state in the next time step. In stage-structured models, the transition matrix is constructed directly from estimated transition probabilities among discrete stages. In contrast, IPMs begin with continuous relationships between size and vital rates. To construct a transition matrix from these continuous functions, we discretize the size distribution into a finite number of size classes. This discretized matrix serves as a numerical approximation of the continuous IPM kernel. Thus, even though IPMs are conceptually continuous, they are implemented computationally as large matrices that closely approximate continuous dynamics. In an IPM, population dynamics are governed by a continuous projection equation: \\[ n(z&#39;, t+1) = \\int K(z&#39;, z)\\, n(z, t)\\, dz \\] where: - \\(z\\) is individual size at time \\(t\\), - \\(z&#39;\\) is size at time \\(t+1\\), - \\(n(z,t)\\) is the size distribution at time \\(t\\), - \\(K(z&#39;,z)\\) is the kernel describing transitions from size \\(z\\) to \\(z&#39;\\). The kernel is typically decomposed into survival–growth (\\(P\\)) and reproduction (\\(F\\)) components: \\[ K(z&#39;, z) = P(z&#39;, z) + F(z&#39;, z) \\] When implemented numerically, the continuous kernel is approximated by a large matrix \\(\\mathbf{K}\\), where each element represents transitions between discretized size classes. 33.6 Building an IPM: Boundary points, mesh points, and step size Constructing an IPM requires defining the size domain over which the population is modeled and how finely that domain is discretized. This involves three key choices: boundary points, mesh points, and step size. Boundary points define the minimum and maximum sizes included in the model. These limits should encompass all biologically plausible sizes observed in the data, often with a small buffer to avoid edge effects. Mesh points are the discrete size values used to approximate the continuous size distribution. The number of mesh points determines the resolution of the IPM: more mesh points yield a closer approximation to the continuous kernel but increase computational cost. Step size is the distance between adjacent mesh points and is determined by the boundary range divided by the number of mesh points. The step size plays a critical role in numerical accuracy, as it scales the contribution of individuals across size classes. Together, these choices determine how well the discretized matrix approximates the underlying continuous population dynamics. In practice, mesh sizes of 50–200 points often provide a good balance between accuracy and computational efficiency, though convergence should always be checked. 33.7 Model Evaluation: Eviction One challenge in Integral Projection Models (IPMs) arises when predicted growth pushes individuals outside the defined size boundaries of the model. For example, a growth model may predict that some individuals shrink below the minimum size or grow beyond the maximum size. This issue is referred to as eviction. If not handled properly, eviction can lead to loss or artificial accumulation of individuals at the boundaries, distorting population dynamics and biasing estimates of population growth rate (\\(\\lambda\\)). 33.7.1 Why Eviction Matters Consider a large plant with size \\(z = 150 \\,\\text{cm}^2\\) and a growth model that predicts next year’s size as: mean: \\(\\mu(z) = 155 \\,\\text{cm}^2\\) standard deviation: \\(\\sigma = 10 \\,\\text{cm}^2\\) If the maximum size boundary is \\(U = 176 \\,\\text{cm}^2\\), some probability mass from this individual’s growth distribution extends beyond the modeled size range. Without correction, this probability mass is effectively lost, implicitly assuming those individuals die. This assumption is often biologically unrealistic. 33.7.2 Eviction Correction Strategies Several strategies exist to address eviction, each corresponding to different biological assumptions. 33.7.2.1 1. Truncation (Renormalization) Method: Redistribute probability mass that would fall outside the boundaries back into the valid size range by renormalizing the growth distribution. Mathematical implementation: \\[ g_{\\text{truncated}}(z&#39;, z) = \\frac{g_{\\text{uncorrected}}(z&#39;, z)} {\\int_L^U g_{\\text{uncorrected}}(z&#39;, z)\\, dz&#39;} \\] where the denominator is: \\[ \\int_L^U g_{\\text{uncorrected}}(z&#39;, z)\\, dz&#39; = \\Phi\\left(\\frac{U - \\mu(z)}{\\sigma}\\right) - \\Phi\\left(\\frac{L - \\mu(z)}{\\sigma}\\right) \\] and \\(\\Phi(\\cdot)\\) is the cumulative distribution function of the normal distribution. Note two different kinds of truncation: Simple truncation divides by (p_upper - p_lower) for EVERY transition: Pro: Conceptually simpler Con: Applies unnecessary operations when eviction risk is ~0% Con: Can introduce small numerical artifacts across the entire matrix Conditional truncation only corrects when eviction is meaningful (&gt;1e-10 probability): Pro: More numerically stable Pro: Matches industry-standard implementations (ipmr) Pro: Computationally more accurate Pro: Only modifies transitions that actually need correction Biological interpretation: Individuals do not actually leave the population; instead, extreme sizes are “folded back” into the observable range. This approach assumes that the boundaries reflect measurement or detection limits rather than true biological limits. When appropriate: Size represents natural constraints Boundaries are conservative relative to the true biological range Extreme sizes are rare in the data For plants demography, I typically use truncation! 33.7.2.2 2. Reflection Method: Reflect probability mass back into the domain, creating symmetric probability density at the boundaries. Mathematical implementation: \\[ g_{\\text{reflected}}(z&#39;, z) = g(z&#39;, z) + g(2L - z&#39;, z) + g(2U - z&#39;, z) \\] Biological interpretation: Minimum and maximum sizes act as hard biological barriers, such as physical or architectural constraints. When appropriate: Clear biological maxima exist (e.g., determinate growth) Minimum size represents a functional threshold 33.7.2.3 3. Redistribution to Boundary Classes Method: Accumulate all evicted probability mass into the boundary size classes. Biological interpretation: Individuals reach a size asymptote and remain at that size indefinitely. When appropriate: Species with determinate growth Maximum size represents a stable life stage 33.7.2.4 4. No Correction (Accept Loss) Method: Allow probability mass to escape the modeled domain, treating eviction as mortality. Biological interpretation: Individuals that grow beyond \\(U\\) or shrink below \\(L\\) are assumed to die. When appropriate: Rarely appropriate in practice May be acceptable if eviction is negligible (e.g., &lt;1% of total probability mass) 33.7.3 Summary Evaluating and correcting for eviction is a critical step in IPM construction. Excessive eviction often signals issues with boundary selection, growth model specification, or extrapolation beyond the data. The chosen correction method should align with both the biology of the species and the interpretation of the size variable. 33.8 Estimating population dynamics parameters Once the transition matrix has been constructed, we can calculate key population dynamics parameters. The most important of these is the long-term population growth rate, \\(\\lambda\\), which describes whether the population is expected to grow, decline, or remain stable over time. Additional quantities of interest include the stable size distribution, which describes the relative frequency of individuals across sizes at equilibrium, and the reproductive value, which measures the relative contribution of individuals of different sizes to future population growth. Beyond asymptotic behavior, IPMs also allow us to quantify short-term or transient dynamics, such as population amplification, attenuation, and inertia. These metrics describe how populations respond to disturbances before reaching long-term equilibrium and are often particularly relevant for conservation and management. 33.9 Calculating confidence intervals Demographic models are built from estimated vital-rate relationships, each of which contains uncertainty. To understand how this uncertainty propagates into population dynamics, we must quantify uncertainty around derived parameters such as \\(\\lambda\\). A common approach is to use resampling methods, such as bootstrapping, in which vital rate models are repeatedly refit to resampled data. Each refitted model is used to reconstruct the IPM and calculate population metrics, generating empirical distributions for parameters of interest. Confidence intervals derived from these distributions provide insight into the robustness of model predictions and help distinguish meaningful biological patterns from sampling variability. Incorporating uncertainty is particularly important when IPMs are used to inform conservation decisions or compare population viability across sites or treatments. 33.10 Putting this all together in code form! For simplicity, let’s go ahead and code this using the ipmr program! Note: From this point forward, the IPM is constructed using log(size) as the state variable. All kernels, mesh points, eviction correction, and demographic metrics are defined on the log scale unless explicitly stated otherwise. Raw units (cm) are used only for interpretation and visualization. library(MASS) library(ggpubr) library(ipmr) species_name &lt;- &quot;SILLAN&quot; trans_years &lt;- &quot;20232024&quot; #============================================== # Transform data #============================================== final_data &lt;- final_data %&gt;% mutate( size_raw = size, sizeNext_raw = sizeNext, size_log = if_else(!is.na(size) &amp; size &gt; 0, log(size), NA_real_), sizeNext_log = if_else(!is.na(sizeNext) &amp; sizeNext &gt; 0, log(sizeNext), NA_real_) ) #=============================================== # Final models (LOG-SCALE STATE VARIABLE) #=============================================== grow_mod &lt;- lm( sizeNext_log ~ size_log + I(size_log^2), data = final_data ) grow_sd &lt;- sd(resid(grow_mod), na.rm = TRUE) surv_mod &lt;- glm( surv ~ size_log, data = final_data, family = binomial() ) repr_mod &lt;- glm( fec1 ~ size_log + I(size_log^2), data = final_data, family = binomial() ) # Pick best form seed_mod &lt;- glm( fec2 ~ size_log + I(size_log^2), data = final_data, family = poisson()) # seed_mod &lt;- glm.nb( # fec2 ~ size_log + I(size_log^2), # data = final_data # ) # #=============================================== # # Model diagnostics # #=============================================== # # cat(&quot;\\n=== Sample Size for Vital Rates ===\\n&quot;) # n_for_models &lt;- sum(!is.na(final_data$size_log) &amp; !is.na(final_data$sizeNext_log)) # cat(&quot;Growth/survival sample size:&quot;, n_for_models, &quot;\\n&quot;) # # if(n_for_models &lt; 100) { # cat(&quot;⚠️ WARNING: Small sample (&lt;100) may yield unreliable estimates\\n&quot;) # } # # # Check seed model overdispersion # dispersion_ratio &lt;- sum(residuals(seed_mod, type = &quot;deviance&quot;)^2) / seed_mod$df.residual # cat(&quot;\\n=== Seed Model Overdispersion ===\\n&quot;) # cat(&quot;Dispersion ratio:&quot;, round(dispersion_ratio, 3), &quot;\\n&quot;) # if(dispersion_ratio &gt; 2) { # cat(&quot;⚠️ OVERDISPERSED (ratio &gt; 2) - consider negative binomial\\n&quot;) # } else { # cat(&quot;✓ Poisson assumption reasonable\\n&quot;) # } #=============================================== # Recruitment information (LOG SCALE) - ROBUST #=============================================== # Strict recruit definition robust_recruit_logical &lt;- is.na(final_data$size_log) &amp; is.na(final_data$surv) &amp; is.na(final_data$fec1) &amp; !is.na(final_data$sizeNext_log) recr_data &lt;- final_data[robust_recruit_logical, ] recr_mu &lt;- mean(recr_data$sizeNext_log, na.rm = TRUE) recr_sd &lt;- sd(recr_data$sizeNext_log, na.rm = TRUE) recr_n &lt;- sum(is.finite(recr_data$sizeNext_log)) seed_n &lt;- sum(final_data$fec2, na.rm = TRUE) if (!is.finite(seed_n) || seed_n &lt;= 0) stop(&quot;seed_n is 0 or non-finite; cannot build fecundity kernel&quot;) if (!is.finite(recr_n) || recr_n &lt;= 0) stop(&quot;recr_n is 0 or non-finite; cannot build recruitment kernel&quot;) if (!is.finite(recr_mu) || !is.finite(recr_sd) || recr_sd &lt;= 0) stop(&quot;Recruit size distribution invalid (mu/sd)&quot;) cat(&quot;\\n=== Recruitment Validation ===\\n&quot;) ## ## === Recruitment Validation === cat(&quot;Recruits:&quot;, recr_n, &quot;\\n&quot;) ## Recruits: 293 cat(&quot;Total seeds produced:&quot;, seed_n, &quot;\\n&quot;) ## Total seeds produced: 5317830 cat(&quot;Establishment probability:&quot;, round(recr_n / seed_n, 4), &quot;\\n&quot;) ## Establishment probability: 1e-04 # Define minimum size to flower (LOG SCALE) min_repro_size_log &lt;- suppressWarnings(min(final_data$size_log[final_data$fec1 == 1], na.rm = TRUE)) if (!is.finite(min_repro_size_log)) { min_repro_size_log &lt;- Inf message(&quot;⚠️ No reproductive individuals (fec1==1). Setting min_repro_size_log = Inf (F kernel will be ~0).&quot;) } #=============================================== # State variable domain (LOG SCALE) - DATA-DRIVEN #=============================================== all_sizes_log &lt;- c(final_data$size_log, final_data$sizeNext_log) size_quantiles &lt;- quantile(all_sizes_log, probs = c(0.01, 0.99), na.rm = TRUE) L &lt;- as.numeric(size_quantiles[1]) * 0.9 U &lt;- as.numeric(size_quantiles[2]) * 1.1 if (!is.finite(L) || !is.finite(U) || L &gt;= U) stop(&quot;Invalid domain bounds: check sizes and quantiles&quot;) # Verification cat(&quot;\\n=== Recruitment Validation ===\\n&quot;) ## ## === Recruitment Validation === cat(&quot;Recruits (strict definition):&quot;, recr_n, &quot;\\n&quot;) ## Recruits (strict definition): 293 cat(&quot;Total seeds produced:&quot;, seed_n, &quot;\\n&quot;) ## Total seeds produced: 5317830 cat(&quot;Establishment probability:&quot;, round(recr_n / seed_n, 4), &quot;\\n&quot;) ## Establishment probability: 1e-04 n_adults &lt;- sum(!is.na(final_data$size_log)) cat(&quot;\\nDemographic structure:\\n&quot;) ## ## Demographic structure: cat(&quot; Adults at time t:&quot;, n_adults, &quot;\\n&quot;) ## Adults at time t: 82 cat(&quot; Recruits at time t+1:&quot;, recr_n, &quot;\\n&quot;) ## Recruits at time t+1: 293 cat(&quot; Recruit:Adult ratio:&quot;, round(recr_n / n_adults, 2), &quot;\\n&quot;) ## Recruit:Adult ratio: 3.57 if(recr_n &gt; n_adults * 2) { cat(&quot;⚠️ High recruitment! Lambda will be recruitment-driven\\n&quot;) } ## ⚠️ High recruitment! Lambda will be recruitment-driven # Visualize recruit distribution x_seq &lt;- seq( min(recr_data$sizeNext_log, na.rm = TRUE), max(recr_data$sizeNext_log, na.rm = TRUE), length.out = 200 ) recr_fit &lt;- data.frame( x = x_seq, y = dnorm(x_seq, mean = recr_mu, sd = recr_sd) ) shapiro_result &lt;- shapiro.test(recr_data$sizeNext_log) recruit_plot &lt;- ggplot(recr_data, aes(x = sizeNext_log)) + geom_histogram(aes(y = after_stat(density)), bins = 30, fill = &quot;skyblue&quot;, alpha = 0.6, color = &quot;white&quot;) + geom_line(data = recr_fit, aes(x = x, y = y), color = &quot;darkblue&quot;, linewidth = 1.2) + labs( x = &quot;Recruit size at time t+1 (log scale)&quot;, y = &quot;Density&quot;, title = &quot;Recruit size distribution and IPM recruitment kernel&quot;, subtitle = paste0(&quot;Blue line = normal distribution used in F kernel\\n&quot;, &quot;Shapiro-Wilk p = &quot;, round(shapiro_result$p.value, 3)) ) + theme_pubr(base_size = 15) print(recruit_plot) # Define minimum size to flower (LOG SCALE) min_repro_size_log &lt;- min( final_data$size_log[final_data$fec1 == 1], na.rm = TRUE ) cat(&quot;\\nMinimum reproductive size (log):&quot;, round(min_repro_size_log, 3), &quot; → raw:&quot;, round(exp(min_repro_size_log), 2), &quot;cm\\n&quot;) ## ## Minimum reproductive size (log): 3.544 → raw: 34.6 cm # Build params list params &lt;- list( recr_mu = recr_mu, recr_sd = recr_sd, grow_sd = grow_sd, surv_mod = surv_mod, grow_mod = grow_mod, repr_mod = repr_mod, seed_mod = seed_mod, recr_n = recr_n, seed_n = seed_n, min_repro_size_log = min_repro_size_log ) #=============================================== # State variable domain (LOG SCALE) - DATA-DRIVEN #=============================================== percentile_lower &lt;- 0.01 percentile_upper &lt;- 0.99 all_sizes_log &lt;- c(final_data$size_log, final_data$sizeNext_log) size_quantiles &lt;- quantile(all_sizes_log, probs = c(0.01, 0.99), na.rm = TRUE) L &lt;- as.numeric(size_quantiles[1]) * 0.9 U &lt;- as.numeric(size_quantiles[2]) * 1.1 if (!is.finite(L) || !is.finite(U) || L &gt;= U) stop(&quot;Invalid domain bounds: check sizes and quantiles&quot;) cat(&quot;\\n=== Domain Boundaries (DATA-DRIVEN) ===\\n&quot;) ## ## === Domain Boundaries (DATA-DRIVEN) === cat(&quot;Method: Exclude bottom/top&quot;, percentile_lower * 100, &quot;%\\n&quot;) ## Method: Exclude bottom/top 1 % cat(&quot;Log scale: [&quot;, round(L, 3), &quot;,&quot;, round(U, 3), &quot;]\\n&quot;) ## Log scale: [ 0 , 5.452 ] cat(&quot;Raw scale: [&quot;, round(exp(L), 3), &quot;,&quot;, round(exp(U), 3), &quot;] cm\\n&quot;) ## Raw scale: [ 1 , 233.144 ] cm excluded_n &lt;- sum(all_sizes_log &lt; size_quantiles[1] | all_sizes_log &gt; size_quantiles[2], na.rm = TRUE) cat(&quot;Excluded outliers:&quot;, excluded_n, &quot;\\n&quot;) ## Excluded outliers: 7 # ============================================================================== # BUILD IPM WITH ipmr # ============================================================================== obs_ipm &lt;- init_ipm( sim_gen = &quot;simple&quot;, di_dd = &quot;di&quot;, det_stoch = &quot;det&quot; ) %&gt;% #------------------------- # P kernel (survival + growth) #------------------------- define_kernel( name = &quot;P&quot;, family = &quot;CC&quot;, formula = s * g, # Survival s = predict( surv_mod, newdata = data.frame(size_log = sa_1), type = &quot;response&quot; ), # Growth mean (log size at t+1) g_mu = predict( grow_mod, newdata = data.frame(size_log = sa_1), type = &quot;response&quot; ), # Growth distribution g = dnorm(sa_2, g_mu, grow_sd), states = list(&quot;sa&quot;), data_list = params, uses_par_sets = FALSE, evict_cor = TRUE, evict_fun = truncated_distributions( fun = &quot;norm&quot;, target = &quot;g&quot; ) ) %&gt;% #------------------------- # F kernel (fecundity) #------------------------- define_kernel( name = &quot;F&quot;, family = &quot;CC&quot;, formula = r_p * r_s * r_d * r_r, r_p = ifelse( sa_1 &lt; min_repro_size_log, 0, predict( repr_mod, newdata = data.frame(size_log = sa_1), type = &quot;response&quot; ) ), r_s = predict( seed_mod, newdata = data.frame(size_log = sa_1), type = &quot;response&quot; ), r_r = recr_n / seed_n, r_d = dnorm(sa_2, recr_mu, recr_sd), states = list(&quot;sa&quot;), data_list = params, uses_par_sets = FALSE, evict_cor = TRUE, evict_fun = truncated_distributions( fun = &quot;norm&quot;, target = &quot;r_d&quot; ) ) %&gt;% #------------------------- # Implementation + domain #------------------------- define_impl( make_impl_args_list( kernel_names = c(&quot;P&quot;, &quot;F&quot;), int_rule = rep(&quot;midpoint&quot;, 2), state_start = rep(&quot;sa&quot;, 2), state_end = rep(&quot;sa&quot;, 2) ) ) %&gt;% define_domains( sa = c(L, U, 100) ) %&gt;% define_pop_state( n_sa = runif(100) ) %&gt;% make_ipm( iterate = TRUE, iterations = 100 ) #=============================================== # Extract kernels and λ #=============================================== P &lt;- obs_ipm$sub_kernels$P F &lt;- obs_ipm$sub_kernels$F K_matrix &lt;- P + F eigs &lt;- eigen(K_matrix) lambda_raw &lt;- max(Re(eigs$values)) cat(&quot;\\n=== IPM Results ===\\n&quot;) ## ## === IPM Results === cat(&quot;Population growth rate (λ):&quot;, round(lambda_raw, 4), &quot;\\n&quot;) ## Population growth rate (λ): 0.9647 if (lambda_raw &gt; 1) { cat(&quot;→ Population GROWING at&quot;, round((lambda_raw - 1) * 100, 2), &quot;% per year\\n&quot;) } else if (lambda_raw &lt; 1) { cat(&quot;→ Population DECLINING at&quot;, round((1 - lambda_raw) * 100, 2), &quot;% per year\\n&quot;) } else { cat(&quot;→ Population STABLE\\n&quot;) } ## → Population DECLINING at 3.53 % per year stable_dist_raw &lt;- Re(eigs$vectors[, which.max(Re(eigs$values))]) stable_dist_raw &lt;- stable_dist_raw / sum(stable_dist_raw) # ============================== # SAVE FULL IPM OBJECT (RDS) # ============================== dir.create(&quot;IPM_outputs&quot;, showWarnings = FALSE) species_dir &lt;- file.path(&quot;IPM_outputs&quot;, paste0(species_name, &quot;_&quot;, trans_years)) dir.create(species_dir, showWarnings = FALSE) mesh_points &lt;- obs_ipm$domains$sa mesh_width &lt;- diff(mesh_points)[1] ipm_rds &lt;- list( metadata = list( species = species_name, transition = trans_years, date_created = Sys.Date(), state_variable = &quot;size_log&quot;, state_scale = &quot;log&quot;, raw_units = &quot;original size units&quot;, mesh_points_n = length(mesh_points), mesh_bounds = c(L = L, U = U), mesh_width = mesh_width ), kernels = list( K = K_matrix, P = P, F = F ), size = list( mesh_points_log = mesh_points, stable_dist = stable_dist_raw ), population_metrics = list( lambda = lambda_raw ), models = list( growth = grow_mod, survival = surv_mod, reproduction = repr_mod, fecundity = seed_mod ), recruitment = list( recr_mu_log = recr_mu, recr_sd_log = recr_sd, recr_n = recr_n, seed_n = seed_n, establishment_prob = recr_n / seed_n ), params = params, data = final_data ) saveRDS( ipm_rds, file = file.path(species_dir, &quot;IPM_full_object.rds&quot;) ) cat( &quot;✓ Saved full IPM object (log-scale) to:&quot;, file.path(species_dir, &quot;IPM_full_object.rds&quot;), &quot;\\n&quot; ) ## ✓ Saved full IPM object (log-scale) to: IPM_outputs/SILLAN_20232024/IPM_full_object.rds Now, let’s bootstrap for confidence intervals! #=============================================== # BOOTSTRAP ANALYSIS - UNCERTAINTY IN LAMBDA #=============================================== library(ggpubr) cat(&quot;\\n=== Starting Bootstrap Analysis ===\\n&quot;) ## ## === Starting Bootstrap Analysis === # Define helper function for safe GLM fitting safe_glm &lt;- function(formula, data, family) { tryCatch( glm(formula, data = data, family = family), error = function(e) NULL, warning = function(w) NULL ) } # Helper to extract state variable name from model get_state_name &lt;- function(mod) { all.vars(formula(mod))[2] } #-------------------------------- # Prepare data splits (ROBUST DEFINITION) #-------------------------------- # Adults: individuals present at time t (with size_log) adults &lt;- final_data[!is.na(final_data$size_log), ] # Recruits: STRICT definition matching Section 1 robust_recruit_logical &lt;- is.na(final_data$size_log) &amp; is.na(final_data$surv) &amp; is.na(final_data$fec1) &amp; !is.na(final_data$sizeNext_log) recr_data &lt;- final_data[robust_recruit_logical, ] cat(&quot;Adults (will be bootstrapped):&quot;, nrow(adults), &quot;\\n&quot;) ## Adults (will be bootstrapped): 82 cat(&quot;Recruits (held constant):&quot;, nrow(recr_data), &quot;\\n&quot;) ## Recruits (held constant): 293 #-------------------------------- # Freeze fixed components #-------------------------------- # Use the mesh from your main IPM fixed_mesh &lt;- obs_ipm$domains$sa # Store full-data models as fallbacks surv_mod_full &lt;- surv_mod repr_mod_full &lt;- repr_mod seed_mod_full &lt;- seed_mod # Store full-data recruitment parameters (NOT bootstrapped) recr_mu_full &lt;- recr_mu recr_sd_full &lt;- recr_sd recr_n_full &lt;- recr_n min_repro_full &lt;- min_repro_size_log # Store proto_ipm for reuse use_proto &lt;- obs_ipm$proto_ipm cat(&quot;\\n✓ Fixed mesh points:&quot;, length(fixed_mesh), &quot;\\n&quot;) ## ## ✓ Fixed mesh points: 0 cat(&quot;✓ Domain bounds (log): [&quot;, round(L, 3), &quot;,&quot;, round(U, 3), &quot;]\\n&quot;) ## ✓ Domain bounds (log): [ 0 , 5.452 ] cat(&quot;✓ Recruitment held constant: μ =&quot;, round(recr_mu_full, 3), &quot;, σ =&quot;, round(recr_sd_full, 3), &quot;\\n&quot;) ## ✓ Recruitment held constant: μ = 1.352 , σ = 0.611 #-------------------------------- # Bootstrap setup #-------------------------------- n_boot &lt;- 50L max_tries &lt;- n_boot * 5 # Storage vectors all_lambdas &lt;- rep(NA_real_, n_boot) mean_size_rep &lt;- rep(NA_real_, n_boot) var_size_rep &lt;- rep(NA_real_, n_boot) prop_stable_repro_vals &lt;- rep(NA_real_, n_boot) valid_iter &lt;- 0 attempts &lt;- 0 cat(&quot;\\n=== Bootstrap Loop ===\\n&quot;) ## ## === Bootstrap Loop === cat(&quot;Target iterations:&quot;, n_boot, &quot;\\n&quot;) ## Target iterations: 50 cat(&quot;Maximum attempts:&quot;, max_tries, &quot;\\n\\n&quot;) ## Maximum attempts: 250 #-------------------------------- # BOOTSTRAP LOOP #-------------------------------- while (valid_iter &lt; n_boot &amp;&amp; attempts &lt; max_tries) { attempts &lt;- attempts + 1 # Progress indicator every 10 attempts if (attempts %% 10 == 0) { cat(&quot;Attempt&quot;, attempts, &quot;| Valid:&quot;, valid_iter, &quot;\\n&quot;) } #-------------------------------- # Resample adults only (NOT recruits) #-------------------------------- boot_ind &lt;- sample(seq_len(nrow(adults)), replace = TRUE) boot_data &lt;- rbind(adults[boot_ind, ], recr_data) # Append FULL recruit dataset #-------------------------------- # Refit vital rate models #-------------------------------- # Growth model (MUST succeed) grow_mod_boot &lt;- tryCatch( lm(sizeNext_log ~ size_log + I(size_log^2), data = boot_data), error = function(e) NULL ) if (is.null(grow_mod_boot)) next grow_sd_boot &lt;- sd(resid(grow_mod_boot), na.rm = TRUE) if (!is.finite(grow_sd_boot) || grow_sd_boot &lt;= 0) next # Survival model (fall back to full model if fails) surv_mod_boot &lt;- safe_glm(surv ~ size_log, boot_data, binomial()) if (is.null(surv_mod_boot)) { surv_mod_boot &lt;- surv_mod_full } # Reproduction probability (fall back if fails) repr_mod_boot &lt;- safe_glm(fec1 ~ size_log + I(size_log^2), boot_data, binomial()) if (is.null(repr_mod_boot)) { repr_mod_boot &lt;- repr_mod_full } # Seed production (fall back if fails) seed_mod_boot &lt;- safe_glm(fec2 ~ size_log + I(size_log^2), boot_data, poisson()) if (is.null(seed_mod_boot)) { seed_mod_boot &lt;- seed_mod_full } # Calculate seed_n from bootstrap sample seed_n_boot &lt;- sum(boot_data$fec2, na.rm = TRUE) if (!is.finite(seed_n_boot) || seed_n_boot &lt;= 0) next #-------------------------------- # Update parameters in proto_ipm #-------------------------------- params_boot &lt;- list( recr_mu = recr_mu_full, # FIXED - not bootstrapped recr_sd = recr_sd_full, # FIXED - not bootstrapped grow_sd = grow_sd_boot, # BOOTSTRAPPED surv_mod = surv_mod_boot, # BOOTSTRAPPED grow_mod = grow_mod_boot, # BOOTSTRAPPED repr_mod = repr_mod_boot, # BOOTSTRAPPED seed_mod = seed_mod_boot, # BOOTSTRAPPED recr_n = recr_n_full, # FIXED - not bootstrapped seed_n = seed_n_boot, # BOOTSTRAPPED min_repro_size_log = min_repro_full # FIXED - not bootstrapped ) # Clone proto_ipm and insert new parameters proto_boot &lt;- use_proto parameters(proto_boot) &lt;- params_boot # Build bootstrapped IPM boot_ipm &lt;- tryCatch( make_ipm(proto_boot, iterate = TRUE, iterations = 100), error = function(e) NULL ) if (is.null(boot_ipm)) next #-------------------------------- # Extract lambda #-------------------------------- lam &lt;- tryCatch( ipmr::lambda(boot_ipm), error = function(e) NA_real_ ) if (!is.finite(lam)) next #-------------------------------- # Extract stable distribution #-------------------------------- stable_vec &lt;- tryCatch({ sv &lt;- as.numeric(ipmr::right_ev(boot_ipm)$sa) if (any(!is.finite(sv)) || sum(sv) &lt;= 0) { NULL } else { sv / sum(sv) } }, error = function(e) NULL) if (is.null(stable_vec)) next #-------------------------------- # Calculate reproductive metrics (ROBUST + SAFE) #-------------------------------- size_classes &lt;- fixed_mesh # Get predictor names from models repr_state &lt;- get_state_name(repr_mod_boot) seed_state &lt;- get_state_name(seed_mod_boot) # Predict reproduction probability rp_raw &lt;- tryCatch( predict( repr_mod_boot, newdata = setNames(data.frame(size_classes), repr_state), type = &quot;response&quot; ), error = function(e) rep(0, length(size_classes)) ) # Enforce minimum reproductive size threshold rp_vals &lt;- ifelse(size_classes &lt; min_repro_full, 0, rp_raw) rp_vals[!is.finite(rp_vals)] &lt;- 0 # Predict seed production rs_vals &lt;- tryCatch( predict( seed_mod_boot, newdata = setNames(data.frame(size_classes), seed_state), type = &quot;response&quot; ), error = function(e) rep(0, length(size_classes)) ) rs_vals[!is.finite(rs_vals)] &lt;- 0 # Combined reproductive intensity repro_intensity &lt;- rp_vals * rs_vals if (sum(repro_intensity) &gt; 0) { w_parent &lt;- repro_intensity / sum(repro_intensity) mean_rep &lt;- sum(size_classes * w_parent) var_rep &lt;- sum((size_classes - mean_rep)^2 * w_parent) prop_rep &lt;- sum(stable_vec[repro_intensity &gt; 0]) } else { mean_rep &lt;- NA_real_ var_rep &lt;- NA_real_ prop_rep &lt;- 0 } #-------------------------------- # SAVE RESULTS #-------------------------------- valid_iter &lt;- valid_iter + 1 all_lambdas[valid_iter] &lt;- lam mean_size_rep[valid_iter] &lt;- mean_rep var_size_rep[valid_iter] &lt;- var_rep prop_stable_repro_vals[valid_iter] &lt;- prop_rep } ## Attempt 10 | Valid: 8 ## Attempt 20 | Valid: 15 ## Attempt 30 | Valid: 24 ## Attempt 40 | Valid: 34 ## Attempt 50 | Valid: 44 #-------------------------------- # BOOTSTRAP SUMMARY #-------------------------------- cat(&quot;\\n=== Bootstrap Complete ===\\n&quot;) ## ## === Bootstrap Complete === cat(&quot;✓ Valid iterations:&quot;, valid_iter, &quot;/&quot;, n_boot, &quot;\\n&quot;) ## ✓ Valid iterations: 50 / 50 cat(&quot;✓ Total attempts:&quot;, attempts, &quot;\\n&quot;) ## ✓ Total attempts: 55 cat(&quot;✓ Success rate:&quot;, round(100 * valid_iter / attempts, 1), &quot;%\\n&quot;) ## ✓ Success rate: 90.9 % if (valid_iter &lt; n_boot) { warning(&quot;Only &quot;, valid_iter, &quot; successful bootstrap iterations (target was &quot;, n_boot, &quot;)&quot;) } # Remove NA values (unfilled slots if valid_iter &lt; n_boot) all_lambdas &lt;- all_lambdas[1:valid_iter] mean_size_rep &lt;- mean_size_rep[1:valid_iter] var_size_rep &lt;- var_size_rep[1:valid_iter] prop_stable_repro_vals &lt;- prop_stable_repro_vals[1:valid_iter] #-------------------------------- # CALCULATE CONFIDENCE INTERVALS #-------------------------------- lambda_ci &lt;- quantile(all_lambdas, probs = c(0.025, 0.975), na.rm = TRUE) lambda_obs &lt;- ipmr::lambda(obs_ipm) cat(&quot;\\n=== Lambda Estimates ===\\n&quot;) ## ## === Lambda Estimates === cat(&quot;Observed λ:&quot;, round(lambda_obs, 4), &quot;\\n&quot;) ## Observed λ: 0.9647 cat(&quot;Bootstrap mean λ:&quot;, round(mean(all_lambdas, na.rm = TRUE), 4), &quot;\\n&quot;) ## Bootstrap mean λ: 0.9412 cat(&quot;95% CI: [&quot;, round(lambda_ci[1], 4), &quot;,&quot;, round(lambda_ci[2], 4), &quot;]\\n&quot;) ## 95% CI: [ 0.7975 , 0.9961 ] #-------------------------------- # VISUALIZE RESULTS #-------------------------------- # Lambda distribution lambda_plot &lt;- ggplot(data.frame(lambda = all_lambdas), aes(x = lambda)) + geom_histogram(bins = 30, fill = &quot;skyblue&quot;, color = &quot;black&quot;, alpha = 0.7) + geom_vline(xintercept = lambda_obs, color = &quot;red&quot;, linewidth = 1.2, linetype = &quot;dashed&quot;) + geom_vline(xintercept = lambda_ci[1], color = &quot;blue&quot;, linewidth = 1, linetype = &quot;dotted&quot;) + geom_vline(xintercept = lambda_ci[2], color = &quot;blue&quot;, linewidth = 1, linetype = &quot;dotted&quot;) + labs( title = &quot;Bootstrap Distribution of λ&quot;, subtitle = paste0(&quot;n = &quot;, valid_iter, &quot; iterations&quot;), x = &quot;Population growth rate (λ)&quot;, y = &quot;Frequency&quot; ) + annotate(&quot;text&quot;, x = lambda_obs, y = Inf, label = paste0(&quot;Observed: &quot;, round(lambda_obs, 3)), vjust = 2, color = &quot;red&quot;, fontface = &quot;bold&quot;) + theme_pubr(base_size = 14) print(lambda_plot) # Save plot ggsave( paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_lambda_bootstrap.png&quot;), lambda_plot, width = 8, height = 6, dpi = 300 ) cat(&quot;\\n✓ Bootstrap complete! Lambda plot saved.\\n&quot;) ## ## ✓ Bootstrap complete! Lambda plot saved. Now, let’s look at these results! To better understand the life history strategy underlying the observed population growth rate, we calculated several additional demographic metrics. These included net reproductive rate (R₀; the expected lifetime offspring per individual), generation time (the average interval between generations), and size-specific patterns in reproduction and survival. Together, these metrics paint a fuller picture of how individuals progress through their life cycle and contribute to population dynamics. #============================================================== # LIFE-HISTORY METRICS FROM A SIZE-STRUCTURED IPM #============================================================== library(ipmr) cat(&quot;\\n=== Computing Life-History Metrics ===\\n&quot;) ## ## === Computing Life-History Metrics === state_var &lt;- &quot;sa&quot; #-------------------------------------------------------------- # 1. Extract discretized kernels #-------------------------------------------------------------- Pm &lt;- obs_ipm$sub_kernels$P Fm &lt;- obs_ipm$sub_kernels$F K &lt;- Pm + Fm n_mesh &lt;- nrow(Pm) #-------------------------------------------------------------- # 2. Extract mesh (CORRECTED - get unique values) #-------------------------------------------------------------- # sa_1 in main_env is the expanded grid (n_mesh × n_mesh values) # We need the unique mesh points sa_1_full &lt;- get(&quot;sa_1&quot;, envir = obs_ipm$env_list$main_env) size_classes &lt;- sort(unique(as.numeric(sa_1_full))) # Verify length if(length(size_classes) != n_mesh) { stop(&quot;Mesh length (&quot;, length(size_classes), &quot;) != kernel dim (&quot;, n_mesh, &quot;)&quot;) } cat(&quot;✓ Extracted mesh from main_env (unique values from sa_1)\\n&quot;) ## ✓ Extracted mesh from main_env (unique values from sa_1) cat(&quot; Original sa_1 length:&quot;, length(sa_1_full), &quot;\\n&quot;) ## Original sa_1 length: 10000 cat(&quot; Unique mesh points:&quot;, n_mesh, &quot;\\n&quot;) ## Unique mesh points: 100 cat(&quot; Domain (log):&quot;, round(range(size_classes), 3), &quot;\\n&quot;) ## Domain (log): 0.027 5.424 cat(&quot; Domain (raw):&quot;, round(exp(range(size_classes)), 2), &quot;cm\\n&quot;) ## Domain (raw): 1.03 226.87 cm #-------------------------------------------------------------- # 3. Population growth rate (λ) #-------------------------------------------------------------- lambda_obs &lt;- ipmr::lambda(obs_ipm) cat(&quot;\\n✓ Lambda:&quot;, round(lambda_obs, 4), &quot;\\n&quot;) ## ## ✓ Lambda: 0.9647 if(lambda_obs &gt; 1) { cat(&quot; → Population GROWING at&quot;, round((lambda_obs - 1) * 100, 2), &quot;% per year\\n&quot;) } else if(lambda_obs &lt; 1) { cat(&quot; → Population DECLINING at&quot;, round((1 - lambda_obs) * 100, 2), &quot;% per year\\n&quot;) } else { cat(&quot; → Population STABLE\\n&quot;) } ## → Population DECLINING at 3.53 % per year #-------------------------------------------------------------- # 4. Stable size distribution #-------------------------------------------------------------- stable_output &lt;- ipmr::right_ev(obs_ipm) stable_vec &lt;- stable_output[[paste0(state_var, &quot;_w&quot;)]] stable_vec &lt;- as.numeric(stable_vec) # Verify length if(length(stable_vec) != n_mesh) { stop(&quot;Stable vector length (&quot;, length(stable_vec), &quot;) != kernel dim (&quot;, n_mesh, &quot;)&quot;) } # Normalize (should already be 1) if(!isTRUE(all.equal(sum(stable_vec), 1))) { stable_vec &lt;- stable_vec / sum(stable_vec) } cat(&quot;✓ Stable distribution extracted (sum =&quot;, round(sum(stable_vec), 6), &quot;)\\n&quot;) ## ✓ Stable distribution extracted (sum = 1 ) # Mean size under stable distribution mean_size_stable_log &lt;- sum(size_classes * stable_vec) mean_size_stable_raw &lt;- exp(mean_size_stable_log) cat(&quot; Mean size (log):&quot;, round(mean_size_stable_log, 3), &quot;\\n&quot;) ## Mean size (log): 0.213 cat(&quot; Mean size (raw):&quot;, round(mean_size_stable_raw, 2), &quot;cm\\n&quot;) ## Mean size (raw): 1.24 cm #-------------------------------------------------------------- # 5. Reproductive value #-------------------------------------------------------------- rv_output &lt;- ipmr::left_ev(obs_ipm) # Try with suffix first, fallback to first element rv_vec &lt;- rv_output[[paste0(state_var, &quot;_w&quot;)]] if(is.null(rv_vec)) rv_vec &lt;- rv_output[[1]] rv_vec &lt;- as.numeric(rv_vec) # Verify length if(length(rv_vec) != n_mesh) { stop(&quot;RV vector length (&quot;, length(rv_vec), &quot;) != kernel dim (&quot;, n_mesh, &quot;)&quot;) } # Scale to max = 1 if(max(rv_vec, na.rm = TRUE) &gt; 0) { rv_vec &lt;- rv_vec / max(rv_vec, na.rm = TRUE) } max_rv &lt;- max(rv_vec, na.rm = TRUE) cat(&quot;✓ Max reproductive value:&quot;, round(max_rv, 3), &quot;\\n&quot;) ## ✓ Max reproductive value: 1 #-------------------------------------------------------------- # 6. Size-specific reproduction #-------------------------------------------------------------- size_specific_repro &lt;- colSums(Fm) if(sum(size_specific_repro) &gt; 0) { mean_rep_obs_log &lt;- sum(size_classes * size_specific_repro) / sum(size_specific_repro) mean_rep_obs_raw &lt;- exp(mean_rep_obs_log) var_rep_obs_log &lt;- sum((size_classes - mean_rep_obs_log)^2 * size_specific_repro) / sum(size_specific_repro) } else { mean_rep_obs_log &lt;- NA_real_ mean_rep_obs_raw &lt;- NA_real_ var_rep_obs_log &lt;- NA_real_ } cat(&quot;✓ Mean reproductive size (log):&quot;, round(mean_rep_obs_log, 3), &quot;\\n&quot;) ## ✓ Mean reproductive size (log): 4.783 cat(&quot; Mean reproductive size (raw):&quot;, round(mean_rep_obs_raw, 2), &quot;cm\\n&quot;) ## Mean reproductive size (raw): 119.47 cm #-------------------------------------------------------------- # 7. Expected remaining lifetime by size #-------------------------------------------------------------- cat(&quot;\\n=== Computing Expected Remaining Lifetime ===\\n&quot;) ## ## === Computing Expected Remaining Lifetime === # Check P eigenvalue P_eigs &lt;- eigen(Pm)$values P_lambda &lt;- max(Re(P_eigs)) cat(&quot;P kernel eigenvalue:&quot;, round(P_lambda, 4), &quot;\\n&quot;) ## P kernel eigenvalue: 0.9647 if(P_lambda &gt;= 0.99) { cat(&quot;⚠️ High P eigenvalue (&gt;0.99) - expected lifetimes may be very long\\n&quot;) } expected_remaining_life &lt;- rep(0, n_mesh) v &lt;- rep(1, n_mesh) tol &lt;- 1e-8 max_iter &lt;- 5000 converged &lt;- FALSE for(iter in seq_len(max_iter)) { expected_remaining_life &lt;- expected_remaining_life + v v_new &lt;- as.numeric(Pm %*% v) diff &lt;- max(abs(v_new - v), na.rm = TRUE) if(diff &lt; tol) { cat(&quot;✓ Converged after&quot;, iter, &quot;iterations\\n&quot;) converged &lt;- TRUE break } if(any(!is.finite(v_new)) || max(v_new) &gt; 1e6) { warning(&quot;⚠️ Lifetime calculation diverging at iteration &quot;, iter) break } v &lt;- v_new } ## ✓ Converged after 498 iterations if(!converged) { cat(&quot;⚠️ Did not fully converge after&quot;, max_iter, &quot;iterations\\n&quot;) } max_life &lt;- max(expected_remaining_life) cat(&quot; Max expected lifetime:&quot;, round(max_life, 2), &quot;time steps\\n&quot;) ## Max expected lifetime: 402.78 time steps if(max_life &gt; 100) { cat(&quot;⚠️ Very high lifetime (&gt;100 years) - survival model may be overfitting\\n&quot;) } ## ⚠️ Very high lifetime (&gt;100 years) - survival model may be overfitting #-------------------------------------------------------------- # 8. Median size (weighted by stable distribution) #-------------------------------------------------------------- cumulative_dist &lt;- cumsum(stable_vec) median_index &lt;- which(cumulative_dist &gt;= 0.5)[1] if(is.na(median_index)) { median_index &lt;- floor(n_mesh / 2) cat(&quot;⚠️ Could not find weighted median, using middle bin\\n&quot;) } median_size_log &lt;- size_classes[median_index] median_size_raw &lt;- exp(median_size_log) life_exp_median_obs &lt;- expected_remaining_life[median_index] cat(&quot;✓ Median size (log):&quot;, round(median_size_log, 3), &quot;\\n&quot;) ## ✓ Median size (log): 0.136 cat(&quot; Median size (raw):&quot;, round(median_size_raw, 2), &quot;cm\\n&quot;) ## Median size (raw): 1.15 cm cat(&quot; Expected lifetime at median:&quot;, round(life_exp_median_obs, 2), &quot;time steps\\n&quot;) ## Expected lifetime at median: 256.59 time steps #-------------------------------------------------------------- # 9. Summary table #-------------------------------------------------------------- summary_table &lt;- data.frame( Metric = c( &quot;Population growth rate (λ)&quot;, &quot;Mean size (stable, log)&quot;, &quot;Mean size (stable, cm)&quot;, &quot;Median size (stable, log)&quot;, &quot;Median size (stable, cm)&quot;, &quot;Mean reproductive size (log)&quot;, &quot;Mean reproductive size (cm)&quot;, &quot;Variance reproductive size (log)&quot;, &quot;Expected lifetime at median&quot;, &quot;Max reproductive value&quot; ), Estimate = round(c( lambda_obs, mean_size_stable_log, mean_size_stable_raw, median_size_log, median_size_raw, mean_rep_obs_log, mean_rep_obs_raw, var_rep_obs_log, life_exp_median_obs, max_rv ), 4) ) cat(&quot;\\n=== LIFE-HISTORY SUMMARY ===\\n&quot;) ## ## === LIFE-HISTORY SUMMARY === print(summary_table, row.names = FALSE) ## Metric Estimate ## Population growth rate (λ) 0.9647 ## Mean size (stable, log) 0.2125 ## Mean size (stable, cm) 1.2368 ## Median size (stable, log) 0.1363 ## Median size (stable, cm) 1.1460 ## Mean reproductive size (log) 4.7830 ## Mean reproductive size (cm) 119.4663 ## Variance reproductive size (log) 0.0700 ## Expected lifetime at median 256.5872 ## Max reproductive value 1.0000 #-------------------------------------------------------------- # 10. Visualizations #-------------------------------------------------------------- png(paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_life_history.png&quot;), width = 12, height = 10, units = &quot;in&quot;, res = 300) par(mfrow = c(2, 2), mar = c(4.5, 4.5, 3, 1)) # Plot 1: Expected lifetime vs log size plot(size_classes, expected_remaining_life, type = &quot;l&quot;, lwd = 3, col = &quot;darkblue&quot;, xlab = &quot;Size (log scale)&quot;, ylab = &quot;Expected remaining lifetime (years)&quot;, main = &quot;A. Expected Lifetime by Size (Log)&quot;, cex.lab = 1.2, cex.main = 1.3) abline(v = median_size_log, col = &quot;red&quot;, lwd = 2, lty = 2) abline(v = mean_size_stable_log, col = &quot;green&quot;, lwd = 2, lty = 2) text(median_size_log, max(expected_remaining_life) * 0.9, paste0(&quot;Median\\n&quot;, round(life_exp_median_obs, 1), &quot; yr&quot;), pos = 4, col = &quot;red&quot;, font = 2, cex = 0.9) legend(&quot;topright&quot;, legend = c(&quot;Median&quot;, &quot;Mean&quot;), col = c(&quot;red&quot;, &quot;green&quot;), lty = 2, lwd = 2, cex = 0.8) grid() # Plot 2: Expected lifetime vs raw size plot(exp(size_classes), expected_remaining_life, type = &quot;l&quot;, lwd = 3, col = &quot;darkblue&quot;, xlab = &quot;Size (cm)&quot;, ylab = &quot;Expected remaining lifetime (years)&quot;, main = &quot;B. Expected Lifetime by Size (Raw)&quot;, cex.lab = 1.2, cex.main = 1.3) abline(v = median_size_raw, col = &quot;red&quot;, lwd = 2, lty = 2) abline(v = mean_size_stable_raw, col = &quot;green&quot;, lwd = 2, lty = 2) legend(&quot;topright&quot;, legend = c(&quot;Median&quot;, &quot;Mean&quot;), col = c(&quot;red&quot;, &quot;green&quot;), lty = 2, lwd = 2, cex = 0.8) grid() # Plot 3: Stable size distribution plot(size_classes, stable_vec, type = &quot;l&quot;, lwd = 3, col = &quot;purple&quot;, xlab = &quot;Size (log scale)&quot;, ylab = &quot;Proportion&quot;, main = &quot;C. Stable Size Distribution&quot;, cex.lab = 1.2, cex.main = 1.3) abline(v = median_size_log, col = &quot;red&quot;, lwd = 2, lty = 2) abline(v = mean_size_stable_log, col = &quot;green&quot;, lwd = 2, lty = 2) legend(&quot;topright&quot;, legend = c(&quot;Median&quot;, &quot;Mean&quot;), col = c(&quot;red&quot;, &quot;green&quot;), lty = 2, lwd = 2, cex = 0.8) grid() # Plot 4: Reproductive value plot(size_classes, rv_vec, type = &quot;l&quot;, lwd = 3, col = &quot;orange&quot;, xlab = &quot;Size (log scale)&quot;, ylab = &quot;Reproductive value (scaled)&quot;, main = &quot;D. Reproductive Value by Size&quot;, cex.lab = 1.2, cex.main = 1.3) grid() dev.off() ## quartz_off_screen ## 2 par(mfrow = c(1, 1)) cat(&quot;\\n✓ Figure saved!\\n&quot;) ## ## ✓ Figure saved! #-------------------------------------------------------------- # 11. Export results #-------------------------------------------------------------- write.csv( summary_table, paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_life_history.csv&quot;), row.names = FALSE ) life_exp_detailed &lt;- data.frame( size_log = size_classes, size_raw_cm = exp(size_classes), expected_remaining_lifetime = expected_remaining_life, stable_distribution = stable_vec, reproductive_value = rv_vec ) write.csv( life_exp_detailed, paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_size_specific_metrics.csv&quot;), row.names = FALSE ) cat(&quot;✓ All results exported successfully!\\n&quot;) ## ✓ All results exported successfully! Interesting! This figure is showing us size-dependent survival and its consequences for expected remaining lifetime in a size-structured Integral Projection Model (IPM). Each point shows the observed survival outcome (0 = died, 1 = survived) for an individual as a function of size at time t. Survival probability is high for small individuals but declines markedly at larger sizes, indicating that large individuals experience elevated mortality risk. This non-monotonic survival–size relationship directly shapes the expected remaining lifetime (ERL) curve derived from the IPM. Individuals at small sizes have long expected remaining lifetimes because they persist with high survival across multiple time steps, even if growth is slow. In contrast, individuals at larger sizes exhibit short expected remaining lifetimes, reflecting increased mortality once large size is reached. The dashed vertical line indicates the median size class, at which survival is approximately 50%, yielding an ERL near one time step. This pattern illustrates that, in size-structured populations, longevity is not necessarily associated with large size; instead, long expected lifetimes can arise from prolonged persistence at small sizes. The IPM faithfully translates this empirically observed survival–size relationship into emergent demographic properties, rather than imposing assumptions about monotonic size–survival relationships. Now, let’s calculate transient dynamics! We have to use the original size distribution, and walk through an individual time step (rather than run to asymptotic population growth / stable size distribution). #============================================================== # TRANSIENT DYNAMICS (LOG-SCALE STATE VARIABLE) #============================================================== library(ipmr) #-------------------------------------------------------------- # 1) Extract mesh + kernels (ROBUST to ipmr storage details) #-------------------------------------------------------------- P &lt;- obs_ipm$sub_kernels$P F &lt;- obs_ipm$sub_kernels$F K &lt;- P + F # The discretized matrix dimension is the truth n_mesh &lt;- nrow(K) # ---- Try to recover the mesh points in a way that matches K ---- # 1) Best case: row/col names are the mesh points size_classes &lt;- suppressWarnings(as.numeric(rownames(K))) # 2) If rownames aren&#39;t numeric, try colnames if (length(size_classes) != n_mesh || anyNA(size_classes)) { size_classes &lt;- suppressWarnings(as.numeric(colnames(K))) } # 3) If still not valid, pull from ipmr environment (sa_1) if (length(size_classes) != n_mesh || anyNA(size_classes)) { size_classes &lt;- NULL if (!is.null(obs_ipm$env_list$main_env) &amp;&amp; exists(&quot;sa_1&quot;, envir = obs_ipm$env_list$main_env, inherits = FALSE)) { sa_1_full &lt;- get(&quot;sa_1&quot;, envir = obs_ipm$env_list$main_env) cand &lt;- sort(unique(as.numeric(sa_1_full))) if (length(cand) == n_mesh) size_classes &lt;- cand } } # 4) Last resort: reconstruct evenly spaced mesh from your domain bounds L, U # (works as long as you still have L and U in your workspace) if (is.null(size_classes) || length(size_classes) != n_mesh || anyNA(size_classes)) { if (!exists(&quot;L&quot;, inherits = TRUE) || !exists(&quot;U&quot;, inherits = TRUE)) { stop(&quot;Could not recover mesh points. Ensure L and U exist, or that K has rownames/colnames.&quot;) } size_classes &lt;- seq(L, U, length.out = n_mesh) } # Final sanity checks stopifnot(nrow(K) == n_mesh, ncol(K) == n_mesh, length(size_classes) == n_mesh) cat(&quot;Mesh points:&quot;, n_mesh, &quot;\\n&quot;) ## Mesh points: 100 cat(&quot;Domain (log):&quot;, round(range(size_classes), 3), &quot;\\n&quot;) ## Domain (log): 0.027 5.424 #-------------------------------------------------------------- # 2) Initial population vector from observed sizes (LOG SCALE) # IMPORTANT: bins need to match the mesh discretization #-------------------------------------------------------------- observed_sizes_log &lt;- final_data$size_log[is.finite(final_data$size_log)] # Build bin edges as midpoints between mesh points (plus endpoints) # This aligns a histogram with the discretized state space edges &lt;- c( size_classes[1] - 0.5 * (size_classes[2] - size_classes[1]), (size_classes[-1] + size_classes[-n_mesh]) / 2, size_classes[n_mesh] + 0.5 * (size_classes[n_mesh] - size_classes[n_mesh - 1]) ) hist_data &lt;- hist(observed_sizes_log, breaks = edges, plot = FALSE) n0 &lt;- as.numeric(hist_data$counts) if (sum(n0) == 0) stop(&quot;Initial vector n0 has all zeros (no finite size_log values).&quot;) n0 &lt;- n0 / sum(n0) # normalize to proportions cat(&quot;Initial population vector:\\n&quot;) ## Initial population vector: cat(&quot; Sum:&quot;, round(sum(n0), 6), &quot;\\n&quot;) ## Sum: 1 cat(&quot; Non-zero bins:&quot;, sum(n0 &gt; 0), &quot;\\n&quot;) ## Non-zero bins: 43 #-------------------------------------------------------------- # 3) Asymptotic properties (dominant eigenvalue/eigenvector) #-------------------------------------------------------------- eig &lt;- eigen(K) lambda_asymptotic &lt;- max(Re(eig$values)) dom_idx &lt;- which.max(Re(eig$values)) w &lt;- Re(eig$vectors[, dom_idx]) w[w &lt; 0] &lt;- 0 if (sum(w) &lt;= 0) { # fallback: absolute value then normalize w &lt;- abs(Re(eig$vectors[, dom_idx])) } w &lt;- w / sum(w) cat(&quot;\\nAsymptotic lambda:&quot;, round(lambda_asymptotic, 4), &quot;\\n&quot;) ## ## Asymptotic lambda: 0.9647 #-------------------------------------------------------------- # 4) One-step transient dynamics #-------------------------------------------------------------- n1 &lt;- as.numeric(K %*% n0) lambda_1 &lt;- sum(n1) / sum(n0) # since sum(n0)=1, this is just sum(n1) n1_normalized &lt;- n1 / sum(n1) deviation &lt;- n1_normalized - n0 cat(&quot;\\nOne-step dynamics:\\n&quot;) ## ## One-step dynamics: cat(&quot; Lambda_1 (from observed n0):&quot;, round(lambda_1, 4), &quot;\\n&quot;) ## Lambda_1 (from observed n0): 4.3125 cat(&quot; Max deviation (|n1 - n0|):&quot;, round(max(abs(deviation)), 4), &quot;\\n&quot;) ## Max deviation (|n1 - n0|): 0.0853 #-------------------------------------------------------------- # 5) Reactivity + inertia # - &quot;Observed one-step amplification&quot; = lambda_1 # - &quot;Worst-case one-step amplification bound&quot; for total abundance: # max(colSums(K)) for nonnegative K under L1 norm # - Inertia: compare total N(t) to lambda^t scaling #-------------------------------------------------------------- # Worst-case one-step amplification (upper bound under L1) reactivity_bound &lt;- max(colSums(K)) # Inertia via repeated multiplication (avoid %^%) T &lt;- 50L nt &lt;- n0 for (tt in seq_len(T)) nt &lt;- as.numeric(K %*% nt) inertia &lt;- sum(nt) / (lambda_asymptotic^T * sum(n0)) cat(&quot;\\nTransient metrics:\\n&quot;) ## ## Transient metrics: cat(&quot; Reactivity (observed, 1-step):&quot;, round(lambda_1, 4), &quot;\\n&quot;) ## Reactivity (observed, 1-step): 4.3125 cat(&quot; Reactivity (worst-case bound):&quot;, round(reactivity_bound, 4), &quot;\\n&quot;) ## Reactivity (worst-case bound): 10.7317 cat(&quot; Inertia (T = &quot;, T, &quot;): &quot;, round(inertia, 4), &quot;\\n&quot;, sep = &quot;&quot;) ## Inertia (T = 50): 4.1249 #-------------------------------------------------------------- # 6) Summary table + export #-------------------------------------------------------------- transient_metrics &lt;- data.frame( Transition = trans_years, Lambda_1_observed = round(lambda_1, 4), Reactivity_bound = round(reactivity_bound, 4), Inertia_T50 = round(inertia, 4), Lambda_asymptotic = round(lambda_asymptotic, 4), T_used = T ) print(transient_metrics) ## Transition Lambda_1_observed Reactivity_bound Inertia_T50 Lambda_asymptotic T_used ## 1 20232024 4.3125 10.7317 4.1249 0.9647 50 dir.create(&quot;IPM_outputs&quot;, showWarnings = FALSE) write.csv( transient_metrics, file = paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_transient_metrics.csv&quot;), row.names = FALSE ) #-------------------------------------------------------------- # 7) Visualization: deviation after one step #-------------------------------------------------------------- deviation_df &lt;- data.frame( size_log = size_classes, size_raw_cm = exp(size_classes), deviation = deviation, initial = n0, final = n1_normalized ) library(ggplot2) p_dev &lt;- ggplot(deviation_df, aes(x = size_log, y = deviation, fill = deviation &gt; 0)) + geom_col(color = &quot;black&quot;, linewidth = 0.2) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_fill_manual(values = c(&quot;TRUE&quot; = &quot;#3B82F6&quot;, &quot;FALSE&quot; = &quot;#EF4444&quot;), guide = &quot;none&quot;) + labs( title = &quot;Deviation from stable size distribution after one time step&quot;, subtitle = paste0(&quot;Observed 1-step growth (λ1) = &quot;, round(lambda_1, 3)), x = &quot;Size class (log scale)&quot;, y = &quot;Final − Initial proportion&quot; ) + theme_minimal(base_size = 14) print(p_dev) ggsave( filename = paste0(&quot;IPM_outputs/&quot;, species_name, &quot;_&quot;, trans_years, &quot;_transient_deviation.png&quot;), plot = p_dev, width = 8, height = 5, dpi = 300 ) Sensitivity and vital rate calculations #------------------------------------------------- # Sensitivity and Elasticity of λ #------------------------------------------------- # Sensitivity: ∂λ / ∂K_ij # Elasticity: proportional sensitivity = (K_ij / λ) * sensitivity # # Row sums of elasticity: # Contribution of individuals of a given size at time t # Column sums: # Contribution of individuals entering a given size at time t+1 # Row sums are most commonly interpreted and plotted. #------------------------------------------------- library(ggpubr) library(ipmr) # Combine kernels K &lt;- obs_ipm$sub_kernels$P + obs_ipm$sub_kernels$F n_size &lt;- nrow(K) # Eigen decomposition eig &lt;- eigen(K) ord &lt;- order(Re(eig$values), decreasing = TRUE) lambda_dom &lt;- Re(eig$values[ord[1]]) # Right eigenvector (stable distribution) w &lt;- Re(eig$vectors[, ord[1]]) w[w &lt; 0] &lt;- 0 w &lt;- w / sum(w) # Left eigenvector (reproductive value) eig_left &lt;- eigen(t(K)) v &lt;- Re(eig_left$vectors[, ord[1]]) v &lt;- v / sum(v * w) # normalize so v · w = 1 # Sensitivity and elasticity sensitivity &lt;- outer(v, w) elasticity &lt;- (K / lambda_dom) * sensitivity #------------------------------------------------- # Prepare plotting data (INDEX-ALIGNED) #------------------------------------------------- # Use indices or safe mesh extraction size_log &lt;- as.numeric(obs_ipm$env_list$main_env$sa_1)[seq_len(n_size)] size_raw &lt;- exp(size_log) sens_df &lt;- expand.grid( from_size = size_log, to_size = size_log ) sens_df$value &lt;- as.vector(sensitivity) elas_df &lt;- expand.grid( from_size = size_log, to_size = size_log ) elas_df$value &lt;- as.vector(elasticity) row_df &lt;- data.frame( size_log = size_log, size_raw_cm = size_raw, elasticity_sum = rowSums(elasticity) ) #------------------------------------------------- # Plots #------------------------------------------------- elas_plot &lt;- ggplot(elas_df, aes(from_size, to_size, fill = value)) + geom_tile() + scale_fill_viridis_c(name = &quot;Elasticity&quot;) + labs( x = &quot;Size at time t (log)&quot;, y = &quot;Size at time t+1 (log)&quot;, title = &quot;Elasticity matrix&quot; ) + theme_pubr() row_plot &lt;- ggplot(row_df, aes(size_log, elasticity_sum)) + geom_line(linewidth = 1.1) + labs( x = &quot;Size at time t (log scale)&quot;, y = &quot;Sum of elasticities&quot;, title = &quot;Contribution of size classes to λ&quot; ) + theme_pubr() combined_plot &lt;- ggarrange(elas_plot, row_plot, labels = c(&quot;A&quot;, &quot;B&quot;), ncol = 2) print(combined_plot) And let’s check out vital rates! #============================================================== # VITAL RATE UNCERTAINTY (LOG-SCALE STATE VARIABLE) #============================================================== library(tidyverse) library(ggpubr) library(viridis) library(ipmr) #-------------------------------------------------------------- # Helper #-------------------------------------------------------------- safe_boot_glm &lt;- function(formula, data, family) { tryCatch( glm(formula, data = data, family = family), error = function(e) NULL ) } #-------------------------------------------------------------- # Prediction grid (LOG SCALE) #-------------------------------------------------------------- size_seq_log &lt;- seq( min(final_data$size_log, na.rm = TRUE), max(final_data$size_log, na.rm = TRUE), length.out = 100 ) n_boot &lt;- 100 set.seed(42) #============================================================== # SURVIVAL #============================================================== boot_preds &lt;- matrix(NA, length(size_seq_log), n_boot) for (i in seq_len(n_boot)) { boot_data &lt;- final_data[sample(nrow(final_data), replace = TRUE), ] mod &lt;- safe_boot_glm(surv ~ size_log, boot_data, binomial()) if (!is.null(mod)) { boot_preds[, i] &lt;- predict( mod, newdata = data.frame(size_log = size_seq_log), type = &quot;response&quot; ) } } boot_df_surv &lt;- tibble( size_log = size_seq_log, size_cm = exp(size_seq_log), median = apply(boot_preds, 1, median, na.rm = TRUE), lower = apply(boot_preds, 1, quantile, 0.025, na.rm = TRUE), upper = apply(boot_preds, 1, quantile, 0.975, na.rm = TRUE) ) surv_uncertainty_plot &lt;- ggplot() + geom_point(data = final_data, aes(x = size_log, y = surv), alpha = 0.3) + geom_line(data = boot_df_surv, aes(x = size_log, y = median), linewidth = 1) + geom_ribbon(data = boot_df_surv, aes(x = size_log, ymin = lower, ymax = upper), alpha = 0.35, fill = &quot;skyblue&quot;) + labs(x = &quot;Size (log cm)&quot;, y = &quot;Survival probability&quot;) + theme_pubr(base_size = 16) #============================================================== # FLOWERING PROBABILITY #============================================================== boot_preds &lt;- matrix(NA, length(size_seq_log), n_boot) for (i in seq_len(n_boot)) { boot_data &lt;- final_data[sample(nrow(final_data), replace = TRUE), ] mod &lt;- safe_boot_glm( fec1 ~ size_log + I(size_log^2), boot_data, binomial() ) if (!is.null(mod)) { boot_preds[, i] &lt;- predict( mod, newdata = data.frame(size_log = size_seq_log), type = &quot;response&quot; ) } } boot_df_fec1 &lt;- tibble( size_log = size_seq_log, size_cm = exp(size_seq_log), median = apply(boot_preds, 1, median, na.rm = TRUE), lower = apply(boot_preds, 1, quantile, 0.025, na.rm = TRUE), upper = apply(boot_preds, 1, quantile, 0.975, na.rm = TRUE) ) fec1_uncertainty_plot &lt;- ggplot() + geom_point(data = final_data, aes(x = size_log, y = fec1), alpha = 0.3) + geom_line(data = boot_df_fec1, aes(x = size_log, y = median), linewidth = 1) + geom_ribbon(data = boot_df_fec1, aes(x = size_log, ymin = lower, ymax = upper), alpha = 0.35, fill = &quot;plum&quot;) + labs(x = &quot;Size (log cm)&quot;, y = &quot;Flowering probability&quot;) + theme_pubr(base_size = 16) #============================================================== # SEED PRODUCTION #============================================================== boot_preds &lt;- matrix(NA, length(size_seq_log), n_boot) for (i in seq_len(n_boot)) { boot_data &lt;- final_data[sample(nrow(final_data), replace = TRUE), ] mod &lt;- safe_boot_glm( fec2 ~ size_log + I(size_log^2), boot_data, poisson() ) if (!is.null(mod)) { boot_preds[, i] &lt;- predict( mod, newdata = data.frame(size_log = size_seq_log), type = &quot;response&quot; ) } } boot_df_fec2 &lt;- tibble( size_log = size_seq_log, size_cm = exp(size_seq_log), median = apply(boot_preds, 1, median, na.rm = TRUE), lower = apply(boot_preds, 1, quantile, 0.025, na.rm = TRUE), upper = apply(boot_preds, 1, quantile, 0.975, na.rm = TRUE) ) fec2_uncertainty_plot &lt;- ggplot() + geom_point(data = final_data, aes(x = size_log, y = fec2), alpha = 0.3) + geom_line(data = boot_df_fec2, aes(x = size_log, y = median), linewidth = 1) + geom_ribbon(data = boot_df_fec2, aes(x = size_log, ymin = lower, ymax = upper), alpha = 0.35, fill = &quot;goldenrod&quot;) + labs(x = &quot;Size (log cm)&quot;, y = &quot;Seed production&quot;) + theme_pubr(base_size = 16) #============================================================== # GROWTH #============================================================== boot_preds &lt;- matrix(NA, length(size_seq_log), n_boot) for (i in seq_len(n_boot)) { boot_data &lt;- final_data[sample(nrow(final_data), replace = TRUE), ] mod &lt;- lm( sizeNext_log ~ size_log + I(size_log^2), data = boot_data ) boot_preds[, i] &lt;- predict( mod, newdata = data.frame(size_log = size_seq_log) ) } boot_df_growth &lt;- tibble( size_log = size_seq_log, size_cm = exp(size_seq_log), median = apply(boot_preds, 1, median), lower = apply(boot_preds, 1, quantile, 0.025), upper = apply(boot_preds, 1, quantile, 0.975) ) growth_uncertainty_plot &lt;- ggplot() + geom_point(data = final_data, aes(x = size_log, y = sizeNext_log), alpha = 0.3) + geom_line(data = boot_df_growth, aes(x = size_log, y = median), linewidth = 1) + geom_ribbon(data = boot_df_growth, aes(x = size_log, ymin = lower, ymax = upper), alpha = 0.35, fill = &quot;darkseagreen3&quot;) + labs(x = &quot;Size (log cm)&quot;, y = &quot;Size at t+1 (log cm)&quot;) + theme_pubr(base_size = 16) #============================================================== # COMBINE #============================================================== uncertainty_panel &lt;- ggarrange( surv_uncertainty_plot, fec1_uncertainty_plot, fec2_uncertainty_plot, growth_uncertainty_plot, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;), ncol = 2, nrow = 2 ) print(uncertainty_panel) 33.11 Test your knowledge Conceptual Understanding: 1. What is an Integral Projection Model (IPM), and how does it differ from a matrix population model? (Hint: think about state variables and discretization.) 2. Why must IPM census timing align with biologically meaningful life-cycle events? Give one example of how poor timing could bias demographic estimates. 3. What characteristics make a variable suitable as a state variable in an IPM? List at least three and briefly explain why each matters. 4. Explain why using more than one state variable can quickly make IPMs impractical. What is meant by the “curse of dimensionality”? Vital Rates and Model Structure: 5. Why is reproduction often modeled using a two-stage (hurdle) approach in plant IPMs? What biological processes do each stage represent? 6. In this case study, why was it problematic to use “height with reproductive structures” as the state variable for fecundity? What kind of modeling issue does this introduce? 7. Why is it generally inappropriate to remove outliers from survival models but reasonable to consider removing them from growth models? Statistical Modeling Choices: 8. Why were log transformations applied to size in most vital-rate models? What biological assumption does this reflect? 9. A quadratic growth model had lower AIC than a linear model. Why is it still important to visually inspect the fitted relationship before choosing it? 10. What does overdispersion indicate in a Poisson model, and why might a negative binomial model be preferred for seed production? IPM Construction and Interpretation: 11. What do the $P$ and $F$ kernels represent biologically? Give one example of a process captured in each. 12. Why must the size domain boundaries (L and U) extend slightly beyond the observed data range? What problem does this help prevent? 13. What is eviction in an IPM, and why can it bias estimates of population growth rate if not corrected? 14. Compare truncation and reflection as eviction-correction strategies. Under what biological assumptions would truncation be preferred? Population Metrics: 15. Interpret the meaning of $\\lambda &lt; 1$, $\\lambda = 1$, and $\\lambda &gt; 1$ in the context of conservation management. 16. What is the stable size distribution, and why does it not describe short-term population behavior? 17. What does reproductive value tell us about individuals of different sizes? How might managers use this information? Transient Dynamics: 18. Explain the difference between asymptotic population growth ($\\lambda$) and one-step transient growth ($\\lambda_1$). 19. What does reactivity measure, and why can it be important even when $\\lambda &lt; 1$? 20. How is inertia interpreted biologically in a conservation context? What does high inertia imply about population response to disturbance? Sensitivity and Elasticity: 21. What is the difference between sensitivity and elasticity of $\\lambda$? Why are elasticities often preferred for interpretation? 22. What does the row sum of the elasticity matrix represent biologically? 23. Why might a size class have high elasticity even if few individuals occupy that size class? Uncertainty and Inference: 24. Why is bootstrapping particularly important for IPMs built from small populations? 25. Why were recruitment parameters held constant during the bootstrap in this analysis? 26. How do uncertainty bands around vital-rate curves help prevent over-interpretation of demographic results? Synthesis / Short Answer: 27. Based on the IPM results, would you prioritize protecting small individuals or large individuals for this species? Justify your answer using survival, reproduction, or elasticity results. 28. Give one example of a management action that could be evaluated using this IPM framework and describe which vital rate it would most likely affect. 33.12 Assignment Using your data, build an ipm and calculate population dynamics! "],["what-are-structural-equation-models.html", "Chapter 34 What are structural equation models? 34.1 Anatomy of a Structural Equation Model 34.2 Building Multivariate Models 34.3 From Concept to Model 34.4 Common Structures in Causal Diagrams 34.5 Chapter 5: Covariance-Based Estimation in SEM 34.6 Getting Started with lavaan – Model Specification, Estimation, and Interpretation", " Chapter 34 What are structural equation models? Structural Equation Modeling (SEM) is a statistical technique that enables the modeling of complex causal relationships among variables. It extends regression by allowing: Simultaneous estimation of multiple equations Inclusion of both observed and latent (unmeasured) variables Specification of indirect effects and feedback loops Assessment of model fit against observed data SEM is often visualized as a path diagram, where arrows represent hypothesized relationships between variables. 34.0.1 When Should You Use SEM? Use SEM when: You have multiple dependent variables that may influence one another You want to estimate direct and indirect effects between variables You need to account for measurement error in survey or ecological constructs You are testing a theory or conceptual model with multiple pathways Your system includes latent constructs like “habitat quality” or “disturbance pressure” inferred from several indicators SEM is ideal when a single regression model is too simplistic to capture the interdependent relationships in your system. 34.0.2 How is SEM Different from Multiple Regression? Feature Multiple Regression SEM Number of equations One Many simultaneously Latent variables ❌ Not allowed ✅ Allowed Indirect effects ❌ Manual calculation ✅ Modeled explicitly Measurement error (in predictors) ❌ Ignored ✅ Can be modeled Model fit assessment R², AIC, etc. Chi-square test, RMSEA, CFI, TLI, etc. In multiple regression, you can only estimate one equation at a time, with no ability to model feedback loops or measurement error. In contrast, SEM treats your whole system as a network, testing how well your full model fits the data. 34.0.3 Summary SEM is a flexible and powerful framework for: Exploring and testing theoretical models Modeling complex causal chains Incorporating unobservable constructs It provides more rigorous insights into systems where variables are interdependent, influenced by hidden factors, and subject to error. 34.1 Anatomy of a Structural Equation Model Structural Equation Modeling (SEM) provides a flexible framework for representing complex causal relationships between variables. In this chapter, we break down the structure of an SEM into its key components. 34.1.1 Types of Variables SEM uses two main types of variables: Observed variables: Directly measured values (e.g., soil nitrogen, species richness). Latent variables: Not directly observed, but inferred from multiple observed indicators (e.g., a latent “Disturbance Pressure” factor inferred from road density, fire frequency, and grazing). Each variable also plays one of two roles in the model: Variable Role Description Exogenous Predictor variables not explained by any other variables in the model. Endogenous Response variables influenced by one or more other variables in the model. Note: Endogenous variables can act as both outcomes and predictors of other endogenous variables. 34.1.2 Path Diagrams Path diagrams are a central feature of SEM. They visually represent the hypothesized relationships between variables using arrows: Single-headed arrows (→) represent causal/predictive paths Double-headed arrows (↔︎) represent covariances (associations not assumed to be causal) 34.2 Building Multivariate Models 34.2.1 What is Causality? Causality refers to understanding the directional effect one variable has on another. In SEM, causal relationships are explicitly modeled, unlike in multiple regression where they may be implied but not specified. Judea Pearl’s Ladder of Causation is a framework for understanding levels of causal reasoning: 1. Observation — association reasoning (“what is”) 2. Intervention — action-based reasoning (“what if I do”) 3. Counterfactuals — imagining alternate realities (“what if I had done”) We ascend the ladder by incorporating more assumptions and a model of the system. 34.2.2 Why move beyond Multiple Regression? Multiple regression models: • Estimate associations while “controlling for” other variables • Assume independence among predictors • Do not explicitly encode causal structure Causal models (via SEM): • Represent direction and strength of causal pathways • Account for mediators, confounders, and latent variables • Enable testing of hypotheses about mechanisms 34.2.3 Meta-Modeling Your System Before diving into data, build a conceptual model: 1. Define your research Purpose: • Discovery: Are you exploring patterns or relationships for the first time? • Hypothesis Testing: Are you evaluating a specific theoretical prediction? • Prediction: Are you aiming to forecast outcomes under new conditions? Tip: Discovery-based models might be more flexible or exploratory, while hypothesis testing demands tighter causal logic and pre-specified relationships. 2. Identify the Focus: What role do your variables play in the system?: • Drivers: Variables that initiate causal change (e.g., treatments, environmental context). • Responses: Outcome variables (e.g., pollinator abundance). • Mediators: Variables that transmit effects from causes to outcomes (e.g., plant cover). Make sure the pieces of your model are causal! Avoid throwing in all your variables just because you measured them — each should have a theorized role. 3. Determine Span of Inference: Are your findings meant to be context-specific or to inform broader generalizations?: • Local/System-Specific: Targeted insights for a particular site or management action. • Generalizable Process: Testing broad ecological principles or multi-site patterns. • Theory Testing: Are you evaluating a known causal pathway or testing a novel ecological hypothesis? This choice influences how you frame your model structure and what covariates (like “site”) you might treat as fixed or random. 34.3 From Concept to Model Once your meta-model is constructed: • Reify with data availability in mind • Ensure your DAG closes appropriate backdoors • Align structure with your research purpose Make sure the pieces of your model are causal! 34.4 Common Structures in Causal Diagrams In structural equation modeling (SEM) and causal inference, understanding the basic building blocks of causal diagrams is crucial. These structures form the foundation for determining what to control for and what to avoid controlling for. Below are the most common structures you’ll encounter in Directed Acyclic Graphs (DAGs), with brief explanations and examples. 34.4.1 Chains (Mediation Paths) Structure: Cause → Mediator → Effect Interpretation: • The mediator is an intermediate variable through which the cause affects the effect. • If you control for the mediator, you block the indirect path, potentially underestimating the total effect of the cause. Example: Fire frequency → Canopy cover → Soil moisture • If you control for canopy cover, you might miss the full effect that fire frequency has on soil moisture via changes in canopy cover. Visual: library(dagitty) library(ggdag) dag &lt;- dagify( SoilMoisture ~ CanopyCover, CanopyCover ~ Fire, labels = c(Fire = &quot;Fire Frequency&quot;, CanopyCover = &quot;Canopy Cover&quot;, SoilMoisture = &quot;Soil Moisture&quot;), exposure = &quot;Fire&quot;, outcome = &quot;SoilMoisture&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 34.4.2 Colliders Structure: Cause1 → Collider ← Cause2 Interpretation: • A collider is a variable that is influenced by two (or more) variables. • Controlling for the collider opens a path between the two causes, creating spurious associations where none may exist. Example: Soil nitrogen → Plant growth ← Pathogen load • Both soil nitrogen and pathogen load affect plant growth. If you control for plant growth (the collider), it might look like soil nitrogen and pathogens are correlated—even if they’re not. Visual: dag &lt;- dagify( PlantGrowth ~ SoilNitrogen + PathogenLoad, labels = c(SoilNitrogen = &quot;Soil N&quot;, PathogenLoad = &quot;Pathogens&quot;, PlantGrowth = &quot;Plant Growth&quot;), exposure = &quot;SoilNitrogen&quot;, outcome = &quot;PathogenLoad&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 34.4.3 Forks (Confounding Paths) Structure: CommonCause → Cause, CommonCause → Effect Interpretation: • This is a confounding structure, where the common cause explains the observed correlation between two variables. • Controlling for the common cause blocks the backdoor path, helping isolate the causal effect. Example: Soil type → Invasive species cover Soil type → Native species richness • If you don’t control for soil type, you may falsely conclude that invasive cover affects native richness, when both are simply driven by the soil. Visual: dag &lt;- dagify( InvasiveCover ~ SoilType, NativeRichness ~ SoilType, labels = c(SoilType = &quot;Soil Type&quot;, InvasiveCover = &quot;Invasive Cover&quot;, NativeRichness = &quot;Native Richness&quot;), exposure = &quot;InvasiveCover&quot;, outcome = &quot;NativeRichness&quot; ) ggdag(dag, text = FALSE, use_labels = &quot;label&quot;) + theme_dag() 34.4.4 Descendants of Colliders Key Point: • Controlling for descendants of colliders can also open spurious paths. Example: Imagine you control for a variable like Plant biomass, which is a descendant of a collider. This can reintroduce bias just like controlling for the collider itself. 34.4.5 Summary of strcutures Structure Do You Control For It? Why? Chain (mediator) ❌ (if estimating total effect) Controls block indirect paths Collider ❌ Conditioning opens spurious paths Fork (common cause) ✅ Controls block confounding Descendant of Collider ❌ Opens collider paths indirectly Understanding these structures helps you build better SEMs, choose correct adjustment sets, and avoid introducing bias into your models. 34.4.6 Identifying Causality You don’t need to know all mechanisms to make causal claims. But you do need to: • Map the system (e.g., using DAGs) • Identify and control for confounders • Avoid controlling for mediators 34.4.7 Backdoor Criterion To estimate a causal effect of X → Y, block all backdoor paths (those that flow into X) by conditioning on appropriate variables not affected by X. 34.4.8 Frontdoor Criterion Useful when you can’t block all backdoor paths. Identify a mediator that: • Is affected by X • Affects Y • Is not affected by any confounders of X and Y 34.4.9 Build your own DAG: SEM Case Study on Pollinator Impacts of Vegetation Management This research project explores how different Integrated Vegetation Management (IVM) treatments conducted by Arizona Public Service (APS) on powerline rights-of-way (ROWs) affect pollinator communities, using Structural Equation Modeling (SEM) to untangle direct and indirect effects. 34.4.9.1 Study Context APS manages vegetation beneath powerlines for safety and access, using a mix of: • Mechanical removal • Herbicide application • Combined Mechanical + Herbicide • Untreated (Control) plots Understanding how these treatments influence floral resources is key to predicting changes in pollinator abundance and diversity. 34.4.9.2 Data Collection At 3 sites, treatments were applied in a randomized block design across plots categorized as: • Control • Herbicide • Mechanical • Mechanical + Herbicide Researchers want to test whether management effects on pollinators are mediated through floral resources, or whether there are residual (direct) effects of treatment type beyond vegetation structure. 34.4.9.3 Key Variables and Their Roles Exogenous (Independent) Variables: • Treatment (main predictor—e.g., herbicide, mowing) • Soil substrate (moderator/stratifier of treatment effects) • Cattle presence (a confounder—not caused by treatment) Plant Community Mediators: • Plant richness • Plant cover • Plant height • Ceanothus presence/abundance • Woody debris Pollinator Response Variables: • Pollinator abundance • Pollinator richness library(dagitty) library(ggdag) library(tidyverse) # Define the DAG ivm_dag &lt;- dagitty(&quot; dag { Treatment Soil_Substrate Cattle Plant_Richness Plant_Cover Plant_Height Ceanothus Woody_Debris Pollinator_Richness Pollinator_Abundance Treatment -&gt; Plant_Richness Treatment -&gt; Plant_Cover Treatment -&gt; Plant_Height Treatment -&gt; Ceanothus Treatment -&gt; Woody_Debris Soil_Substrate -&gt; Treatment Soil_Substrate -&gt; Plant_Richness Soil_Substrate -&gt; Plant_Cover Soil_Substrate -&gt; Woody_Debris Cattle -&gt; Plant_Richness Cattle -&gt; Plant_Cover Cattle -&gt; Pollinator_Abundance Cattle -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Abundance Plant_Cover -&gt; Pollinator_Richness Plant_Cover -&gt; Pollinator_Abundance Plant_Height -&gt; Pollinator_Richness Plant_Height -&gt; Pollinator_Abundance Ceanothus -&gt; Pollinator_Richness Ceanothus -&gt; Pollinator_Abundance Woody_Debris -&gt; Pollinator_Richness Woody_Debris -&gt; Pollinator_Abundance } &quot;) node_roles &lt;- tibble( name = c( &quot;Treatment&quot;, &quot;Soil_Substrate&quot;, &quot;Cattle&quot;, &quot;Plant_Richness&quot;, &quot;Plant_Cover&quot;, &quot;Plant_Height&quot;, &quot;Ceanothus&quot;, &quot;Woody_Debris&quot;, &quot;Pollinator_Richness&quot;, &quot;Pollinator_Abundance&quot; ), role = c( &quot;Treatment&quot;, &quot;Context&quot;, &quot;Context&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Pollinator&quot;, &quot;Pollinator&quot; ) ) # Get layout and merge roles dag_df &lt;- tidy_dagitty(ivm_dag, layout = &quot;nicely&quot;) %&gt;% left_join(node_roles, by = &quot;name&quot;) # Plot using ggplot2 with corrected edge structure ggplot() + geom_segment( data = dag_df %&gt;% filter(!is.na(xend)), aes(x = x, y = y, xend = xend, yend = yend), arrow = arrow(length = unit(0.02, &quot;npc&quot;)), color = &quot;grey40&quot; ) + geom_point( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, color = role), size = 8, alpha = 0.85 ) + geom_text( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, label = name), color = &quot;black&quot;, size = 4 ) + scale_color_manual(values = c( &quot;Treatment&quot; = &quot;#FB7E21FF&quot;, &quot;Context&quot; = &quot;#A91601FF&quot;, &quot;Plant&quot; = &quot;#18DDC2FF&quot;, &quot;Pollinator&quot; = &quot;#00468BFF&quot; )) + labs( title = &quot;Hypothesized DAG for Pollinator Response to IVM Treatment&quot;, color = &quot;Variable Type&quot; ) + theme_void() 34.4.10 Adjustment Sets An adjustment set is a group of variables you control for (include as covariates) in order to estimate the causal effect of one variable (say, Treatment) on another (say, Pollinator_Richness) without bias. In short, it blocks backdoor paths — those sneaky alternative routes through which spurious associations can travel. To find variables to condition on: # adjustmentSets(ivm_dag, exposure = &quot;Treatment&quot;, outcome = &quot;Pollinator_Richness&quot;) # adjustmentSets(ivm_dag, exposure = &quot;Treatment&quot;, outcome = &quot;Pollinator_Abundance&quot;) Interpretation: To estimate the total causal effect of Treatment on Pollinator_Richness, you only need to adjust for Soil_Substrate. This means: • Soil_Substrate is a backdoor variable — it opens a non-causal path because it influences both Treatment and plant variables that, in turn, influence pollinators. • Controlling for Soil_Substrate blocks that spurious path and gives you an unbiased estimate of the effect of Treatment. Do not control for: • Mediators, like Plant_Richness, Plant_Cover, or Woody_Debris, if you want the total effect of treatment. • Colliders, such as anything caused by both Treatment and another variable (you don’t have a clear collider in this DAG, but good to keep in mind). Example in a model: • model &lt;- lm(Pollinator_Richness ~ Treatment + Soil_Substrate, data = your_data) GREG HERE YOU NEED TO CREATE YOUR FINAL DATASET BY SUMMARIZING THE VEG DATA AND ADDING YOUR POLLINATOR DATA PER PLOT. THEN WE CAN ADJUST THE CODE BELOW TO TEST WHETHER YOU REPLICATION / DATA ARE OK AND THEN MOVE ONTO NEXT STEPS 34.5 Chapter 5: Covariance-Based Estimation in SEM # library(lavaan) # library(mvtnorm) # library(mvnormtest) # library(psych) # library(Matrix) 34.5.1 What is Covariance-Based SEM? Structural Equation Modeling (SEM) using covariance-based maximum likelihood estimation fits parameters so that the model-implied covariance matrix matches the observed covariance matrix as closely as possible. Unlike individual regression models: SEM accounts for how estimation of one parameter affects others. SEM allows for modeling feedbacks and latent variables. SEM is based on maximum likelihood estimation (MLE). 34.5.2 Maximum Likelihood Estimation In SEM, MLE identifies parameters that maximize the likelihood of observing the data, given the model. This involves: Exploring the parameter space iteratively. Estimating model fit using a fitting function like ML. Computationally intensive with more parameters. 34.5.3 Assumptions Behind ML Estimation Multivariate normality (use mvnormtest::mshapiro.test()) # Load necessary package # if (!requireNamespace(&quot;mvnormtest&quot;, quietly = TRUE)) { # install.packages(&quot;mvnormtest&quot;) # } # library(mvnormtest) # # # Simulate multivariate normal data # set.seed(123) # data &lt;- data.frame( # x1 = rnorm(100), # x2 = rnorm(100), # x3 = rnorm(100) # ) # # # Apply Mardia-Shapiro-Wilk test (requires transpose) # mshapiro.test(t(data)) No severe skew or missing data No redundant variables (covariance matrix must be positive definite) # # Check skew and kurtosis # psych::describe(data) # # # Check for missing data # summary(is.na(data)) # Should be all FALSE Sufficient sample size relative to parameters # # Load the lavaan package # if (!requireNamespace(&quot;lavaan&quot;, quietly = TRUE)) { # install.packages(&quot;lavaan&quot;) # } # library(lavaan) # # # Define a simple SEM model # model &lt;- &#39; # y1 ~ x1 + x2 # y2 ~ y1 # &#39; # # # Simulate data # set.seed(123) # data &lt;- data.frame( # x1 = rnorm(100), # x2 = rnorm(100), # y1 = rnorm(100), # y2 = rnorm(100) # ) # # # Fit the model # fit &lt;- sem(model, data = data) # # # Print summary # summary(fit) # # # Count parameters # n_params &lt;- lavInspect(fit, &quot;npar&quot;) # Number of free parameters # n_obs &lt;- nrow(data) # # # Portnoy&#39;s rule # portnoy_value &lt;- n_params^(3/2) / n_obs # portnoy_value 34.5.4 Identifiability Before fitting a SEM, you must ensure it is identified — meaning you have enough unique information to estimate all model parameters. 34.5.4.1 Key Rules T-rule: Number of parameters ≤ unique entries in covariance matrix. # # Number of unique observed covariances # p &lt;- ncol(data) # n_cov &lt;- p * (p + 1) / 2 # # # Compare to number of free parameters # n_cov # lavInspect(fit, &quot;npar&quot;) # Should be ≤ n_cov Order condition: For each endogenous variable, incoming paths ≤ connected variables. There’s no direct test — but: • Draw your DAG. • Count how many arrows go into each endogenous variable. • Make sure that number ≤ number of variables related to it. Rank condition: Variables in feedback loops must be influenced by different causes. • For feedback loops: ensure that each variable has at least one unique exogenous predictor. • Use DAG tools (ggdag or dagitty) to visualize and confirm. If these rules are violated, the model is underidentified and cannot be estimated. 34.5.5 Degrees of Freedom DF = number of observed variances/covariances – number of estimated parameters Just-identified models (DF = 0): Can’t test fit Overidentified models (DF &gt; 0): Preferred — allows model fit evaluation # library(lavaan) # # # define model as a lavaan-style string # model &lt;- &#39; # cover ~ age + elev # firesev ~ age + cover # &#39; # # fit &lt;- sem(model, data = keeley) # fitMeasures(fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;pvalue&quot;, &quot;cfi&quot;, &quot;rmsea&quot;)) 34.5.6 Sample Size Considerations A model’s complexity is limited by your sample size: Rule of thumb: ≥ 5 observations per estimated parameter Preferably: ≥ 20 observations per parameter Use Portnoy’s rule: ρ3/2 / n → 0 Account for: Exogenous variable variances/covariances (often directly estimated from data) Endogenous variable error variances (often derived, not estimated directly) 34.5.7 Summary Covariance-based SEM is powerful but demands careful model design: Check identifiability before estimation Be aware of sample size constraints Use model diagnostics to evaluate fit after estimation 34.5.8 Chapter 6: Structural Equation Modeling in R with lavaan 34.6 Getting Started with lavaan – Model Specification, Estimation, and Interpretation Setting Up Before you begin, make sure the lavaan and lavaanPlot packages are installed: What is lavaan? • lavaan stands for Latent Variable Analysis. • Developed by Yves Rosseel (2010). • Syntax is similar to regression in R using formulas. • It supports latent and observed variables, covariance-based SEM, mediation, path analysis, and more. Example: Post-Fire Plant Recovery We’ll analyze a dataset from Keeley et al. (2006) studying how stand age, fire severity, and other factors affect plant cover. Step 1: Start Simple – A Regression as SEM # Load dataset # Example: keeley &lt;- read.csv(&quot;path/to/your/keeley_data.csv&quot;) # Fit SEM #model1 &lt;- &#39;cover ~ age&#39; #fit1 &lt;- sem(model1, data = keeley) #summary(fit1, standardized = TRUE, rsquare = TRUE) Intercepts and Mean Structures To explicitly estimate intercepts: #fit1_mean &lt;- sem(model1, data = keeley, meanstructure = TRUE) #summary(fit1_mean) Viewing the Model #lavaanPlot(model = fit1, coefs = TRUE, stand = TRUE) Standardized Estimates standardizedSolution(fit1) This gives standardized coefficients and helps compare the relative strength of predictors. Mediation Example: Indirect Effects #model2 &lt;- &#39; # firesev ~ age # cover ~ firesev + age #&#39; #fit2 &lt;- sem(model2, data = keeley) #summary(fit2, standardized = TRUE, rsquare = TRUE) Direct, Indirect, and Total Effects #model3 &lt;- &#39; # firesev ~ af*age # cover ~ fc*firesev + ac*age # Derived # indirect := af * fc # total := ac + (af * fc) #&#39; #fit3 &lt;- sem(model3, data = keeley) #standardizedSolution(fit3) Warnings: Variance Scaling #varTable(fit3) If you get a warning about variances differing by orders of magnitude, consider rescaling your variables or using standardized solutions. Visualizing Complex Models #lavaanPlot( # model = fit3, # coefs = TRUE, # stand = TRUE, # sig = 0.05, # graph_options = list(layout = &quot;circo&quot;) #) Final Exercise Prompt Try fitting the following model: #model_final &lt;- &#39; # rich ~ distance + abiotic + hetero # hetero ~ distance # abiotic ~ distance # abiotic ~~ hetero #&#39; #fit_final &lt;- sem(model_final, data = keeley) #summary(fit_final, standardized = TRUE) 34.6.1 Chapter 7:Assessing Fit and Normality # library(lavaan) # library(mvnormtest) # library(MVN) Overview In this tutorial, we learn how to evaluate model fit and test for normality, key assumptions in covariance-based SEM. We’ll cover: • Standard fit indices (e.g., RMSEA, CFI) • Residuals and modification indices • Normality diagnostics • Remedies for assumption violations Example: Fully Mediated SEM #model_full &lt;- &#39; # firesev ~ age # cover ~ firesev #&#39; #fit_full &lt;- sem(model_full, data = keeley, meanstructure = TRUE) #summary(fit_full, fit.measures = TRUE) Interpretation: • Chi-square (p &gt; 0.05) → Model is not significantly different from the observed data. • Check additional fit indices: RMSEA, CFI, SRMR, AIC, BIC. Fit Indices (Kline 2023 Recommendations) Fit Measure Interpretation Chi-square test Prefer p &gt; 0.05 RMSEA 90% CI lower bound &lt; 0.05 CFI &gt; 0.90 SRMR &lt; 0.10 Diagnosing Misfit with Residuals #residuals(fit_full, type = &quot;cor&quot;) # residual correlations #modificationIndices(fit_full, standardized = FALSE, sort. = TRUE) • Large residuals or modification indices &gt; 3.84 suggest misfit. • Inspect residual correlation between rich and distance. Testing Normality of Residuals # library(MVN) # Step 1: Get residuals from lavaan model #resids &lt;- lavPredict(fit_full, type = &quot;ov&quot;) # residuals for observed variables # Optional: check univariate normality visually #apply(resids[, 1:2], 2, function(x) { # qqnorm(x); qqline(x) #}) # Step 2: Multivariate Shapiro-Wilk (for n ≤ 50) #mshapiro.test(t(resids[, 1:2])) # Step 3: Mardia&#39;s test for multivariate normality #MVN::mvn(data = resids[, 1:2], mvn_test = &quot;mardia&quot;) # Step 1: Get residuals from lavaan model #tryCatch({ # resids &lt;- lavPredict(fit_full, type = &quot;ov&quot;) # Make sure residuals are numeric and have no missing values # if (!is.null(resids) &amp;&amp; is.matrix(resids) &amp;&amp; all(is.finite(resids[, 1:2]))) { # Step 2: Multivariate Shapiro-Wilk (for n ≤ 50) # print(mshapiro.test(t(resids[, 1:2]))) # Step 3: Mardia&#39;s test # print(MVN::mvn(data = resids[, 1:2], mvn_test = &quot;mardia&quot;)) # } else { # message(&quot;Residuals are missing, not numeric, or contain NA/Inf values.&quot;) # } #}, error = function(e) { # message(&quot;MVN test failed: &quot;, conditionMessage(e)) #}) ⸻ If Assumptions Are Violated… Option 1: Satorra-Bentler Correction #fit_sb &lt;- sem(model_full, data = keeley, test = &quot;Satorra.Bentler&quot;) #summary(fit_sb) Option 2: Bollen-Stine Bootstrap #fit_bs &lt;- sem(model_full, data = keeley, test = &quot;bollen.stine&quot;, se = &quot;boot&quot;, bootstrap = 1000) #summary(fit_bs) Summary: • Use fit indices and residuals to assess model performance. • Check assumptions of normality; consider corrections if violated. • Explore modification indices to identify potential improvements. 34.6.2 Chapter 8: Comparing Models and Testing Mediation This section introduces two major approaches for comparing SEM models: • Likelihood Ratio Tests (LRTs) for nested models. • Information Criteria (e.g., AIC, AICc) for both nested and non-nested models. We also explore mediation, which refers to how a relationship between two variables is explained by one or more intervening variables. # Load required libraries # library(lavaan) # library(AICcmodavg) # # # Fully Mediated Model # fullMedModel &lt;- &#39; # firesev ~ age # cover ~ firesev # &#39; # fullMedSEM &lt;- sem(fullMedModel, data = keeley) # # # Partially Mediated Model # partialMedModel &lt;- &#39; # firesev ~ age # cover ~ firesev + age # &#39; # partialMedSEM &lt;- sem(partialMedModel, data = keeley) # # # Likelihood Ratio Test (nested models) # anova(partialMedSEM, fullMedSEM) Interpretation: A non-significant LRT suggests that the simpler (fully mediated) model fits the data about as well as the more complex model. AIC-Based Model Comparison # # install.packages(&quot;AICcmodavg&quot;) # library(AICcmodavg) # # # AICc model comparison # aictab( # cand.set = list(fullMedSEM, partialMedSEM), # modnames = c(&quot;Full&quot;, &quot;Partial&quot;) # ) Interpretation: Models within 2 ΔAICc units are considered roughly equivalent. Higher AIC weight (AICcWt) indicates stronger support for that model. Additional Example: Distance and Species Richness Key Takeaways: • Use LRT for nested models; lower chi-square and higher p-value = simpler model may suffice. • Use AICc for broader comparisons; lower AICc and higher weight = better. • Mediation is central to SEM and can be tested with both approaches. • Fully vs. Partially Mediated models differ by whether direct paths bypass mediators. 34.6.3 Chapter 8: Latent Variables as Drivers What is a Latent Variable? Latent variables are unobserved constructs that we infer from multiple observed indicators. They represent abstract concepts like intelligence, disturbance, or biodiversity. • In SEM, latent variables are drawn as circles. • Observed indicators are squares or rectangles. • Latent variables are typically estimated through Confirmatory Factor Analysis (CFA). Confirmatory Factor Analysis (CFA) CFA allows you to test whether certain observed variables co-vary in ways consistent with an underlying theoretical construct. Example: Aposematism in Poison Frogs # Sample covariance matrix from Santos &amp; Cannatella (2011) # santosCov &lt;- read.table(&quot;https://raw.githubusercontent.com/username/santosCov.txt&quot;, na.strings = #&quot;.&quot;) #santosCov &lt;- as.matrix(santosCov) # # Create covariance matrix manually (example values) # santosCov &lt;- matrix(c( # 1.00, 0.45, 0.38, # 0.45, 1.00, 0.50, # 0.38, 0.50, 1.00 # ), nrow = 3, byrow = TRUE) # # # Add row and column names (must match your CFA model exactly) # colnames(santosCov) &lt;- rownames(santosCov) &lt;- c(&quot;Alkaloid.quantity&quot;, &quot;Alkaloid.diversity&quot;, &quot;Conspicuous.coloration&quot;) # # # Specify CFA model # santosCFA1 &lt;- &#39; # Aposematism =~ Alkaloid.quantity + Alkaloid.diversity + Conspicuous.coloration # &#39; # # # Fit the model # santosFit1 &lt;- sem(santosCFA1, sample.cov = santosCov, sample.nobs = 21) # summary(santosFit1, standardized = TRUE) Why Use Latent Variables? • Increase accuracy by pooling information across multiple imperfect indicators. • Reduce measurement error. • Enable modeling of unobservable constructs. Identification Rules (How to Know Your Model Can Be Estimated): 1. T-Rule: Number of estimated parameters ≤ number of unique elements in the covariance matrix. 2. Three-indicator rule: Each latent variable has ≥ 3 uncorrelated indicators → SUFFICIENT. 3. Two-indicator rule: Works for multiple latent variables if indicators don’t share variance → SUFFICIENT. 4. Fixing scale: • Set variance of latent = 1.0, or • Set one loading to 1.0 to put latent on that indicator’s scale. Models with 2 indicators and shared error may be underidentified. Fit a Second Latent Variable: Body Size #santosSize &lt;- &#39; # Size =~ Log.Mass + Log.RMR + Log.Scope #&#39; #santosSizeFit &lt;- sem(santosSize, sample.cov = santosCov, sample.nobs = 21) #summary(santosSizeFit, standardized = TRUE) Combine Latent Variables You can model multiple latent variables and test how they relate to each other. #santosCFA2 &lt;- &#39; # Aposematism =~ Alkaloid.quantity + Alkaloid.diversity + Conspicuous.coloration + #Ant.Mite.Specialization + log.Prey # Scale =~ Log.Mass + Log.RMR + Log.Scope + Conspicuous.coloration #&#39; #santosFit2 &lt;- sem(santosCFA2, sample.cov = santosCov, sample.nobs = 21) #summary(santosFit2, standardized = TRUE) Summary: • Latent variables allow you to estimate unobservable concepts. • CFA is the method used to define latent variables in SEM. • Identification is critical—use the rules to check if your model can be estimated. • Measurement error is reduced by leveraging multiple indicators. 34.6.4 Chapter 10: Latent Responses and Measurement Error # library(lavaan) # library(semPlot) Overview In this section, we explore how latent variables can be modeled as responses and how to account for measurement error in observed indicators. Latent variables are constructs that cannot be measured directly (e.g., biodiversity, ecosystem health, intelligence), but are inferred from multiple observed indicators. Key Concepts Latent Variables as Responses Latent variables can be endogenous (influenced by other variables in the model). For instance: • A latent construct such as “Habitat Quality” could be influenced by soil moisture, disturbance, and vegetation cover. • Each latent construct is defined by observed indicators, which are imperfect and contain measurement error. Measurement Error SEM is powerful because it separates true score variance from error variance. Each observed variable has two components: • The true score linked to the latent construct. • The error term (random noise or instrument error). Accounting for measurement error prevents biased parameter estimates and inflated correlations. Example: Latent Response Model with Measurement Error We model a latent response Performance, influenced by an observed predictor Treatment, and measured via three indicators: perf1, perf2, perf3. # # Define the SEM # model &lt;- &#39; # # Measurement model # Performance =~ perf1 + perf2 + perf3 # # # Structural model # Performance ~ Treatment # &#39; # # # Simulate data # set.seed(123) # n &lt;- 200 # Treatment &lt;- rnorm(n) # perf1 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # perf2 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # perf3 &lt;- 0.6*Treatment + rnorm(n, sd = 1) # data &lt;- data.frame(Treatment, perf1, perf2, perf3) # # # Fit the SEM # fit &lt;- sem(model, data = data) # summary(fit, standardized = TRUE) Visualizing the SEM #semPaths(fit, &quot;std&quot;, layout = &quot;tree&quot;, whatLabels = &quot;std&quot;) Why Model Latent Responses? • More reliable constructs by combining multiple indicators. • Reduces noise from any single observed variable. • Better reflects theoretical constructs (e.g., stress, biodiversity). Key Assumptions • Indicators are unidimensional (reflect one latent factor). • Measurement errors are uncorrelated. • Sufficient variation and correlation among indicators. Takeaway Modeling latent responses allows you to capture complex, unobserved constructs while accounting for error in measurements. SEM enables estimation of both the relationships among constructs and their measurement structure. "],["piecewise-sems.html", "Chapter 35 Piecewise SEMs 35.1 Overview 35.2 Why Use Piecewise SEM, instead of a covariance SEM? 35.3 SEM Example: Resilience to Drought in Arizona 35.4 Part 1: What is Piecewise SEM? 35.5 Overview 35.6 Example with Powerline Data", " Chapter 35 Piecewise SEMs 35.1 Overview This chapter introduces local (piece wise) SEM — an approach that decomposes a full SEM into a series of local linear models. It contrasts with global covariance-based SEM in both assumptions and evaluation. We will compare and contrast the two approaches, then perform an SEM. 35.2 Why Use Piecewise SEM, instead of a covariance SEM? Structural Equation Modeling (SEM) is a powerful framework for testing hypotheses about complex systems with multiple interrelated variables. In ecology and related fields, researchers often choose between covariance-based SEM (e.g., lavaan) and piecewise SEM (e.g., piecewiseSEM package in R). The choice depends on data structure, sample size, distributional assumptions, and model complexity. 35.2.1 Comparison of SEM Approaches Feature Covariance-Based SEM (lavaan) Piecewise SEM (piecewiseSEM) Data assumptions Assumes multivariate normality Robust to non-normal and non-independent data Model structure All relationships modeled simultaneously Model split into a series of (G)LMs or mixed models Fit assessment Global fit indices: χ², RMSEA, CFI, SRMR Local fit via D-separation and AIC Handling of missing data Can use FIML or imputation Depends on method used in each submodel Sample size requirements High; often N &gt; 200 recommended More flexible with small N Handling of hierarchical data Difficult to include random effects Allows mixed models with random effects Ease of interpreting indirect effects Straightforward via standardized estimates Requires manual calculation of indirect effects Measurement error modeling Supports latent variables Does not support latent variables Modularity and flexibility Limited to standard SEM frameworks Very flexible, especially for ecological or field data 35.2.2 Benefits of Covariance-Based SEM Ideal for testing complex, theory-driven models with latent variables. Provides global fit indices to assess how well the model captures the covariance structure. Useful for confirmatory modeling, especially in psychology, sociology, and tightly controlled experimental settings. 35.2.3 Benefits of Piecewise SEM More robust to violations of normality, independence, and small sample size. Supports hierarchical, nested, or repeated-measures data using mixed models. Offers modular modeling, which makes it easier to fit ecologically realistic models (e.g., with random effects, Poisson/binomial responses). Better suited to observational field data with complex structure. 35.2.4 When to Use Each Approach Use Covariance SEM (lavaan) when: You have a large sample size and want to model latent variables or measurement error. Your data meet assumptions of multivariate normality and independence. You’re interested in global fit metrics and standardized path coefficients. Use Piecewise SEM when: Your data are non-normal, hierarchical, or have small sample sizes. You need to model random effects, non-Gaussian outcomes, or temporal/spatial structure. You’re focusing on causal structure, not measurement error. 35.2.5 Models differ in approach Covariance-based SEM estimates all paths simultaneously by fitting a single model to the entire covariance matrix, providing global fit indices like chi-square (χ²) and RMSEA to assess how well the model reproduces the observed data. In contrast, piecewise SEM fits each path as a separate (G)LM or mixed model, and assesses overall model fit using D-separation tests, which evaluate whether any unmodeled relationships (i.e., conditional independencies) remain between variables—offering a more flexible, modular approach to complex or non-normal ecological data. 35.3 SEM Example: Resilience to Drought in Arizona This dataset combines climate, topographic, and biodiversity indicators to evaluate ecological resilience across sites in Arizona following a period of drought. The central research question is: What environmental and community-level factors predict ecological recovery or resilience in post-drought southwestern ecosystems? Data were compiled from NOAA climate records and field observations, and are structured at the plot level. Key variables include: Climate trends: Change in growing season temperature (gs_temp_slope) and precipitation (ppt_slope) Post-recovery climate: Including growing season mean maximum temperature (gs_tmax_mean), total monsoonal precipitation averaged over 2022-2023 (monsoon_ppt_mean), total winter precipitation averageed over 2022-2023 post-recovery time period (winter_ppt_mean) Drought indicators: Standardized indices including PET (potential evapotranspiration), DDD (drought duration), and DSI (drought severity index), and SWA (Soil Water Availability) Site disturbance history: Time since last fire (TSLF_imputed) Topographic factors: Slope and Aspect Community attributes: Taxonomic diversity (Diversity_q1), connectivity (dist_km) Recovery outcomes: Compositional dissimilarity (bray_curtis) and a remotely sensed recovery index (Recovery_Index) As always, a first step is to remove colinear variables from your dataset. When two or more predictors in your model are highly correlated, they share overlapping information about the response variable. This makes it harder for the model to determine which variable is actually responsible for changes in the response. We removed colinear variables in Chapter 11 - Model selection. After finalizing a dataset, we can build a path diagram and and SEM. We hypothesize that: Recovery (here modeled as bray_curtis) will depend on recent climatic trends (temp_slope, ppt_slope), the strength of the drought (PET, DDD, DSI, SWA), post-drought climatic recovery conditions (gs_tmax_mean, monsoon_ppt_mean, winter_ppt_mean), which could be mediated by the location of the community (Slope, Aspect) and affected by disturbance history (TSLF_imputed). Finally, we expect communities that are more diverse (Diversity_q1) and connected (dist_km) to demonstrate higher levels of recovery. Similarly, overall site diversity (Diversity_q1) will be affected by connectivity (dist_km), as well as recent climatic trends (temp_slope, ppt_slope), the strength of the drought (PET, DDD, DSI, SWA), post-drought climatic recovery conditions (gs_tmax_mean, monsoon_ppt_mean, winter_ppt_mean), which could be mediated by the location of the community (Slope, Aspect) and affected by disturbance history (TSLF_imputed). We expect that the strength of the drought (PET, DDD, DSI, SWA) will depend on its landscape position (Slope, Aspect), as well as recent climate change (temp_slope, ppt_slope). Go over causal chains, mediators, etc. Directed Separation (D-sep) D-sep tests whether missing paths in your model are truly unnecessary. It evaluates conditional independence assumptions implied by the model. Understanding D-separation • Two variables are D-separated if they are conditionally independent, given a set of other variables. • D-sep claims are testable and form the basis set of the model. # Define DAG g &lt;- dagitty(&quot;dag { x -&gt; y2 -&gt; y1 x -&gt; y1 }&quot;) # View conditional independencies implied by the DAG impliedConditionalIndependencies(g) Model Fit via Fisher’s C library(piecewiseSEM) # Simulate example data set.seed(123) n &lt;- 100 x &lt;- rnorm(n) y2 &lt;- 0.5 * x + rnorm(n) y1 &lt;- 0.6 * x + 0.4 * y2 + rnorm(n) example_data &lt;- data.frame(x, y1, y2) # Fit piecewise SEM mod_list &lt;- psem( lm(y2 ~ x, data = example_data), lm(y1 ~ x + y2, data = example_data) ) # ✅ Get model fit statistics (replaces sem.fit) fisherC(mod_list) ## Fisher.C df P.Value ## 1 NA 0 NA # ✅ Get standardized path coefficients (replaces sem.coefs) stdCoefs(mod_list) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate sig ## 1 y2 x 0.4475284 0.10687862 98 4.187258 6.172903e-05 0.3895619 *** ## 2 y1 x 0.4549228 0.11372501 97 4.000200 1.236720e-04 0.3509054 *** ## 3 y1 y2 0.4238113 0.09899469 97 4.281152 4.371472e-05 0.3755510 *** # ✅ Optional: View DAG plot(getDAG(mod_list)) Interpretation: • p &gt; 0.05 → model is not rejected, D-sep claims hold. • p &lt; 0.05 → model is rejected, missing paths may be important. Summary: • Piecewise SEM is ideal when: • Data violate global SEM assumptions. • Sample size is too small for global SEM. • You want to understand model fit using D-sep logic. • Use dagitty to derive implied independencies. • Use sem.fit() and sem.coefs() for piecewise evaluation. 35.3.1 Chapter 12: Introduction to Piecewise SEM in R Learning Objectives By the end of this tutorial, you will be able to: • Understand how piecewise SEM differs from traditional covariance-based SEM. • Fit a multi-equation SEM using the psem() function. • Evaluate model fit using d-separation tests and Fisher’s C statistic. • Extract path coefficients and R² values. • Visualize model structure and relationships using visreg, DiagrammeR, or plot(). 35.4 Part 1: What is Piecewise SEM? Piecewise SEM uses a local estimation approach: each equation is estimated separately using standard regression (e.g., lm, lmer). This provides greater flexibility, such as: • Including non-normal or mixed-effect models. • Dealing with small sample sizes or nested structures. • Assessing model fit through d-sep tests (Shipley’s test of directed separation). Limitations: • Can’t handle latent variables. • Not suitable for cyclical feedback loops. • Difficult to interpret in overidentified models with correlated errors. Part 2: Load Packages and Data # Load libraries library(piecewiseSEM) library(visreg) library(DiagrammeR) data(keeley) # from piecewiseSEM and work through this information Part 3: Specify and Fit Your Model # Fit individual models mod1 &lt;- lm(abiotic ~ distance, data = keeley) mod2 &lt;- lm(hetero ~ distance, data = keeley) mod3 &lt;- lm(rich ~ abiotic + hetero, data = keeley) # Combine into a psem object keeley_sem &lt;- psem(mod1, mod2, mod3) Evaluate Model Fit # Directed separation test #dSep(keeley_sem) # Fisher&#39;s C statistic #fisherC(keeley_sem) Interpret: • A non-significant p-value (&gt; 0.05) = model fits. • Significant missing paths → consider adding them and reassessing fit. Part 5: Summarize Coefficients and R² # Coefficients coefs(keeley_sem) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 abiotic distance 0.3998 0.0823 88 4.8562 0e+00 0.4597 *** ## 2 hetero distance 0.0045 0.0013 88 3.4593 8e-04 0.3460 *** ## 3 rich abiotic 0.8136 0.1746 87 4.6586 0e+00 0.4136 *** ## 4 rich hetero 45.0702 11.6797 87 3.8589 2e-04 0.3426 *** # R-squared values rsquared(keeley_sem) ## Response family link method R.squared ## 1 abiotic gaussian identity none 0.2113455 ## 2 hetero gaussian identity none 0.1197074 ## 3 rich gaussian identity none 0.3667967 Part 6: Plot Your Model Option A: Quick Base R Plot keeley_sem &lt;- psem( lm(firesev ~ age + cover, data = keeley), lm(cover ~ age + elev + firesev, data = keeley), data = keeley ) plot(keeley_sem) #Option B: Refined Graph with DiagrammeR # Optional customization plot(keeley_sem, node_attrs = list( x = c(2.5, 2.5, 4, 1), y = c(3, 1, 2, 2), shape = &quot;rectangle&quot;, fillcolor = &quot;white&quot; )) Part 7: Mediation Example mod_firesev &lt;- lm(firesev ~ age, data = keeley) mod_cover &lt;- lm(cover ~ firesev, data = keeley) firesev_model &lt;- psem(mod_firesev, mod_cover) summary(firesev_model) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of firesev_model ## ## Call: ## firesev ~ age ## cover ~ firesev ## ## AIC ## 364.696 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## cover ~ age + ... coef 87 -1.8018 0.075 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 3.297 with P-value = 0.069 and on 1 degrees of freedom ## Fisher&#39;s C = 5.18 with P-value = 0.075 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## firesev age 0.0597 0.0125 88 4.7781 0 0.4539 *** ## cover firesev -0.0839 0.0184 88 -4.5594 0 -0.4371 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## firesev none 0.21 ## cover none 0.19 dSep(firesev_model) ## | | | 0% | |=======================================================================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 cover ~ age + ... coef 87 -1.80184 0.07503437 rsquared(firesev_model) ## Response family link method R.squared ## 1 firesev gaussian identity none 0.2059938 ## 2 cover gaussian identity none 0.1910867 Bonus: Visualize with Covariates Held Constant # Visualize fire severity&#39;s effect on cover # visreg(firesev_model[[2]], xvar = &quot;firesev&quot;) Wrap-Up Piecewise SEM offers flexibility and clarity for causal inference in ecology. By evaluating each path independently while testing the full model’s coherence through d-sep and Fisher’s C, you gain both transparency and statistical rigor. 35.4.1 Chapter 13: Nonlinearity and Interaction in SEM Overview In this tutorial, we’ll cover: • Nonlinearities (e.g., polynomial terms) • Centering variables to reduce multicollinearity • Interaction terms • Implementing these in SEM frameworks Example 1: Nonlinear Effects (Cardinale et al. 2009) Load and Prepare Data # Download data url &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1oHBul4_JcqlPFZgYsH3WOIZJRQRw1O4F&quot; cardinale &lt;- read.csv(url) # Check it loaded head(cardinale) ## Stream Well N Chl SR SA ## 1 Adobe Creek 1 0e+00 0.0094 105 26 ## 2 Adobe Creek 5 1e-06 0.0100 105 24 ## 3 Adobe Creek 3 1e-04 0.0613 105 20 ## 4 Adobe Creek 4 1e-02 0.1003 105 23 ## 5 Adobe Creek 2 1e+00 0.2000 105 20 ## 6 Adobe Creek 1 0e+00 0.0377 105 21 # Log-transform variables cardinale$logN &lt;- log10(cardinale$N + 1e-6) cardinale$logN2 &lt;- cardinale$logN^2 cardinale$logChl &lt;- log10(cardinale$Chl) #Fit SEM with piecewiseSEM model1 &lt;- psem( lm(SA ~ logN + logN2 + SR, data = cardinale), lm(logChl ~ SA + logN + logN2, data = cardinale), logN %~~% logN2, data = cardinale ) summary(model1) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of model1 ## ## Call: ## SA ~ logN + logN2 + SR ## logChl ~ SA + logN + logN2 ## logN ~~ logN2 ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN -2.9944 1.5375 123 -1.9476 0.0537 -0.5044 ## SA logN2 -0.4742 0.2424 123 -1.9568 0.0526 -0.5067 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN 0.1168 0.0953 123 1.2258 0.2226 0.3858 ## logChl logN2 0.0032 0.015 123 0.2108 0.8334 0.0664 ## ~~logN ~~logN2 -0.9685 - 125 -43.4652 0.0000 -0.9685 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Reducing Collinearity via Centering # Center predictors cardinale$logN.cen &lt;- scale(cardinale$logN, scale = FALSE) cardinale$logN2.cen &lt;- cardinale$logN.cen^2 # Check correlation cor(cardinale$logN.cen, cardinale$logN2.cen) ## [,1] ## [1,] 0.5126311 Refit Model with Centered Predictors model2 &lt;- psem( lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale), lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale), logN.cen %~~% logN2.cen, data = cardinale ) summary(model2) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of model2 ## ## Call: ## SA ~ logN.cen + logN2.cen + SR ## logChl ~ SA + logN.cen + logN2.cen ## logN.cen ~~ logN2.cen ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN.cen 0.3668 0.446 123 0.8223 0.4125 0.0618 ## SA logN2.cen -0.4742 0.2424 123 -1.9568 0.0526 -0.1470 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN.cen 0.0944 0.0275 123 3.4320 0.0008 0.3116 *** ## logChl logN2.cen 0.0032 0.015 123 0.2108 0.8334 0.0193 ## ~~logN.cen ~~logN2.cen 0.5126 - 125 6.6752 0.0000 0.5126 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Try lavaan for the Same Model Example 2: Interaction Effects (Keeley et al.) Center and Create Interaction url2 &lt;- &quot;https://drive.google.com/uc?export=download&amp;id=1YTsFP1T__Hn13hTvj9TVOK-wbGDxLd01&quot; # Try to read the CSV directly keeley &lt;- read.csv(url2) keeley$age_cent &lt;- scale(keeley$age, scale = FALSE) keeley$fire_cent &lt;- scale(keeley$firesev, scale = FALSE) keeley$int_term &lt;- keeley$age_cent * keeley$fire_cent Fit SEM with Interaction in piecewiseSEM keeley_int &lt;- psem( lm(cover ~ age_cent * fire_cent, data = keeley), lm(fire_cent ~ age_cent, data = keeley), data = keeley ) summary(keeley_int) ## ## Structural Equation Model of keeley_int ## ## Call: ## cover ~ age_cent * fire_cent ## fire_cent ~ age_cent ## ## AIC ## 362.993 ## ## --- ## Tests of directed separation: ## ## No independence claims present. Tests of directed separation not possible. ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0 with P-value = 1 and on 0 degrees of freedom ## Fisher&#39;s C = NA with P-value = NA and on 0 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## cover age_cent -0.0050 0.0027 86 -1.8810 0.0634 -0.1985 ## cover fire_cent -0.0684 0.0203 86 -3.3752 0.0011 -0.3561 ** ## cover age_cent:fire_cent -0.0021 0.0014 86 -1.5263 0.1306 -0.1438 ## fire_cent age_cent 0.0597 0.0125 88 4.7781 0.0000 0.4539 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## cover none 0.24 ## fire_cent none 0.21 Optional: Fit Interaction SEM with lavaan Final Notes: • Polynomial terms allow us to model curvature. • Centering reduces collinearity and changes interpretation. • Interaction terms help model conditional effects. • Both lavaan and piecewiseSEM support these techniques. 35.4.2 Chapter 14: GLMs with SEM using PiecewiseSEM This section integrates Generalized Linear Models (GLMs) into Structural Equation Modeling, especially using piecewiseSEM. It also introduces important adjustments for working with non-normal data, and compares latent theoretic (LT) and observed error (OE) approaches for standardizing coefficients. 35.5 Overview In this tutorial, we’ll: • Learn how to incorporate GLMs into SEM using piecewiseSEM • Understand how to deal with non-normality and directed separation warnings • Compute standardized coefficients using both Latent Theoretic (LT) and Observed Error (OE) approaches Data from Anderson et al. 2010 Example # Simulated structure to mimic Anderson et al. set.seed(42) anderson &lt;- data.frame( biomass.kg = rnorm(100, mean = 10, sd = 2), leafN = rnorm(100, mean = 3, sd = 0.5), landscape = sample(0:1, 100, replace = TRUE), hotspotYN = rbinom(100, 1, 0.4) ) Model: Using GLM in psem library(piecewiseSEM) anderson.sem &lt;- psem( lm(leafN ~ biomass.kg, data = anderson), glm(hotspotYN ~ leafN + biomass.kg + landscape, family = &quot;binomial&quot;, data = anderson) ) summary(anderson.sem) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of anderson.sem ## ## Call: ## leafN ~ biomass.kg ## hotspotYN ~ leafN + biomass.kg + landscape ## ## AIC ## 270.381 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## leafN ~ landscape + ... coef 97 1.1151 0.2676 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 1.274 with P-value = 0.259 and on 1 degrees of freedom ## Fisher&#39;s C = 2.637 with P-value = 0.268 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## leafN biomass.kg 0.0068 0.0219 98 0.3098 0.7574 0.0313 ## hotspotYN leafN -0.1212 0.4652 96 -0.2604 0.7945 -0.0301 ## hotspotYN biomass.kg 0.0374 0.1005 96 0.3720 0.7099 0.0428 ## hotspotYN landscape -0.1553 0.4181 96 -0.3715 0.7103 -0.0427 ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## leafN none 0 ## hotspotYN nagelkerke 0 Directed Separation &amp; Non-Normality # Add the &#39;conserve = TRUE&#39; argument to be conservative in tests summary(anderson.sem, conserve = TRUE) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of anderson.sem ## ## Call: ## leafN ~ biomass.kg ## hotspotYN ~ leafN + biomass.kg + landscape ## ## AIC ## 270.381 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## leafN ~ landscape + ... coef 97 1.1151 0.2676 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 1.274 with P-value = 0.259 and on 1 degrees of freedom ## Fisher&#39;s C = 2.637 with P-value = 0.268 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## leafN biomass.kg 0.0068 0.0219 98 0.3098 0.7574 0.0313 ## hotspotYN leafN -0.1212 0.4652 96 -0.2604 0.7945 -0.0301 ## hotspotYN biomass.kg 0.0374 0.1005 96 0.3720 0.7099 0.0428 ## hotspotYN landscape -0.1553 0.4181 96 -0.3715 0.7103 -0.0427 ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## leafN none 0 ## hotspotYN nagelkerke 0 If the model includes non-normal endogenous variables (e.g., binary hotspotYN), the direction of independence tests matters. Use: dSep(anderson.sem, direction = c(&quot;hotspotYN &lt;- leafN&quot;)) ## | | | 0% | |=======================================================================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 leafN ~ landscape + ... coef 97 1.115091 0.2675663 Or specify a correlated error structure: anderson.sem2 &lt;- update(anderson.sem, hotspotYN %~~% leafN) dSep(anderson.sem2) ## | | | 0% | |=======================================================================================================================================| 100% ## Independ.Claim Test.Type DF Crit.Value P.Value ## 1 leafN ~ landscape + ... coef 97 1.115091 0.2675663 Standardizing Coefficients Latent Theoretic (LT) Approach anderson.glm &lt;- anderson.sem[[2]] Betas &lt;- coefs(anderson.sem)[2:4, 3] # GLM coefficients preds &lt;- predict(anderson.glm, type = &quot;link&quot;) sd.y.LT &lt;- sqrt(var(preds) + pi^2/3) sd.x &lt;- sapply(anderson[, c(&quot;leafN&quot;, &quot;biomass.kg&quot;, &quot;landscape&quot;)], sd) Betas.LT &lt;- Betas * sd.x / sd.y.LT Betas.LT ## leafN biomass.kg landscape ## -0.03014129 0.04284880 -0.04271486 Observed Error (OE) Approach preds_response &lt;- predict(anderson.glm, type = &quot;response&quot;) R &lt;- cor(anderson$hotspotYN, preds_response) sd.y.OE &lt;- sqrt(var(preds_response)) / R Betas.OE &lt;- Betas * sd.x / sd.y.OE Betas.OE ## leafN biomass.kg landscape ## -0.1089265 0.1548496 -0.1543656 Compare LT vs OE Approaches # Indirect effect: leafN → hotspotYN (through biomass.kg) Beta.leafN &lt;- coefs(anderson.sem)$Std.Estimate[1] indirect_LT &lt;- Beta.leafN * Betas.LT[1] indirect_OE &lt;- Beta.leafN * Betas.OE[1] c(LT = indirect_LT, OE = indirect_OE) ## LT.leafN OE.leafN ## -0.0009434225 -0.0034093982 Summary: • Use glm() in psem() for binary or count outcomes. • Add conserve = TRUE for directed separation when variables are non-normal. • Use both LT and OE standardization to interpret effect sizes. 35.5.1 Chapter 15: Categorical Predictors &amp; Multigroup SEM # library(lme4) # library(piecewiseSEM) # library(emmeans) # library(lavaan) Overview In this tutorial, we explore: • Using categorical predictors in SEM. • Accounting for random effects (e.g., genotype). • Conducting multigroup SEM across different contexts or study sites. Categorical Predictors and Random Effects Example: Bowen et al. (2017) tested whether Phragmites genotype affects soil microbes and productivity. library(multcompView) # Simulated structure: Genotype nested within Phragmites status (e.g., native, invasive) set.seed(1) n &lt;- 90 bowen &lt;- data.frame( status = factor(rep(c(&quot;native&quot;, &quot;invasive&quot;, &quot;introduced&quot;), each = 30)), Genotype = rep(paste0(&quot;G&quot;, 1:9), each = 10), observed_otus = rnorm(n, mean = 2500, sd = 100), RNA.DNA = rnorm(n, 0.7, 0.05), below.C = rnorm(n, 43, 1), abovebiomass_g = rnorm(n, 2, 0.5) ) # Mixed models for each component div_mod &lt;- lmer(observed_otus ~ status + (1 | Genotype), data = bowen) activity_mod &lt;- lmer(RNA.DNA ~ status + observed_otus + (1 | Genotype), data = bowen) carbon_mod &lt;- lmer(below.C ~ observed_otus + status + (1 | Genotype), data = bowen) biomass_mod &lt;- lmer(abovebiomass_g ~ RNA.DNA + observed_otus + below.C + status + (1 | Genotype), data = bowen) # Build piecewise SEM bowen_mod &lt;- psem(div_mod, activity_mod, carbon_mod, biomass_mod, data = bowen) summary(bowen_mod) ## | | | 0% ## | |=======================================================================================================================================| 100% ## ## Structural Equation Model of bowen_mod ## ## Call: ## observed_otus ~ status ## RNA.DNA ~ status + observed_otus ## below.C ~ observed_otus + status ## abovebiomass_g ~ RNA.DNA + observed_otus + below.C + status ## ## AIC ## 1251.338 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## below.C ~ RNA.DNA + ... coef 85 -0.1384 0.8902 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 3.513 with P-value = 0.061 and on 1 degrees of freedom ## Fisher&#39;s C = 0.233 with P-value = 0.89 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## observed_otus status - - 2.0000 0.0237 0.9766 - ## observed_otus status = native 2508.2458 16.3598 6.0000 153.3172 0.0000 - *** ## observed_otus status = introduced 2511.0278 16.3598 6.0000 153.4872 0.0000 - *** ## observed_otus status = invasive 2513.2775 16.3598 6.0000 153.6247 0.0000 - *** ## RNA.DNA observed_otus 0 1e-04 84.2102 -0.3354 0.7381 - ## RNA.DNA status - - 2.0000 2.0441 0.2111 - ## RNA.DNA status = invasive 0.6835 0.0104 5.9386 65.7032 0.0000 - *** ## RNA.DNA status = native 0.7056 0.0104 5.9389 67.8238 0.0000 - *** ## RNA.DNA status = introduced 0.7119 0.0104 5.9365 68.4304 0.0000 - *** ## below.C observed_otus -4e-04 0.0012 86.0000 -0.3219 0.7483 - ## below.C status - - 2.0000 0.7820 0.4997 - ## below.C status = invasive 42.763 0.1857 5.9128 230.2879 0.0000 - *** ## below.C status = introduced 43.0245 0.1857 5.9100 231.7263 0.0000 - *** ## below.C status = native 43.0658 0.1857 5.9132 231.9142 0.0000 - *** ## abovebiomass_g RNA.DNA 0.1948 1.1068 84.0000 0.1760 0.8607 - ## abovebiomass_g observed_otus 2e-04 6e-04 84.0000 0.4172 0.6776 - ## abovebiomass_g below.C -0.1292 0.0523 84.0000 -2.4692 0.0156 - * ## abovebiomass_g status - - 2.0000 0.2393 0.7943 - ## abovebiomass_g status = introduced 2.0074 0.0911 5.8667 22.0333 0.0000 - *** ## abovebiomass_g status = native 2.0829 0.0905 5.7339 23.0193 0.0000 - *** ## abovebiomass_g status = invasive 2.0871 0.0927 6.2237 22.5236 0.0000 - *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method Marginal Conditional ## observed_otus none 0.00 0.00 ## RNA.DNA none 0.06 0.10 ## below.C none 0.02 0.02 ## abovebiomass_g none 0.07 0.07 Visualizing Categorical Effects Estimated Marginal Means by status: lapply(bowen_mod[-length(bowen_mod)], emmeans, specs = ~status) ## [[1]] ## status emmean SE df lower.CL upper.CL ## introduced 2511 16.4 6 2471 2551 ## invasive 2513 16.4 6 2473 2553 ## native 2508 16.4 6 2468 2548 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[2]] ## status emmean SE df lower.CL upper.CL ## introduced 0.712 0.0104 5.94 0.686 0.737 ## invasive 0.684 0.0104 5.94 0.658 0.709 ## native 0.706 0.0104 5.94 0.680 0.731 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[3]] ## status emmean SE df lower.CL upper.CL ## introduced 43.0 0.186 5.91 42.6 43.5 ## invasive 42.8 0.186 5.91 42.3 43.2 ## native 43.1 0.186 5.91 42.6 43.5 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## [[4]] ## status emmean SE df lower.CL upper.CL ## introduced 2.01 0.0911 5.87 1.78 2.23 ## invasive 2.09 0.0927 6.22 1.86 2.31 ## native 2.08 0.0905 5.73 1.86 2.31 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 # Post-hoc Tests (Tukey) generic_tukey &lt;- function(x) emmeans(x, list(pairwise ~ status)) lapply(bowen_mod[-length(bowen_mod)], generic_tukey) ## [[1]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 2511 16.4 6 2471 2551 ## invasive 2513 16.4 6 2473 2553 ## native 2508 16.4 6 2468 2548 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive -2.25 23.1 6 -0.097 0.9948 ## introduced - native 2.78 23.1 6 0.120 0.9921 ## invasive - native 5.03 23.1 6 0.217 0.9744 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[2]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 0.712 0.0104 5.94 0.686 0.737 ## invasive 0.684 0.0104 5.94 0.658 0.709 ## native 0.706 0.0104 5.94 0.680 0.731 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive 0.02831 0.0147 5.94 1.924 0.2130 ## introduced - native 0.00624 0.0147 5.94 0.424 0.9072 ## invasive - native -0.02207 0.0147 5.94 -1.500 0.3560 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[3]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 43.0 0.186 5.91 42.6 43.5 ## invasive 42.8 0.186 5.91 42.3 43.2 ## native 43.1 0.186 5.91 42.6 43.5 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive 0.2615 0.263 5.91 0.996 0.6061 ## introduced - native -0.0413 0.263 5.91 -0.157 0.9865 ## invasive - native -0.3029 0.263 5.92 -1.153 0.5204 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates ## ## ## [[4]] ## $`emmeans of status` ## status emmean SE df lower.CL upper.CL ## introduced 2.01 0.0911 5.87 1.78 2.23 ## invasive 2.09 0.0927 6.22 1.86 2.31 ## native 2.08 0.0905 5.73 1.86 2.31 ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## ## $`pairwise differences of status` ## 1 estimate SE df t.ratio p.value ## introduced - invasive -0.07972 0.132 6.41 -0.603 0.8234 ## introduced - native -0.07557 0.128 5.67 -0.592 0.8295 ## invasive - native 0.00415 0.131 6.21 0.032 0.9994 ## ## Degrees-of-freedom method: kenward-roger ## P value adjustment: tukey method for comparing a family of 3 estimates Multigroup SEM in lavaan Fit the same SEM model to different groups and test whether path coefficients differ. # Create simulated dataset group_df &lt;- data.frame( site = rep(c(&quot;A&quot;, &quot;B&quot;), each = 50), x = rnorm(100), m = rnorm(100), y = rnorm(100) ) # Define a simple SEM model sem_model &lt;- &#39; m ~ a*x y ~ b*m + c*x &#39; # Fit multi-group SEM fit_multi &lt;- lavaan::sem(sem_model, data = group_df, group = &quot;site&quot;) # View summary summary(fit_multi, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6-19 ended normally after 12 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## Number of equality constraints 3 ## ## Number of observations per group: ## A 50 ## B 50 ## ## Model Test User Model: ## ## Test statistic 0.790 ## Degrees of freedom 3 ## P-value (Chi-square) 0.852 ## Test statistic for each group: ## A 0.498 ## B 0.292 ## ## Model Test Baseline Model: ## ## Test statistic 2.093 ## Degrees of freedom 6 ## P-value 0.911 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) -0.131 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -293.784 ## Loglikelihood unrestricted model (H1) -293.389 ## ## Akaike (AIC) 609.568 ## Bayesian (BIC) 638.225 ## Sample-size adjusted Bayesian (SABIC) 603.484 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.130 ## P-value H_0: RMSEA &lt;= 0.050 0.874 ## P-value H_0: RMSEA &gt;= 0.080 0.098 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.029 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [A]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) -0.011 0.099 -0.116 0.908 -0.011 -0.009 ## y ~ ## m (b) -0.105 0.095 -1.106 0.269 -0.105 -0.128 ## x (c) 0.031 0.101 0.310 0.757 0.031 0.031 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.144 0.170 0.844 0.398 0.144 0.119 ## .y 0.076 0.139 0.544 0.586 0.076 0.077 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 1.445 0.289 5.000 0.000 1.445 1.000 ## .y 0.960 0.192 5.000 0.000 0.960 0.983 ## ## ## Group 2 [B]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) -0.011 0.099 -0.116 0.908 -0.011 -0.014 ## y ~ ## m (b) -0.105 0.095 -1.106 0.269 -0.105 -0.088 ## x (c) 0.031 0.101 0.310 0.757 0.031 0.031 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m -0.116 0.134 -0.860 0.390 -0.116 -0.124 ## .y -0.240 0.160 -1.506 0.132 -0.240 -0.215 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.872 0.174 5.000 0.000 0.872 1.000 ## .y 1.234 0.247 5.000 0.000 1.234 0.991 Constraining Parameters Across Groups You can test whether coefficients differ across groups: A significant p-value means the unconstrained model fits better — i.e., group differences do matter. Summary: • Use lme4 and piecewiseSEM for models with random effects. • lavaan enables multigroup comparisons to test generality across systems. • Post-hoc tools like emmeans help interpret categorical predictors. 35.5.2 Chapter 16: Multigroup SEM in R library(lavaan) What is Multigroup SEM? Multigroup SEM allows you to: • Test whether path coefficients differ between groups. • Assess whether a model holds equally well across groups. • Investigate measurement invariance (i.e., whether constructs are perceived similarly). Example Model Setup We’ll build a simple mediation model where group is a binary factor (“A” vs “B”). # Simulate data set.seed(123) n &lt;- 100 group &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = n) x &lt;- rnorm(2 * n) m &lt;- 0.5 * x + rnorm(2 * n) y &lt;- 0.6 * m + 0.3 * x + rnorm(2 * n) data &lt;- data.frame(group, x, m, y) Define the SEM model &lt;- &#39; m ~ a*x y ~ b*m + c*x &#39; Fit Multigroup SEM fit_multi &lt;- sem(model, data = data, group = &quot;group&quot;) summary(fit_multi, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6-19 ended normally after 13 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## Number of equality constraints 3 ## ## Number of observations per group: ## A 100 ## B 100 ## ## Model Test User Model: ## ## Test statistic 6.839 ## Degrees of freedom 3 ## P-value (Chi-square) 0.077 ## Test statistic for each group: ## A 3.618 ## B 3.220 ## ## Model Test Baseline Model: ## ## Test statistic 131.688 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.969 ## Tucker-Lewis Index (TLI) 0.939 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -556.173 ## Loglikelihood unrestricted model (H1) -552.754 ## ## Akaike (AIC) 1134.347 ## Bayesian (BIC) 1170.628 ## Sample-size adjusted Bayesian (SABIC) 1135.779 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.113 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.228 ## P-value H_0: RMSEA &lt;= 0.050 0.139 ## P-value H_0: RMSEA &gt;= 0.080 0.755 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.083 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [A]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) 0.453 0.075 6.064 0.000 0.453 0.401 ## y ~ ## m (b) 0.542 0.068 7.947 0.000 0.542 0.460 ## x (c) 0.295 0.078 3.756 0.000 0.295 0.222 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.125 0.094 1.323 0.186 0.125 0.122 ## .y 0.116 0.098 1.178 0.239 0.116 0.096 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 0.885 0.125 7.071 0.000 0.885 0.840 ## .y 0.958 0.135 7.071 0.000 0.958 0.657 ## ## ## Group 2 [B]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## m ~ ## x (a) 0.453 0.075 6.064 0.000 0.453 0.387 ## y ~ ## m (b) 0.542 0.068 7.947 0.000 0.542 0.504 ## x (c) 0.295 0.078 3.756 0.000 0.295 0.235 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m -0.041 0.104 -0.397 0.691 -0.041 -0.037 ## .y -0.048 0.094 -0.513 0.608 -0.048 -0.040 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .m 1.074 0.152 7.071 0.000 1.074 0.850 ## .y 0.874 0.124 7.071 0.000 0.874 0.599 Test for Invariance To test for invariance, you can constrain parameters to be equal across groups. # Constrain &#39;a&#39; and &#39;b&#39; to be equal across groups model_constrained &lt;- &#39; m ~ c(a, a)*x y ~ c(b, b)*m + c*x &#39; fit_constrained &lt;- sem(model_constrained, data = data, group = &quot;group&quot;) anova(fit_multi, fit_constrained) # Chi-square test for invariance ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit_multi 3 1134.3 1170.6 6.8386 ## fit_constrained 3 1134.3 1170.6 6.8386 0 0 0 Interpretation: • If the constrained model does not significantly worsen fit, the paths a and b are likely invariant. • If the fit gets significantly worse, the relationship differs between groups and should be modeled separately. Visualizing Standardized Results # library(semPlot) # semPaths(fit_multi, &quot;std&quot;, layout = &quot;tree&quot;, whatLabels = &quot;std&quot;, edge.label.cex = 1.2) Summary Multigroup SEM lets you: • Evaluate moderation by group. • Test for measurement invariance. • Gain deeper insight into context-dependent pathways. 35.5.3 Chapter 17: Mixed models in piecewise SEM, covering: • Fixed vs. random effects • Adding group-level predictors • Understanding R² and model comparison • Dealing with hierarchical structure and sample size Introduction This tutorial introduces how to incorporate mixed effects into Structural Equation Modeling using the piecewiseSEM package. Mixed models are essential when your data are hierarchically structured (e.g., plots within sites, streams within watersheds). Step 1: Load Data and Create Variables # Log-transform predictors cardinale$logN &lt;- log10(cardinale$N + 1e-6) cardinale$logN2 &lt;- cardinale$logN^2 cardinale$logChl &lt;- log10(cardinale$Chl) # Centering predictors to reduce multicollinearity cardinale$logN.cen &lt;- scale(cardinale$logN, scale = FALSE) cardinale$logN2.cen &lt;- scale(cardinale$logN^2, scale = FALSE) Step 2: Fit Fixed Effects SEM cardinale.sem &lt;- psem( lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale), lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale), logN.cen %~~% logN2.cen, data = cardinale ) summary(cardinale.sem) ## | | | 0% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of cardinale.sem ## ## Call: ## SA ~ logN.cen + logN2.cen + SR ## logChl ~ SA + logN.cen + logN2.cen ## logN.cen ~~ logN2.cen ## ## AIC ## 1192.444 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## logChl ~ SR + ... coef 122 0.6639 0.508 ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 0.458 with P-value = 0.499 and on 1 degrees of freedom ## Fisher&#39;s C = 1.355 with P-value = 0.508 and on 2 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## SA logN.cen -2.9944 1.5375 123 -1.9476 0.0537 -0.5044 ## SA logN2.cen -0.4742 0.2424 123 -1.9568 0.0526 -0.5067 ## SA SR 0.3838 0.0359 123 10.6844 0.0000 0.6893 *** ## logChl SA 0.0201 0.004 123 5.0327 0.0000 0.3946 *** ## logChl logN.cen 0.1168 0.0953 123 1.2258 0.2226 0.3858 ## logChl logN2.cen 0.0032 0.015 123 0.2108 0.8334 0.0664 ## ~~logN.cen ~~logN2.cen -0.9685 - 125 -43.4652 0.0000 -0.9685 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## SA none 0.49 ## logChl none 0.25 Step 3: Add Random Effects with lme() #cardinale.mixed &lt;- psem( # lme(SA ~ logN.cen + logN2.cen + SR, random = ~1 | Stream, data = cardinale), # lme(logChl ~ SA + logN.cen + logN2.cen, random = ~1 | Stream, data = cardinale), # logN.cen %~~% logN2.cen, # data = cardinale #) #summary(cardinale.mixed) Step 4: Compare Models # Compare R-squared #rsquared(cardinale.sem) #rsquared(cardinale.mixed) • Marginal R²: Variance explained by fixed effects. • Conditional R²: Variance explained by both fixed and random effects. Step 5: Optional — Add Group-Level Predictors To address possible Simpson’s paradox or correlated random effects: # Example if &quot;site_mean&quot; were available # cardinale$stream_mean_logN &lt;- ave(cardinale$logN, cardinale$Stream) # cardinale$deviation_logN &lt;- cardinale$logN - cardinale$stream_mean_logN This lets you include: • stream_mean_logN (group-level predictor) • deviation_logN (individual-level deviation) Step 6: Basis Set and Fisher’s C #fisherC(cardinale.mixed) Summary: • Mixed models let you account for non-independence among groups. • Use piecewiseSEM with lme() to include random effects. • Be cautious of group-level confounding — use centering and group-level predictors. • Use rsquared() and fisherC() for model comparison and goodness-of-fit. 35.6 Example with Powerline Data library(readr) # Read CSV directly into R powerline_plants &lt;- read.csv(&quot;https://drive.google.com/uc?export=download&amp;id=1MVlaEshEn7M2g8rOiJ8fWPPozn3WgNck&quot;) We are starting with our original DAG (below): library(dagitty) library(ggdag) library(tidyverse) # Define the DAG ivm_dag &lt;- dagitty(&quot; dag { Treatment Soil_Substrate Cattle Plant_Richness Plant_Cover Plant_Height Ceanothus Woody_Debris Pollinator_Richness Pollinator_Abundance Treatment -&gt; Plant_Richness Treatment -&gt; Plant_Cover Treatment -&gt; Plant_Height Treatment -&gt; Ceanothus Treatment -&gt; Woody_Debris Soil_Substrate -&gt; Treatment Soil_Substrate -&gt; Plant_Richness Soil_Substrate -&gt; Plant_Cover Soil_Substrate -&gt; Woody_Debris Cattle -&gt; Plant_Richness Cattle -&gt; Plant_Cover Cattle -&gt; Pollinator_Abundance Cattle -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Richness Plant_Richness -&gt; Pollinator_Abundance Plant_Cover -&gt; Pollinator_Richness Plant_Cover -&gt; Pollinator_Abundance Plant_Height -&gt; Pollinator_Richness Plant_Height -&gt; Pollinator_Abundance Ceanothus -&gt; Pollinator_Richness Ceanothus -&gt; Pollinator_Abundance Woody_Debris -&gt; Pollinator_Richness Woody_Debris -&gt; Pollinator_Abundance } &quot;) node_roles &lt;- tibble( name = c( &quot;Treatment&quot;, &quot;Soil_Substrate&quot;, &quot;Cattle&quot;, &quot;Plant_Richness&quot;, &quot;Plant_Cover&quot;, &quot;Plant_Height&quot;, &quot;Ceanothus&quot;, &quot;Woody_Debris&quot;, &quot;Pollinator_Richness&quot;, &quot;Pollinator_Abundance&quot; ), role = c( &quot;Treatment&quot;, &quot;Context&quot;, &quot;Context&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Plant&quot;, &quot;Pollinator&quot;, &quot;Pollinator&quot; ) ) # Get layout and merge roles dag_df &lt;- tidy_dagitty(ivm_dag, layout = &quot;nicely&quot;) %&gt;% left_join(node_roles, by = &quot;name&quot;) # Plot using ggplot2 with corrected edge structure ggplot() + geom_segment( data = dag_df %&gt;% filter(!is.na(xend)), aes(x = x, y = y, xend = xend, yend = yend), arrow = arrow(length = unit(0.02, &quot;npc&quot;)), color = &quot;grey40&quot; ) + geom_point( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, color = role), size = 8, alpha = 0.85 ) + geom_text( data = dag_df %&gt;% filter(!is.na(x)), aes(x = x, y = y, label = name), color = &quot;black&quot;, size = 4 ) + scale_color_manual(values = c( &quot;Treatment&quot; = &quot;#FB7E21FF&quot;, &quot;Context&quot; = &quot;#A91601FF&quot;, &quot;Plant&quot; = &quot;#18DDC2FF&quot;, &quot;Pollinator&quot; = &quot;#00468BFF&quot; )) + labs( title = &quot;Hypothesized DAG for Pollinator Response to IVM Treatment&quot;, color = &quot;Variable Type&quot; ) + theme_void() Then, we need to create linear models, treating each “node” as its own regression model. First, we have to summarize our data in a way that can be input into the linear models. library(piecewiseSEM) # List all variables used across all models sem_vars &lt;- c( &quot;Species_Richness&quot;, &quot;Treatment&quot;, &quot;Q_Substrate_BareSoil&quot;, &quot;Plot_DungCount&quot;, &quot;Q_Substrate_PerennialVeg&quot;, &quot;Height_cm&quot;, &quot;Q_Substrate_WoodyDebris&quot; ) # Remove all rows with NA in any of the SEM variables sem_data &lt;- powerline_plants %&gt;% dplyr::select(all_of(sem_vars)) %&gt;% na.omit() # Ensure Treatment is a factor sem_data$Treatment &lt;- as.factor(sem_data$Treatment) # Check structure to confirm str(sem_data) ## &#39;data.frame&#39;: 811 obs. of 7 variables: ## $ Species_Richness : int 10 10 11 10 12 11 7 7 12 2 ... ## $ Treatment : Factor w/ 4 levels &quot;Control&quot;,&quot;Herbicide&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## $ Q_Substrate_BareSoil : num 0 5 7 0 0 10 2 0 2 0 ... ## $ Plot_DungCount : int 5 5 5 5 5 0 0 0 0 0 ... ## $ Q_Substrate_PerennialVeg: num 70 10 8 5 10 40 25 50 40 30 ... ## $ Height_cm : num 28 19.1 38.6 37.2 22 ... ## $ Q_Substrate_WoodyDebris : num 0 30 5 70 2 4 5 1 10 0 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:57] 186 187 188 189 190 191 192 193 195 200 ... ## ..- attr(*, &quot;names&quot;)= chr [1:57] &quot;186&quot; &quot;187&quot; &quot;188&quot; &quot;189&quot; ... sem_data$Treatment &lt;- droplevels(as.factor(sem_data$Treatment)) # Fit models using this cleaned dataset mod1 &lt;- lm(Species_Richness ~ Treatment + Q_Substrate_BareSoil + Plot_DungCount, data = sem_data) mod2 &lt;- lm(Q_Substrate_PerennialVeg ~ Species_Richness + Treatment + Q_Substrate_BareSoil + Plot_DungCount, data = sem_data) mod3 &lt;- lm(Height_cm ~ Q_Substrate_PerennialVeg + Treatment, data = sem_data) mod4 &lt;- lm(Q_Substrate_WoodyDebris ~ Height_cm + Treatment + Q_Substrate_BareSoil, data = sem_data) # You can now also safely fit mod6 and mod7 using the same sem_data: # mod6 &lt;- lm(Pollinator_Richness ~ Species_Richness + Q_Substrate_PerennialVeg + Height_cm + Ceanothus + Q_Substrate_WoodyDebris + Plot_DungCount, data = sem_data) # mod7 &lt;- lm(Pollinator_Abundance ~ Species_Richness + Q_Substrate_PerennialVeg + Height_cm + Ceanothus + Q_Substrate_WoodyDebris + Plot_DungCount, data = sem_data) # Assemble SEM mods &lt;- list(mod1, mod2, mod3, mod4) lapply(mods, function(m) summary(m)$coefficients) ## [[1]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.45334250 0.289907535 25.709378 6.893932e-107 ## TreatmentHerbicide 0.48512839 0.352320044 1.376954 1.689094e-01 ## TreatmentMech_Herb 0.62503883 0.349579557 1.787973 7.415638e-02 ## TreatmentMechanical 0.55821899 0.349940535 1.595182 1.110639e-01 ## Q_Substrate_BareSoil -0.01678677 0.008023078 -2.092310 3.672344e-02 ## Plot_DungCount 0.12104150 0.013556336 8.928777 2.878250e-18 ## ## [[2]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 35.4547726 2.19617613 16.1438657 5.408706e-51 ## Species_Richness -0.5979172 0.19785399 -3.0220122 2.590654e-03 ## TreatmentHerbicide -5.8459701 1.98011740 -2.9523351 3.245600e-03 ## TreatmentMech_Herb -3.3269277 1.96629833 -1.6919750 9.103821e-02 ## TreatmentMechanical -1.7501657 1.96753433 -0.8895223 3.739885e-01 ## Q_Substrate_BareSoil -0.2827075 0.04516078 -6.2600221 6.258592e-10 ## Plot_DungCount -0.5791996 0.07977940 -7.2600139 9.140497e-13 ## ## [[3]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 18.3949479 3.69826014 4.973946 8.020316e-07 ## Q_Substrate_PerennialVeg 0.4754358 0.07599831 6.255872 6.411886e-10 ## TreatmentHerbicide 0.6336287 4.59697384 0.137836 8.904044e-01 ## TreatmentMech_Herb -8.5325534 4.52497644 -1.885657 5.970059e-02 ## TreatmentMechanical -8.2148870 4.48866890 -1.830139 6.759835e-02 ## ## [[4]] ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 17.123628791 1.32713403 12.9027124 9.334527e-35 ## Height_cm -0.003170525 0.01291842 -0.2454267 8.061886e-01 ## TreatmentHerbicide -2.448347212 1.71763567 -1.4254171 1.544243e-01 ## TreatmentMech_Herb -9.527420893 1.70339367 -5.5931996 3.054932e-08 ## TreatmentMechanical -4.985879621 1.68835021 -2.9531075 3.237464e-03 ## Q_Substrate_BareSoil -0.134960227 0.03912324 -3.4496179 5.905788e-04 # Rebuild the SEM with standardized estimates sem_model &lt;- psem(mod1, mod2, mod3, mod4) # Summary with standardization explicitly requested summary(sem_model, standardize = &quot;scale&quot;) ## | | | 0% | |====================== | 17% | |============================================= | 33% | |==================================================================== | 50% | |========================================================================================== | 67% | |================================================================================================================ | 83% | |=======================================================================================================================================| 100% ## ## Structural Equation Model of sem_model ## ## Call: ## Species_Richness ~ Treatment + Q_Substrate_BareSoil + Plot_DungCount ## Q_Substrate_PerennialVeg ~ Species_Richness + Treatment + Q_Substrate_BareSoil + Plot_DungCount ## Height_cm ~ Q_Substrate_PerennialVeg + Treatment ## Q_Substrate_WoodyDebris ~ Height_cm + Treatment + Q_Substrate_BareSoil ## ## AIC ## 26815.430 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Test.Type DF Crit.Value P.Value ## Height_cm ~ Q_Substrate_BareSoil + ... coef 805 -0.0972 0.9226 ## Height_cm ~ Plot_DungCount + ... coef 805 -1.8759 0.0610 ## Q_Substrate_WoodyDebris ~ Plot_DungCount + ... coef 804 5.5138 0.0000 *** ## Height_cm ~ Species_Richness + ... coef 803 -2.6518 0.0082 ** ## Q_Substrate_WoodyDebris ~ Species_Richness + ... coef 803 -1.2738 0.2031 ## Q_Substrate_WoodyDebris ~ Q_Substrate_PerennialVeg + ... coef 802 -9.6809 0.0000 *** ## ## -- ## Global goodness-of-fit: ## ## Chi-Squared = 131.991 with P-value = 0 and on 6 degrees of freedom ## Fisher&#39;s C = 145.828 with P-value = 0 and on 12 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## Species_Richness Q_Substrate_BareSoil -0.0168 0.008 805 -2.0923 0.0367 - * ## Species_Richness Plot_DungCount 0.121 0.0136 805 8.9288 0.0000 - *** ## Species_Richness Treatment - - 3 1.2817 0.2795 - ## Species_Richness Treatment = Control 8.2476 0.2538 805 32.4946 0.0000 - *** ## Species_Richness Treatment = Herbicide 8.7327 0.2455 805 35.5697 0.0000 - *** ## Species_Richness Treatment = Mechanical 8.8058 0.2377 805 37.0411 0.0000 - *** ## Species_Richness Treatment = Mech_Herb 8.8726 0.2394 805 37.0675 0.0000 - *** ## Q_Substrate_PerennialVeg Species_Richness -0.5979 0.1979 804 -3.0220 0.0026 - ** ## Q_Substrate_PerennialVeg Q_Substrate_BareSoil -0.2827 0.0452 804 -6.2600 0.0000 - *** ## Q_Substrate_PerennialVeg Plot_DungCount -0.5792 0.0798 804 -7.2600 0.0000 - *** ## Q_Substrate_PerennialVeg Treatment - - 3 3.1825 0.0234 - * ## Q_Substrate_PerennialVeg Treatment = Herbicide 17.0791 1.3782 804 12.3919 0.0000 - *** ## Q_Substrate_PerennialVeg Treatment = Mech_Herb 19.5981 1.3443 804 14.5791 0.0000 - *** ## Q_Substrate_PerennialVeg Treatment = Mechanical 21.1749 1.3348 804 15.8639 0.0000 - *** ## Q_Substrate_PerennialVeg Treatment = Control 22.925 1.4273 804 16.0614 0.0000 - *** ## Height_cm Q_Substrate_PerennialVeg 0.4754 0.076 806 6.2559 0.0000 - *** ## Height_cm Treatment - - 3 2.5277 0.0562 - ## Height_cm Treatment = Mech_Herb 19.4516 3.1101 806 6.2543 0.0000 - *** ## Height_cm Treatment = Mechanical 19.7692 3.0711 806 6.4371 0.0000 - *** ## Height_cm Treatment = Control 27.9841 3.2834 806 8.5229 0.0000 - *** ## Height_cm Treatment = Herbicide 28.6178 3.2007 806 8.9411 0.0000 - *** ## Q_Substrate_WoodyDebris Height_cm -0.0032 0.0129 805 -0.2454 0.8062 - ## Q_Substrate_WoodyDebris Q_Substrate_BareSoil -0.135 0.0391 805 -3.4496 0.0006 - *** ## Q_Substrate_WoodyDebris Treatment - - 3 11.5674 0.0000 - *** ## Q_Substrate_WoodyDebris Treatment = Mech_Herb 6.2042 1.1687 805 5.3088 0.0000 - *** ## Q_Substrate_WoodyDebris Treatment = Mechanical 10.7458 1.1506 805 9.3395 0.0000 - *** ## Q_Substrate_WoodyDebris Treatment = Herbicide 13.2833 1.1961 805 11.1051 0.0000 - *** ## Q_Substrate_WoodyDebris Treatment = Control 15.7316 1.2336 805 12.7526 0.0000 - *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## --- ## Individual R-squared: ## ## Response method R.squared ## Species_Richness none 0.09 ## Q_Substrate_PerennialVeg none 0.15 ## Height_cm none 0.05 ## Q_Substrate_WoodyDebris none 0.06 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
