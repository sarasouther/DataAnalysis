# Apply Mardia-Shapiro-Wilk test (requires transpose)
mshapiro.test(t(data))
# Check skew and kurtosis
psych::describe(data)
# Check for missing data
summary(is.na(data))  # Should be all FALSE
# Count parameters in a simple lavaan model
model <- '
y1 ~ x1 + x2
y2 ~ y1
'
# Simulate data
data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), y1 = rnorm(100), y2 = rnorm(100))
# Estimate number of parameters
fit <- sem(model, data = data)
summary(fit)
# Count parameters
n_params <- lavInspect(fit, "npar")
n_obs <- nrow(data)
# Portnoy’s Rule
portnoy_value <- n_params^(3/2) / n_obs
portnoy_value  # Should be close to 0
# Load the lavaan package
if (!requireNamespace("lavaan", quietly = TRUE)) {
install.packages("lavaan")
}
library(lavaan)
# Define a simple SEM model
model <- '
y1 ~ x1 + x2
y2 ~ y1
'
# Simulate data
set.seed(123)
data <- data.frame(
x1 = rnorm(100),
x2 = rnorm(100),
y1 = rnorm(100),
y2 = rnorm(100)
)
# Fit the model
fit <- sem(model, data = data)
# Print summary
summary(fit)
# Count parameters
n_params <- lavInspect(fit, "npar")  # Number of free parameters
n_obs <- nrow(data)
# Portnoy's rule
portnoy_value <- n_params^(3/2) / n_obs
portnoy_value
# Number of unique observed covariances
p <- ncol(data)
n_cov <- p * (p + 1) / 2
# Compare to number of free parameters
n_cov
lavInspect(fit, "npar")  # Should be ≤ n_cov
library(lavaan)
# define model as a lavaan-style string
model <- '
cover ~ age + elev
firesev ~ age + cover
'
fit <- sem(model, data = keeley)
fitMeasures(fit, c("chisq", "df", "pvalue", "cfi", "rmsea"))
bookdown::render_book("index.Rmd")
library(piecewiseSEM)
# Simulate example data
set.seed(123)
n <- 100
x <- rnorm(n)
y2 <- 0.5 * x + rnorm(n)
y1 <- 0.6 * x + 0.4 * y2 + rnorm(n)
example_data <- data.frame(x, y1, y2)
# Fit piecewise SEM
mod_list <- psem(
lm(y2 ~ x, data = example_data),
lm(y1 ~ x + y2, data = example_data)
)
# ✅ Get model fit statistics (replaces sem.fit)
fisherC(mod_list)
# ✅ Get standardized path coefficients (replaces sem.coefs)
stdCoefs(mod_list)
# ✅ Optional: View DAG
plot(getDAG(mod_list))
# Load libraries
library(piecewiseSEM)
library(visreg)
library(DiagrammeR)
# Load sample data (or use your own)
data(keeley)  # from piecewiseSEM
# Fit individual models
mod1 <- lm(abiotic ~ distance, data = keeley)
mod2 <- lm(hetero ~ distance, data = keeley)
mod3 <- lm(rich ~ abiotic + hetero, data = keeley)
# Combine into a psem object
keeley_sem <- psem(mod1, mod2, mod3)
# Coefficients
coefs(keeley_sem)
# R-squared values
rsquared(keeley_sem)
keeley_sem <- psem(
lm(firesev ~ age + cover, data = keeley),
lm(cover ~ age + elev + firesev, data = keeley),
data = keeley
)
plot(keeley_sem)
#Option B: Refined Graph with DiagrammeR
# Optional customization
plot(keeley_sem,
node_attrs = list(
x = c(2.5, 2.5, 4, 1),
y = c(3, 1, 2, 2),
shape = "rectangle",
fillcolor = "white"
))
mod_firesev  <- lm(firesev ~ age, data = keeley)
mod_cover    <- lm(cover ~ firesev, data = keeley)
firesev_model <- psem(mod_firesev, mod_cover)
summary(firesev_model)
dSep(firesev_model)
rsquared(firesev_model)
# Visualize fire severity's effect on cover
visreg(firesev_model[[2]], xvar = "firesev")
# Download data
url <- "https://drive.google.com/uc?export=download&id=1oHBul4_JcqlPFZgYsH3WOIZJRQRw1O4F"
cardinale <- read.csv(url)
# Check it loaded
head(cardinale)
# Log-transform variables
cardinale$logN <- log10(cardinale$N + 1e-6)
cardinale$logN2 <- cardinale$logN^2
cardinale$logChl <- log10(cardinale$Chl)
#Fit SEM with piecewiseSEM
model1 <- psem(
lm(SA ~ logN + logN2 + SR, data = cardinale),
lm(logChl ~ SA + logN + logN2, data = cardinale),
logN %~~% logN2,
data = cardinale
)
summary(model1)
# Center predictors
cardinale$logN.cen <- scale(cardinale$logN, scale = FALSE)
cardinale$logN2.cen <- cardinale$logN.cen^2
# Check correlation
cor(cardinale$logN.cen, cardinale$logN2.cen)
model2 <- psem(
lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale),
lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale),
logN.cen %~~% logN2.cen,
data = cardinale
)
summary(model2)
url2 <- "https://drive.google.com/uc?export=download&id=1YTsFP1T__Hn13hTvj9TVOK-wbGDxLd01"
# Try to read the CSV directly
keeley <- read.csv(url2)
keeley$age_cent <- scale(keeley$age, scale = FALSE)
keeley$fire_cent <- scale(keeley$firesev, scale = FALSE)
keeley$int_term <- keeley$age_cent * keeley$fire_cent
keeley_int <- psem(
lm(cover ~ age_cent * fire_cent, data = keeley),
lm(fire_cent ~ age_cent, data = keeley),
data = keeley
)
summary(keeley_int)
# Simulated structure to mimic Anderson et al.
set.seed(42)
anderson <- data.frame(
biomass.kg = rnorm(100, mean = 10, sd = 2),
leafN = rnorm(100, mean = 3, sd = 0.5),
landscape = sample(0:1, 100, replace = TRUE),
hotspotYN = rbinom(100, 1, 0.4)
)
library(piecewiseSEM)
anderson.sem <- psem(
lm(leafN ~ biomass.kg, data = anderson),
glm(hotspotYN ~ leafN + biomass.kg + landscape, family = "binomial", data = anderson)
)
summary(anderson.sem)
# Add the 'conserve = TRUE' argument to be conservative in tests
summary(anderson.sem, conserve = TRUE)
dSep(anderson.sem, direction = c("hotspotYN <- leafN"))
anderson.sem2 <- update(anderson.sem, hotspotYN %~~% leafN)
dSep(anderson.sem2)
anderson.glm <- anderson.sem[[2]]
Betas <- coefs(anderson.sem)[2:4, 3]  # GLM coefficients
preds <- predict(anderson.glm, type = "link")
sd.y.LT <- sqrt(var(preds) + pi^2/3)
sd.x <- sapply(anderson[, c("leafN", "biomass.kg", "landscape")], sd)
Betas.LT <- Betas * sd.x / sd.y.LT
Betas.LT
preds_response <- predict(anderson.glm, type = "response")
R <- cor(anderson$hotspotYN, preds_response)
sd.y.OE <- sqrt(var(preds_response)) / R
Betas.OE <- Betas * sd.x / sd.y.OE
Betas.OE
# Indirect effect: leafN → hotspotYN (through biomass.kg)
Beta.leafN <- coefs(anderson.sem)$Std.Estimate[1]
indirect_LT <- Beta.leafN * Betas.LT[1]
indirect_OE <- Beta.leafN * Betas.OE[1]
c(LT = indirect_LT, OE = indirect_OE)
library(lme4)
library(piecewiseSEM)
library(emmeans)
library(lavaan)
library(multcompView)
# Simulated structure: Genotype nested within Phragmites status (e.g., native, invasive)
set.seed(1)
n <- 90
bowen <- data.frame(
status = factor(rep(c("native", "invasive", "introduced"), each = 30)),
Genotype = rep(paste0("G", 1:9), each = 10),
observed_otus = rnorm(n, mean = 2500, sd = 100),
RNA.DNA = rnorm(n, 0.7, 0.05),
below.C = rnorm(n, 43, 1),
abovebiomass_g = rnorm(n, 2, 0.5)
)
# Mixed models for each component
div_mod <- lmer(observed_otus ~ status + (1 | Genotype), data = bowen)
activity_mod <- lmer(RNA.DNA ~ status + observed_otus + (1 | Genotype), data = bowen)
carbon_mod <- lmer(below.C ~ observed_otus + status + (1 | Genotype), data = bowen)
biomass_mod <- lmer(abovebiomass_g ~ RNA.DNA + observed_otus + below.C + status + (1 | Genotype), data = bowen)
# Build piecewise SEM
bowen_mod <- psem(div_mod, activity_mod, carbon_mod, biomass_mod, data = bowen)
summary(bowen_mod)
lapply(bowen_mod[-length(bowen_mod)], emmeans, specs = ~status)
# Post-hoc Tests (Tukey)
generic_tukey <- function(x) emmeans(x, list(pairwise ~ status))
lapply(bowen_mod[-length(bowen_mod)], generic_tukey)
# Create simulated dataset
group_df <- data.frame(
site = rep(c("A", "B"), each = 50),
x = rnorm(100),
m = rnorm(100),
y = rnorm(100)
)
# Define a simple SEM model
sem_model <- '
m ~ a*x
y ~ b*m + c*x
'
# Fit multi-group SEM
fit_multi <- lavaan::sem(sem_model, data = group_df, group = "site")
# View summary
summary(fit_multi, fit.measures = TRUE, standardized = TRUE)
# Simulate data
set.seed(123)
n <- 100
group <- rep(c("A", "B"), each = n)
x <- rnorm(2 * n)
m <- 0.5 * x + rnorm(2 * n)
y <- 0.6 * m + 0.3 * x + rnorm(2 * n)
data <- data.frame(group, x, m, y)
model <- '
m ~ a*x
y ~ b*m + c*x
'
fit_multi <- sem(model, data = data, group = "group")
summary(fit_multi, fit.measures = TRUE, standardized = TRUE)
# Constrain 'a' and 'b' to be equal across groups
model_constrained <- '
m ~ c(a, a)*x
y ~ c(b, b)*m + c*x
'
fit_constrained <- sem(model_constrained, data = data, group = "group")
anova(fit_multi, fit_constrained)  # Chi-square test for invariance
library(semPlot)
semPaths(fit_multi, "std", layout = "tree", whatLabels = "std", edge.label.cex = 1.2)
# Log-transform predictors
cardinale$logN <- log10(cardinale$N + 1e-6)
cardinale$logN2 <- cardinale$logN^2
cardinale$logChl <- log10(cardinale$Chl)
# Centering predictors to reduce multicollinearity
cardinale$logN.cen <- scale(cardinale$logN, scale = FALSE)
cardinale$logN2.cen <- scale(cardinale$logN^2, scale = FALSE)
cardinale.sem <- psem(
lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale),
lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale),
logN.cen %~~% logN2.cen,
data = cardinale
)
summary(cardinale.sem)
# Log-transform predictors
cardinale$logN <- log10(cardinale$N + 1e-6)
cardinale$logN2 <- cardinale$logN^2
cardinale$logChl <- log10(cardinale$Chl)
# Centering predictors to reduce multicollinearity
cardinale$logN.cen <- scale(cardinale$logN, scale = FALSE)
cardinale$logN2.cen <- scale(cardinale$logN^2, scale = FALSE)
cardinale.sem <- psem(
lm(SA ~ logN.cen + logN2.cen + SR, data = cardinale),
lm(logChl ~ SA + logN.cen + logN2.cen, data = cardinale),
logN.cen %~~% logN2.cen,
data = cardinale
)
summary(cardinale.sem)
# Example if "site_mean" were available
cardinale$stream_mean_logN <- ave(cardinale$logN, cardinale$Stream)
cardinale$deviation_logN <- cardinale$logN - cardinale$stream_mean_logN
example1 <- read.csv("/Users/sks379/Desktop/GraduateStudents/Stats and Lit Review Lessons/Class2_Probability/example1.csv", header=TRUE)
library(knitr)
library(readr)
url <- "https://drive.google.com/uc?export=download&id=1KDvCzj9-YzN1zDHdLutcpruYx5mpcEWH"
example1 <- read_csv(url)
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
str(haphap)
# Load necessary libraries
library(tidyverse)
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
# Set working directory
setwd("//Users/sks379/Desktop/HAPHAPProtocolAnalyses/")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
# Set working directory
setwd("/Users/sks379/Desktop/HAPHAPProtocolAnalyses/")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
# Set working directory
setwd("/Users/sks379/Desktop/HAPHAPProtocolAnalyses")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
problems()
# Load necessary libraries
library(tidyverse)
# Set working directory
setwd("/Users/sks379/Desktop/HAPHAPProtocolAnalyses/")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
unique(your_data$`...13`)
unique(haphap$`...13`)
unique(hapap$`...14`)
unique(haphap$`...13`)
unique(haphap$`...14`)
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
problems(haphap)
# Load necessary libraries
library(tidyverse)
# Set working directory
setwd("/Users/sks379/Desktop/HAPHAPProtocolAnalyses/")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
problems(haphap)
# Set working directory
setwd("/Users/sks379/Desktop/HAPHAPProtocolAnalyses/")
# Read in the CSV files
haphap <- read_csv("HAPHAP_2023.csv")
haphap_2024 <- dplyr::filter(haphap, Year == "2024")
haphap_repro <- dplyr::filter(haphap, TotalInflorescencePlant > 0)
plot(haphap_repro$LengthIinflorescence, haphap_repro$NumFlowerFruits)
haphap_reprosummary <- dplyr::mutate(haphap_repro, mean_TotalInflorescencePlant = mean(TotalInflorescencePlant), min_Inflorescence = min(LengthIinflorescence), mean_Inflorescence = mean(LengthIinflorescence), max_Inflorescence = max(Inflorescence), TotalSeedperPlant = sum(NumFlowerFruits), na.rm = TRUE)
haphap_reprosummary <- dplyr::mutate(haphap_repro, mean_TotalInflorescencePlant = mean(TotalInflorescencePlant), min_Inflorescence = min(LengthIinflorescence), mean_Inflorescence = mean(LengthIinflorescence), max_Inflorescence = max(LengthIinflorescence), TotalSeedperPlant = sum(NumFlowerFruits), na.rm = TRUE)
haphap_reprosummary
haphap_reprosummary <- haphap_repro %>%
group_by(ID) %>%
summarise(
mean_TotalInflorescencePlant = mean(TotalInflorescencePlant, na.rm = TRUE),  # likely same value per plant
min_Inflorescence = min(LengthIinflorescence, na.rm = TRUE),
mean_Inflorescence = mean(LengthIinflorescence, na.rm = TRUE),
max_Inflorescence = max(LengthIinflorescence, na.rm = TRUE),
TotalSeedperPlant = sum(NumFlowerFruits, na.rm = TRUE),
.groups = "drop"
)
library(AICcmodavg)
# Build a list of models
models <- list(
lm_min_linear  = lm(TotalSeedperPlant ~ min_Inflorescence, data = haphap_reprosummary),
lm_min_poly    = lm(TotalSeedperPlant ~ poly(min_Inflorescence, 2), data = haphap_reprosummary),
lm_mean_linear = lm(TotalSeedperPlant ~ mean_Inflorescence, data = haphap_reprosummary),
lm_mean_poly   = lm(TotalSeedperPlant ~ poly(mean_Inflorescence, 2), data = haphap_reprosummary),
lm_max_linear  = lm(TotalSeedperPlant ~ max_Inflorescence, data = haphap_reprosummary),
lm_max_poly    = lm(TotalSeedperPlant ~ poly(max_Inflorescence, 2), data = haphap_reprosummary),
lm_totalinflo_linear = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant, data = haphap_reprosummary),
lm_totalinflo_poly   = lm(TotalSeedperPlant ~ poly(mean_TotalInflorescencePlant, 2), data = haphap_reprosummary),
lm_combo1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary)  # includes interaction
)
# Compare models using AICc
aic_table <- aictab(cand.set = models, second.ord = TRUE)
print(aic_table)
# Visualize the best model(s) if needed
# Example: if lm_mean_linear was best
ggplot(haphap_reprosummary, aes(x = mean_Inflorescence, y = TotalSeedperPlant)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x) +
labs(title = "Mean Inflorescence vs Total Seed per Plant",
x = "Mean Inflorescence Length", y = "Total Seeds")
# Build a list of models
models <- list(
lm_min_linear  = lm(TotalSeedperPlant ~ min_Inflorescence, data = haphap_reprosummary),
lm_min_poly    = lm(TotalSeedperPlant ~ poly(min_Inflorescence, 2), data = haphap_reprosummary),
lm_mean_linear = lm(TotalSeedperPlant ~ mean_Inflorescence, data = haphap_reprosummary),
lm_mean_poly   = lm(TotalSeedperPlant ~ poly(mean_Inflorescence, 2), data = haphap_reprosummary),
lm_max_linear  = lm(TotalSeedperPlant ~ max_Inflorescence, data = haphap_reprosummary),
lm_max_poly    = lm(TotalSeedperPlant ~ poly(max_Inflorescence, 2), data = haphap_reprosummary),
lm_totalinflo_linear = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant, data = haphap_reprosummary),
lm_totalinflo_poly   = lm(TotalSeedperPlant ~ poly(mean_TotalInflorescencePlant, 2), data = haphap_reprosummary),
lm_combo1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary),
lm_combo_max = lm(TotalSeedperPlant ~ max_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo_max = lm(TotalSeedperPlant ~ max_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary),
lm_combo1_min = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo2_min = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary)
)
# Build a list of models
models <- list(
lm_min_linear  = lm(TotalSeedperPlant ~ min_Inflorescence, data = haphap_reprosummary),
lm_min_poly    = lm(TotalSeedperPlant ~ poly(min_Inflorescence, 2), data = haphap_reprosummary),
lm_mean_linear = lm(TotalSeedperPlant ~ mean_Inflorescence, data = haphap_reprosummary),
lm_mean_poly   = lm(TotalSeedperPlant ~ poly(mean_Inflorescence, 2), data = haphap_reprosummary),
lm_max_linear  = lm(TotalSeedperPlant ~ max_Inflorescence, data = haphap_reprosummary),
lm_max_poly    = lm(TotalSeedperPlant ~ poly(max_Inflorescence, 2), data = haphap_reprosummary),
lm_totalinflo_linear = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant, data = haphap_reprosummary),
lm_totalinflo_poly   = lm(TotalSeedperPlant ~ poly(mean_TotalInflorescencePlant, 2), data = haphap_reprosummary),
lm_combo1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary),
lm_combo_max = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + max_Inflorescence, data = haphap_reprosummary),
lm_combo_max = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * max_Inflorescence, data = haphap_reprosummary),
lm_combo1_min = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + min_Inflorescence, data = haphap_reprosummary),
lm_combo2_min = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * min_Inflorescence, data = haphap_reprosummary)
)
# Compare models using AICc
aic_table <- aictab(cand.set = models, second.ord = TRUE)
print(aic_table)
# Build a list of models
models <- list(
lm_min_linear  = lm(TotalSeedperPlant ~ min_Inflorescence, data = haphap_reprosummary),
lm_min_poly    = lm(TotalSeedperPlant ~ poly(min_Inflorescence, 2), data = haphap_reprosummary),
lm_mean_linear = lm(TotalSeedperPlant ~ mean_Inflorescence, data = haphap_reprosummary),
lm_mean_poly   = lm(TotalSeedperPlant ~ poly(mean_Inflorescence, 2), data = haphap_reprosummary),
lm_max_linear  = lm(TotalSeedperPlant ~ max_Inflorescence, data = haphap_reprosummary),
lm_max_poly    = lm(TotalSeedperPlant ~ poly(max_Inflorescence, 2), data = haphap_reprosummary),
lm_totalinflo_linear = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant, data = haphap_reprosummary),
lm_totalinflo_poly   = lm(TotalSeedperPlant ~ poly(mean_TotalInflorescencePlant, 2), data = haphap_reprosummary),
lm_combo1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + mean_Inflorescence, data = haphap_reprosummary),
lm_combo2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * mean_Inflorescence, data = haphap_reprosummary),
lm_combo_max1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + max_Inflorescence, data = haphap_reprosummary),
lm_combo_max2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * max_Inflorescence, data = haphap_reprosummary),
lm_combo1_min1 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant + min_Inflorescence, data = haphap_reprosummary),
lm_combo2_min2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * min_Inflorescence, data = haphap_reprosummary)
)
# Compare models using AICc
aic_table <- aictab(cand.set = models, second.ord = TRUE)
print(aic_table)
TotalSeedperPlant ~ mean_TotalInflorescencePlant + max_Inflorescence + mean_TotalInflorescencePlant:max_Inflorescence
summary(lm_combo_max2)$r.squared
lm_combo_max2 = lm(TotalSeedperPlant ~ mean_TotalInflorescencePlant * max_Inflorescence, data = haphap_reprosummary)
summary(lm_combo_max2)$r.squared
summary(lm_combo_max2)$adj.r.squared
broom::glance(lm_combo_max2)
ggplot(haphap_reprosummary, aes(x = max_Inflorescence, y = mean_TotalInflorescencePlant, z = TotalSeedperPlant)) +
geom_point(aes(color = TotalSeedperPlant)) +
stat_summary_2d(bins = 15) +
labs(title = "Interaction: Max Inflorescence × Total Inflorescences",
x = "Max Inflorescence Length (cm)",
y = "Mean Total Inflorescences per Plant",
fill = "Seed Count") +
theme_minimal()
# Create a binned version of mean_TotalInflorescencePlant
haphap_reprosummary$inflo_bin <- cut(haphap_reprosummary$mean_TotalInflorescencePlant,
breaks = 3,
labels = c("Low", "Medium", "High"))
ggplot(haphap_reprosummary, aes(x = max_Inflorescence, y = TotalSeedperPlant)) +
geom_point(aes(color = inflo_bin)) +
geom_smooth(method = "lm", aes(color = inflo_bin), se = FALSE) +
labs(title = "Effect of Max Inflorescence on Seed Production\nby Total Inflorescence Class",
x = "Max Inflorescence Length (cm)",
y = "Total Seeds per Plant",
color = "Inflo. Count Level") +
theme_minimal()
haphap_reprosummary <- haphap_reprosummary %>%
mutate(log_Seeds = log1p(TotalSeedperPlant))  # log1p handles 0s safely
model_log <- lm(log_Seeds ~ mean_TotalInflorescencePlant * max_Inflorescence, data = haphap_reprosummary)
summary(model_log)
glm_nb <- MASS::glm.nb(TotalSeedperPlant ~ mean_TotalInflorescencePlant * max_Inflorescence,
data = haphap_reprosummary)
summary(glm_nb)
plot(lm_combo_max2, which = 1)  # Residuals vs Fitted
library(dplyr)
# Create a new data frame for predictions
new_data <- haphap_reprosummary %>%
select(mean_TotalInflorescencePlant, max_Inflorescence) %>%
distinct() %>%
expand.grid(
mean_TotalInflorescencePlant = quantile(haphap_reprosummary$mean_TotalInflorescencePlant, probs = c(0.25, 0.5, 0.75)),
max_Inflorescence = seq(min(haphap_reprosummary$max_Inflorescence, na.rm = TRUE),
max(haphap_reprosummary$max_Inflorescence, na.rm = TRUE), length.out = 100)
)
# Add predictions from the model
new_data$predicted <- predict(glm_nb, newdata = new_data, type = "response")
# Convert inflorescence count to categorical for color
new_data$Inflorescence_Class <- factor(new_data$mean_TotalInflorescencePlant,
labels = c("Low", "Medium", "High"))
# Add predictions from the model
new_data$predicted <- predict(glm_nb, newdata = new_data, type = "response")
# Convert inflorescence count to categorical for color
new_data$Inflorescence_Class <- factor(new_data$mean_TotalInflorescencePlant,
labels = c("Low", "Medium", "High"))
ggplot(haphap_reprosummary, aes(x = max_Inflorescence, y = TotalSeedperPlant)) +
geom_point(alpha = 0.5, aes(color = inflo_bin)) +
geom_line(data = new_data, aes(x = max_Inflorescence, y = predicted, color = Inflorescence_Class), size = 1.2) +
labs(title = "Predicted Seed Count by Max Inflorescence Length",
subtitle = "Negative Binomial GLM with Total Inflorescence Count Interaction",
x = "Max Inflorescence Length (cm)",
y = "Predicted Seeds per Plant",
color = "Inflorescence Class") +
theme_minimal()
# Residuals vs Fitted
plot(glm_nb, which = 1)
