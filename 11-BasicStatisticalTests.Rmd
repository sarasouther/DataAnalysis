# Basic statistical testing 

## A short statistical review
# Hypothesis Testing Fundamentals

This chapter introduces the logic that underlies *every* statistical test you will encounter. Whether you're running a t-test, ANOVA, regression, or chi-square test, the reasoning is always the same:

1. State what you'd expect if nothing interesting is happening (the null hypothesis)
2. Collect data and calculate a test statistic
3. Ask: "How surprising is my result if the null hypothesis were true?"
4. If very surprising (p ≤ 0.05), reject the null hypothesis

Once you understand this framework, learning new statistical tests becomes much easier—you're just learning different ways to apply the same logic.

## The core question

Every statistical test answers a simple question:

**Could this pattern have arisen by chance alone, or is something real going on?**

"Chance alone" means random sampling variation—the noise that's inevitable when we measure a subset of a population. Even if there's no true difference between groups, our samples won't be identical. The question is whether our observed difference is large enough to be convincing, or whether it's within the range we'd expect from random noise.

## A worked example: Seedling heights after fire

Let's work through the logic with an example you might actually encounter.

### The scenario

You're studying post-fire forest regeneration. You hypothesize that fire creates conditions that promote seedling growth—perhaps by reducing competition or releasing nutrients. You establish plots in burned and unburned areas and measure seedling heights.

**Research question:** Do seedlings grow taller in burned areas compared to unburned areas?

### The data

```{r hypothesis-setup, message=FALSE, warning=FALSE}
library(tidyverse)
set.seed(42)

# Seedling heights (cm) from burned and unburned plots
burned <- c(18.2, 22.1, 19.8, 24.3, 20.5, 21.7, 23.4, 19.2, 22.8, 20.1,
            21.3, 23.9, 18.7, 22.4, 20.9)
unburned <- c(15.3, 17.8, 14.2, 16.9, 18.1, 15.7, 17.2, 16.4, 14.8, 17.5,
              16.1, 15.9, 18.3, 16.7, 15.4)

# Combine into a data frame
seedlings <- data.frame(
  height = c(burned, unburned),
  treatment = rep(c("Burned", "Unburned"), each = 15)
)

# Quick summary
seedlings %>%
  group_by(treatment) %>%
  summarise(
    n = n(),
    mean = mean(height),
    sd = sd(height),
    se = sd / sqrt(n)
  )
```

The burned plots have a mean height of 21.3 cm, while unburned plots average 16.4 cm—a difference of about 4.9 cm. But is this difference *real*, or could it just be sampling variation?

### Visualize first

```{r hypothesis-visualize, fig.cap="Seedling heights in burned vs. unburned plots. Burned plots appear to have taller seedlings on average, but is this difference statistically significant?"}
ggplot(seedlings, aes(x = treatment, y = height, fill = treatment)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_jitter(width = 0.1, alpha = 0.6, size = 2) +
  scale_fill_manual(values = c("darkorange", "forestgreen")) +
  labs(x = "Treatment",
       y = "Seedling Height (cm)",
       title = "Seedling Heights: Burned vs. Unburned Plots") +
  theme_minimal() +
  theme(legend.position = "none")
```

The boxplots suggest a difference, but the distributions overlap somewhat. We need a formal test.

## Step 1: State the hypotheses

### The null hypothesis (H₀)

The **null hypothesis** states that nothing interesting is happening—there is no effect, no difference, no relationship. It's the skeptic's position: "Your treatment didn't do anything; any pattern you see is just noise."

For our example:

> **H₀:** Mean seedling height is the same in burned and unburned plots.
> 
> Mathematically: μ_burned = μ_unburned (or equivalently, μ_burned - μ_unburned = 0)

The null hypothesis must be **specific** because we need to calculate exactly what we'd expect to see if it were true.

### The alternative hypothesis (H_A)

The **alternative hypothesis** states that something *is* going on. It's typically what you hope to demonstrate.

> **H_A:** Mean seedling height differs between burned and unburned plots.
> 
> Mathematically: μ_burned ≠ μ_unburned

Note that H_A is **general**—it just says "they differ" without specifying which is larger. This is called a **two-tailed test** because we'd reject H₀ whether burned plots were taller *or* shorter than unburned.

### One-tailed vs. two-tailed tests

If we had strong prior reason to predict that burned plots would have *taller* (not just different) seedlings, we could use a **one-tailed test**:

> **H_A (one-tailed):** μ_burned > μ_unburned

One-tailed tests are more powerful (easier to detect an effect) but only in one direction. Use them only when:
- You have strong theoretical justification for the direction
- A difference in the other direction would be scientifically meaningless

**When in doubt, use a two-tailed test.** In this course, we'll primarily use two-tailed tests.

## Step 2: Calculate a test statistic

A **test statistic** is a single number that summarizes how different your data are from what the null hypothesis predicts. Different tests use different statistics, but the logic is always the same: bigger values mean more evidence against the null.

For comparing two means, we use the **t-statistic**:

$$t = \frac{\bar{x}_1 - \bar{x}_2}{SE_{difference}}$$