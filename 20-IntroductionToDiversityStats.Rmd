# Diversity statistics

How do we describe the variety of species, traits or phylogenies in a particular area? With diversity statistics! Simple species counts, or species richness, is a time-old method for describing diversity. Since the olden days of creating 'species lists' for every habitat under the sun, new methods have emerged to describe the variety of life within ecological communities. These statistics attempt to deal with a problem inherent to diversity assessments: It is really hard to find all the species within an ecosystem and the more you look, the more species you find! 

There are a variety of different diversity statistics, which vary in terms of how much they weight relative abundances of species. These metrics are:

**Species richness**: Simple counts of species in an area. Common species and rare species are given the same weight, since each species no matter how abundant it is, increases species richness by 1 unit! Includes no measure of **evenness**. **Evenness** is a measure of relative abundance of species at a site. The more equal species are in proportion to each other the greater the evenness of the site. 

The **Shannon diversity index** is a diversity index based on both richness (species counts) and evenness (relative abundance). 

The **Simpson diversity index**, like the Shannon diversity index, combines richness and evenness, but more strongly weights evenness relative to richness.  

These three metrics, richness, Shannon diversity and Simpson diversity index can be expressed as Hill numbers, or the effective number of species. The advantage of using Hill numbers, rather than generating diversity metrics using other indices, is that they are more easily interpreted, since they follow the doubling rule, and more easily compared to better understand diversity in a system. Hill numbers are parameterized by a diversity order q, which determines the measures’ sensitivity to species relative abundances. Hill numbers include the three most widely used species diversity measures as special cases: species richness (q = 0), Shannon diversity (q = 1) and Simpson diversity (q = 2).  

Specifically:

$$^qD = \left(\sum_{i=1}^{S} p_i^q\right)^{1/(1-q)}$$
When q = 0, $^0D$ is simply species richness, which counts species equally without regard to their relative abundances. For q = 1, the equation above is undefined, since 1/0, but the limit as q tends to 1 is the exponential of the familiar Shannon index, referred to as Shannon diversity. The measure for q = 1 counts individuals equally and thus counts species in proportion to their abundances; the measure $^1D$ can be interpreted as the effective number of common species in the assemblage. The measure for q = 2 ($^2D$), referred to as Simpson diversity, discounts all but the dominant species and can be interpreted as the effective number of dominant species in the assemblage.

**The doubling rule** refers to the fact that as a species assemblage goes from 8 species to 16 the calculated Hill numbers double. This seems like, of course, that would be the case, BUT diversity indices like the Shannon entropy ("Shannon-Wiener index") and the Gini-Simpson index do not follow the doubling rule! By calling all of these indices “diversities” and treating them as if they were interchangeable in formulas or analyses requiring diversities, we will often generate misleading results.So, Hill numbers are *true diversities* (also referred to as the *effective number of species*), rather than just indices of diversity, unanchored to the actual diversity at a site. In other words, a community with eight equally-common species has a diversity of eight species, or a community with S equally-common species has a diversity of S species. This definition behaves as we expect of a diversity; the diversity of a community of sixteen equally-common species is double that of a community with eight equally-common species. One reason to calculate the effective number of species rather than diversity indices is that it allows straightforward and intuitive comparisons among communities.

The goal in many diversity analyses is to make fair comparison of diversities across multiple assemblages that may vary in the size of their species pools or in the way in which they are sampled. Diversity metrics are strongly affected by both search time and search area. Even when researchers standardize search effort, both in terms of time spent surveying a plot and by plot area, diversity metrics are extremely sensitive to the diversity of the community itself. A more diverse community with high unevenness (i.e., lots of rare species) would require more search effort to estimate **true diversity** relative to a low diversity community with high evenness. For that reason, even when we've established appropriate sampling stategies, we have to standardize communities in order to compare them. 

For this reason, community ecologists use statistical techniques like **extrapolation** and **rarefaction** to estimate the 'true' number of species within an area based on your sample. 

Rarefaction deals with unequal sampling by down-sampling the larger samples until they contain the same number of observed individuals or sampling units as the smallest sample. In the past, rarefaction was the principal means to compare assemblages. When using rarefaction, you lose data, since you cull your other assemblages to be equivalently comparable with your "worst" sample. For this reason, many community ecologists now choose to generate asymptotic estimates of diversity, which involves combining rarefaction with extrapolation. To calculate asymptotic diversity estimates, you first generate a rarefaction/extrapolation sampling curve (R/E curve) that estimates diversity over a series of sampling units. Diversity estimates below your sample's observed diversity estimate is derived from rarefaction (referred to as the *sample-size-based approach* to standardize data based on sample effort), and estimates above the observed diversity are derived from extrapolation. 

There are several ways of extrapolating diversity data beyond your actual sample. Parametric methods extend the species accumulation curve by fitting parametric functions. Most commonly, however, a non-parametric method that uses the frequency of rare species in a sample is used for extrapolating samples (a method developed by Alan Turing when designing the enigma machine). This approach standardizes data based on **sample completeness**, an estimated assemblage characteristic. Sampling completeness is the ratio between the detected and estimated diversity and indicates the proportion of detected species. The comparison between detected and estimated diversity is made by calculating and comparing sample coverage (thus these methods for extrapolating data are referred to as *coverage-based approaches*), or the total relative abundances of the observed species. The sample completeness curve provides a bridge between the size- and coverage-based R/E sampling curves. In other words, since sample completeness can be calculated for rarefied samples (i.e., use your actual data to compare detected to estimated diversity), sample completeness can be used to anchor and unite the rarefaction and extrapolation curves.

By combining R/E curves to estimate of diversity and expressing diversity estimates as Hill numbers, iNEXT is a great all around package to compare diversity among assemblages of ecological data. This framework allows ecologists to compare of the species diversity of different assemblages in time or space, with reliable statistical inferences about these comparisons. 

## iNext

*What type of data do you have?*
The first decision to make is to determine what type of data you will analyze. 

For calculating diversity statistics, there are two principle forms of diversity data:
**Abundance data** are data that include a measure of abundance - This could be data with counts of species or that includes cover data. When R/E curves are generated, the sampling unit is an individual. For example, to generate rarefaction curves, rarefied assemblages are created by randomly removing *individuals* within an assemblage. 

Note that many ecological studies collect abundance data within a plot or quadrat. In these cases, species are not independently sampled, and many ecologist recommend converting these datasets to incidence data (discussed below) to calculate diversity estimates, while others simply treat it as abundance data. Currently, statisticians are deriving methods to deal with sample-based abundance data (see Chui 2023) again using Turing's methods of estimate completeness - hopefully, these new equations are integrated into the iNEXT package soon!

**Sample-based incidence data** are data that note whether a give species is present or absent, and does not include information on how abundant that species is within an assemblage. In these cases the sampling unit is a trap, net, quadrat, plot, or timed survey. For sample-based incidence data, the sampling units (i.e., plots, quadrats, etc.), rather than individuals, are removed to generate rarefied diversity estimates. Note that for both abundance data and incidence data, the rarefaction process is repeated numerous times, allowing us to calculate confidence intervals (described in more detail below). 

There are two kinds of incidence input data for iNEXT: (1) incidence-raw data: for each assemblage, input data consist of a species-by-sampling-unit matrix; when there are N assemblages, input data consist of N matrices via a list object, with each matrix being a species-by-sampling-unit matrix. In iNEXT, this type of data is specified by datatype="incidence_raw". (2) Incidence-frequency data: input data for each assemblage consist of the number of sampling units (T) followed by the observed incidence frequencies (Y1, Y2, …, YS). 

Let's check out a few of these examples. First, we will begin with the abundance dataset, spider. The spider dataset was collected at Harvard Experimental Forest. Researchers killed hemlock trees using two different methods (girdling or logging), in order to observe the effect of hemlock loss on the remnant community. Here, Sackett et al. (2011) provides abundance data for spiders collected on trees killed by girdling the trunk or by logging. 

```{r cars}
library(iNEXT)
library(tidyverse)
#or
#library(devtools)
#install_github('AnneChao/iNEXT')

#First let's check out two abundance datasets

#Individual‐based abundance data (datatype="abundance"): Input data for each assemblage/site include species abundances in an empirical sample of n individuals (“reference sample”). When there are N assemblages, input data consist of an S by N abundance matrix, or N lists of species abundances.

#Check out spider
data("spider"); spider
#The spider dataset consists of abundance data from two canopy manipulation treatments (“Girdled” and “Logged”) of hemlock. Counts of individuals for species are provided for girdled and logged trees.

#Go ahead and estimate diversity
out <- iNEXT(spider, q=c(0, 1, 2), datatype="abundance", endpoint=500)
ggiNEXT(out, type=1, facet.var="Assemblage")
```

The iNEXT functions calculates our R/E curve. There are several components of this function (taken from the package information):
1. The first term in the iNEXT function specifies the dataset. 
2. Argument q allows you to select the type of diversity estimate that you are interested in. Here, we have chosen to calculate Hill numbers q = 0 (richness), 1 (Shannons), and 2 (Simpsons). 
3. The argument datatype allows you to specify which type of data you are inputting (“abundance”, “incidence_raw” or “incidence_freq”). 
4. The argument size to specify sample sizes for which diversity estimates are computed. If
NULL, then diversity estimates will be calculated for those sample sizes determined by the specified/default endpoint and knots. 
5. Argument endpoint is an integer specifying the sample size that is the endpoint for R/E calculation; If
NULL, then endpoint=double the sample size of your assemblage (total sample size for abundance data; total sampling units for incidence data). As a general rule of thumb, for species richness, the size in the R/E curve can be extrapolated to at most double or triple the minimum observed sample size, guided by an estimated asymptote. For Shannon diversity and Simpson diversity, if the data are not too sparse, the extrapolation can be reliably extended to infinity to attain the estimated asymptote. 
6. Knots an integer specifying the number of equally‐spaced knots between size 1 and the endpoint; default is 40. se a logical variable to calculate the bootstrap standard error and conf confidence interval. nboot an integer specifying the number of bootstrap replications; default is 50.

Let's take a look at another abundance dataset and use this next analysis to discuss the components of the output from the iNEXT function. The bird dataset consists of abundance tallies for birds at two sites: North site and South site.

```{r}
#Check out the other abundance dataset, called 'bird'
data("bird"); bird

#calculate diversity metrics for the bird dataset
birdtest <- iNEXT(bird, q=c(0,1,2), datatype="abundance", size=NULL, endpoint=NULL, knots=40, se=TRUE, conf=0.95, nboot=50)

birdtest$AsyEst

#plot your bird data
ggiNEXT(birdtest, type=1, se=TRUE, facet.var="None", color.var="Assemblage", grey=FALSE)

```
The iNEXT() function returns the "iNEXT" object, which includes three output lists (taken from the iNEXT package documentation): 
1. $DataInfo for summarizing data information; 
2. $iNextEst for showing size- and coverage-based diversity estimates along with related statistics for a series of rarefied and extrapolated samples; 
3. $AsyEst for showing asymptotic diversity estimates along with related statistics. 
4. $DataInfo, as shown below, returns basic data information including the reference sample size (n), observed species richness (S.obs), sample coverage estimate for the reference sample (SC), and the first ten frequency counts (f1‐f10). This part of output can also be computed by the function DataInfo()

You can take a look at the entire output by calling 'birdtest' or you can grab the data that you will use in your analyses (like we did above), by calling 'birdtest$AsyEst'. 

For each estimate, 95% confidence intervals are calculated by bootstrapping samples. In the size-based standardization (i.e., rarefaction), the sample size is fixed in each regenerated bootstrap sample. In the coverage-based standardization (i.e., extrapolated), for a given standardized coverage value, bootstrapping is again used, but using random draws based on simulated data. The result is that the sampling uncertainty is greater in the coverage-based standardization and the resulting confidence interval is wider than that in the corresponding size-based standardization. The bootstrapping default is 50, and since it is a random process expect CI to differ each time you calculate them.

Now let's look at incidence data. First let's look at the tropical ant data (in the dataset ant included in the package) at five elevations (50m, 500m, 1070m, 1500m, and 2000m) collected by Longino & Colwell (2011) from Costa Rica. The 5 lists of incidence frequencies are shown below. The first entry of each list must be the total number of sampling units, followed by the species incidence frequencies.

```{r}
#incidence dataset
data(ant)
str(ant)
```

Look at the second incidence dataset. The ciliates data were collected from three coastal dune habitats to demonstrate the use of the input datatype="incidence_raw". The data set (ciliates) included in the package is a list of three species-by-plot matrices. 

```{r}
data(ciliates)
str(ciliates)

#Run the following commands to get the output as shown below.
out.raw <- iNEXT(ciliates, q = 0, datatype="incidence_raw", endpoint=150)
```

## Coverage‐based R/E sampling curves

You can derive a single measure of diversity for the same coverage/sample to compare among communities using estimateD.
```{r}
#The following command returns the species diversity with a specified level of sample coverage of 98.5% for the ant data. For some assemblages, this coverage value corresponds to rarefaction (i.e., less than the coverage of the reference sample), while for the others it corresponds to extrapolation (i.e., greater than the coverage of the reference sample), as indicated under the method column of the output.

estimateD(ant, datatype="incidence_freq",
 base="coverage", level=0.985, conf=0.95)
```

## Data manipulation

Scripts from the iNEXT package are fairly straightforward and easy to run. The challenge with these datasets is wrangling the data into the correct format for analysis. Since diversity statistics are often paired with NMDS data, let's start with an example in which we wrangle data formatted for the Vegan package. 

```{r results='hide', warning=FALSE}
library(readr)

# Download and read the first dataset
url1 <- "https://drive.google.com/uc?export=download&id=1c1guQTQwGNfA5Kx-xNPKRDsSJrBR-HxW"
env_matrix <- read_csv(url1)

# Download and read the second dataset
url2 <- "https://drive.google.com/uc?export=download&id=1jCqfJPEuEWo4uNZfxW43VkSvEDDtayF5"
species_matrix <- read_csv(url2)

```

This data is incidence data collected at 3 replicate control plots and 6 treatment plots before and after disturbance. 

```{r}
# Load necessary libraries
library(tidyverse)

print(colnames(species_matrix))
print(colnames(env_matrix))

# combine the datasets, by hand or with code!
combined_data <- inner_join(species_matrix, env_matrix, by = c("...1" = "...1"))

# Split the data into different groups
control_pre <- combined_data %>% 
  filter(Treatment == "Control" & Treatment_status == "PreTreatment")

#remove unnecessary columns
colnames(control_pre)
control_pre <- dplyr::select(control_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1))
control_pret <- t(control_pre)

control_post <- combined_data %>% 
  filter(Treatment == "Control" & Treatment_status == "PostTreatment")
colnames(control_post)
control_post <- dplyr::select(control_post, -c(Year, PlotN, Treatment, Treatment_status, ...1))
control_postt <- t(control_post)

treatment_pre <- combined_data %>% 
  filter(Treatment == "Treatment" & Treatment_status == "PreTreatment")
colnames(treatment_pre)
treatment_pre <- dplyr::select(treatment_pre, -c(Year, PlotN, Treatment, Treatment_status, ...1))
treatment_pret <- t(treatment_pre)

treatment_post <- combined_data %>% 
  filter(Treatment == "Treatment" & Treatment_status == "PostTreatment")
colnames(treatment_post)
treatment_post <- dplyr::select(treatment_post, -c(Year, PlotN, Treatment, Treatment_status, ...1))
treatment_postt <- t(treatment_post)

#combine matrices, control_pre, control_post, treatment_pre, treatment_post, in a matrix of N lists
combined_list <- list(control_pre = control_pre,
                      control_post = control_post,
                      treatment_pre = treatment_pre,
                      treatment_post = treatment_post)

lapply(combined_list, head)

combined_list <- lapply(combined_list, function(x) {
  if(is.data.frame(x)) as.matrix(x) else x
})

str(combined_list)

```

Now that we have the data in the correct format, let's analyze!

```{r}
library(iNEXT)

# Example of running iNEXT on incidence_raw data
results <- suppressWarnings({iNEXT(combined_list, q=0, datatype="incidence_raw")})

# Plot the results
plot(results)
```

Let's transform an abundance dataset! This dataset consists of observations of pollinators within an ecoregion for two time periods. Far more observations were collected after the development of cell phones and app-based species identification software like iNaturalist. In order to compare the two assemblages, you must calculate asymptotic diversity estimates using R/E curves. The dataset has been cleaned and spatially-thinned, so that we assume that each observation indicates a distinct individual and thus we have an estimate of abundance within this ecoregion. First, check out the dataset. Here, each row corresponds to an observation. In order to run analyses on this data, we must transform the data into either an S by N abundance matrix (bird data), or N lists of species abundances (spider data). Let's transform our data into the list structure.

```{r}
#you have to adjust the code to port in this datasets!
library(readr)

url3 <- "https://drive.google.com/uc?export=download&id=1bpLmtDDEPAdSaTPFPNg33hyj6y0viqxk"
arcticlocs <- read_csv(url3)

#time periods
arcticlocsTP1 <- filter(arcticlocs, year >= 1939 & year < 1979)
arcticlocsTP2 <- filter(arcticlocs, year >= 1980 & year < 2021)

obsTP1 <- length(arcticlocsTP1$genus)
obsTP2 <- length(arcticlocsTP2$genus)

lengthsofobs <- c(obsTP1, obsTP2)

#Time period 1
arcticlocsTP1sum <- plyr::count(arcticlocsTP1, 'genus')
arcticlocsTP1unitnum <- length(arcticlocsTP1$genus)
arcticlocsTP1V <- c(arcticlocsTP1unitnum, arcticlocsTP1sum$freq)
arcticlocsTP1Vn <- as.numeric(arcticlocsTP1V)

#Time period 2
arcticlocsTP2sum <- plyr::count(arcticlocsTP2, 'genus')
arcticlocsTP2unitnum <- length(arcticlocsTP2$genus)
arcticlocsTP2V <- c(arcticlocsTP2unitnum, arcticlocsTP2sum$freq)
arcticlocsTP2Vn <- as.numeric(arcticlocsTP2V)

arctic <- list("TimePeriod1" = arcticlocsTP1Vn,
               "TimePeriod2" = arcticlocsTP2Vn)

str(arctic)
```

Now, our data consists of two lists - one for time period one and one describing time period two. Let's run our analyses. Note that ggiNEXT is a wrapper for the standard ggplot function, and can be manipulated just like ggplot.

```{r}
#establish the max extrapolation number (two times the largest sample) and the knots manually
maxrun <- (max(obsTP1, obsTP2)*2)
t <- seq(1, maxrun, by=1)

out.inc <- iNEXT(arctic,  q=c(0,1,2), datatype="incidence_freq", size=t, nboot=200)

arcticfigure <- ggiNEXT(out.inc, facet.var="Order.q", se =TRUE, grey = TRUE) + ylab("Generic diversity") + ggtitle("Arctic cordillera") + theme_bw() + 
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)); arcticfigure
```

Wonderful! You've transformed your data into the iNEXT format according to your data type. Now, work through an example with your own data! Put your data into the correct format based on your data, and analyze away. 







